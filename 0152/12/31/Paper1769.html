<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>HRENet: A Hard Region Enhancement Network for Polyp Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="HRENet: A Hard Region Enhancement Network for Polyp Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yutian Shen, Xiao Jia, Max Q.-H. Meng Abstract Automatic polyp segmentation in the screening system is of great practical significance for the diagnosis and treatment of colorec- tal cancer. However, accurate segmentation in the colonoscopy images still remains a challenge. In this paper, we propose a hard region en- hancement network (HRENet) based on an encoder-decoder framework. Specifically, we design an informative context enhancement (ICE) mod- ule to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. We also develop an adaptive fea- ture aggregation (AFA) module to select and aggregate the features from multiple semantic levels. In addition, we train the model with a proposed edge and structure consistency aware loss (ESCLoss) to further boost the performance. Extensive experiments on three public datasets show that our proposed algorithm outperforms the state-of-the-art approaches in terms of both learning ability and generalization capability. In particu- lar, our HRENet achieves a mIoU of 92.11% and a Dice of 92.56% on Kvasir-SEG dataset. And the model trained with Kvasir-SEG and CVC- Clinic DB retains a high inference performance on the unseen dataset CVC-Colon DB with a mIoU of 88.42% and a Dice of 85.26%. The code is available at: https://github.com/CathySH/HRENet. Link to paper https://doi.org/10.1007/978-3-030-87193-2_53 Link to the code repository https://github.com/CathySH/HRENet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper -The authors utilizing the hard region attention map to generate the grid, which is utilized to resample and enhance features. -Moreover, an edge loss is proposed to persevere the consistency of the prediction of object boundary. -Achieve sota performance on three benchmark datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting idea to enhance feature by sampling the feature of the hard region. Comprehensive experiments Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The idea of this paper is very similar to the following paper: [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) there are two main differences: 1) how to construct the input of grid generator, in paper [1], important regions are utilized to generate grid, and in this paper, authors adopt the hard region for grid generation. It should be noted that the “easy” regions may also be important, and undersampling them may lose critical information. 2) paper[1] implements image-level resampling while in this paper, authors conduct feature-level resampling, the author should compare and discuss their difference, moreover, in the section of the experiment, it will be better if the authors can provide the results of the paper [1], since they have high-similarity task attribute and this paper derived from it). The novelty of adaptive feature aggregation seems limited, which is simply combined by a non-local operation, a deformable conv, and a se block. The edge loss has been explored in many medical segmentation tasks, however, the author did not cite/discuss/compare with them. As a contribution of the paper, authors should make full discussion and comparison. The author should provide quantitive metrics such as parameters/flops to make a fair comparison with other methods. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Yes, I think it can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to “list the main weaknesses of the paper” Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper borrows too much from paper [1], but does not discuss and compared with the paper. Besides, the novelty of the AFA module and edge loss is limited. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A deep learning polyp segmentation method is proposed. The method mainly includes three contributions (1) an informative context enhancement (ICE) module where the mapping is based on [15], (2) an adaptive feature aggregation (AFA) module, and (3) the structure consistency aware loss (ESCLoss). Experiment results demonstrate the effectiveness of the proposed method. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed method target on exploring features on the hard region for a better polyp segmentation. For this purpose, the authors combine the ICE, AFA and ESCLoss. The idea is well motivated and the experimental results prove the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While it is interesting, I notice that the ESCLoss is a combination of BCE, Dice, edge penalty loss (the focal loss), and SSIM based structure loss. No further discussion about the effectiveness of each part of the loss. Moreover, how to choose the weights between those losses. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducibility Response is good. The authors list the detailed information point to point on the list. Public datasets are used and the authors will provide the code and pre-trained model. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be nice to investigate more about how to combine those losses (BCE, Dice, focal loss, structure loss) and the necessary/effectiveness of them in future work. Minor: Please add the unit (%) of the reported results in Tables. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is interesting and well explained. Extensive experiments including comparison with SOTA methods and ablation studies, on suitable public datasets show the effectiveness of the idea. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Authors propose a hard region enhancement network (HRENet) based on an encoder-decoder framework. The contributions can be summarized into three aspects. Firstly, an informative context enhancement (ICE) module is designed to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. Secondly, an adaptive feature aggregation (AFA) module is developed to select and aggregate the features from multiple semantic levels. Thirdly, the segmentation model is optimized with a proposed edge and structure consistency aware loss (ESCLoss). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Although the proposed ICE borrows the idea from [15], it is a smart way to enhance the features from the lower-level encoder with explicit attention on hard regions, so as to improve the polyp segmentation performance in uncertain regions. AFA is developed to aggregate features from different semantic levels, including the enhanced features of ICE module and those passed from encoder and the previous decoder block. The proposed edge and structure consistency aware loss is a hybrid objective function to optimize the proposed HRENet, where the proposed structure consistency loss is somewhat novel and aims at adapting HRENet to different scales. Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. HRENet is proposed for enhancing the polyp segmentation performance in uncertain regions. It should be compared with other data hard sample mining methods, such as focal loss etc. The proposed AFA module is a combination of state-of-the-art components, including self-attention module [19], deformable convolution [4] and SE attention, but the last one has not been cited in the manuscript. The word `Down-concatenations’ only appears in experiment section, which should also be mentioned in methodology part. It is not clear whether the Lds should be calculate if ablating ICE module. I wonder whether the contribution of ICE module is owing to the introduced deep supervision loss. [*1] Hu, Jie, Li Shen, and Gang Sun. “Squeeze-and-excitation networks.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2018. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Moreover, the source code will be published, which is a positive aspect of this paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It is better for authors to provide the computational resource demands, including training time, inference time and the number of trainable parameters. Because there is a concern that the proposed ICE and AFA modules will introduce large number of parameters, and whether the proposed method could achieve real-time segmentation that is of high importance in clinical practice. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I gave the overall score mainly considering the novelty of paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposed a hard region enhancement network for polyp segmentation. An information context enhancement (ICE) module on hard regions, an adaptive feature aggregation module and edge &amp; structure consistency are combined to achieve good performance over three benchmark datasets. The reviewers raised several concerns, including comparison with other sample mining method (especially the paper Recasens et al. ECCV 2018 R1 mentioned), unclear contribution of ICE module, further discussion on the different parts of loss, etc. Overall, the reviewers gave all positive comments. Therefore, a decision of provisonal accept is recommended. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback As introduced in the paper, the ICE module is implemented to complement the features for each decoder block to improve the segmentation. Features from encoder block and the previous decoder block can be utilized to segment so-called “easy” regions, and the ICE module mainly provides information for difficult-to-classify pixels identified from the decoder feature and a grid is generated to guide the corresponding feature-level resampling. While in paper [1], a saliency map is generated from a low-resolution version of the input image to guide the image-level resampling for task like fine-grained object classification. The effectiveness of each part of the combined loss had been examined. For example, the HRE model trained with only supervision loss achieves a mIoU of 91.45% and a Dice of 91.60%, which is lower than the model with combined loss showing the effectiveness. Meanwhile, several kinds of losses have been examined and the performance is not that satisfied compared with current model. Due to the page limit, I didn’t give these experimental result. As for the weight chosen for different parts of the combined loss, I hadn’t conducted experiments about these weight parameters. These will be further investigated in the future work. Many thanks to all the reviewers for their helpful suggestions. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yutian Shen, Xiao Jia, Max Q.-H. Meng Abstract Automatic polyp segmentation in the screening system is of great practical significance for the diagnosis and treatment of colorec- tal cancer. However, accurate segmentation in the colonoscopy images still remains a challenge. In this paper, we propose a hard region en- hancement network (HRENet) based on an encoder-decoder framework. Specifically, we design an informative context enhancement (ICE) mod- ule to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. We also develop an adaptive fea- ture aggregation (AFA) module to select and aggregate the features from multiple semantic levels. In addition, we train the model with a proposed edge and structure consistency aware loss (ESCLoss) to further boost the performance. Extensive experiments on three public datasets show that our proposed algorithm outperforms the state-of-the-art approaches in terms of both learning ability and generalization capability. In particu- lar, our HRENet achieves a mIoU of 92.11% and a Dice of 92.56% on Kvasir-SEG dataset. And the model trained with Kvasir-SEG and CVC- Clinic DB retains a high inference performance on the unseen dataset CVC-Colon DB with a mIoU of 88.42% and a Dice of 85.26%. The code is available at: https://github.com/CathySH/HRENet. Link to paper https://doi.org/10.1007/978-3-030-87193-2_53 Link to the code repository https://github.com/CathySH/HRENet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper -The authors utilizing the hard region attention map to generate the grid, which is utilized to resample and enhance features. -Moreover, an edge loss is proposed to persevere the consistency of the prediction of object boundary. -Achieve sota performance on three benchmark datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting idea to enhance feature by sampling the feature of the hard region. Comprehensive experiments Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The idea of this paper is very similar to the following paper: [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) there are two main differences: 1) how to construct the input of grid generator, in paper [1], important regions are utilized to generate grid, and in this paper, authors adopt the hard region for grid generation. It should be noted that the “easy” regions may also be important, and undersampling them may lose critical information. 2) paper[1] implements image-level resampling while in this paper, authors conduct feature-level resampling, the author should compare and discuss their difference, moreover, in the section of the experiment, it will be better if the authors can provide the results of the paper [1], since they have high-similarity task attribute and this paper derived from it). The novelty of adaptive feature aggregation seems limited, which is simply combined by a non-local operation, a deformable conv, and a se block. The edge loss has been explored in many medical segmentation tasks, however, the author did not cite/discuss/compare with them. As a contribution of the paper, authors should make full discussion and comparison. The author should provide quantitive metrics such as parameters/flops to make a fair comparison with other methods. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Yes, I think it can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to “list the main weaknesses of the paper” Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper borrows too much from paper [1], but does not discuss and compared with the paper. Besides, the novelty of the AFA module and edge loss is limited. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A deep learning polyp segmentation method is proposed. The method mainly includes three contributions (1) an informative context enhancement (ICE) module where the mapping is based on [15], (2) an adaptive feature aggregation (AFA) module, and (3) the structure consistency aware loss (ESCLoss). Experiment results demonstrate the effectiveness of the proposed method. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed method target on exploring features on the hard region for a better polyp segmentation. For this purpose, the authors combine the ICE, AFA and ESCLoss. The idea is well motivated and the experimental results prove the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While it is interesting, I notice that the ESCLoss is a combination of BCE, Dice, edge penalty loss (the focal loss), and SSIM based structure loss. No further discussion about the effectiveness of each part of the loss. Moreover, how to choose the weights between those losses. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducibility Response is good. The authors list the detailed information point to point on the list. Public datasets are used and the authors will provide the code and pre-trained model. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be nice to investigate more about how to combine those losses (BCE, Dice, focal loss, structure loss) and the necessary/effectiveness of them in future work. Minor: Please add the unit (%) of the reported results in Tables. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is interesting and well explained. Extensive experiments including comparison with SOTA methods and ablation studies, on suitable public datasets show the effectiveness of the idea. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Authors propose a hard region enhancement network (HRENet) based on an encoder-decoder framework. The contributions can be summarized into three aspects. Firstly, an informative context enhancement (ICE) module is designed to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. Secondly, an adaptive feature aggregation (AFA) module is developed to select and aggregate the features from multiple semantic levels. Thirdly, the segmentation model is optimized with a proposed edge and structure consistency aware loss (ESCLoss). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Although the proposed ICE borrows the idea from [15], it is a smart way to enhance the features from the lower-level encoder with explicit attention on hard regions, so as to improve the polyp segmentation performance in uncertain regions. AFA is developed to aggregate features from different semantic levels, including the enhanced features of ICE module and those passed from encoder and the previous decoder block. The proposed edge and structure consistency aware loss is a hybrid objective function to optimize the proposed HRENet, where the proposed structure consistency loss is somewhat novel and aims at adapting HRENet to different scales. Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. HRENet is proposed for enhancing the polyp segmentation performance in uncertain regions. It should be compared with other data hard sample mining methods, such as focal loss etc. The proposed AFA module is a combination of state-of-the-art components, including self-attention module [19], deformable convolution [4] and SE attention, but the last one has not been cited in the manuscript. The word `Down-concatenations’ only appears in experiment section, which should also be mentioned in methodology part. It is not clear whether the Lds should be calculate if ablating ICE module. I wonder whether the contribution of ICE module is owing to the introduced deep supervision loss. [*1] Hu, Jie, Li Shen, and Gang Sun. “Squeeze-and-excitation networks.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2018. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Moreover, the source code will be published, which is a positive aspect of this paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It is better for authors to provide the computational resource demands, including training time, inference time and the number of trainable parameters. Because there is a concern that the proposed ICE and AFA modules will introduce large number of parameters, and whether the proposed method could achieve real-time segmentation that is of high importance in clinical practice. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I gave the overall score mainly considering the novelty of paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposed a hard region enhancement network for polyp segmentation. An information context enhancement (ICE) module on hard regions, an adaptive feature aggregation module and edge &amp; structure consistency are combined to achieve good performance over three benchmark datasets. The reviewers raised several concerns, including comparison with other sample mining method (especially the paper Recasens et al. ECCV 2018 R1 mentioned), unclear contribution of ICE module, further discussion on the different parts of loss, etc. Overall, the reviewers gave all positive comments. Therefore, a decision of provisonal accept is recommended. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback As introduced in the paper, the ICE module is implemented to complement the features for each decoder block to improve the segmentation. Features from encoder block and the previous decoder block can be utilized to segment so-called “easy” regions, and the ICE module mainly provides information for difficult-to-classify pixels identified from the decoder feature and a grid is generated to guide the corresponding feature-level resampling. While in paper [1], a saliency map is generated from a low-resolution version of the input image to guide the image-level resampling for task like fine-grained object classification. The effectiveness of each part of the combined loss had been examined. For example, the HRE model trained with only supervision loss achieves a mIoU of 91.45% and a Dice of 91.60%, which is lower than the model with combined loss showing the effectiveness. Meanwhile, several kinds of losses have been examined and the performance is not that satisfied compared with current model. Due to the page limit, I didn’t give these experimental result. As for the weight chosen for different parts of the combined loss, I hadn’t conducted experiments about these weight parameters. These will be further investigated in the future work. Many thanks to all the reviewers for their helpful suggestions. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0152/12/31/Paper1769" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0152/12/31/Paper1769" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0152-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="HRENet: A Hard Region Enhancement Network for Polyp Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0152/12/31/Paper1769"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0152/12/31/Paper1769","headline":"HRENet: A Hard Region Enhancement Network for Polyp Segmentation","dateModified":"0152-12-31T00:00:00-05:17","datePublished":"0152-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Yutian Shen, Xiao Jia, Max Q.-H. Meng Abstract Automatic polyp segmentation in the screening system is of great practical significance for the diagnosis and treatment of colorec- tal cancer. However, accurate segmentation in the colonoscopy images still remains a challenge. In this paper, we propose a hard region en- hancement network (HRENet) based on an encoder-decoder framework. Specifically, we design an informative context enhancement (ICE) mod- ule to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. We also develop an adaptive fea- ture aggregation (AFA) module to select and aggregate the features from multiple semantic levels. In addition, we train the model with a proposed edge and structure consistency aware loss (ESCLoss) to further boost the performance. Extensive experiments on three public datasets show that our proposed algorithm outperforms the state-of-the-art approaches in terms of both learning ability and generalization capability. In particu- lar, our HRENet achieves a mIoU of 92.11% and a Dice of 92.56% on Kvasir-SEG dataset. And the model trained with Kvasir-SEG and CVC- Clinic DB retains a high inference performance on the unseen dataset CVC-Colon DB with a mIoU of 88.42% and a Dice of 85.26%. The code is available at: https://github.com/CathySH/HRENet. Link to paper https://doi.org/10.1007/978-3-030-87193-2_53 Link to the code repository https://github.com/CathySH/HRENet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper -The authors utilizing the hard region attention map to generate the grid, which is utilized to resample and enhance features. -Moreover, an edge loss is proposed to persevere the consistency of the prediction of object boundary. -Achieve sota performance on three benchmark datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting idea to enhance feature by sampling the feature of the hard region. Comprehensive experiments Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The idea of this paper is very similar to the following paper: [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) there are two main differences: 1) how to construct the input of grid generator, in paper [1], important regions are utilized to generate grid, and in this paper, authors adopt the hard region for grid generation. It should be noted that the “easy” regions may also be important, and undersampling them may lose critical information. 2) paper[1] implements image-level resampling while in this paper, authors conduct feature-level resampling, the author should compare and discuss their difference, moreover, in the section of the experiment, it will be better if the authors can provide the results of the paper [1], since they have high-similarity task attribute and this paper derived from it). The novelty of adaptive feature aggregation seems limited, which is simply combined by a non-local operation, a deformable conv, and a se block. The edge loss has been explored in many medical segmentation tasks, however, the author did not cite/discuss/compare with them. As a contribution of the paper, authors should make full discussion and comparison. The author should provide quantitive metrics such as parameters/flops to make a fair comparison with other methods. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Yes, I think it can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to “list the main weaknesses of the paper” Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper borrows too much from paper [1], but does not discuss and compared with the paper. Besides, the novelty of the AFA module and edge loss is limited. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A deep learning polyp segmentation method is proposed. The method mainly includes three contributions (1) an informative context enhancement (ICE) module where the mapping is based on [15], (2) an adaptive feature aggregation (AFA) module, and (3) the structure consistency aware loss (ESCLoss). Experiment results demonstrate the effectiveness of the proposed method. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed method target on exploring features on the hard region for a better polyp segmentation. For this purpose, the authors combine the ICE, AFA and ESCLoss. The idea is well motivated and the experimental results prove the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While it is interesting, I notice that the ESCLoss is a combination of BCE, Dice, edge penalty loss (the focal loss), and SSIM based structure loss. No further discussion about the effectiveness of each part of the loss. Moreover, how to choose the weights between those losses. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducibility Response is good. The authors list the detailed information point to point on the list. Public datasets are used and the authors will provide the code and pre-trained model. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be nice to investigate more about how to combine those losses (BCE, Dice, focal loss, structure loss) and the necessary/effectiveness of them in future work. Minor: Please add the unit (%) of the reported results in Tables. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is interesting and well explained. Extensive experiments including comparison with SOTA methods and ablation studies, on suitable public datasets show the effectiveness of the idea. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Authors propose a hard region enhancement network (HRENet) based on an encoder-decoder framework. The contributions can be summarized into three aspects. Firstly, an informative context enhancement (ICE) module is designed to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. Secondly, an adaptive feature aggregation (AFA) module is developed to select and aggregate the features from multiple semantic levels. Thirdly, the segmentation model is optimized with a proposed edge and structure consistency aware loss (ESCLoss). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Although the proposed ICE borrows the idea from [15], it is a smart way to enhance the features from the lower-level encoder with explicit attention on hard regions, so as to improve the polyp segmentation performance in uncertain regions. AFA is developed to aggregate features from different semantic levels, including the enhanced features of ICE module and those passed from encoder and the previous decoder block. The proposed edge and structure consistency aware loss is a hybrid objective function to optimize the proposed HRENet, where the proposed structure consistency loss is somewhat novel and aims at adapting HRENet to different scales. Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. HRENet is proposed for enhancing the polyp segmentation performance in uncertain regions. It should be compared with other data hard sample mining methods, such as focal loss etc. The proposed AFA module is a combination of state-of-the-art components, including self-attention module [19], deformable convolution [4] and SE attention, but the last one has not been cited in the manuscript. The word `Down-concatenations’ only appears in experiment section, which should also be mentioned in methodology part. It is not clear whether the Lds should be calculate if ablating ICE module. I wonder whether the contribution of ICE module is owing to the introduced deep supervision loss. [*1] Hu, Jie, Li Shen, and Gang Sun. “Squeeze-and-excitation networks.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2018. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Moreover, the source code will be published, which is a positive aspect of this paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It is better for authors to provide the computational resource demands, including training time, inference time and the number of trainable parameters. Because there is a concern that the proposed ICE and AFA modules will introduce large number of parameters, and whether the proposed method could achieve real-time segmentation that is of high importance in clinical practice. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I gave the overall score mainly considering the novelty of paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposed a hard region enhancement network for polyp segmentation. An information context enhancement (ICE) module on hard regions, an adaptive feature aggregation module and edge &amp; structure consistency are combined to achieve good performance over three benchmark datasets. The reviewers raised several concerns, including comparison with other sample mining method (especially the paper Recasens et al. ECCV 2018 R1 mentioned), unclear contribution of ICE module, further discussion on the different parts of loss, etc. Overall, the reviewers gave all positive comments. Therefore, a decision of provisonal accept is recommended. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback As introduced in the paper, the ICE module is implemented to complement the features for each decoder block to improve the segmentation. Features from encoder block and the previous decoder block can be utilized to segment so-called “easy” regions, and the ICE module mainly provides information for difficult-to-classify pixels identified from the decoder feature and a grid is generated to guide the corresponding feature-level resampling. While in paper [1], a saliency map is generated from a low-resolution version of the input image to guide the image-level resampling for task like fine-grained object classification. The effectiveness of each part of the combined loss had been examined. For example, the HRE model trained with only supervision loss achieves a mIoU of 91.45% and a Dice of 91.60%, which is lower than the model with combined loss showing the effectiveness. Meanwhile, several kinds of losses have been examined and the performance is not that satisfied compared with current model. Due to the page limit, I didn’t give these experimental result. As for the weight chosen for different parts of the combined loss, I hadn’t conducted experiments about these weight parameters. These will be further investigated in the future work. Many thanks to all the reviewers for their helpful suggestions. [1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018) back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Shen, Yutian,Jia, Xiao,Meng, Max Q.-H." />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>HRENet: A Hard Region Enhancement Network for Polyp Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Oncology"
        class="post-category">
        Clinical applications - Oncology
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Shen, Yutian"
        class="post-tags">
        Shen, Yutian
      </a> |  
      
      <a href="kittywong/tags#Jia, Xiao"
        class="post-tags">
        Jia, Xiao
      </a> |  
      
      <a href="kittywong/tags#Meng, Max Q.-H."
        class="post-tags">
        Meng, Max Q.-H.
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Yutian Shen, Xiao Jia, Max Q.-H. Meng
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Automatic polyp segmentation in the screening system is of great practical significance for the diagnosis and treatment of colorec- tal cancer. However, accurate segmentation in the colonoscopy images still remains a challenge. In this paper, we propose a hard region en- hancement network (HRENet) based on an encoder-decoder framework. Specifically, we design an informative context enhancement (ICE) mod- ule to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. We also develop an adaptive fea- ture aggregation (AFA) module to select and aggregate the features from multiple semantic levels. In addition, we train the model with a proposed edge and structure consistency aware loss (ESCLoss) to further boost the performance. Extensive experiments on three public datasets show that our proposed algorithm outperforms the state-of-the-art approaches in terms of both learning ability and generalization capability. In particu- lar, our HRENet achieves a mIoU of 92.11% and a Dice of 92.56% on Kvasir-SEG dataset. And the model trained with Kvasir-SEG and CVC- Clinic DB retains a high inference performance on the unseen dataset CVC-Colon DB with a mIoU of 88.42% and a Dice of 85.26%. The code is available at: https://github.com/CathySH/HRENet.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87193-2_53">https://doi.org/10.1007/978-3-030-87193-2_53</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/CathySH/HRENet
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>-The authors utilizing the hard region attention map to generate the grid, which is utilized to resample and enhance features. 
-Moreover, an edge loss is proposed to persevere the consistency of the prediction of object boundary.
-Achieve sota performance on three benchmark datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Interesting idea to enhance feature by sampling the feature of the hard region.
Comprehensive experiments</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>The idea of this paper is very similar to the following paper:
[1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018)
there are two main differences: 1) how to construct the input of grid generator, in paper [1], important regions are utilized to generate grid, and in this paper, authors adopt the hard region for grid generation. It should be noted that the “easy” regions may also be important, and undersampling them may lose critical information. 2) paper[1] implements image-level resampling while in this paper, authors conduct feature-level resampling, the author should compare and discuss their difference, moreover, in the section of the experiment, it will be better if the authors can provide the results of the paper [1], since they have high-similarity task attribute and this paper derived from it).</li>
        <li>The novelty of adaptive feature aggregation seems limited, which is simply combined by a non-local operation, a deformable conv, and a se block.</li>
        <li>The edge loss has been explored in many medical segmentation tasks, however, the author did not cite/discuss/compare with them. As a contribution of the paper, authors should make full discussion and comparison.</li>
        <li>The author should provide quantitive metrics such as parameters/flops to make a fair comparison with other methods.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Yes, I think it can be reproduced</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please refer to “list the main weaknesses of the paper”</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ol>
        <li>The paper borrows too much from paper [1], but does not discuss and compared with the paper. Besides, the novelty of the AFA module and edge loss is limited.</li>
      </ol>

      <p>[1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018)</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>A deep learning polyp segmentation method is proposed. The method mainly includes three contributions (1) an informative context enhancement (ICE) module where the mapping is based on [15], (2) an adaptive feature aggregation (AFA) module, and (3) the structure consistency aware loss (ESCLoss). Experiment results demonstrate the effectiveness of the proposed method.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The proposed method target on exploring features on the hard region for a better polyp segmentation. For this purpose, the authors combine the ICE, AFA and ESCLoss. The idea is well motivated and the experimental results prove the idea.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>While it is interesting, I notice that the ESCLoss is a combination of BCE, Dice, edge penalty loss (the focal loss), and SSIM based structure loss. No further discussion about the effectiveness of each part of the loss. Moreover, how to choose the weights between those losses.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Reproducibility Response is good. The authors list the detailed information point to point on the list. Public datasets are used and the authors will provide the code and pre-trained model.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>It would be nice to investigate more about how to combine those losses (BCE, Dice, focal loss, structure loss) and the necessary/effectiveness of them in future work.</p>

      <p>Minor:
Please add the unit (%) of the reported results in Tables.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The proposed method is interesting and well explained. Extensive experiments including comparison with SOTA methods and ablation studies, on suitable public datasets show the effectiveness of the idea.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>Authors propose a hard region enhancement network (HRENet) based on an encoder-decoder framework. The contributions can be summarized into three aspects. Firstly, an informative context enhancement (ICE) module is designed to explore and intensify the features from the lower-level encoder with explicit attention on hard regions. Secondly, an adaptive feature aggregation (AFA) module is developed to select and aggregate the features from multiple semantic levels. Thirdly, the segmentation model is optimized with a proposed edge and structure consistency aware loss (ESCLoss).</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>Although the proposed ICE borrows the idea from [15], it is a smart way to enhance the features from the lower-level encoder with explicit attention on hard regions, so as to improve the polyp segmentation performance in uncertain regions.</li>
        <li>AFA is developed to aggregate features from different semantic levels, including the enhanced features of ICE module and those passed from encoder and the previous decoder block.</li>
        <li>The proposed edge and structure consistency aware loss is a hybrid objective function to optimize the proposed HRENet, where the proposed structure consistency loss is somewhat novel and aims at adapting HRENet to different scales.</li>
        <li>Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>HRENet is proposed for enhancing the polyp segmentation performance in uncertain regions. It should be compared with other data hard sample mining methods, such as focal loss etc.</li>
        <li>The proposed AFA module is a combination of state-of-the-art components, including self-attention module [19], deformable convolution [4] and SE attention, but the last one has not been cited in the manuscript.</li>
        <li>The word `Down-concatenations’ only appears in experiment section, which should also be mentioned in methodology part.</li>
        <li>It is not clear whether the Lds should be calculate if ablating ICE module. I wonder whether the contribution of ICE module is owing to the introduced deep supervision loss.</li>
      </ul>

      <p>[*1] Hu, Jie, Li Shen, and Gang Sun. “Squeeze-and-excitation networks.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Authors utilize three benchmark datasets to evaluate the proposed method, and the comprehensive experiments are convincing. Moreover, the source code will be published, which is a positive aspect of this paper.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>It is better for authors to provide the computational resource demands, including training time, inference time and the number of trainable parameters. Because there is a concern that the proposed ICE and AFA modules will introduce large number of parameters, and whether the proposed method could achieve real-time segmentation that is of high importance in clinical practice.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>I gave the overall score mainly considering the novelty of paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper proposed a hard region enhancement network for polyp segmentation. An information context enhancement (ICE) module on hard regions, an adaptive feature aggregation module and edge &amp; structure consistency are combined to achieve good performance over three benchmark datasets. The reviewers raised several concerns, including comparison with other sample mining method (especially the paper Recasens et al. ECCV 2018 R1 mentioned), unclear contribution of ICE module, further discussion on the different parts of loss, etc. Overall, the reviewers gave all positive comments. Therefore, a decision of provisonal accept is recommended.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <ol>
    <li>As introduced in the paper, the ICE module is implemented to complement the features for each decoder block to improve the segmentation. Features from encoder block and the previous decoder block can be utilized to segment so-called “easy” regions, and the ICE module mainly provides information for difficult-to-classify pixels identified from the decoder feature and a grid is generated to guide the corresponding feature-level resampling. While in paper [1], a saliency map is generated from a low-resolution version of the input image to guide the image-level resampling for task like fine-grained object classification.</li>
    <li>The effectiveness of each part of the combined loss had been examined. For example, the HRE model trained with only supervision loss achieves a mIoU of 91.45% and a Dice of 91.60%, which is lower than the model with combined loss showing the effectiveness. Meanwhile, several kinds of losses have been examined and the performance is not that satisfied compared with current model. Due to the page limit, I didn’t give these experimental result. As for the weight chosen for different parts of the combined loss, I hadn’t conducted experiments about these weight parameters. These will be further investigated in the future work.</li>
    <li>Many thanks to all the reviewers for their helpful suggestions.
[1] Recasens, A., Kellnhofer, P., Stent, S., Matusik, W., Torralba, A.: Learning to zoom: a saliency-based sampling layer for neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 51–66 (2018)</li>
  </ol>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0152-12-31
      -->
      <!--
      
        ,
        updated at 
        0153-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Oncology"
        class="post-category">
        Clinical applications - Oncology
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Shen, Yutian"
        class="post-category">
        Shen, Yutian
      </a> |  
      
      <a href="kittywong/tags#Jia, Xiao"
        class="post-category">
        Jia, Xiao
      </a> |  
      
      <a href="kittywong/tags#Meng, Max Q.-H."
        class="post-category">
        Meng, Max Q.-H.
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0153/12/31/Paper1857">
          A Novel Hybrid Convolutional Neural Network for Accurate Organ Segmentation in 3D Head and Neck CT Images
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0151/12/31/Paper1688">
          3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
