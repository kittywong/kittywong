<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>RLP-Net: Recursive Light Propagation Network for 3-D Virtual Refocusing | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="RLP-Net: Recursive Light Propagation Network for 3-D Virtual Refocusing" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Changyeop Shin, Hyun Ryu, Eun-Seo Cho, Young-Gyu Yoon Abstract High-speed optical 3-D fluorescence microscopy is an essential tool for capturing the rapid dynamics of biological systems such as cellular signaling and complex movements. Designing such an optical system is constrained by the inherent trade-off among resolution, speed, and noise which comes from the limited number of photons that can be collected. In this paper, we propose a recursive light propagation network (RLP-Net) that infers the 3-D volume from two adjacent 2-D wide-field fluorescence images via virtual refocusing. Specifically, we propose a recursive inference scheme in which the network progressively predicts the subsequent planes along the axial direction. This recursive inference scheme reflects that the law of physics for the light propagation remains spatially invariant and therefore a fixed function (i.e., a neural network) for a short distance light propagation can be recursively applied for a longer distance light propagation. Experimental results show that the proposed method can faithfully reconstruct the 3-D volume from two planes in terms of both quantitative measures and visual quality. The source code used in the paper is available at https://github.com/NICALab/rlpnet. Link to paper https://doi.org/10.1007/978-3-030-87231-1_18 Link to the code repository https://github.com/NICALab/rlpnet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper addresses the problem of virtual refocusing in light microscopy, i.e. reconstructing a volumetric 3D image from only a single/two adjacent acquired image planes. Specifically the authors propose to recursively apply an appropriately trained network that propagates the intensity image to the next intensity image along the optical axis. The proposes method uses several loss components that are motivated by the physical properties of light propagation. The authors finally evaluate their method on two datasets and demonstrate the superiority compared to another state-of-the art method for virtual refocusing. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. very well written and clearly described sound experiments and superior performance compared to another state-of-the art method Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. physical model of light propagation is not entirely correct code not available to the public Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was available to the reviewer. Datasets (and code) seems not to be available to the public Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. Of course there are clear correlations between adjacent image planes especially for epifluorescence imaging where the PSF essentially “extends into infinity”. But for other modalities that include optical sectioning (confocal, spinning disk, light sheet) the assumed properties of light propagation don’t hold (e.g. for an infinitely thin light sheet, there are no correlations between adjacent image planes due to “light propagation” only correlations from the imaged structures). So might be worth commenting on that. In the equation for the cycle loss, how is “back-propagating” by -l implemented? Reversing the two adjacent images I_k, I_k+1 ? More details regarding that would be helpful. In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? Making the code available to the public would increase the impact of the paper Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A generally well written paper with a clear idea and sound execution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors present a recursive neural network to approximate light propagation and estimate a 3D volume from 2D sections imaged by fluorescence (wide-field) microscopy. The authors derive their network from first principles of light propagation (which is great). The approach is validated using bead samples and images of C elegans specimen and qualitatively and quantitatively compared to a state-of-the-art approach (Deep Z). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The neural network design is derived in a principled way, which is a great strength of this work compared to many papers I have seen. The application of this method is very interesting and important for many types of live microscopy experiments. The methods and the motivation are well explained and discussed. I enjoyed reading this paper. The validation is sound and the results are convincing to me. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I actually do not find a major weakness here. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I haven’t tried, but I am confident, that we could reproduce the results. The method is well explained and the code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I enjoyed reading this paper. Great work! Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper describes an interesting application and it is one of the few papers that use a solid, clear approach when designing the neural network to solve this particular task. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces RLP-Net for 3D virtual refocusing, where two adjacent 2D fluorescence images are adopted for learning light propagation in a recursive manner. Both quantitative and qualitative experiments are provided. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The overall method is clear and technically sound. The motivations of recursive light propagation from two 2-D images are provided. The ablation study of memory module is well conducted. Paper is well organized and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The comparison is not fair enough. The Deep-Z method is not a strong baseline. Technically speaking, The Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. Thus, it is not so surprising that RLP-Net outperforms Deep-Z by a large margin. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code is provided but has not been carefully checked. I believe it is not difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to the weaknesses listed above. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, I lean to recommend acceptance due to the promising method and good writing. However, the authors are encouraged to clarify the cost of RLP-Net, in terms of the data acquisition and network computation. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers unanimously recommend acceptance. The topic and proposed approach are interesting, the results are promising, and the paper is very well written. One reviewer is concerned about the correctness of the physical model of light propagation, and another about the fairness of the chosen baseline for comparison. These issues, in addition to several others pointed out by the reviewers, need to be clarified in the revision. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers for their positive assessment and constructive comments. Below is our response to the major comments. Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. A: We agree that our light propagation model does not hold for optical sectioning methods, which is why we set our goal as ‘to infer the volume from wide-field fluorescence images.’ To avoid any potential confusion, we will revise the manuscript to clarify that our method is not compatible with optical sectioning methods. However, we would like to rebut the statement of the reviewer that single light field propagating through free space does not suffice to describe fluorescent light propagation. Fluorescent light is indeed incoherent, as the reviewer pointed out, and thus can be described as a 4-D light-field, which allows digital refocusing of light-field microscopy images (Levoy et al, 2006) – albeit at limited resolution due to limited sampling density. How is “back-propagating” by -l implemented? A: The concatenation order of two input images determines the inference direction as explained in the Section 2.1. For example, the network infers I_{k+2} if the input is (I_k, I_{k+1}) and infers I_{k-1} if the input is (I_{k+1}, I_k) In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? A: We speculate that unexpected change of PSNR as a function of propagation distance stems from the sparsity of the beads in space. Due to the sparsity, some planes include sharply focused beads whereas others don’t, which manifest itself as varying level of difficulties in predicting different planes. Making the code available to the public would increase the impact of the paper A: We agree with the reviewer’s thought and plan to include the link to our github repository (which is already ready) in the final submission. Comparison for the RLP-Net (taking two input images) and Deep-Z (taking single input image) is not fair enough as Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. A: We agree that utilizing two images gives an advantage to RLP-Net. To compensate for the disadvantage, we computed Deep-Z output using two input images, independently, and then took the average as the prediction as described in Section 3. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? A: The performance of RLP-Net indeed comes with a cost. Presuming a fast axial scanning method such as electrically tunable lens, taking two images that are axially nearby takes twice as long compared to taking one image. RLP-Net took approximately 0.1 second for a single volume inferencing whereas Deep-Z took about 0.08 second for an input image with 128 × 128 pixels. We will clarify this in the revised version of manuscript. The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. A: We agree that understanding failure cases is important and will discuss that in the revised version of the manuscript. We would like to mention that, if the sample moves too fast to take two images, it would not be possible to take a 3-D image at all with a conventional method. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Changyeop Shin, Hyun Ryu, Eun-Seo Cho, Young-Gyu Yoon Abstract High-speed optical 3-D fluorescence microscopy is an essential tool for capturing the rapid dynamics of biological systems such as cellular signaling and complex movements. Designing such an optical system is constrained by the inherent trade-off among resolution, speed, and noise which comes from the limited number of photons that can be collected. In this paper, we propose a recursive light propagation network (RLP-Net) that infers the 3-D volume from two adjacent 2-D wide-field fluorescence images via virtual refocusing. Specifically, we propose a recursive inference scheme in which the network progressively predicts the subsequent planes along the axial direction. This recursive inference scheme reflects that the law of physics for the light propagation remains spatially invariant and therefore a fixed function (i.e., a neural network) for a short distance light propagation can be recursively applied for a longer distance light propagation. Experimental results show that the proposed method can faithfully reconstruct the 3-D volume from two planes in terms of both quantitative measures and visual quality. The source code used in the paper is available at https://github.com/NICALab/rlpnet. Link to paper https://doi.org/10.1007/978-3-030-87231-1_18 Link to the code repository https://github.com/NICALab/rlpnet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper addresses the problem of virtual refocusing in light microscopy, i.e. reconstructing a volumetric 3D image from only a single/two adjacent acquired image planes. Specifically the authors propose to recursively apply an appropriately trained network that propagates the intensity image to the next intensity image along the optical axis. The proposes method uses several loss components that are motivated by the physical properties of light propagation. The authors finally evaluate their method on two datasets and demonstrate the superiority compared to another state-of-the art method for virtual refocusing. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. very well written and clearly described sound experiments and superior performance compared to another state-of-the art method Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. physical model of light propagation is not entirely correct code not available to the public Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was available to the reviewer. Datasets (and code) seems not to be available to the public Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. Of course there are clear correlations between adjacent image planes especially for epifluorescence imaging where the PSF essentially “extends into infinity”. But for other modalities that include optical sectioning (confocal, spinning disk, light sheet) the assumed properties of light propagation don’t hold (e.g. for an infinitely thin light sheet, there are no correlations between adjacent image planes due to “light propagation” only correlations from the imaged structures). So might be worth commenting on that. In the equation for the cycle loss, how is “back-propagating” by -l implemented? Reversing the two adjacent images I_k, I_k+1 ? More details regarding that would be helpful. In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? Making the code available to the public would increase the impact of the paper Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A generally well written paper with a clear idea and sound execution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors present a recursive neural network to approximate light propagation and estimate a 3D volume from 2D sections imaged by fluorescence (wide-field) microscopy. The authors derive their network from first principles of light propagation (which is great). The approach is validated using bead samples and images of C elegans specimen and qualitatively and quantitatively compared to a state-of-the-art approach (Deep Z). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The neural network design is derived in a principled way, which is a great strength of this work compared to many papers I have seen. The application of this method is very interesting and important for many types of live microscopy experiments. The methods and the motivation are well explained and discussed. I enjoyed reading this paper. The validation is sound and the results are convincing to me. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I actually do not find a major weakness here. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I haven’t tried, but I am confident, that we could reproduce the results. The method is well explained and the code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I enjoyed reading this paper. Great work! Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper describes an interesting application and it is one of the few papers that use a solid, clear approach when designing the neural network to solve this particular task. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces RLP-Net for 3D virtual refocusing, where two adjacent 2D fluorescence images are adopted for learning light propagation in a recursive manner. Both quantitative and qualitative experiments are provided. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The overall method is clear and technically sound. The motivations of recursive light propagation from two 2-D images are provided. The ablation study of memory module is well conducted. Paper is well organized and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The comparison is not fair enough. The Deep-Z method is not a strong baseline. Technically speaking, The Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. Thus, it is not so surprising that RLP-Net outperforms Deep-Z by a large margin. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code is provided but has not been carefully checked. I believe it is not difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to the weaknesses listed above. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, I lean to recommend acceptance due to the promising method and good writing. However, the authors are encouraged to clarify the cost of RLP-Net, in terms of the data acquisition and network computation. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers unanimously recommend acceptance. The topic and proposed approach are interesting, the results are promising, and the paper is very well written. One reviewer is concerned about the correctness of the physical model of light propagation, and another about the fairness of the chosen baseline for comparison. These issues, in addition to several others pointed out by the reviewers, need to be clarified in the revision. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers for their positive assessment and constructive comments. Below is our response to the major comments. Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. A: We agree that our light propagation model does not hold for optical sectioning methods, which is why we set our goal as ‘to infer the volume from wide-field fluorescence images.’ To avoid any potential confusion, we will revise the manuscript to clarify that our method is not compatible with optical sectioning methods. However, we would like to rebut the statement of the reviewer that single light field propagating through free space does not suffice to describe fluorescent light propagation. Fluorescent light is indeed incoherent, as the reviewer pointed out, and thus can be described as a 4-D light-field, which allows digital refocusing of light-field microscopy images (Levoy et al, 2006) – albeit at limited resolution due to limited sampling density. How is “back-propagating” by -l implemented? A: The concatenation order of two input images determines the inference direction as explained in the Section 2.1. For example, the network infers I_{k+2} if the input is (I_k, I_{k+1}) and infers I_{k-1} if the input is (I_{k+1}, I_k) In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? A: We speculate that unexpected change of PSNR as a function of propagation distance stems from the sparsity of the beads in space. Due to the sparsity, some planes include sharply focused beads whereas others don’t, which manifest itself as varying level of difficulties in predicting different planes. Making the code available to the public would increase the impact of the paper A: We agree with the reviewer’s thought and plan to include the link to our github repository (which is already ready) in the final submission. Comparison for the RLP-Net (taking two input images) and Deep-Z (taking single input image) is not fair enough as Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. A: We agree that utilizing two images gives an advantage to RLP-Net. To compensate for the disadvantage, we computed Deep-Z output using two input images, independently, and then took the average as the prediction as described in Section 3. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? A: The performance of RLP-Net indeed comes with a cost. Presuming a fast axial scanning method such as electrically tunable lens, taking two images that are axially nearby takes twice as long compared to taking one image. RLP-Net took approximately 0.1 second for a single volume inferencing whereas Deep-Z took about 0.08 second for an input image with 128 × 128 pixels. We will clarify this in the revised version of manuscript. The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. A: We agree that understanding failure cases is important and will discuss that in the revised version of the manuscript. We would like to mention that, if the sample moves too fast to take two images, it would not be possible to take a 3-D image at all with a conventional method. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0617/12/31/Paper0632" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0617/12/31/Paper0632" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0617-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="RLP-Net: Recursive Light Propagation Network for 3-D Virtual Refocusing" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0617/12/31/Paper0632"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0617/12/31/Paper0632","headline":"RLP-Net: Recursive Light Propagation Network for 3-D Virtual Refocusing","dateModified":"0618-01-04T00:00:00-05:17","datePublished":"0617-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Changyeop Shin, Hyun Ryu, Eun-Seo Cho, Young-Gyu Yoon Abstract High-speed optical 3-D fluorescence microscopy is an essential tool for capturing the rapid dynamics of biological systems such as cellular signaling and complex movements. Designing such an optical system is constrained by the inherent trade-off among resolution, speed, and noise which comes from the limited number of photons that can be collected. In this paper, we propose a recursive light propagation network (RLP-Net) that infers the 3-D volume from two adjacent 2-D wide-field fluorescence images via virtual refocusing. Specifically, we propose a recursive inference scheme in which the network progressively predicts the subsequent planes along the axial direction. This recursive inference scheme reflects that the law of physics for the light propagation remains spatially invariant and therefore a fixed function (i.e., a neural network) for a short distance light propagation can be recursively applied for a longer distance light propagation. Experimental results show that the proposed method can faithfully reconstruct the 3-D volume from two planes in terms of both quantitative measures and visual quality. The source code used in the paper is available at https://github.com/NICALab/rlpnet. Link to paper https://doi.org/10.1007/978-3-030-87231-1_18 Link to the code repository https://github.com/NICALab/rlpnet Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper addresses the problem of virtual refocusing in light microscopy, i.e. reconstructing a volumetric 3D image from only a single/two adjacent acquired image planes. Specifically the authors propose to recursively apply an appropriately trained network that propagates the intensity image to the next intensity image along the optical axis. The proposes method uses several loss components that are motivated by the physical properties of light propagation. The authors finally evaluate their method on two datasets and demonstrate the superiority compared to another state-of-the art method for virtual refocusing. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. very well written and clearly described sound experiments and superior performance compared to another state-of-the art method Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. physical model of light propagation is not entirely correct code not available to the public Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was available to the reviewer. Datasets (and code) seems not to be available to the public Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. Of course there are clear correlations between adjacent image planes especially for epifluorescence imaging where the PSF essentially “extends into infinity”. But for other modalities that include optical sectioning (confocal, spinning disk, light sheet) the assumed properties of light propagation don’t hold (e.g. for an infinitely thin light sheet, there are no correlations between adjacent image planes due to “light propagation” only correlations from the imaged structures). So might be worth commenting on that. In the equation for the cycle loss, how is “back-propagating” by -l implemented? Reversing the two adjacent images I_k, I_k+1 ? More details regarding that would be helpful. In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? Making the code available to the public would increase the impact of the paper Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A generally well written paper with a clear idea and sound execution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors present a recursive neural network to approximate light propagation and estimate a 3D volume from 2D sections imaged by fluorescence (wide-field) microscopy. The authors derive their network from first principles of light propagation (which is great). The approach is validated using bead samples and images of C elegans specimen and qualitatively and quantitatively compared to a state-of-the-art approach (Deep Z). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The neural network design is derived in a principled way, which is a great strength of this work compared to many papers I have seen. The application of this method is very interesting and important for many types of live microscopy experiments. The methods and the motivation are well explained and discussed. I enjoyed reading this paper. The validation is sound and the results are convincing to me. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I actually do not find a major weakness here. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I haven’t tried, but I am confident, that we could reproduce the results. The method is well explained and the code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I enjoyed reading this paper. Great work! Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper describes an interesting application and it is one of the few papers that use a solid, clear approach when designing the neural network to solve this particular task. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces RLP-Net for 3D virtual refocusing, where two adjacent 2D fluorescence images are adopted for learning light propagation in a recursive manner. Both quantitative and qualitative experiments are provided. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The overall method is clear and technically sound. The motivations of recursive light propagation from two 2-D images are provided. The ablation study of memory module is well conducted. Paper is well organized and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The comparison is not fair enough. The Deep-Z method is not a strong baseline. Technically speaking, The Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. Thus, it is not so surprising that RLP-Net outperforms Deep-Z by a large margin. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code is provided but has not been carefully checked. I believe it is not difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to the weaknesses listed above. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, I lean to recommend acceptance due to the promising method and good writing. However, the authors are encouraged to clarify the cost of RLP-Net, in terms of the data acquisition and network computation. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers unanimously recommend acceptance. The topic and proposed approach are interesting, the results are promising, and the paper is very well written. One reviewer is concerned about the correctness of the physical model of light propagation, and another about the fairness of the chosen baseline for comparison. These issues, in addition to several others pointed out by the reviewers, need to be clarified in the revision. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers for their positive assessment and constructive comments. Below is our response to the major comments. Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. A: We agree that our light propagation model does not hold for optical sectioning methods, which is why we set our goal as ‘to infer the volume from wide-field fluorescence images.’ To avoid any potential confusion, we will revise the manuscript to clarify that our method is not compatible with optical sectioning methods. However, we would like to rebut the statement of the reviewer that single light field propagating through free space does not suffice to describe fluorescent light propagation. Fluorescent light is indeed incoherent, as the reviewer pointed out, and thus can be described as a 4-D light-field, which allows digital refocusing of light-field microscopy images (Levoy et al, 2006) – albeit at limited resolution due to limited sampling density. How is “back-propagating” by -l implemented? A: The concatenation order of two input images determines the inference direction as explained in the Section 2.1. For example, the network infers I_{k+2} if the input is (I_k, I_{k+1}) and infers I_{k-1} if the input is (I_{k+1}, I_k) In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this? A: We speculate that unexpected change of PSNR as a function of propagation distance stems from the sparsity of the beads in space. Due to the sparsity, some planes include sharply focused beads whereas others don’t, which manifest itself as varying level of difficulties in predicting different planes. Making the code available to the public would increase the impact of the paper A: We agree with the reviewer’s thought and plan to include the link to our github repository (which is already ready) in the final submission. Comparison for the RLP-Net (taking two input images) and Deep-Z (taking single input image) is not fair enough as Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. A: We agree that utilizing two images gives an advantage to RLP-Net. To compensate for the disadvantage, we computed Deep-Z output using two input images, independently, and then took the average as the prediction as described in Section 3. The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance? A: The performance of RLP-Net indeed comes with a cost. Presuming a fast axial scanning method such as electrically tunable lens, taking two images that are axially nearby takes twice as long compared to taking one image. RLP-Net took approximately 0.1 second for a single volume inferencing whereas Deep-Z took about 0.08 second for an input image with 128 × 128 pixels. We will clarify this in the revised version of manuscript. The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images. A: We agree that understanding failure cases is important and will discuss that in the revised version of the manuscript. We would like to mention that, if the sample moves too fast to take two images, it would not be possible to take a 3-D image at all with a conventional method. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Shin, Changyeop,Ryu, Hyun,Cho, Eun-Seo,Yoon, Young-Gyu" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>RLP-Net: Recursive Light Propagation Network for 3-D Virtual Refocusing</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a>
      
      <a 
        href="kittywong/categories#Modalities - Microscopy"
        class="post-category">
        Modalities - Microscopy
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Shin, Changyeop"
        class="post-tags">
        Shin, Changyeop
      </a> |  
      
      <a href="kittywong/tags#Ryu, Hyun"
        class="post-tags">
        Ryu, Hyun
      </a> |  
      
      <a href="kittywong/tags#Cho, Eun-Seo"
        class="post-tags">
        Cho, Eun-Seo
      </a> |  
      
      <a href="kittywong/tags#Yoon, Young-Gyu"
        class="post-tags">
        Yoon, Young-Gyu
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Changyeop Shin, Hyun Ryu, Eun-Seo Cho, Young-Gyu Yoon
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>High-speed optical 3-D fluorescence microscopy is an essential tool for capturing the rapid dynamics of biological systems such as cellular signaling and complex movements. Designing such an optical system is constrained by the inherent trade-off among resolution, speed, and noise which comes from the limited number of photons that can be collected. In this paper, we propose a recursive light propagation network (RLP-Net) that infers the 3-D volume from two adjacent 2-D wide-field fluorescence images via virtual refocusing. Specifically, we propose a recursive inference scheme in which the network progressively predicts the subsequent planes along the axial direction. This recursive inference scheme reflects that the law of physics for the light propagation remains spatially invariant and therefore a fixed function (i.e., a neural network) for a short distance light propagation can be recursively applied for a longer distance light propagation. Experimental results show that the proposed method can faithfully reconstruct the 3-D volume from two planes in terms of both quantitative measures and visual quality. The source code  used in the paper is available at https://github.com/NICALab/rlpnet.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87231-1_18">https://doi.org/10.1007/978-3-030-87231-1_18</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/NICALab/rlpnet
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper addresses the problem of virtual refocusing in light microscopy, i.e. reconstructing a volumetric 3D image from only a single/two adjacent acquired image planes. Specifically the authors propose to recursively apply an appropriately trained network that propagates the intensity image to the next intensity image along the optical axis. The proposes method uses several loss components that are motivated by the physical properties of light propagation. The authors finally evaluate their method on two datasets and demonstrate the superiority compared to another state-of-the art method for virtual refocusing.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>very well written and clearly described</li>
        <li>sound experiments and superior performance compared to another state-of-the art method</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>physical model of light propagation is not entirely correct</li>
        <li>code not available to the public</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Code was available to the reviewer. Datasets (and code) seems not to be available to the public</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>
          <p>Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid. Of course there are clear correlations between adjacent image planes especially for epifluorescence imaging where the PSF essentially “extends into infinity”. But for other modalities that include optical sectioning (confocal, spinning disk, light sheet) the assumed properties of light propagation don’t hold (e.g. for an infinitely thin light sheet, there are no correlations between adjacent image planes due to “light propagation” only correlations from the imaged structures). So might be worth commenting on that.</p>
        </li>
        <li>
          <p>In the equation for the cycle loss, how is “back-propagating” by -l implemented? Reversing the two adjacent images I_k, I_k+1 ? More details regarding that would be helpful.</p>
        </li>
        <li>
          <p>In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this?</p>
        </li>
        <li>
          <p>Making the code available to the public would increase the impact of the paper</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>A generally well written paper with a clear idea and sound execution.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors present a recursive neural network to approximate light propagation and  estimate a 3D volume from 2D sections imaged by fluorescence (wide-field) microscopy. The authors derive their network from first principles of light propagation (which is great). The approach is validated using bead samples and images of C elegans specimen and qualitatively and quantitatively compared to a state-of-the-art approach (Deep Z).</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The neural network design is derived in a principled way, which is a great strength of this work compared to many papers I have seen.</p>

      <p>The application of this method is very interesting and important for many types of live microscopy experiments.</p>

      <p>The methods and the motivation are well explained and discussed. I enjoyed reading this paper.</p>

      <p>The validation is sound and the results are convincing to me.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>I actually do not find a major weakness here.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>I haven’t tried, but I am confident, that we could reproduce the results. The method is well explained and the code is available.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>I enjoyed reading this paper. Great work!</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This paper describes an interesting application and it is one of the few papers that use a solid, clear approach when designing the neural network to solve this particular task.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper introduces RLP-Net for 3D virtual refocusing, where two adjacent 2D fluorescence images are adopted for learning light propagation in a recursive manner. Both quantitative and qualitative experiments are provided.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The overall method is clear and technically sound.</li>
        <li>The motivations of recursive light propagation from two 2-D images are provided.</li>
        <li>The ablation study of memory module is well conducted.</li>
        <li>Paper is well organized and easy to follow.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The comparison is not fair enough. The Deep-Z method is not a strong baseline. Technically speaking, The Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images. Thus, it is not so surprising that RLP-Net outperforms Deep-Z by a large margin.</li>
        <li>The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance?</li>
        <li>The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Code is provided but has not been carefully checked. I believe it is not difficult to reproduce the results.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please refer to the weaknesses listed above.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Overall, I lean to recommend acceptance due to the promising method and good writing. However, the authors are encouraged to clarify the cost of RLP-Net, in terms of the data acquisition and network computation.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The reviewers unanimously recommend acceptance. The topic and proposed approach are interesting, the results are promising, and the paper is very well written. One reviewer is concerned about the correctness of the physical model of light propagation, and another about the fairness of the chosen baseline for comparison. These issues, in addition to several others pointed out by the reviewers, need to be clarified in the revision.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the reviewers for their positive assessment and constructive comments. Below is our response to the major comments.</p>

  <ol>
    <li>
      <p>Image formation in fluorescence microscopy is generally incoherent and the acquired images dependent both on the illumination light and the fluorophore distribution (i.e. are not given by a single light field propagating through free space). For both reasons, the assumed model of light propagation including the stated properties in 2.1 are not entirely physically valid.
A: We agree that our light propagation model does not hold for optical sectioning methods, which is why we set our goal as ‘to infer the volume from wide-field fluorescence images.’ To avoid any potential confusion, we will revise the manuscript to clarify that our method is not compatible with optical sectioning methods.
However, we would like to rebut the statement of the reviewer that single light field propagating through free space does not suffice to describe fluorescent light propagation. Fluorescent light is indeed incoherent, as the reviewer pointed out, and thus can be described as a 4-D light-field, which allows digital refocusing of light-field microscopy images (Levoy et al, 2006) – albeit at limited resolution due to limited sampling density.</p>
    </li>
    <li>
      <p>How is “back-propagating” by -l implemented?
A: The concatenation order of two input images determines the inference direction as explained in the Section 2.1. For example, the network infers I_{k+2} if the input is (I_k, I_{k+1}) and infers I_{k-1} if the input is (I_{k+1}, I_k)</p>
    </li>
    <li>
      <p>In table 1, the PSNR of RLP/DEEP-Z for the beads dataset is increasing with the propagation distance, which is a bit counter-intuitive. What is the reason for this?
A: We speculate that unexpected change of PSNR as a function of propagation distance stems from the sparsity of the beads in space. Due to the sparsity, some planes include sharply focused beads whereas others don’t, which manifest itself as varying level of difficulties in predicting different planes.</p>
    </li>
    <li>
      <p>Making the code available to the public would increase the impact of the paper
A: We agree with the reviewer’s thought and plan to include the link to our github repository (which is already ready) in the final submission.</p>
    </li>
    <li>
      <p>Comparison for the RLP-Net (taking two input images) and Deep-Z (taking single input image) is not fair enough as Deep-Z utilizes only one image for 3-D virtual refocusing while RLP-Net utilizes two images.
A: We agree that utilizing two images gives an advantage to RLP-Net. To compensate for the disadvantage, we computed Deep-Z output using two input images, independently, and then took the average as the prediction as described in Section 3.</p>
    </li>
    <li>
      <p>The cost of RLP-Net is not clear, in terms of (a) the additional one image required in the data acquisition process, and (b) the computational burden of network inference (e.g., running time). Is it really worth in practice to adopt RLP-Net for performance?
A: The performance of RLP-Net indeed comes with a cost. Presuming a fast axial scanning method such as electrically tunable lens, taking two images that are axially nearby takes twice as long compared to taking one image. RLP-Net took approximately 0.1 second for a single volume  inferencing whereas Deep-Z took about 0.08 second for an input image with 128 × 128 pixels. We will clarify this in the revised version of manuscript.</p>
    </li>
    <li>
      <p>The potential failure case has not been discussed, e.g., when the moving of object is too fast to capture two adjacent images.
A: We agree that understanding failure cases is important and will discuss that in the revised version of the manuscript. We would like to mention that, if the sample moves too fast to take two images, it would not be possible to take a 3-D image at all with a conventional method.</p>
    </li>
  </ol>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0617-12-31
      -->
      <!--
      
        ,
        updated at 
        0618-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - Microscopy"
        class="post-category">
        Modalities - Microscopy
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Shin, Changyeop"
        class="post-category">
        Shin, Changyeop
      </a> |  
      
      <a href="kittywong/tags#Ryu, Hyun"
        class="post-category">
        Ryu, Hyun
      </a> |  
      
      <a href="kittywong/tags#Cho, Eun-Seo"
        class="post-category">
        Cho, Eun-Seo
      </a> |  
      
      <a href="kittywong/tags#Yoon, Young-Gyu"
        class="post-category">
        Yoon, Young-Gyu
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0618/12/31/Paper0633">
          Noise Mapping and Removal in Complex-Valued Multi-Channel MRI via Optimal Shrinkage of Singular Values
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0616/12/31/Paper0582">
          Estimation of High Frame Rate Digital Subtraction Angiography Sequences at Low Radiation Dose
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
