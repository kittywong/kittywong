<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Positional Contrastive Learning for Volumetric Medical Image Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Positional Contrastive Learning for Volumetric Medical Image Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi Abstract The success of deep learning heavily depends on the availability of large labeled training sets. However, it is hard to get large labeled datasets in medical image domain because of the strict privacy concern and costly labeling efforts. Contrastive learning, an unsupervised learning technique, has been proved powerful in learning image-level representations from unlabeled data. The learned encoder can then be transferred or fine-tuned to improve the performance of downstream tasks with limited labels. A critical step in contrastive learning is the generation of contrastive data pairs, which is relatively simple for natural image classification but quite challenging for medical image segmentation due to the existence of the same tissue or organ across the dataset. As a result, when applied to medical image segmentation, most state-of-the-art contrastive learning frameworks inevitably introduce a lot of false negative pairs and result in degraded segmentation quality. To address this issue, we propose a novel positional contrastive learning (PCL) framework to generate contrastive data pairs by leveraging the position information in volumetric medical images. Experimental results on CT and MRI datasets demonstrate that the proposed PCL method can substantially improve the segmentation performance compared to existing methods in both semi-supervised setting and transfer learning setting. Link to paper https://doi.org/10.1007/978-3-030-87196-3_21 Link to the code repository https://github.com/dewenzeng/positional_cl Link to the dataset(s) https://github.com/XiaoweiXu/Whole-heart-and-great-vessel-segmentation-of-chd_segmentation https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html https://zmiclab.github.io/projects/mmwhs/ http://segchd.csail.mit.edu/ Reviews Review #1 Please describe the contribution of the paper In this paper, the authors propose a contrastive learning-based method for volumetric medical image segmentation. Specifically, a new positional contrastive learning method is proposed to generate positive/negative pairs according to the position of the slices. Extensive experimental evaluations on 4 datasets validate the effectiveness of the proposed method. The main contribution of this paper is the proposed positional contrastive learning method, which could also be useful for other applications and medical modalities. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using positional information to design positive and negative pairs for contrastive learning is interesting and makes sense for the specific segmentation application. This positional-based idea could also be useful for other medical applications. The effectiveness of the proposed method is demonstrated by extensive experiments on 4 datasets with better performance than other selected methods. Details are shown in Table 1 and 2. The authors provide detailed discussions for the experimental results, which bring insights to the community. The paper is well-written and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Given that there is prior work [2] that also use positional information for 3D medical images, the novelty of the proposed method is a bit limited. The idea of predicting position as a way for self-supervised learning is not new in the medical domain, e.g., [1, *2]. [1] Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis, TMI 2020. [*2] Learning to map 2D ultrasound images into 3D space with minimal human annotation, MedIA 2021. The threshold t is a key hyperparameter in the proposed method. But a detailed discussion is lacking and there is no experimental analysis of this parameter. The claim at the end of Sec.3 is not convincing. Why the standard contrastive loss [3] that only has one positive pair is a drawback? Why the proposed method that uses much more positive pairs is better? The effectiveness of contrastive learning also depends on the negative pairs. Such a claim is also not validated in the experiment. Missing reference to contrastive learning when first mentioning in the Introduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was not submitted. But it should not be difficult to reproduce the method in this paper, given that sufficient details were provided and the datasets used are all publicly available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors are suggested to do a more thorough literature review for self-supervised learning in the medical domain, especially for contrastive learning based approaches. Examples but not limited to: [3] Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis, MICCAI 2019, MedIA 2020. [4] Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound, MICCAI 2020. [5] Parts2Whole: Self-supervised Contrastive Learning via Reconstruction, MICCAI workshop 2020. [6] Contrastive Rendering for Ultrasound Image Segmentation, MICCAI 2020. [*7] Self-supervised feature learning for 3d medical images by playing a rubik’s cube, MICCAI 2019. It would be better if the performance for the setting without data augmentation, to isolate the influence from augmentation. It would be better to analyse the influence of the number of positive pairs and negative pairs. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, the paper is well-written with a simple but effective idea for self-supervised contrastive learning. The authors also provide sufficient experimental evaluations with thorough analysis and discussion for the results. All these aspects contribute to the pros of the paper. Although there are some concerns as mentioned above, I believe this paper and the corresponding findings could be interesting to the audience of MICCAI 2021 and those issues could be addressed in a minor revision. As a result, I would recommend acceptance. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This work designs a new contrastive learning framework for 3D medical images. Position information of each slice is added to distinguish the positive/negative samples, in order to mitigate the problem of more false negative pairs. The motivation behind this is that adjacent slices in the same volume or corresponding slices in different volumes have similar content. The performance on different dataset has shown the effectiveness of the introduced framework. Authors also conduct transfer learning to verify whether the learned representations are transferable. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This work proposes a novel contrastive learning framework by involving the position information of each slide, which is suitable for 3D medical images. The results on different datasets have shown that it outperforms the andom setting, other self-supervised learning settings, and other methods for 3D medical images. Authors also conducts transfer learning experiment to show the effectiveness of the proposed framework. The paper is well-written and well-organized. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Not sure about whether the assumption holds that volumes of different patients are aligned for these dataset. It would be better to do analysis on it. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations that are used in the contrastive learning. Some data augmentations are not suitable for medical images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code for SimCLR has been public. Authors have provided some details about the experiments. I think it is ok to reproduce the work of this paper if the dataset is public as well. As mentioned in the authors’ reproducibility response, they plan to release the code and training models. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be better to have the analysis on the assumption that volumes of different patients are aligned for different datasets Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A novel contrastive learning framework is proposed in this work. Adding position information is suitable for 3D medical images, which is helpful for the community. As such, I prefer the accept as my rating at the current stage What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The authors utilized the positional information of 2D slices embedded in 3D volumetric medical images to reduce the false-negative samples and improved the convenient contrastive learning (e.g., SimCLR). Specifically, for each anchor image x, its positive samples include its augmented view and all 2D slices whose position is close to x. The proposed PCL is evaluated on 4 segmentation tasks in both semi-supervised and transfer learning settings, and demonstrates superior performance compared with several state-of-the-art self-supervised learning baselines, including SimCLR and GCL. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The manuscript is well written and illustrated, making it very easy to follow. The authors clearly point out the false-negative problem when conventional contrastive learning methods are applied on 2D slices from 3D volumetric medical images, and proposed a novel yet simple self-supervised learning method to address the limitation. The proposed PCL demonstrates superior performance compared with serval self-supervised learning baselines, including PIRL, SimCLR, and GCL. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. On page 4, the authors mentioned that the corresponding 2D slices in different volumes could be defined as positive pairs if the volumes of different patients are “perfectly aligned.” However, it is generally not possible considering the movement of patients and different protocols and machines during the collecting process. Therefore, how is the alignment problem solved during the training of PCL? In the supplementary, what is the average number of positive samples with different thresholds? Especially when the threshold is small, the positive samples will only contain the augmented view most of the time, and PCL will be downgraded to SimCLR. However, PCL is insensitive to different thresholds and significantly outperforms SimCLR even with the smallest threshold. Therefore, what is the main reason that PCL still significantly outperforms SimCLR with a small threshold? Or to what degree will PCL be downgraded to SimCLR? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Fairly possible. The datasets used in this paper are publicly available, and the main idea is an improved version of SimCLR, which has official implementation. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Since the 3D segmentation tasks are solved with 2D sliced-based methods, the ImageNet-pretrained model would still serve as a strong baseline and should be included. Additionally, the baselines did not incorporate recent progress in self-supervised learning. For example, SwAV [1] and BYOL [2] show superior performance compared with SimCLR. It would be more comprehensive to include SwAV and BYOL as baselines. On the other hand, it would be interesting to see how the segmentation tasks can be solved with 3D volume-based self-supervised learning methods such as Models Genesis [3] and Rubiks Cube [4]. The title emphasized “segmentation” and PCL is only evaluated on segmentation tasks. However, PCL is not specifically designed for segmentation tasks but rather a general self-supervised learning approach. Therefore, the title may be misleading to some extent, and the impact of PCL may be restricted. On page 1, the authors mentioned that “due to the strict privacy concern…acquiring such large labeled datasets is usually prohibitive…a large amount of unlabeled image data…is generated every day all around the world.” The logic here has some flaws since “privacy concern” exists for both labeled and unlabeled images. Please consider rephasing these two sentences. [1] Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. and Joulin, A., 2020. Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882. [2] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Pires, B.A., Guo, Z.D., Azar, M.G. and Piot, B., 2020. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733. [3] Zhou, Z., Sodha, V., Siddiquee, M.M.R., Feng, R., Tajbakhsh, N., Gotway, M.B. and Liang, J., 2019, October. Models genesis: Generic autodidactic models for 3d medical image analysis. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 384-393). Springer, Cham. [4] Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y. and Zheng, Y., 2019, October. Self-supervised feature learning for 3d medical images by playing a rubik’s cube. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 420-428). Springer, Cham. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The manuscript is well written and illustrated. The authors identify one limitation of conventional contrastive learning methods and proposed a novel yet simple approach to address it. The performance is superior compared with serval existing self-supervised methods. There are some missing details/explanations (e.g., the alignment problem, performance of PCL with small thresholds) which may potentially downgrade this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviews for this paper are throughout positive. The idea of integrating positional information in the context of contrastive learning is appealing and the experiments are convincing. There are a couple of details missing and the issue raised regarding the alignment problem should be clarified in the paper. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank all reviewers and meta-reviewer for their time and recognition of this paper’s contributions. Here, we focus on addressing some concerns and questions of the reviewers. Reviewer #1: Why not use the standard contrastive loss? Response: We use the contrastive loss in Section 3.3 because it is neat and can handle multiple positive pairs at the same time so that our PCL can be better utilized. Of course, one can also use standard contrastive loss [3] to handle these positive pairs pair by pair (which is what paper [2] did). The implementation would be a bit redundant, but the performance will not change much. It would be better to see the performance for the setting without data augmentation. Response: We have experimented finetuning without data augmentation. In fact, the performance of both random initialization and PCL degrade, though the former much more significant. In other words, the gains of PCL become more significant. We do not use these results in the paper because data augmentation is a common technique that people normally use. It would be better to analyze the influence of the number of positive pairs and negative pairs. Response: The influence of positive pairs can be seen in Table 1 in the supplementary (though we did not have space to discuss it in the paper). Basically, there exists an optimal threshold with the best learning performance, when the threshold is too small, the number of positive pairs in a mini-batch decreases, information in adjacent slices can not be fully utilized (false-negative rate increases). However, when the threshold is too large, the number of positive pairs increases, so will the false positive rate which can decrease the learning performance. Reviewer #2: Not sure about whether the assumption holds that volumes of different patients are aligned for these datasets. It would be better to do an analysis on it. Response: The volumes in CHD (and ACDC) dataset were taken by standard process to capture the same anatomical areas, so they were already roughly aligned as they were acquired. Like [2], we did not use an external tool to align volumes in any of the datasets. We believe rough alignment is enough for PCL to work. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations. Response: Yes, it is based on SimCLR. We only use weak data augmentation for contrastive learning and details can be found in Section 4.1. Code will be release for reproductivity. Reviewer #3: 1: How is the alignment problem solved during the training of PCL? Response: In our analysis, we assume perfect alignment for ease of discussion. In our experiments, all data are only roughly aligned because they capture the same anatomical areas; no external tools are used to align them. Please refer to Reviewer #2 Q1. 2: What is the average number of positive samples with different thresholds? Why the smallest thresholds still outperform SimCLR? Response: Even with the smallest threshold we use (in the supplementary), PCL does not downgrade to SimCLR: the average number of positive samples for CHD (z-axis dimension about 130~300) is 6.7, and for ACDC (z-axis dimension about 10) it is 23.6. We have put the average number of positive samples in the table in our revised version. We will investigate the extreme case (threshold close to 0) in our further work – thank you for your suggestion! 3: Compare to SwAV and BYOL? Response: Both SwAV and BYOL are based on learning features from two different views of one data, our method of generating multiple positive pairs can actually build on them to leverage the structural information in medical images. Thank you for the suggestion, we will investigate these directions in our future work. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi Abstract The success of deep learning heavily depends on the availability of large labeled training sets. However, it is hard to get large labeled datasets in medical image domain because of the strict privacy concern and costly labeling efforts. Contrastive learning, an unsupervised learning technique, has been proved powerful in learning image-level representations from unlabeled data. The learned encoder can then be transferred or fine-tuned to improve the performance of downstream tasks with limited labels. A critical step in contrastive learning is the generation of contrastive data pairs, which is relatively simple for natural image classification but quite challenging for medical image segmentation due to the existence of the same tissue or organ across the dataset. As a result, when applied to medical image segmentation, most state-of-the-art contrastive learning frameworks inevitably introduce a lot of false negative pairs and result in degraded segmentation quality. To address this issue, we propose a novel positional contrastive learning (PCL) framework to generate contrastive data pairs by leveraging the position information in volumetric medical images. Experimental results on CT and MRI datasets demonstrate that the proposed PCL method can substantially improve the segmentation performance compared to existing methods in both semi-supervised setting and transfer learning setting. Link to paper https://doi.org/10.1007/978-3-030-87196-3_21 Link to the code repository https://github.com/dewenzeng/positional_cl Link to the dataset(s) https://github.com/XiaoweiXu/Whole-heart-and-great-vessel-segmentation-of-chd_segmentation https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html https://zmiclab.github.io/projects/mmwhs/ http://segchd.csail.mit.edu/ Reviews Review #1 Please describe the contribution of the paper In this paper, the authors propose a contrastive learning-based method for volumetric medical image segmentation. Specifically, a new positional contrastive learning method is proposed to generate positive/negative pairs according to the position of the slices. Extensive experimental evaluations on 4 datasets validate the effectiveness of the proposed method. The main contribution of this paper is the proposed positional contrastive learning method, which could also be useful for other applications and medical modalities. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using positional information to design positive and negative pairs for contrastive learning is interesting and makes sense for the specific segmentation application. This positional-based idea could also be useful for other medical applications. The effectiveness of the proposed method is demonstrated by extensive experiments on 4 datasets with better performance than other selected methods. Details are shown in Table 1 and 2. The authors provide detailed discussions for the experimental results, which bring insights to the community. The paper is well-written and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Given that there is prior work [2] that also use positional information for 3D medical images, the novelty of the proposed method is a bit limited. The idea of predicting position as a way for self-supervised learning is not new in the medical domain, e.g., [1, *2]. [1] Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis, TMI 2020. [*2] Learning to map 2D ultrasound images into 3D space with minimal human annotation, MedIA 2021. The threshold t is a key hyperparameter in the proposed method. But a detailed discussion is lacking and there is no experimental analysis of this parameter. The claim at the end of Sec.3 is not convincing. Why the standard contrastive loss [3] that only has one positive pair is a drawback? Why the proposed method that uses much more positive pairs is better? The effectiveness of contrastive learning also depends on the negative pairs. Such a claim is also not validated in the experiment. Missing reference to contrastive learning when first mentioning in the Introduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was not submitted. But it should not be difficult to reproduce the method in this paper, given that sufficient details were provided and the datasets used are all publicly available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors are suggested to do a more thorough literature review for self-supervised learning in the medical domain, especially for contrastive learning based approaches. Examples but not limited to: [3] Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis, MICCAI 2019, MedIA 2020. [4] Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound, MICCAI 2020. [5] Parts2Whole: Self-supervised Contrastive Learning via Reconstruction, MICCAI workshop 2020. [6] Contrastive Rendering for Ultrasound Image Segmentation, MICCAI 2020. [*7] Self-supervised feature learning for 3d medical images by playing a rubik’s cube, MICCAI 2019. It would be better if the performance for the setting without data augmentation, to isolate the influence from augmentation. It would be better to analyse the influence of the number of positive pairs and negative pairs. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, the paper is well-written with a simple but effective idea for self-supervised contrastive learning. The authors also provide sufficient experimental evaluations with thorough analysis and discussion for the results. All these aspects contribute to the pros of the paper. Although there are some concerns as mentioned above, I believe this paper and the corresponding findings could be interesting to the audience of MICCAI 2021 and those issues could be addressed in a minor revision. As a result, I would recommend acceptance. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This work designs a new contrastive learning framework for 3D medical images. Position information of each slice is added to distinguish the positive/negative samples, in order to mitigate the problem of more false negative pairs. The motivation behind this is that adjacent slices in the same volume or corresponding slices in different volumes have similar content. The performance on different dataset has shown the effectiveness of the introduced framework. Authors also conduct transfer learning to verify whether the learned representations are transferable. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This work proposes a novel contrastive learning framework by involving the position information of each slide, which is suitable for 3D medical images. The results on different datasets have shown that it outperforms the andom setting, other self-supervised learning settings, and other methods for 3D medical images. Authors also conducts transfer learning experiment to show the effectiveness of the proposed framework. The paper is well-written and well-organized. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Not sure about whether the assumption holds that volumes of different patients are aligned for these dataset. It would be better to do analysis on it. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations that are used in the contrastive learning. Some data augmentations are not suitable for medical images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code for SimCLR has been public. Authors have provided some details about the experiments. I think it is ok to reproduce the work of this paper if the dataset is public as well. As mentioned in the authors’ reproducibility response, they plan to release the code and training models. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be better to have the analysis on the assumption that volumes of different patients are aligned for different datasets Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A novel contrastive learning framework is proposed in this work. Adding position information is suitable for 3D medical images, which is helpful for the community. As such, I prefer the accept as my rating at the current stage What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The authors utilized the positional information of 2D slices embedded in 3D volumetric medical images to reduce the false-negative samples and improved the convenient contrastive learning (e.g., SimCLR). Specifically, for each anchor image x, its positive samples include its augmented view and all 2D slices whose position is close to x. The proposed PCL is evaluated on 4 segmentation tasks in both semi-supervised and transfer learning settings, and demonstrates superior performance compared with several state-of-the-art self-supervised learning baselines, including SimCLR and GCL. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The manuscript is well written and illustrated, making it very easy to follow. The authors clearly point out the false-negative problem when conventional contrastive learning methods are applied on 2D slices from 3D volumetric medical images, and proposed a novel yet simple self-supervised learning method to address the limitation. The proposed PCL demonstrates superior performance compared with serval self-supervised learning baselines, including PIRL, SimCLR, and GCL. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. On page 4, the authors mentioned that the corresponding 2D slices in different volumes could be defined as positive pairs if the volumes of different patients are “perfectly aligned.” However, it is generally not possible considering the movement of patients and different protocols and machines during the collecting process. Therefore, how is the alignment problem solved during the training of PCL? In the supplementary, what is the average number of positive samples with different thresholds? Especially when the threshold is small, the positive samples will only contain the augmented view most of the time, and PCL will be downgraded to SimCLR. However, PCL is insensitive to different thresholds and significantly outperforms SimCLR even with the smallest threshold. Therefore, what is the main reason that PCL still significantly outperforms SimCLR with a small threshold? Or to what degree will PCL be downgraded to SimCLR? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Fairly possible. The datasets used in this paper are publicly available, and the main idea is an improved version of SimCLR, which has official implementation. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Since the 3D segmentation tasks are solved with 2D sliced-based methods, the ImageNet-pretrained model would still serve as a strong baseline and should be included. Additionally, the baselines did not incorporate recent progress in self-supervised learning. For example, SwAV [1] and BYOL [2] show superior performance compared with SimCLR. It would be more comprehensive to include SwAV and BYOL as baselines. On the other hand, it would be interesting to see how the segmentation tasks can be solved with 3D volume-based self-supervised learning methods such as Models Genesis [3] and Rubiks Cube [4]. The title emphasized “segmentation” and PCL is only evaluated on segmentation tasks. However, PCL is not specifically designed for segmentation tasks but rather a general self-supervised learning approach. Therefore, the title may be misleading to some extent, and the impact of PCL may be restricted. On page 1, the authors mentioned that “due to the strict privacy concern…acquiring such large labeled datasets is usually prohibitive…a large amount of unlabeled image data…is generated every day all around the world.” The logic here has some flaws since “privacy concern” exists for both labeled and unlabeled images. Please consider rephasing these two sentences. [1] Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. and Joulin, A., 2020. Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882. [2] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Pires, B.A., Guo, Z.D., Azar, M.G. and Piot, B., 2020. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733. [3] Zhou, Z., Sodha, V., Siddiquee, M.M.R., Feng, R., Tajbakhsh, N., Gotway, M.B. and Liang, J., 2019, October. Models genesis: Generic autodidactic models for 3d medical image analysis. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 384-393). Springer, Cham. [4] Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y. and Zheng, Y., 2019, October. Self-supervised feature learning for 3d medical images by playing a rubik’s cube. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 420-428). Springer, Cham. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The manuscript is well written and illustrated. The authors identify one limitation of conventional contrastive learning methods and proposed a novel yet simple approach to address it. The performance is superior compared with serval existing self-supervised methods. There are some missing details/explanations (e.g., the alignment problem, performance of PCL with small thresholds) which may potentially downgrade this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviews for this paper are throughout positive. The idea of integrating positional information in the context of contrastive learning is appealing and the experiments are convincing. There are a couple of details missing and the issue raised regarding the alignment problem should be clarified in the paper. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank all reviewers and meta-reviewer for their time and recognition of this paper’s contributions. Here, we focus on addressing some concerns and questions of the reviewers. Reviewer #1: Why not use the standard contrastive loss? Response: We use the contrastive loss in Section 3.3 because it is neat and can handle multiple positive pairs at the same time so that our PCL can be better utilized. Of course, one can also use standard contrastive loss [3] to handle these positive pairs pair by pair (which is what paper [2] did). The implementation would be a bit redundant, but the performance will not change much. It would be better to see the performance for the setting without data augmentation. Response: We have experimented finetuning without data augmentation. In fact, the performance of both random initialization and PCL degrade, though the former much more significant. In other words, the gains of PCL become more significant. We do not use these results in the paper because data augmentation is a common technique that people normally use. It would be better to analyze the influence of the number of positive pairs and negative pairs. Response: The influence of positive pairs can be seen in Table 1 in the supplementary (though we did not have space to discuss it in the paper). Basically, there exists an optimal threshold with the best learning performance, when the threshold is too small, the number of positive pairs in a mini-batch decreases, information in adjacent slices can not be fully utilized (false-negative rate increases). However, when the threshold is too large, the number of positive pairs increases, so will the false positive rate which can decrease the learning performance. Reviewer #2: Not sure about whether the assumption holds that volumes of different patients are aligned for these datasets. It would be better to do an analysis on it. Response: The volumes in CHD (and ACDC) dataset were taken by standard process to capture the same anatomical areas, so they were already roughly aligned as they were acquired. Like [2], we did not use an external tool to align volumes in any of the datasets. We believe rough alignment is enough for PCL to work. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations. Response: Yes, it is based on SimCLR. We only use weak data augmentation for contrastive learning and details can be found in Section 4.1. Code will be release for reproductivity. Reviewer #3: 1: How is the alignment problem solved during the training of PCL? Response: In our analysis, we assume perfect alignment for ease of discussion. In our experiments, all data are only roughly aligned because they capture the same anatomical areas; no external tools are used to align them. Please refer to Reviewer #2 Q1. 2: What is the average number of positive samples with different thresholds? Why the smallest thresholds still outperform SimCLR? Response: Even with the smallest threshold we use (in the supplementary), PCL does not downgrade to SimCLR: the average number of positive samples for CHD (z-axis dimension about 130~300) is 6.7, and for ACDC (z-axis dimension about 10) it is 23.6. We have put the average number of positive samples in the table in our revised version. We will investigate the extreme case (threshold close to 0) in our further work – thank you for your suggestion! 3: Compare to SwAV and BYOL? Response: Both SwAV and BYOL are based on learning features from two different views of one data, our method of generating multiple positive pairs can actually build on them to leverage the structural information in medical images. Thank you for the suggestion, we will investigate these directions in our future work. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0220/12/31/Paper1432" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0220/12/31/Paper1432" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0220-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Positional Contrastive Learning for Volumetric Medical Image Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0220/12/31/Paper1432"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0220/12/31/Paper1432","headline":"Positional Contrastive Learning for Volumetric Medical Image Segmentation","dateModified":"0221-01-01T00:00:00-05:17","datePublished":"0220-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi Abstract The success of deep learning heavily depends on the availability of large labeled training sets. However, it is hard to get large labeled datasets in medical image domain because of the strict privacy concern and costly labeling efforts. Contrastive learning, an unsupervised learning technique, has been proved powerful in learning image-level representations from unlabeled data. The learned encoder can then be transferred or fine-tuned to improve the performance of downstream tasks with limited labels. A critical step in contrastive learning is the generation of contrastive data pairs, which is relatively simple for natural image classification but quite challenging for medical image segmentation due to the existence of the same tissue or organ across the dataset. As a result, when applied to medical image segmentation, most state-of-the-art contrastive learning frameworks inevitably introduce a lot of false negative pairs and result in degraded segmentation quality. To address this issue, we propose a novel positional contrastive learning (PCL) framework to generate contrastive data pairs by leveraging the position information in volumetric medical images. Experimental results on CT and MRI datasets demonstrate that the proposed PCL method can substantially improve the segmentation performance compared to existing methods in both semi-supervised setting and transfer learning setting. Link to paper https://doi.org/10.1007/978-3-030-87196-3_21 Link to the code repository https://github.com/dewenzeng/positional_cl Link to the dataset(s) https://github.com/XiaoweiXu/Whole-heart-and-great-vessel-segmentation-of-chd_segmentation https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html https://zmiclab.github.io/projects/mmwhs/ http://segchd.csail.mit.edu/ Reviews Review #1 Please describe the contribution of the paper In this paper, the authors propose a contrastive learning-based method for volumetric medical image segmentation. Specifically, a new positional contrastive learning method is proposed to generate positive/negative pairs according to the position of the slices. Extensive experimental evaluations on 4 datasets validate the effectiveness of the proposed method. The main contribution of this paper is the proposed positional contrastive learning method, which could also be useful for other applications and medical modalities. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using positional information to design positive and negative pairs for contrastive learning is interesting and makes sense for the specific segmentation application. This positional-based idea could also be useful for other medical applications. The effectiveness of the proposed method is demonstrated by extensive experiments on 4 datasets with better performance than other selected methods. Details are shown in Table 1 and 2. The authors provide detailed discussions for the experimental results, which bring insights to the community. The paper is well-written and easy to follow. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Given that there is prior work [2] that also use positional information for 3D medical images, the novelty of the proposed method is a bit limited. The idea of predicting position as a way for self-supervised learning is not new in the medical domain, e.g., [1, *2]. [1] Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis, TMI 2020. [*2] Learning to map 2D ultrasound images into 3D space with minimal human annotation, MedIA 2021. The threshold t is a key hyperparameter in the proposed method. But a detailed discussion is lacking and there is no experimental analysis of this parameter. The claim at the end of Sec.3 is not convincing. Why the standard contrastive loss [3] that only has one positive pair is a drawback? Why the proposed method that uses much more positive pairs is better? The effectiveness of contrastive learning also depends on the negative pairs. Such a claim is also not validated in the experiment. Missing reference to contrastive learning when first mentioning in the Introduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Code was not submitted. But it should not be difficult to reproduce the method in this paper, given that sufficient details were provided and the datasets used are all publicly available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors are suggested to do a more thorough literature review for self-supervised learning in the medical domain, especially for contrastive learning based approaches. Examples but not limited to: [3] Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis, MICCAI 2019, MedIA 2020. [4] Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound, MICCAI 2020. [5] Parts2Whole: Self-supervised Contrastive Learning via Reconstruction, MICCAI workshop 2020. [6] Contrastive Rendering for Ultrasound Image Segmentation, MICCAI 2020. [*7] Self-supervised feature learning for 3d medical images by playing a rubik’s cube, MICCAI 2019. It would be better if the performance for the setting without data augmentation, to isolate the influence from augmentation. It would be better to analyse the influence of the number of positive pairs and negative pairs. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Overall, the paper is well-written with a simple but effective idea for self-supervised contrastive learning. The authors also provide sufficient experimental evaluations with thorough analysis and discussion for the results. All these aspects contribute to the pros of the paper. Although there are some concerns as mentioned above, I believe this paper and the corresponding findings could be interesting to the audience of MICCAI 2021 and those issues could be addressed in a minor revision. As a result, I would recommend acceptance. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This work designs a new contrastive learning framework for 3D medical images. Position information of each slice is added to distinguish the positive/negative samples, in order to mitigate the problem of more false negative pairs. The motivation behind this is that adjacent slices in the same volume or corresponding slices in different volumes have similar content. The performance on different dataset has shown the effectiveness of the introduced framework. Authors also conduct transfer learning to verify whether the learned representations are transferable. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This work proposes a novel contrastive learning framework by involving the position information of each slide, which is suitable for 3D medical images. The results on different datasets have shown that it outperforms the andom setting, other self-supervised learning settings, and other methods for 3D medical images. Authors also conducts transfer learning experiment to show the effectiveness of the proposed framework. The paper is well-written and well-organized. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Not sure about whether the assumption holds that volumes of different patients are aligned for these dataset. It would be better to do analysis on it. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations that are used in the contrastive learning. Some data augmentations are not suitable for medical images. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code for SimCLR has been public. Authors have provided some details about the experiments. I think it is ok to reproduce the work of this paper if the dataset is public as well. As mentioned in the authors’ reproducibility response, they plan to release the code and training models. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be better to have the analysis on the assumption that volumes of different patients are aligned for different datasets Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A novel contrastive learning framework is proposed in this work. Adding position information is suitable for 3D medical images, which is helpful for the community. As such, I prefer the accept as my rating at the current stage What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The authors utilized the positional information of 2D slices embedded in 3D volumetric medical images to reduce the false-negative samples and improved the convenient contrastive learning (e.g., SimCLR). Specifically, for each anchor image x, its positive samples include its augmented view and all 2D slices whose position is close to x. The proposed PCL is evaluated on 4 segmentation tasks in both semi-supervised and transfer learning settings, and demonstrates superior performance compared with several state-of-the-art self-supervised learning baselines, including SimCLR and GCL. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The manuscript is well written and illustrated, making it very easy to follow. The authors clearly point out the false-negative problem when conventional contrastive learning methods are applied on 2D slices from 3D volumetric medical images, and proposed a novel yet simple self-supervised learning method to address the limitation. The proposed PCL demonstrates superior performance compared with serval self-supervised learning baselines, including PIRL, SimCLR, and GCL. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. On page 4, the authors mentioned that the corresponding 2D slices in different volumes could be defined as positive pairs if the volumes of different patients are “perfectly aligned.” However, it is generally not possible considering the movement of patients and different protocols and machines during the collecting process. Therefore, how is the alignment problem solved during the training of PCL? In the supplementary, what is the average number of positive samples with different thresholds? Especially when the threshold is small, the positive samples will only contain the augmented view most of the time, and PCL will be downgraded to SimCLR. However, PCL is insensitive to different thresholds and significantly outperforms SimCLR even with the smallest threshold. Therefore, what is the main reason that PCL still significantly outperforms SimCLR with a small threshold? Or to what degree will PCL be downgraded to SimCLR? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Fairly possible. The datasets used in this paper are publicly available, and the main idea is an improved version of SimCLR, which has official implementation. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Since the 3D segmentation tasks are solved with 2D sliced-based methods, the ImageNet-pretrained model would still serve as a strong baseline and should be included. Additionally, the baselines did not incorporate recent progress in self-supervised learning. For example, SwAV [1] and BYOL [2] show superior performance compared with SimCLR. It would be more comprehensive to include SwAV and BYOL as baselines. On the other hand, it would be interesting to see how the segmentation tasks can be solved with 3D volume-based self-supervised learning methods such as Models Genesis [3] and Rubiks Cube [4]. The title emphasized “segmentation” and PCL is only evaluated on segmentation tasks. However, PCL is not specifically designed for segmentation tasks but rather a general self-supervised learning approach. Therefore, the title may be misleading to some extent, and the impact of PCL may be restricted. On page 1, the authors mentioned that “due to the strict privacy concern…acquiring such large labeled datasets is usually prohibitive…a large amount of unlabeled image data…is generated every day all around the world.” The logic here has some flaws since “privacy concern” exists for both labeled and unlabeled images. Please consider rephasing these two sentences. [1] Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. and Joulin, A., 2020. Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882. [2] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Pires, B.A., Guo, Z.D., Azar, M.G. and Piot, B., 2020. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733. [3] Zhou, Z., Sodha, V., Siddiquee, M.M.R., Feng, R., Tajbakhsh, N., Gotway, M.B. and Liang, J., 2019, October. Models genesis: Generic autodidactic models for 3d medical image analysis. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 384-393). Springer, Cham. [4] Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y. and Zheng, Y., 2019, October. Self-supervised feature learning for 3d medical images by playing a rubik’s cube. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 420-428). Springer, Cham. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The manuscript is well written and illustrated. The authors identify one limitation of conventional contrastive learning methods and proposed a novel yet simple approach to address it. The performance is superior compared with serval existing self-supervised methods. There are some missing details/explanations (e.g., the alignment problem, performance of PCL with small thresholds) which may potentially downgrade this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviews for this paper are throughout positive. The idea of integrating positional information in the context of contrastive learning is appealing and the experiments are convincing. There are a couple of details missing and the issue raised regarding the alignment problem should be clarified in the paper. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank all reviewers and meta-reviewer for their time and recognition of this paper’s contributions. Here, we focus on addressing some concerns and questions of the reviewers. Reviewer #1: Why not use the standard contrastive loss? Response: We use the contrastive loss in Section 3.3 because it is neat and can handle multiple positive pairs at the same time so that our PCL can be better utilized. Of course, one can also use standard contrastive loss [3] to handle these positive pairs pair by pair (which is what paper [2] did). The implementation would be a bit redundant, but the performance will not change much. It would be better to see the performance for the setting without data augmentation. Response: We have experimented finetuning without data augmentation. In fact, the performance of both random initialization and PCL degrade, though the former much more significant. In other words, the gains of PCL become more significant. We do not use these results in the paper because data augmentation is a common technique that people normally use. It would be better to analyze the influence of the number of positive pairs and negative pairs. Response: The influence of positive pairs can be seen in Table 1 in the supplementary (though we did not have space to discuss it in the paper). Basically, there exists an optimal threshold with the best learning performance, when the threshold is too small, the number of positive pairs in a mini-batch decreases, information in adjacent slices can not be fully utilized (false-negative rate increases). However, when the threshold is too large, the number of positive pairs increases, so will the false positive rate which can decrease the learning performance. Reviewer #2: Not sure about whether the assumption holds that volumes of different patients are aligned for these datasets. It would be better to do an analysis on it. Response: The volumes in CHD (and ACDC) dataset were taken by standard process to capture the same anatomical areas, so they were already roughly aligned as they were acquired. Like [2], we did not use an external tool to align volumes in any of the datasets. We believe rough alignment is enough for PCL to work. Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations. Response: Yes, it is based on SimCLR. We only use weak data augmentation for contrastive learning and details can be found in Section 4.1. Code will be release for reproductivity. Reviewer #3: 1: How is the alignment problem solved during the training of PCL? Response: In our analysis, we assume perfect alignment for ease of discussion. In our experiments, all data are only roughly aligned because they capture the same anatomical areas; no external tools are used to align them. Please refer to Reviewer #2 Q1. 2: What is the average number of positive samples with different thresholds? Why the smallest thresholds still outperform SimCLR? Response: Even with the smallest threshold we use (in the supplementary), PCL does not downgrade to SimCLR: the average number of positive samples for CHD (z-axis dimension about 130~300) is 6.7, and for ACDC (z-axis dimension about 10) it is 23.6. We have put the average number of positive samples in the table in our revised version. We will investigate the extreme case (threshold close to 0) in our further work – thank you for your suggestion! 3: Compare to SwAV and BYOL? Response: Both SwAV and BYOL are based on learning features from two different views of one data, our method of generating multiple positive pairs can actually build on them to leverage the structural information in medical images. Thank you for the suggestion, we will investigate these directions in our future work. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Zeng, Dewen,Wu, Yawen,Hu, Xinrong,Xu, Xiaowei,Yuan, Haiyun,Huang, Meiping,Zhuang, Jian,Hu, Jingtong,Shi, Yiyu" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Positional Contrastive Learning for Volumetric Medical Image Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Semi-supervised learning"
        class="post-category">
        Machine Learning - Semi-supervised learning
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Zeng, Dewen"
        class="post-tags">
        Zeng, Dewen
      </a> |  
      
      <a href="kittywong/tags#Wu, Yawen"
        class="post-tags">
        Wu, Yawen
      </a> |  
      
      <a href="kittywong/tags#Hu, Xinrong"
        class="post-tags">
        Hu, Xinrong
      </a> |  
      
      <a href="kittywong/tags#Xu, Xiaowei"
        class="post-tags">
        Xu, Xiaowei
      </a> |  
      
      <a href="kittywong/tags#Yuan, Haiyun"
        class="post-tags">
        Yuan, Haiyun
      </a> |  
      
      <a href="kittywong/tags#Huang, Meiping"
        class="post-tags">
        Huang, Meiping
      </a> |  
      
      <a href="kittywong/tags#Zhuang, Jian"
        class="post-tags">
        Zhuang, Jian
      </a> |  
      
      <a href="kittywong/tags#Hu, Jingtong"
        class="post-tags">
        Hu, Jingtong
      </a> |  
      
      <a href="kittywong/tags#Shi, Yiyu"
        class="post-tags">
        Shi, Yiyu
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, Yiyu Shi
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>The success of deep learning heavily depends on the availability of large labeled training sets. However, it is hard to get large labeled datasets in medical image domain because of the strict privacy concern and costly labeling efforts. Contrastive learning, an unsupervised learning technique, has been proved powerful in learning image-level representations from unlabeled data. The learned encoder can then be transferred or fine-tuned to improve the performance of downstream tasks with limited labels. A critical step in contrastive learning is the generation of contrastive data pairs, which is relatively simple for natural image classification but quite challenging for medical image segmentation due to the existence of the same tissue or organ across the dataset. As a result, when applied to medical image segmentation, most state-of-the-art contrastive learning frameworks inevitably introduce a lot of false negative pairs and result in degraded segmentation quality. To address this issue, we propose a novel positional contrastive learning (PCL) framework to generate contrastive data pairs by leveraging the position information in volumetric medical images. Experimental results on CT and MRI datasets demonstrate that the proposed PCL method can substantially improve the segmentation performance compared to existing methods in both semi-supervised setting and transfer learning setting.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87196-3_21">https://doi.org/10.1007/978-3-030-87196-3_21</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/dewenzeng/positional_cl
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://github.com/XiaoweiXu/Whole-heart-and-great-vessel-segmentation-of-chd_segmentation
https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html
https://zmiclab.github.io/projects/mmwhs/
http://segchd.csail.mit.edu/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>In this paper, the authors propose a contrastive learning-based method for volumetric medical image segmentation. Specifically, a new positional contrastive learning method is proposed to generate positive/negative pairs according to the position of the slices. Extensive experimental evaluations on 4 datasets validate the effectiveness of the proposed method. The main contribution of this paper is the proposed positional contrastive learning method, which could also be useful for other applications and medical modalities.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>
          <p>The idea of using positional information to design positive and negative pairs for contrastive learning is interesting and makes sense for the specific segmentation application. This positional-based idea could also be useful for other medical applications.</p>
        </li>
        <li>
          <p>The effectiveness of the proposed method is demonstrated by extensive experiments on 4 datasets with better performance than other selected methods. Details are shown in Table 1 and 2.</p>
        </li>
        <li>
          <p>The authors provide detailed discussions for the experimental results, which bring insights to the community.</p>
        </li>
        <li>
          <p>The paper is well-written and easy to follow.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>
          <p>Given that there is prior work [2] that also use positional information for 3D medical images, the novelty of the proposed method is a bit limited.</p>
        </li>
        <li>
          <p>The idea of predicting position as a way for self-supervised learning is not new in the medical domain, e.g., [<em>1, *2].
[</em>1] Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis, TMI 2020.
[*2] Learning to map 2D ultrasound images into 3D space with minimal human annotation, MedIA 2021.</p>
        </li>
        <li>
          <p>The threshold t is a key hyperparameter in the proposed method. But a detailed discussion is lacking and there is no experimental analysis of this parameter.</p>
        </li>
        <li>
          <p>The claim at the end of Sec.3 is not convincing. Why the standard contrastive loss [3] that only has one positive pair is a drawback? Why the proposed method that uses much more positive pairs is better? The effectiveness of contrastive learning also depends on the negative pairs. Such a claim is also not validated in the experiment.</p>
        </li>
        <li>
          <p>Missing reference to contrastive learning when first mentioning in the Introduction.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Code was not submitted. But it should not be difficult to reproduce the method in this paper, given that sufficient details were provided and the datasets used are all publicly available.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>
          <p>The authors are suggested to do a more thorough literature review for self-supervised learning in the medical domain, especially for contrastive learning based approaches. Examples but not limited to:
[<em>3] Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis, MICCAI 2019, MedIA 2020.
[</em>4] Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound, MICCAI 2020.
[<em>5] Parts2Whole: Self-supervised Contrastive Learning via Reconstruction, MICCAI workshop 2020.
[</em>6] Contrastive Rendering for Ultrasound Image Segmentation, MICCAI 2020.
[*7] Self-supervised feature
learning for 3d medical images by playing a rubik’s cube, MICCAI 2019.</p>
        </li>
        <li>
          <p>It would be better if the performance for the setting without data augmentation, to isolate the influence from augmentation.</p>
        </li>
        <li>
          <p>It would be better to analyse the influence of the number of positive pairs and negative pairs.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Overall, the paper is well-written with a simple but effective idea for self-supervised contrastive learning. The authors also provide sufficient experimental evaluations with thorough analysis and discussion for the results. All these aspects contribute to the pros of the paper. Although there are some concerns as mentioned above, I believe this paper and the corresponding findings could be interesting to the audience of MICCAI 2021 and those issues could be addressed in a minor revision. As a result, I would recommend acceptance.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>

      <p>This work designs a new contrastive learning framework for 3D medical images. Position information of each slice is added to distinguish the positive/negative samples, in order to mitigate the problem of more false negative pairs. The motivation behind this is that adjacent slices in the same volume or corresponding slices in different volumes have similar content. The performance on different dataset has shown the effectiveness of the introduced framework. Authors also conduct transfer learning to verify whether the learned representations are transferable.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>

      <ul>
        <li>This work proposes a novel contrastive learning framework by involving the position information of each slide, which is suitable for 3D medical images.</li>
        <li>The results on different datasets have shown that it outperforms the andom setting, other self-supervised learning settings, and other methods for 3D medical images. Authors also conducts transfer learning experiment to show the effectiveness of the proposed framework.</li>
        <li>The paper is well-written and well-organized.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>

      <ul>
        <li>Not sure about whether the assumption holds that volumes of different patients are aligned for these dataset. It would be better to do analysis on it.</li>
        <li>Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations that are used in the contrastive learning. Some data augmentations are not suitable for medical images.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>

      <p>The code for SimCLR has been public. Authors have provided some details about the experiments. I think it is ok to reproduce the work of this paper if the dataset is public as well. As mentioned in the authors’ reproducibility response, they plan to release the code and training models.</p>

    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>

      <p>It would be better to have the analysis on the assumption that volumes of different patients are aligned for different datasets</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>

      <p>A novel contrastive learning framework is proposed in this work. Adding position information is suitable for 3D medical images, which is helpful for the community.  As such, I prefer the accept as my rating at the current stage</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors utilized the positional information of 2D slices embedded in 3D volumetric medical images to reduce the false-negative samples and improved the convenient contrastive learning (e.g., SimCLR). Specifically, for each anchor image x, its positive samples include its augmented view and all 2D slices whose position is close to x. The proposed PCL is evaluated on 4 segmentation tasks in both semi-supervised and transfer learning settings, and demonstrates superior performance compared with several state-of-the-art self-supervised learning baselines, including SimCLR and GCL.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The manuscript is well written and illustrated, making it very easy to follow.</li>
        <li>The authors clearly point out the false-negative problem when conventional contrastive learning methods are applied on 2D slices from 3D volumetric medical images, and proposed a novel yet simple self-supervised learning method to address the limitation.</li>
        <li>The proposed PCL demonstrates superior performance compared with serval self-supervised learning baselines, including PIRL, SimCLR, and GCL.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>On page 4, the authors mentioned that the corresponding 2D slices in different volumes could be defined as positive pairs if the volumes of different patients are “perfectly aligned.” However, it is generally not possible considering the movement of patients and different protocols and machines during the collecting process. Therefore, how is the alignment problem solved during the training of PCL?</li>
        <li>In the supplementary, what is the average number of positive samples with different thresholds? Especially when the threshold is small, the positive samples will only contain the augmented view most of the time, and PCL will be downgraded to SimCLR. However, PCL is insensitive to different thresholds and significantly outperforms SimCLR even with the smallest threshold. Therefore, what is the main reason that PCL still significantly outperforms SimCLR with a small threshold? Or to what degree will PCL be downgraded to SimCLR?</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Fairly possible. The datasets used in this paper are publicly available, and the main idea is an improved version of SimCLR, which has official implementation.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>Since the 3D segmentation tasks are solved with 2D sliced-based methods, the ImageNet-pretrained model would still serve as a strong baseline and should be included. Additionally, the baselines did not incorporate recent progress in self-supervised learning. For example, SwAV [1] and BYOL [2] show superior performance compared with SimCLR. It would be more comprehensive to include SwAV and BYOL as baselines.</li>
        <li>On the other hand, it would be interesting to see how the segmentation tasks can be solved with 3D volume-based self-supervised learning methods such as Models Genesis [3] and Rubiks Cube [4].</li>
        <li>The title emphasized “segmentation” and PCL is only evaluated on segmentation tasks. However,  PCL is not specifically designed for segmentation tasks but rather a general self-supervised learning approach. Therefore, the title may be misleading to some extent, and the impact of PCL may be restricted.</li>
        <li>On page 1, the authors mentioned that “due to the strict privacy concern…acquiring such large labeled datasets is usually prohibitive…a large amount of unlabeled image data…is generated every day all around the world.” The logic here has some flaws since “privacy concern” exists for both labeled and unlabeled images. Please consider rephasing these two sentences.</li>
      </ol>

      <p>[1] Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P. and Joulin, A., 2020. Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882.
[2] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Pires, B.A., Guo, Z.D., Azar, M.G. and Piot, B., 2020. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733.
[3] Zhou, Z., Sodha, V., Siddiquee, M.M.R., Feng, R., Tajbakhsh, N., Gotway, M.B. and Liang, J., 2019, October. Models genesis: Generic autodidactic models for 3d medical image analysis. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 384-393). Springer, Cham.
[4] Zhuang, X., Li, Y., Hu, Y., Ma, K., Yang, Y. and Zheng, Y., 2019, October. Self-supervised feature learning for 3d medical images by playing a rubik’s cube. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 420-428). Springer, Cham.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ul>
        <li>The manuscript is well written and illustrated.</li>
        <li>The authors identify one limitation of conventional contrastive learning methods and proposed a novel yet simple approach to address it.</li>
        <li>The performance is superior compared with serval existing self-supervised methods.</li>
        <li>There are some missing details/explanations (e.g., the alignment problem, performance of PCL with small thresholds) which may potentially downgrade this paper.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The reviews for this paper are throughout positive. The idea of integrating positional information in the context of contrastive learning is appealing and the experiments are convincing. There are a couple of details missing and the issue raised regarding the alignment problem should be clarified in the paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank all reviewers and meta-reviewer for their time and recognition of this paper’s contributions. Here, we focus on addressing some concerns and questions of the reviewers.</p>

  <p>Reviewer #1:</p>
  <ol>
    <li>
      <p>Why not use the standard contrastive loss?
Response: We use the contrastive loss in Section 3.3 because it is neat and can handle multiple positive pairs at the same time so that our PCL can be better utilized. Of course, one can also use standard contrastive loss [3] to handle these positive pairs pair by pair (which is what paper [2] did). The implementation would be a bit redundant, but the performance will not change much.</p>
    </li>
    <li>
      <p>It would be better to see the performance for the setting without data augmentation.
Response: We have experimented finetuning without data augmentation. In fact, the performance of both random initialization and PCL degrade, though the former much more significant. In other words, the gains of PCL become more significant. We do not use these results in the paper because data augmentation is a common technique that people normally use.</p>
    </li>
    <li>
      <p>It would be better to analyze the influence of the number of positive pairs and negative pairs.
Response: The influence of positive pairs can be seen in Table 1 in the supplementary (though we did not have space to discuss it in the paper). Basically, there exists an optimal threshold with the best learning performance, when the threshold is too small, the number of positive pairs in a mini-batch decreases, information in adjacent slices can not be fully utilized (false-negative rate increases). However,  when the threshold is too large, the number of positive pairs increases, so will the false positive rate which can decrease the learning performance.</p>
    </li>
  </ol>

  <p>Reviewer #2:</p>
  <ol>
    <li>
      <p>Not sure about whether the assumption holds that volumes of different patients are aligned for these datasets. It would be better to do an analysis on it.
Response: The volumes in CHD (and ACDC) dataset were taken by standard process to capture the same anatomical areas, so they were already roughly aligned as they were acquired. Like [2], we did not use an external tool to align volumes in any of the datasets. We believe rough alignment is enough for PCL to work.</p>
    </li>
    <li>
      <p>Is PCL based on the SimCLR framework? It would be better to provide more details on the data augmentations.
Response: Yes, it is based on SimCLR. We only use weak data augmentation for contrastive learning and details can be found in Section 4.1. Code will be release for reproductivity.</p>
    </li>
  </ol>

  <p>Reviewer #3:
1: How is the alignment problem solved during the training of PCL?
Response: In our analysis, we assume perfect alignment for ease of discussion. In our experiments, all data are only roughly aligned because they capture the same anatomical areas; no external tools are used to align them. Please refer to Reviewer #2 Q1.</p>

  <p>2: What is the average number of positive samples with different thresholds? Why the smallest thresholds still outperform SimCLR?
Response: Even with the smallest threshold we use (in the supplementary), PCL does not downgrade to SimCLR: the average number of positive samples for CHD (z-axis dimension about 130~300) is 6.7, and for ACDC (z-axis dimension about 10) it is 23.6. We have put the average number of positive samples in the table in our revised version. We will investigate the extreme case (threshold close to 0) in our further work – thank you for your suggestion!</p>

  <p>3: Compare to SwAV and BYOL?
Response: Both SwAV and BYOL are based on learning features from two different views of one data, our method of generating multiple positive pairs can actually build on them to leverage the structural information in medical images. Thank you for the suggestion, we will investigate these directions in our future work.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0220-12-31
      -->
      <!--
      
        ,
        updated at 
        0221-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a> |
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Semi-supervised learning"
        class="post-category">
        Machine Learning - Semi-supervised learning
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Zeng, Dewen"
        class="post-category">
        Zeng, Dewen
      </a> |  
      
      <a href="kittywong/tags#Wu, Yawen"
        class="post-category">
        Wu, Yawen
      </a> |  
      
      <a href="kittywong/tags#Hu, Xinrong"
        class="post-category">
        Hu, Xinrong
      </a> |  
      
      <a href="kittywong/tags#Xu, Xiaowei"
        class="post-category">
        Xu, Xiaowei
      </a> |  
      
      <a href="kittywong/tags#Yuan, Haiyun"
        class="post-category">
        Yuan, Haiyun
      </a> |  
      
      <a href="kittywong/tags#Huang, Meiping"
        class="post-category">
        Huang, Meiping
      </a> |  
      
      <a href="kittywong/tags#Zhuang, Jian"
        class="post-category">
        Zhuang, Jian
      </a> |  
      
      <a href="kittywong/tags#Hu, Jingtong"
        class="post-category">
        Hu, Jingtong
      </a> |  
      
      <a href="kittywong/tags#Shi, Yiyu"
        class="post-category">
        Shi, Yiyu
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0221/12/31/Paper1497">
          Longitudinal self-supervision to disentangle inter-patient variability from disease progression
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0219/12/31/Paper1235">
          Contrastive Pre-training and Representation Distillation for Medical Visual Question Answering Based on Radiology Images
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
