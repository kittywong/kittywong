<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Multiple Meta-model Quantifying for Medical Visual Question Answering | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Multiple Meta-model Quantifying for Medical Visual Question Answering" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tuong Do, Binh X. Nguyen, Erman Tjiputra, Minh Tran, Quang D. Tran, Anh Nguyen Abstract Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models. Link to paper https://doi.org/10.1007/978-3-030-87240-3_7 Link to the code repository https://github.com/aioz-ai/MICCAI21_MMQ Link to the dataset(s) VQA-RAD dataset: https://www.nature.com/articles/sdata2018251 Pathvqa dataset: https://arxiv.org/pdf/2003.10286.pdf Reviews Review #1 Please describe the contribution of the paper This paper proposes a multiple meta-model quantifying method to learn meta-annotation for pre-training and leverage the pre-trained knowledge for the medical VQA task. The proposed method aims to address some problems of meta-learning pre-training for medical VQA tasks, e.g., previous methods are heavily impacted by the meta-annotation phase for all images in the medical dataset so that noisy labels may occur when labeling images in an unsupervised manner, high-level semantic labels cause uncertainty during learning, and so on. The proposed method does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A meta-learning pre-training method was proposed for medical VQA tasks to address some problems that exist in previous works.   The model does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. The motivation and problem description are clear and significant. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Although the model outperforms all the baseline models, the baseline models are weak.   There are some grammar issues. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors do not provide code and other implementation details of their model. I am not sure if the results reported in this paper are reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The motivation and problem description are clear and significant. You should choose more recently proposed strong VQA methods as your baseline. You can provide more implementation details in your paper for reproducibility. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The strengths and weaknesses listed in parts 3 and 4. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 6 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The author proposed a framework using meta-learning to refine the training dataset, and showed that the pre-trained meta-learning models are useful in the downstream medical visual question answering task. The proposed method is validated on two public datasets and can outperform the MEVF method published in MICCAI 2019. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper proposed a novel algorithm for the data refinement based on the predicted score from the pre-trained meta-learning model. The pre-trained meta-models are successfully applied in the visual question answering task which means the feature extractor probably learned the semantic information from the meta-training tasks. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main contribution of this paper is using meta-learning for the data refinement, so it will be very interesting to add another baseline where the MEVF method uses meta-model pre-trained on the refined dataset to show the effectiveness of using multiple meta-learning models. The author mentioned that they used uncertainty in the data refinement process, but from what they described in the algorithm part, they were using predicted scores rather than uncertainty. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It should be reproducible as long as the code is published. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In generall, it is a good paper using meta-learning. Besides what mentioned in the weakness section, One thing is that the data pool used in the paper does not have unlabeled data. I believe all of them are labeled as required for the meta-training process. I guess using noisy-labeled data is more appropriate. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The data refinement part is novel. It is a good paper using meta-learning to obtain a more powerful feature extractor. It improves over the previous SOTA method. The writing can be improved and one baseline is expected as the ablation study for using multiple meta-learning models. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an approach for VQA on two public medical datasets. In this paper MMQ, and adaption from MAML, is introced. This adapation is mostly directed to overcome the extra complications with transfer learning in medical imaging. Authors show how this meta-learning method outperforms current VQA methods, as well as how data refinement on the meta-model can increase performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -creative approach in medical vqa, described accurately in the methods section -Shown good performance against earlier methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -grammatical errors and double paragraph headers -Structure of paper is sometimes unclear -algorithms on page 5 are not clear. It might be possible to integrate these more with the rest of the paper -best performance in tables should be in bold for optimal clarity -No example of output is shown Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors indicated to make code publicly available. Method is clearly described, but the paper is missing relevant information on training settings and hyperparameters Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Interesting contribution, with interesting results. Integration of the algorithms on page 5 with the paper and showing an example of the model output are major area’s for improvement. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Quality of writing, strucuture of paper What is the ranking of this paper in your review stack? 3 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers and myself agree that the paper is of high enough quality for acceptance at MICCAI. All reviewers have favorably reviewed the work, and have also provided constrcutive feedback to the paper to improve its quality. I would ask the authors to take these into account before submitted their final version. In particular, there are number of references on the topic of med-VQA that could be added. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank the Reviewers and the AC for taking the time to consider our paper and give constructive feedback. We address the main concerns below. Writing issues: grammatical errors, algorithms, and the structure of paper (R1, R2, R3). We thank reviewers to point out our mistakes and unclear parts of our paper. All of them will be fixed and re-organized when we publish our camera ready version. Source code: training settings, hyper parameters, and implementation details (R1, R2, R3). The training setup, hyper parameters, and implementation details were presented in our Supplementary Material due to the paper’s length limitation. We will publish the source code with all these details for further research. The baseline (R1,R2). We agreed that there maybe other recent VQA baselines in computer vision that outperforms the baseline we used. However, they are not directly applied in medical images. Furthermore, as suggested by R2, we can also integrate our multiple meta-models learning process into MEVF. This will be done in our future work. The uncertainty in the the data refinement process (R2). From our understanding, the uncertainty occurs when the model cannot produce a high enough prediction score for a specific sample during training. Regardless of the reason behind is the incorrect annotation or the highly semantic label, the most recognizable sign of this problem is the “uncertainty” probability score of training samples, i.e., the predicted score (as mentioned by R2). We agreed that there are other methods that can output uncertainty scores (e.g. using label distribution). This could be an interesting direction to improve the accuracy of the medical VQA task in the future. Example output (R3). The example outputs of our proposed MMQ will be added. References (AC). We have intensively searched for more related papers and added them to our camera ready version. Thanks for your suggestion. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tuong Do, Binh X. Nguyen, Erman Tjiputra, Minh Tran, Quang D. Tran, Anh Nguyen Abstract Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models. Link to paper https://doi.org/10.1007/978-3-030-87240-3_7 Link to the code repository https://github.com/aioz-ai/MICCAI21_MMQ Link to the dataset(s) VQA-RAD dataset: https://www.nature.com/articles/sdata2018251 Pathvqa dataset: https://arxiv.org/pdf/2003.10286.pdf Reviews Review #1 Please describe the contribution of the paper This paper proposes a multiple meta-model quantifying method to learn meta-annotation for pre-training and leverage the pre-trained knowledge for the medical VQA task. The proposed method aims to address some problems of meta-learning pre-training for medical VQA tasks, e.g., previous methods are heavily impacted by the meta-annotation phase for all images in the medical dataset so that noisy labels may occur when labeling images in an unsupervised manner, high-level semantic labels cause uncertainty during learning, and so on. The proposed method does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A meta-learning pre-training method was proposed for medical VQA tasks to address some problems that exist in previous works.   The model does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. The motivation and problem description are clear and significant. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Although the model outperforms all the baseline models, the baseline models are weak.   There are some grammar issues. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors do not provide code and other implementation details of their model. I am not sure if the results reported in this paper are reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The motivation and problem description are clear and significant. You should choose more recently proposed strong VQA methods as your baseline. You can provide more implementation details in your paper for reproducibility. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The strengths and weaknesses listed in parts 3 and 4. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 6 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The author proposed a framework using meta-learning to refine the training dataset, and showed that the pre-trained meta-learning models are useful in the downstream medical visual question answering task. The proposed method is validated on two public datasets and can outperform the MEVF method published in MICCAI 2019. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper proposed a novel algorithm for the data refinement based on the predicted score from the pre-trained meta-learning model. The pre-trained meta-models are successfully applied in the visual question answering task which means the feature extractor probably learned the semantic information from the meta-training tasks. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main contribution of this paper is using meta-learning for the data refinement, so it will be very interesting to add another baseline where the MEVF method uses meta-model pre-trained on the refined dataset to show the effectiveness of using multiple meta-learning models. The author mentioned that they used uncertainty in the data refinement process, but from what they described in the algorithm part, they were using predicted scores rather than uncertainty. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It should be reproducible as long as the code is published. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In generall, it is a good paper using meta-learning. Besides what mentioned in the weakness section, One thing is that the data pool used in the paper does not have unlabeled data. I believe all of them are labeled as required for the meta-training process. I guess using noisy-labeled data is more appropriate. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The data refinement part is novel. It is a good paper using meta-learning to obtain a more powerful feature extractor. It improves over the previous SOTA method. The writing can be improved and one baseline is expected as the ablation study for using multiple meta-learning models. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an approach for VQA on two public medical datasets. In this paper MMQ, and adaption from MAML, is introced. This adapation is mostly directed to overcome the extra complications with transfer learning in medical imaging. Authors show how this meta-learning method outperforms current VQA methods, as well as how data refinement on the meta-model can increase performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -creative approach in medical vqa, described accurately in the methods section -Shown good performance against earlier methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -grammatical errors and double paragraph headers -Structure of paper is sometimes unclear -algorithms on page 5 are not clear. It might be possible to integrate these more with the rest of the paper -best performance in tables should be in bold for optimal clarity -No example of output is shown Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors indicated to make code publicly available. Method is clearly described, but the paper is missing relevant information on training settings and hyperparameters Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Interesting contribution, with interesting results. Integration of the algorithms on page 5 with the paper and showing an example of the model output are major area’s for improvement. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Quality of writing, strucuture of paper What is the ranking of this paper in your review stack? 3 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers and myself agree that the paper is of high enough quality for acceptance at MICCAI. All reviewers have favorably reviewed the work, and have also provided constrcutive feedback to the paper to improve its quality. I would ask the authors to take these into account before submitted their final version. In particular, there are number of references on the topic of med-VQA that could be added. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank the Reviewers and the AC for taking the time to consider our paper and give constructive feedback. We address the main concerns below. Writing issues: grammatical errors, algorithms, and the structure of paper (R1, R2, R3). We thank reviewers to point out our mistakes and unclear parts of our paper. All of them will be fixed and re-organized when we publish our camera ready version. Source code: training settings, hyper parameters, and implementation details (R1, R2, R3). The training setup, hyper parameters, and implementation details were presented in our Supplementary Material due to the paper’s length limitation. We will publish the source code with all these details for further research. The baseline (R1,R2). We agreed that there maybe other recent VQA baselines in computer vision that outperforms the baseline we used. However, they are not directly applied in medical images. Furthermore, as suggested by R2, we can also integrate our multiple meta-models learning process into MEVF. This will be done in our future work. The uncertainty in the the data refinement process (R2). From our understanding, the uncertainty occurs when the model cannot produce a high enough prediction score for a specific sample during training. Regardless of the reason behind is the incorrect annotation or the highly semantic label, the most recognizable sign of this problem is the “uncertainty” probability score of training samples, i.e., the predicted score (as mentioned by R2). We agreed that there are other methods that can output uncertainty scores (e.g. using label distribution). This could be an interesting direction to improve the accuracy of the medical VQA task in the future. Example output (R3). The example outputs of our proposed MMQ will be added. References (AC). We have intensively searched for more related papers and added them to our camera ready version. Thanks for your suggestion. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0506/12/31/Paper0066" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0506/12/31/Paper0066" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0506-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multiple Meta-model Quantifying for Medical Visual Question Answering" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0506/12/31/Paper0066"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0506/12/31/Paper0066","headline":"Multiple Meta-model Quantifying for Medical Visual Question Answering","dateModified":"0507-01-03T00:00:00-05:17","datePublished":"0506-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Tuong Do, Binh X. Nguyen, Erman Tjiputra, Minh Tran, Quang D. Tran, Anh Nguyen Abstract Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models. Link to paper https://doi.org/10.1007/978-3-030-87240-3_7 Link to the code repository https://github.com/aioz-ai/MICCAI21_MMQ Link to the dataset(s) VQA-RAD dataset: https://www.nature.com/articles/sdata2018251 Pathvqa dataset: https://arxiv.org/pdf/2003.10286.pdf Reviews Review #1 Please describe the contribution of the paper This paper proposes a multiple meta-model quantifying method to learn meta-annotation for pre-training and leverage the pre-trained knowledge for the medical VQA task. The proposed method aims to address some problems of meta-learning pre-training for medical VQA tasks, e.g., previous methods are heavily impacted by the meta-annotation phase for all images in the medical dataset so that noisy labels may occur when labeling images in an unsupervised manner, high-level semantic labels cause uncertainty during learning, and so on. The proposed method does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A meta-learning pre-training method was proposed for medical VQA tasks to address some problems that exist in previous works.   The model does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets. The motivation and problem description are clear and significant. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Although the model outperforms all the baseline models, the baseline models are weak.   There are some grammar issues. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors do not provide code and other implementation details of their model. I am not sure if the results reported in this paper are reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The motivation and problem description are clear and significant. You should choose more recently proposed strong VQA methods as your baseline. You can provide more implementation details in your paper for reproducibility. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The strengths and weaknesses listed in parts 3 and 4. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 6 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The author proposed a framework using meta-learning to refine the training dataset, and showed that the pre-trained meta-learning models are useful in the downstream medical visual question answering task. The proposed method is validated on two public datasets and can outperform the MEVF method published in MICCAI 2019. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper proposed a novel algorithm for the data refinement based on the predicted score from the pre-trained meta-learning model. The pre-trained meta-models are successfully applied in the visual question answering task which means the feature extractor probably learned the semantic information from the meta-training tasks. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main contribution of this paper is using meta-learning for the data refinement, so it will be very interesting to add another baseline where the MEVF method uses meta-model pre-trained on the refined dataset to show the effectiveness of using multiple meta-learning models. The author mentioned that they used uncertainty in the data refinement process, but from what they described in the algorithm part, they were using predicted scores rather than uncertainty. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It should be reproducible as long as the code is published. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In generall, it is a good paper using meta-learning. Besides what mentioned in the weakness section, One thing is that the data pool used in the paper does not have unlabeled data. I believe all of them are labeled as required for the meta-training process. I guess using noisy-labeled data is more appropriate. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The data refinement part is novel. It is a good paper using meta-learning to obtain a more powerful feature extractor. It improves over the previous SOTA method. The writing can be improved and one baseline is expected as the ablation study for using multiple meta-learning models. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an approach for VQA on two public medical datasets. In this paper MMQ, and adaption from MAML, is introced. This adapation is mostly directed to overcome the extra complications with transfer learning in medical imaging. Authors show how this meta-learning method outperforms current VQA methods, as well as how data refinement on the meta-model can increase performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -creative approach in medical vqa, described accurately in the methods section -Shown good performance against earlier methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -grammatical errors and double paragraph headers -Structure of paper is sometimes unclear -algorithms on page 5 are not clear. It might be possible to integrate these more with the rest of the paper -best performance in tables should be in bold for optimal clarity -No example of output is shown Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors indicated to make code publicly available. Method is clearly described, but the paper is missing relevant information on training settings and hyperparameters Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Interesting contribution, with interesting results. Integration of the algorithms on page 5 with the paper and showing an example of the model output are major area’s for improvement. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Quality of writing, strucuture of paper What is the ranking of this paper in your review stack? 3 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers and myself agree that the paper is of high enough quality for acceptance at MICCAI. All reviewers have favorably reviewed the work, and have also provided constrcutive feedback to the paper to improve its quality. I would ask the authors to take these into account before submitted their final version. In particular, there are number of references on the topic of med-VQA that could be added. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank the Reviewers and the AC for taking the time to consider our paper and give constructive feedback. We address the main concerns below. Writing issues: grammatical errors, algorithms, and the structure of paper (R1, R2, R3). We thank reviewers to point out our mistakes and unclear parts of our paper. All of them will be fixed and re-organized when we publish our camera ready version. Source code: training settings, hyper parameters, and implementation details (R1, R2, R3). The training setup, hyper parameters, and implementation details were presented in our Supplementary Material due to the paper’s length limitation. We will publish the source code with all these details for further research. The baseline (R1,R2). We agreed that there maybe other recent VQA baselines in computer vision that outperforms the baseline we used. However, they are not directly applied in medical images. Furthermore, as suggested by R2, we can also integrate our multiple meta-models learning process into MEVF. This will be done in our future work. The uncertainty in the the data refinement process (R2). From our understanding, the uncertainty occurs when the model cannot produce a high enough prediction score for a specific sample during training. Regardless of the reason behind is the incorrect annotation or the highly semantic label, the most recognizable sign of this problem is the “uncertainty” probability score of training samples, i.e., the predicted score (as mentioned by R2). We agreed that there are other methods that can output uncertainty scores (e.g. using label distribution). This could be an interesting direction to improve the accuracy of the medical VQA task in the future. Example output (R3). The example outputs of our proposed MMQ will be added. References (AC). We have intensively searched for more related papers and added them to our camera ready version. Thanks for your suggestion. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Do, Tuong,Nguyen, Binh X.,Tjiputra, Erman,Tran, Minh,Tran, Quang D.,Nguyen, Anh" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Multiple Meta-model Quantifying for Medical Visual Question Answering</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Do, Tuong"
        class="post-tags">
        Do, Tuong
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Binh X."
        class="post-tags">
        Nguyen, Binh X.
      </a> |  
      
      <a href="kittywong/tags#Tjiputra, Erman"
        class="post-tags">
        Tjiputra, Erman
      </a> |  
      
      <a href="kittywong/tags#Tran, Minh"
        class="post-tags">
        Tran, Minh
      </a> |  
      
      <a href="kittywong/tags#Tran, Quang D."
        class="post-tags">
        Tran, Quang D.
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Anh"
        class="post-tags">
        Nguyen, Anh
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Tuong Do, Binh X. Nguyen, Erman Tjiputra, Minh Tran, Quang D. Tran, Anh Nguyen
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Transfer learning is an important step to extract meaningful features and overcome the data limitation in the medical Visual Question Answering (VQA) task. However, most of the existing medical VQA methods rely on external data for transfer learning, while the meta-data within the dataset is not fully utilized. In this paper, we present a new multiple meta-model quantifying method that effectively learns meta-annotation and leverages meaningful features to the medical VQA task. Our proposed method is designed to increase meta-data by auto-annotation, deal with noisy labels, and output meta-models which provide robust features for medical VQA tasks. Extensively experimental results on two public medical VQA datasets show that our approach achieves superior accuracy in comparison with other state-of-the-art methods, while does not require external data to train meta-models.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87240-3_7">https://doi.org/10.1007/978-3-030-87240-3_7</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/aioz-ai/MICCAI21_MMQ
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>VQA-RAD dataset: https://www.nature.com/articles/sdata2018251
Pathvqa dataset: https://arxiv.org/pdf/2003.10286.pdf
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes a multiple meta-model quantifying method to learn meta-annotation for pre-training and leverage the pre-trained knowledge for the medical VQA task. The proposed method aims to address some problems of meta-learning pre-training for medical VQA tasks, e.g., previous methods are heavily impacted by the meta-annotation phase for all images in the medical dataset so that noisy labels may occur when labeling images in an unsupervised manner, high-level semantic labels cause uncertainty during learning, and so on. The proposed method does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>A meta-learning pre-training method was proposed for medical VQA tasks to address some problems that exist in previous works.
 </li>
        <li>The model does not make use of additional out-of-dataset images, while achieving high accuracy in two challenging medical VQA datasets.</li>
      </ul>

      <p>The motivation and problem description are clear and significant.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>Although the model outperforms all the baseline models, the baseline models are weak.
 </li>
        <li>There are some grammar issues.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors do not provide code and other implementation details of their model. I am not sure if the results reported in this paper are reproducible.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The motivation and problem description are clear and significant.</p>

      <p>You should choose more recently proposed strong VQA methods as your baseline.</p>

      <p>You can provide more implementation details in your paper for reproducibility.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The strengths and weaknesses listed in parts 3 and 4.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The author proposed a framework using meta-learning to refine the training dataset, and showed that the pre-trained meta-learning models are useful in the downstream medical visual question answering task. The proposed method is validated on two public datasets and can outperform the MEVF method published in MICCAI 2019.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>This paper proposed a novel algorithm for the data refinement based on the predicted score from the pre-trained meta-learning model.</li>
        <li>The pre-trained meta-models are successfully applied in the visual question answering task which means the feature extractor probably learned the semantic information from the meta-training tasks.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The main contribution of this paper is using meta-learning for the data refinement, so it will be very interesting to add another baseline where the MEVF method uses meta-model pre-trained on the refined dataset to show the effectiveness of using multiple meta-learning models.</li>
        <li>The author mentioned that they used uncertainty in the data refinement process, but from what they described in the algorithm part, they were using predicted scores rather than uncertainty.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>It should be reproducible as long as the code is published.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>In generall, it is a good paper using meta-learning. Besides what mentioned in the weakness section, One thing is that the data pool used in the paper does not have unlabeled data. I believe all of them are labeled as required for the meta-training process. I guess using noisy-labeled data is more appropriate.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The data refinement part is novel. It is a good paper using meta-learning to obtain a more powerful feature extractor. It improves over the previous SOTA method. The writing can be improved and one baseline is expected as the ablation study for using multiple meta-learning models.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes an approach for VQA on two public medical datasets. In this paper MMQ, and adaption from MAML, is introced. This adapation is mostly directed to overcome the extra complications with transfer learning in medical imaging. Authors show how this meta-learning method outperforms current VQA methods, as well as how data refinement on the meta-model can increase performance.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>-creative approach in medical vqa, described accurately in the methods section
-Shown good performance against earlier methods.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>-grammatical errors and double paragraph headers
-Structure of paper is sometimes unclear
-algorithms on page 5 are not clear. It might be possible to integrate these more with the rest of the paper
-best performance in tables should be in bold for optimal clarity
-No example of output is shown</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Authors indicated to make code publicly available. Method is clearly described, but the paper is missing relevant information on training settings and hyperparameters</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Interesting contribution, with interesting results. Integration of the algorithms on page 5 with the paper and showing an example of the model output are major area’s for improvement.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Quality of writing, strucuture of paper</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The reviewers and myself agree that the paper is of high enough quality for acceptance at MICCAI. All reviewers have favorably reviewed the work, and have also provided constrcutive feedback to the paper to improve its quality. I would ask the authors to take these into account before submitted their final version. In particular, there are number of references on the topic of med-VQA that could be added.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We sincerely thank the Reviewers and the AC for taking the time to consider our paper and give constructive feedback. We address the main concerns below.</p>

  <ol>
    <li>Writing issues: grammatical errors, algorithms, and the structure of paper (R1, R2, R3).</li>
  </ol>

  <p>We thank reviewers to point out our mistakes and unclear parts of our paper. All of them will be fixed and re-organized when we publish our camera ready version.</p>

  <ol>
    <li>Source code: training settings, hyper parameters, and implementation details (R1, R2, R3).</li>
  </ol>

  <p>The training setup, hyper parameters, and implementation details were presented in our Supplementary Material due to the paper’s length limitation. We will publish the source code with all these details for further research.</p>

  <ol>
    <li>The baseline (R1,R2).</li>
  </ol>

  <p>We agreed that there maybe other recent VQA baselines in computer vision that outperforms the baseline we used. However, they are not directly applied in medical images. Furthermore, as suggested by R2, we can also integrate our multiple meta-models learning process into MEVF. This will be done in our future work.</p>

  <ol>
    <li>The uncertainty in the the data refinement process (R2).</li>
  </ol>

  <p>From our understanding, the uncertainty occurs when the model cannot produce a high enough prediction score for a specific sample during training. Regardless of the reason behind is the incorrect annotation or the highly semantic label, the most recognizable sign of this problem is the “uncertainty” probability score of training samples, i.e., the predicted score (as mentioned by R2). We agreed that there are other methods that can output uncertainty scores (e.g. using label distribution). This could be an interesting direction to improve the accuracy of the medical VQA task in the future.</p>

  <ol>
    <li>Example output (R3).</li>
  </ol>

  <p>The example outputs of our proposed MMQ will be added.</p>

  <ol>
    <li>References (AC).</li>
  </ol>

  <p>We have intensively searched for more related papers and added them to our camera ready version. Thanks for your suggestion.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0506-12-31
      -->
      <!--
      
        ,
        updated at 
        0507-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Do, Tuong"
        class="post-category">
        Do, Tuong
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Binh X."
        class="post-category">
        Nguyen, Binh X.
      </a> |  
      
      <a href="kittywong/tags#Tjiputra, Erman"
        class="post-category">
        Tjiputra, Erman
      </a> |  
      
      <a href="kittywong/tags#Tran, Minh"
        class="post-category">
        Tran, Minh
      </a> |  
      
      <a href="kittywong/tags#Tran, Quang D."
        class="post-category">
        Tran, Quang D.
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Anh"
        class="post-category">
        Nguyen, Anh
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0507/12/31/Paper0111">
          mfTrans-Net: Quantitative Measurement of Hepatocellular Carcinoma via Multi-Function Transformer Regression Network
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0505/12/31/Paper0062">
          Enhanced Breast Lesion Classification via Knowledge Guided Cross-Modal and Semantic Data Augmentation
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
