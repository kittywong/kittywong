<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Learnable Oriented-Derivative Network for Polyp Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Learnable Oriented-Derivative Network for Polyp Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Mengjun Cheng, Zishang Kong, Guoli Song, Yonghong Tian, Yongsheng Liang, Jie Chen Abstract Gastrointestinal polyps are the main cause of colorectal cancer. Given the polyp variations in terms of size, color, texture and poor optical conditions brought by endoscopy, polyp segmentation is still a challenging problem. In this paper, we propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyp segmentation. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Extensive experiments and ablation studies show that the proposed LOD-Net achieves superior performance compared to the state-of-the-art methods by a significant margin on publicly available datasets, including CVC-ClinicDB, CVC-ColonDB, Kvasir, ETIS, and EndoScene. For examples, for the dataset Kvasir, we achieve an mIoU of 88.5% vs. 82.9% by PraNet; for the dataset ETIS, we achieve an mIoU of 88.4% vs. 72.7% by PraNet. The code is available at https://github.com/midsdsy/LOD-Net. Link to paper https://doi.org/10.1007/978-3-030-87193-2_68 Link to the code repository https://github.com/midsdsy/LOD-Net Link to the dataset(s) https://github.com/DengPingFan/PraNet Reviews Review #1 Please describe the contribution of the paper This paper provides a Learnable Oriented-Derivative Network that introduces the boundary information in the segmentation and boosts the segmentation quality, especially in low-contrast regions. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is easy to follow. The figures are of good quality. Learning derivative at the boundary area and incorporating the boundary information in segmentation is a novel idea. The results look promising. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The manuscript lacks a baseline experiment that does not use any orientation gradient strategy. The baseline would be essential to demonstrate the effectiveness of the proposed idea. The model is built upon Mask R-CNN, which is not wise as Mask R-CNN is for multi-object instance segmentation. Since the dataset images are limited, it would be better to employ a lightweight architecture or detector. Some descriptions of the manuscript are not clear. Figure 4 is not even mentioned in the manuscript. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code is publicly released. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html On page 2: “we find that in feature maps, oriented derivatives of pixels in boundary regions are larger than those of other pixels” is not substantiated with figures or statistics. On page3: “However traditional methods ignore oriented derivative other than orientation of gradients, whose representation capability is insufficient” is not clear. Which traditional method do you refer to? Equation 1 and 2 should switch position. Besides, what’s the definition of normalized parameter D? In Equation 4, what is o? It would be better to introduce section 2.3 together with Figure 2. Figure 4 is not even mentioned in the manuscript. Experiment: – No validation set is employed; what’s the criterion to stop training? How to avoid overfitting? – It looks like Mask R-CNN is a very big architecture. As the manuscript only has one object in each image, it’s not wise to use a multi-object detector. It would better to clarify the number of model parameters and inference speed. – Table 2 lacks the baseline experiment without any orientation strategy. Other comments: Page 3: “a adaptive”-&gt;”an adaptive” Page 5: “Soomth”-&gt;”Smooth” Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of addressing the boundary is novel. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within object, achieving good results on four benchmarking datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea is interesting and novel. To the best of my knowledge, this is the first time that combines learned oriented derivative feature on object boundary and high-level semantic feature within object for object segmentation. Based on the experimental results, the proposed method is effective. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Some important ablation study using the same network backbone and metrics are missing. There is a MICCAI 2020 paper “Learning Directional Feature Maps for Cardiac MRI Segmentation” that shares similar idea by leveraging feature related to object boundary. Though the enhanced feature is very different, a comparison between them would still be appreciated. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors have released the code. Though I have not checked the code, I believe one can reproduce the results based on the released code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Some of my suggestions are given in the following (see also weakness part) I would like to suggest to show some qualitative illustrations in the paper. Include the ablation study in the supplementary file to the main paper and use the same metrics. Add the comparison the one related work sharing somehow similar idea. Proofread the paper. Some typos: a Adaptive –&gt; An adaptive Fig.Number –&gt; Fig. Number Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good results (see the strengths) What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper Authors propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyps. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Novelty: This paper aims to enhance the representation around boundary and refine the boundary prediction. The proposed solution of highlighting border region in feature map is novel. Experiments: Authors utilize four public polyp datasets to evaluate the proposed method and conduct extensive experiments to demonstrate the effectiveness of the proposed method. Moreover, the source code is available, which is a positive aspect of this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In Figure 2, it seems that the ground truth is an input of network, since the data flow starting from ground truth is concatenated with high-level semantic features for further processing. I wonder how to input the ground truth of test image to the network to obtain final segmentation results during inference phase. The expression of oi,j in equation (4) has not been defined. The calculation of evaluation metrics utilized in this paper is inconsistent with that in SOTA methods, such that the comparison results displayed in Table I is not convincing. I have checked the evaluation code provided by authors and that of PraNet [8]. In the provided code, authors firstly calculate the total intersect and union of whole dataset and then calculate the score of mIoU and mDice. In the code of PraNet, the mIoU and mDice is calculated by the mean of IoU and Dice score for each image rather than the whole dataset. In practice, the former one usually leads to higher scores of mIoU and mDice. However, authors directly borrow results reported from PraNet [3], which is unfair. The ablation study is insufficient. The main missing experiment results is the quantitative result of baseline model (Mask R-CNN), which ablates all the proposed components compared with ‘ours’. Moreover, it is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize four benchmark datasets to evaluate the proposed method, and the source code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The quantitative result of baseline model (Mask R-CNN) should be provided to demonstrate the effectiveness of the proposed metho. It is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Considering the novelty of paper and unconvincing experimental results, I suggest to ‘boderline reject’. This paper proposes an effective idea to boost the accurate prediction around boundary in polyp images. I am open to raise my rating if the authors can solve my questions. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 7 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within the object, achieving good results on four benchmark datasets. However, some important ablation studies using the same network backbone and metrics are missing, such as the baseline model Mask R-CNN. Moreover, some descriptions of the manuscript are not clear, including the number of model parameters, parameter settings, criteria to stop the training. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank area chair and reviewers for their appreciation and suggestions of our work. Below please check our clarifications regarding their major concerns. For Reviewer #2, Reviewer #3, Reviewer #5, and meta-reviewer: We provided more quantitative and qualitative results in our Github page, https://github.com/ midsdsy/LOD-Net. Ablation studies with baseline Mask-RCNN. We put the suggested ablation studies in the supplemental materials due to the space limitation, for example, 78.5 vs. 76.0 in CVC-ClinicDB (seen) and 54.9 vs. 51.6 in ETIS-LaribPolypDB (unseen). Moreover, in terms of the metrics for polyp segmentation, our proposed method also performs better compared to Mask-RCNN, for example by mDice and mIoU with an improvement of 1.4% and 2.6% on Kvasir (seen) and an improvement of 4.1% and 7.0% on ETIS-LaribPolypDB (unseen), respectively. Descriptions of manuscript. To be specific, the normalized parameter D in Eq.2 and Eq.3 is the Euclidean distance between the current pixel and sampled pixel. The o_{ij} in Eq.4 is the predicted oriented derivative. Training Settings. We set the hyper-parameters like learning rate and batch size according to the commonly used settings of object detectors. All of parameters are open-sourced. We stop the training based on the convergence condition of loss function. The model achieves a total loss of about 0.16 in 7k iterations and stays relatively stable in following iterations. The total number of our model parameters is 15.28M, which is trivially more than Mask R-CNN (14.76M) and less than PraNet (30.49M) and HarDNet (17.42M). Visualization. We provided the visualization of learned oriented derivatives in our Github page. For Reviewer #2: Lightweight architecture. For datasets like Kvasir and CVC-ClinicDB, one can find there are multiple polyps in an image. A multi-object detector like Mask R-CNN is thus a suitable baseline model. In addition, it should be noted that our proposed oriented-derivative representation could be implemented in both single-object and multi-object detectors so long as we replace their mask head with ours. For Reviewer #5: GT of test images. Fig.2 shows the workflow of our proposed method during training. During inference, we do not use the ground truth of test images, but use the predicted pixel-based oriented-derivative to generate the feature map with size of 28x28x256 and also use it for adaptive thresholding module and the following steps. Evaluation metrics. For the calculation of mDice and mIoU, we use the metric code of mmSegmentation which is an open-source project with 1.8k stars by OpenMMLab. Besides the difference mentioned by the reviewer, it should be noted that our code uses a simpler threshold selection policy compared to PraNet. The code from PraNet calculates a mean metric value of all images by mean of different thresholds in [1:-1/255:0], while our code only uses a fixed threshold 0.5 for evaluation. Here the results in the same metrics, for example, by mIoU we achieved 88.45% vs. 82.87% by PraNet in Kvasir (seen) and we achieved 88.37% vs. 72.71% by PraNet in ETIS (unseen). More results are shown in our Github page. In addition, we will update the results in our final manuscript. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Mengjun Cheng, Zishang Kong, Guoli Song, Yonghong Tian, Yongsheng Liang, Jie Chen Abstract Gastrointestinal polyps are the main cause of colorectal cancer. Given the polyp variations in terms of size, color, texture and poor optical conditions brought by endoscopy, polyp segmentation is still a challenging problem. In this paper, we propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyp segmentation. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Extensive experiments and ablation studies show that the proposed LOD-Net achieves superior performance compared to the state-of-the-art methods by a significant margin on publicly available datasets, including CVC-ClinicDB, CVC-ColonDB, Kvasir, ETIS, and EndoScene. For examples, for the dataset Kvasir, we achieve an mIoU of 88.5% vs. 82.9% by PraNet; for the dataset ETIS, we achieve an mIoU of 88.4% vs. 72.7% by PraNet. The code is available at https://github.com/midsdsy/LOD-Net. Link to paper https://doi.org/10.1007/978-3-030-87193-2_68 Link to the code repository https://github.com/midsdsy/LOD-Net Link to the dataset(s) https://github.com/DengPingFan/PraNet Reviews Review #1 Please describe the contribution of the paper This paper provides a Learnable Oriented-Derivative Network that introduces the boundary information in the segmentation and boosts the segmentation quality, especially in low-contrast regions. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is easy to follow. The figures are of good quality. Learning derivative at the boundary area and incorporating the boundary information in segmentation is a novel idea. The results look promising. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The manuscript lacks a baseline experiment that does not use any orientation gradient strategy. The baseline would be essential to demonstrate the effectiveness of the proposed idea. The model is built upon Mask R-CNN, which is not wise as Mask R-CNN is for multi-object instance segmentation. Since the dataset images are limited, it would be better to employ a lightweight architecture or detector. Some descriptions of the manuscript are not clear. Figure 4 is not even mentioned in the manuscript. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code is publicly released. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html On page 2: “we find that in feature maps, oriented derivatives of pixels in boundary regions are larger than those of other pixels” is not substantiated with figures or statistics. On page3: “However traditional methods ignore oriented derivative other than orientation of gradients, whose representation capability is insufficient” is not clear. Which traditional method do you refer to? Equation 1 and 2 should switch position. Besides, what’s the definition of normalized parameter D? In Equation 4, what is o? It would be better to introduce section 2.3 together with Figure 2. Figure 4 is not even mentioned in the manuscript. Experiment: – No validation set is employed; what’s the criterion to stop training? How to avoid overfitting? – It looks like Mask R-CNN is a very big architecture. As the manuscript only has one object in each image, it’s not wise to use a multi-object detector. It would better to clarify the number of model parameters and inference speed. – Table 2 lacks the baseline experiment without any orientation strategy. Other comments: Page 3: “a adaptive”-&gt;”an adaptive” Page 5: “Soomth”-&gt;”Smooth” Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of addressing the boundary is novel. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within object, achieving good results on four benchmarking datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea is interesting and novel. To the best of my knowledge, this is the first time that combines learned oriented derivative feature on object boundary and high-level semantic feature within object for object segmentation. Based on the experimental results, the proposed method is effective. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Some important ablation study using the same network backbone and metrics are missing. There is a MICCAI 2020 paper “Learning Directional Feature Maps for Cardiac MRI Segmentation” that shares similar idea by leveraging feature related to object boundary. Though the enhanced feature is very different, a comparison between them would still be appreciated. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors have released the code. Though I have not checked the code, I believe one can reproduce the results based on the released code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Some of my suggestions are given in the following (see also weakness part) I would like to suggest to show some qualitative illustrations in the paper. Include the ablation study in the supplementary file to the main paper and use the same metrics. Add the comparison the one related work sharing somehow similar idea. Proofread the paper. Some typos: a Adaptive –&gt; An adaptive Fig.Number –&gt; Fig. Number Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good results (see the strengths) What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper Authors propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyps. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Novelty: This paper aims to enhance the representation around boundary and refine the boundary prediction. The proposed solution of highlighting border region in feature map is novel. Experiments: Authors utilize four public polyp datasets to evaluate the proposed method and conduct extensive experiments to demonstrate the effectiveness of the proposed method. Moreover, the source code is available, which is a positive aspect of this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In Figure 2, it seems that the ground truth is an input of network, since the data flow starting from ground truth is concatenated with high-level semantic features for further processing. I wonder how to input the ground truth of test image to the network to obtain final segmentation results during inference phase. The expression of oi,j in equation (4) has not been defined. The calculation of evaluation metrics utilized in this paper is inconsistent with that in SOTA methods, such that the comparison results displayed in Table I is not convincing. I have checked the evaluation code provided by authors and that of PraNet [8]. In the provided code, authors firstly calculate the total intersect and union of whole dataset and then calculate the score of mIoU and mDice. In the code of PraNet, the mIoU and mDice is calculated by the mean of IoU and Dice score for each image rather than the whole dataset. In practice, the former one usually leads to higher scores of mIoU and mDice. However, authors directly borrow results reported from PraNet [3], which is unfair. The ablation study is insufficient. The main missing experiment results is the quantitative result of baseline model (Mask R-CNN), which ablates all the proposed components compared with ‘ours’. Moreover, it is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize four benchmark datasets to evaluate the proposed method, and the source code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The quantitative result of baseline model (Mask R-CNN) should be provided to demonstrate the effectiveness of the proposed metho. It is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Considering the novelty of paper and unconvincing experimental results, I suggest to ‘boderline reject’. This paper proposes an effective idea to boost the accurate prediction around boundary in polyp images. I am open to raise my rating if the authors can solve my questions. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 7 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within the object, achieving good results on four benchmark datasets. However, some important ablation studies using the same network backbone and metrics are missing, such as the baseline model Mask R-CNN. Moreover, some descriptions of the manuscript are not clear, including the number of model parameters, parameter settings, criteria to stop the training. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank area chair and reviewers for their appreciation and suggestions of our work. Below please check our clarifications regarding their major concerns. For Reviewer #2, Reviewer #3, Reviewer #5, and meta-reviewer: We provided more quantitative and qualitative results in our Github page, https://github.com/ midsdsy/LOD-Net. Ablation studies with baseline Mask-RCNN. We put the suggested ablation studies in the supplemental materials due to the space limitation, for example, 78.5 vs. 76.0 in CVC-ClinicDB (seen) and 54.9 vs. 51.6 in ETIS-LaribPolypDB (unseen). Moreover, in terms of the metrics for polyp segmentation, our proposed method also performs better compared to Mask-RCNN, for example by mDice and mIoU with an improvement of 1.4% and 2.6% on Kvasir (seen) and an improvement of 4.1% and 7.0% on ETIS-LaribPolypDB (unseen), respectively. Descriptions of manuscript. To be specific, the normalized parameter D in Eq.2 and Eq.3 is the Euclidean distance between the current pixel and sampled pixel. The o_{ij} in Eq.4 is the predicted oriented derivative. Training Settings. We set the hyper-parameters like learning rate and batch size according to the commonly used settings of object detectors. All of parameters are open-sourced. We stop the training based on the convergence condition of loss function. The model achieves a total loss of about 0.16 in 7k iterations and stays relatively stable in following iterations. The total number of our model parameters is 15.28M, which is trivially more than Mask R-CNN (14.76M) and less than PraNet (30.49M) and HarDNet (17.42M). Visualization. We provided the visualization of learned oriented derivatives in our Github page. For Reviewer #2: Lightweight architecture. For datasets like Kvasir and CVC-ClinicDB, one can find there are multiple polyps in an image. A multi-object detector like Mask R-CNN is thus a suitable baseline model. In addition, it should be noted that our proposed oriented-derivative representation could be implemented in both single-object and multi-object detectors so long as we replace their mask head with ours. For Reviewer #5: GT of test images. Fig.2 shows the workflow of our proposed method during training. During inference, we do not use the ground truth of test images, but use the predicted pixel-based oriented-derivative to generate the feature map with size of 28x28x256 and also use it for adaptive thresholding module and the following steps. Evaluation metrics. For the calculation of mDice and mIoU, we use the metric code of mmSegmentation which is an open-source project with 1.8k stars by OpenMMLab. Besides the difference mentioned by the reviewer, it should be noted that our code uses a simpler threshold selection policy compared to PraNet. The code from PraNet calculates a mean metric value of all images by mean of different thresholds in [1:-1/255:0], while our code only uses a fixed threshold 0.5 for evaluation. Here the results in the same metrics, for example, by mIoU we achieved 88.45% vs. 82.87% by PraNet in Kvasir (seen) and we achieved 88.37% vs. 72.71% by PraNet in ETIS (unseen). More results are shown in our Github page. In addition, we will update the results in our final manuscript. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0167/12/31/Paper2375" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0167/12/31/Paper2375" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0167-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Learnable Oriented-Derivative Network for Polyp Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0167/12/31/Paper2375"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0167/12/31/Paper2375","headline":"Learnable Oriented-Derivative Network for Polyp Segmentation","dateModified":"0167-12-31T00:00:00-05:17","datePublished":"0167-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Mengjun Cheng, Zishang Kong, Guoli Song, Yonghong Tian, Yongsheng Liang, Jie Chen Abstract Gastrointestinal polyps are the main cause of colorectal cancer. Given the polyp variations in terms of size, color, texture and poor optical conditions brought by endoscopy, polyp segmentation is still a challenging problem. In this paper, we propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyp segmentation. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Extensive experiments and ablation studies show that the proposed LOD-Net achieves superior performance compared to the state-of-the-art methods by a significant margin on publicly available datasets, including CVC-ClinicDB, CVC-ColonDB, Kvasir, ETIS, and EndoScene. For examples, for the dataset Kvasir, we achieve an mIoU of 88.5% vs. 82.9% by PraNet; for the dataset ETIS, we achieve an mIoU of 88.4% vs. 72.7% by PraNet. The code is available at https://github.com/midsdsy/LOD-Net. Link to paper https://doi.org/10.1007/978-3-030-87193-2_68 Link to the code repository https://github.com/midsdsy/LOD-Net Link to the dataset(s) https://github.com/DengPingFan/PraNet Reviews Review #1 Please describe the contribution of the paper This paper provides a Learnable Oriented-Derivative Network that introduces the boundary information in the segmentation and boosts the segmentation quality, especially in low-contrast regions. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is easy to follow. The figures are of good quality. Learning derivative at the boundary area and incorporating the boundary information in segmentation is a novel idea. The results look promising. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The manuscript lacks a baseline experiment that does not use any orientation gradient strategy. The baseline would be essential to demonstrate the effectiveness of the proposed idea. The model is built upon Mask R-CNN, which is not wise as Mask R-CNN is for multi-object instance segmentation. Since the dataset images are limited, it would be better to employ a lightweight architecture or detector. Some descriptions of the manuscript are not clear. Figure 4 is not even mentioned in the manuscript. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The code is publicly released. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html On page 2: “we find that in feature maps, oriented derivatives of pixels in boundary regions are larger than those of other pixels” is not substantiated with figures or statistics. On page3: “However traditional methods ignore oriented derivative other than orientation of gradients, whose representation capability is insufficient” is not clear. Which traditional method do you refer to? Equation 1 and 2 should switch position. Besides, what’s the definition of normalized parameter D? In Equation 4, what is o? It would be better to introduce section 2.3 together with Figure 2. Figure 4 is not even mentioned in the manuscript. Experiment: – No validation set is employed; what’s the criterion to stop training? How to avoid overfitting? – It looks like Mask R-CNN is a very big architecture. As the manuscript only has one object in each image, it’s not wise to use a multi-object detector. It would better to clarify the number of model parameters and inference speed. – Table 2 lacks the baseline experiment without any orientation strategy. Other comments: Page 3: “a adaptive”-&gt;”an adaptive” Page 5: “Soomth”-&gt;”Smooth” Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of addressing the boundary is novel. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within object, achieving good results on four benchmarking datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea is interesting and novel. To the best of my knowledge, this is the first time that combines learned oriented derivative feature on object boundary and high-level semantic feature within object for object segmentation. Based on the experimental results, the proposed method is effective. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Some important ablation study using the same network backbone and metrics are missing. There is a MICCAI 2020 paper “Learning Directional Feature Maps for Cardiac MRI Segmentation” that shares similar idea by leveraging feature related to object boundary. Though the enhanced feature is very different, a comparison between them would still be appreciated. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors have released the code. Though I have not checked the code, I believe one can reproduce the results based on the released code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Some of my suggestions are given in the following (see also weakness part) I would like to suggest to show some qualitative illustrations in the paper. Include the ablation study in the supplementary file to the main paper and use the same metrics. Add the comparison the one related work sharing somehow similar idea. Proofread the paper. Some typos: a Adaptive –&gt; An adaptive Fig.Number –&gt; Fig. Number Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good results (see the strengths) What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper Authors propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyps. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Novelty: This paper aims to enhance the representation around boundary and refine the boundary prediction. The proposed solution of highlighting border region in feature map is novel. Experiments: Authors utilize four public polyp datasets to evaluate the proposed method and conduct extensive experiments to demonstrate the effectiveness of the proposed method. Moreover, the source code is available, which is a positive aspect of this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In Figure 2, it seems that the ground truth is an input of network, since the data flow starting from ground truth is concatenated with high-level semantic features for further processing. I wonder how to input the ground truth of test image to the network to obtain final segmentation results during inference phase. The expression of oi,j in equation (4) has not been defined. The calculation of evaluation metrics utilized in this paper is inconsistent with that in SOTA methods, such that the comparison results displayed in Table I is not convincing. I have checked the evaluation code provided by authors and that of PraNet [8]. In the provided code, authors firstly calculate the total intersect and union of whole dataset and then calculate the score of mIoU and mDice. In the code of PraNet, the mIoU and mDice is calculated by the mean of IoU and Dice score for each image rather than the whole dataset. In practice, the former one usually leads to higher scores of mIoU and mDice. However, authors directly borrow results reported from PraNet [3], which is unfair. The ablation study is insufficient. The main missing experiment results is the quantitative result of baseline model (Mask R-CNN), which ablates all the proposed components compared with ‘ours’. Moreover, it is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors utilize four benchmark datasets to evaluate the proposed method, and the source code is available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The quantitative result of baseline model (Mask R-CNN) should be provided to demonstrate the effectiveness of the proposed metho. It is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Considering the novelty of paper and unconvincing experimental results, I suggest to ‘boderline reject’. This paper proposes an effective idea to boost the accurate prediction around boundary in polyp images. I am open to raise my rating if the authors can solve my questions. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 7 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within the object, achieving good results on four benchmark datasets. However, some important ablation studies using the same network backbone and metrics are missing, such as the baseline model Mask R-CNN. Moreover, some descriptions of the manuscript are not clear, including the number of model parameters, parameter settings, criteria to stop the training. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank area chair and reviewers for their appreciation and suggestions of our work. Below please check our clarifications regarding their major concerns. For Reviewer #2, Reviewer #3, Reviewer #5, and meta-reviewer: We provided more quantitative and qualitative results in our Github page, https://github.com/ midsdsy/LOD-Net. Ablation studies with baseline Mask-RCNN. We put the suggested ablation studies in the supplemental materials due to the space limitation, for example, 78.5 vs. 76.0 in CVC-ClinicDB (seen) and 54.9 vs. 51.6 in ETIS-LaribPolypDB (unseen). Moreover, in terms of the metrics for polyp segmentation, our proposed method also performs better compared to Mask-RCNN, for example by mDice and mIoU with an improvement of 1.4% and 2.6% on Kvasir (seen) and an improvement of 4.1% and 7.0% on ETIS-LaribPolypDB (unseen), respectively. Descriptions of manuscript. To be specific, the normalized parameter D in Eq.2 and Eq.3 is the Euclidean distance between the current pixel and sampled pixel. The o_{ij} in Eq.4 is the predicted oriented derivative. Training Settings. We set the hyper-parameters like learning rate and batch size according to the commonly used settings of object detectors. All of parameters are open-sourced. We stop the training based on the convergence condition of loss function. The model achieves a total loss of about 0.16 in 7k iterations and stays relatively stable in following iterations. The total number of our model parameters is 15.28M, which is trivially more than Mask R-CNN (14.76M) and less than PraNet (30.49M) and HarDNet (17.42M). Visualization. We provided the visualization of learned oriented derivatives in our Github page. For Reviewer #2: Lightweight architecture. For datasets like Kvasir and CVC-ClinicDB, one can find there are multiple polyps in an image. A multi-object detector like Mask R-CNN is thus a suitable baseline model. In addition, it should be noted that our proposed oriented-derivative representation could be implemented in both single-object and multi-object detectors so long as we replace their mask head with ours. For Reviewer #5: GT of test images. Fig.2 shows the workflow of our proposed method during training. During inference, we do not use the ground truth of test images, but use the predicted pixel-based oriented-derivative to generate the feature map with size of 28x28x256 and also use it for adaptive thresholding module and the following steps. Evaluation metrics. For the calculation of mDice and mIoU, we use the metric code of mmSegmentation which is an open-source project with 1.8k stars by OpenMMLab. Besides the difference mentioned by the reviewer, it should be noted that our code uses a simpler threshold selection policy compared to PraNet. The code from PraNet calculates a mean metric value of all images by mean of different thresholds in [1:-1/255:0], while our code only uses a fixed threshold 0.5 for evaluation. Here the results in the same metrics, for example, by mIoU we achieved 88.45% vs. 82.87% by PraNet in Kvasir (seen) and we achieved 88.37% vs. 72.71% by PraNet in ETIS (unseen). More results are shown in our Github page. In addition, we will update the results in our final manuscript. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Cheng, Mengjun,Kong, Zishang,Song, Guoli,Tian, Yonghong,Liang, Yongsheng,Chen, Jie" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Learnable Oriented-Derivative Network for Polyp Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Cheng, Mengjun"
        class="post-tags">
        Cheng, Mengjun
      </a> |  
      
      <a href="kittywong/tags#Kong, Zishang"
        class="post-tags">
        Kong, Zishang
      </a> |  
      
      <a href="kittywong/tags#Song, Guoli"
        class="post-tags">
        Song, Guoli
      </a> |  
      
      <a href="kittywong/tags#Tian, Yonghong"
        class="post-tags">
        Tian, Yonghong
      </a> |  
      
      <a href="kittywong/tags#Liang, Yongsheng"
        class="post-tags">
        Liang, Yongsheng
      </a> |  
      
      <a href="kittywong/tags#Chen, Jie"
        class="post-tags">
        Chen, Jie
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Mengjun Cheng, Zishang Kong, Guoli Song, Yonghong Tian, Yongsheng Liang, Jie Chen
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Gastrointestinal polyps are the main cause of colorectal cancer.<br />
Given the polyp variations in terms of size, color, texture and poor optical conditions brought by endoscopy, polyp segmentation is still a challenging problem. In this paper, we propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyp segmentation. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network. Extensive experiments and ablation studies show that the proposed LOD-Net achieves superior performance compared to the state-of-the-art methods by a significant margin on publicly available datasets, including CVC-ClinicDB, CVC-ColonDB, Kvasir, ETIS, and EndoScene. For examples,  for the dataset Kvasir, we achieve an mIoU of 88.5% vs. 82.9% by PraNet; for the dataset ETIS, we achieve an mIoU of 88.4% vs. 72.7% by PraNet. The code is available at https://github.com/midsdsy/LOD-Net.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87193-2_68">https://doi.org/10.1007/978-3-030-87193-2_68</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/midsdsy/LOD-Net
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://github.com/DengPingFan/PraNet
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper provides a Learnable Oriented-Derivative Network that introduces the boundary information in the segmentation and boosts the segmentation quality, especially in low-contrast regions.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The paper is easy to follow. The figures are of good quality.</li>
        <li>Learning derivative at the boundary area and incorporating the boundary information in segmentation is a novel idea.</li>
        <li>The results look promising.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The manuscript lacks a baseline experiment that does not use any orientation gradient strategy. The baseline would be essential to demonstrate the effectiveness of the proposed idea.</li>
        <li>The model is built upon Mask R-CNN, which is not wise as Mask R-CNN is for multi-object instance segmentation. Since the dataset images are limited, it would be better to employ a lightweight architecture or detector.</li>
        <li>Some descriptions of the manuscript are not clear. Figure 4 is not even mentioned in the manuscript.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The code is publicly released.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>On page 2: “we find that in feature maps, oriented derivatives of pixels in boundary regions are larger than those of other pixels” is not substantiated with figures or statistics.</li>
        <li>On page3: “However traditional methods ignore oriented derivative other than orientation of gradients, whose representation capability is insufficient” is not clear. Which traditional method do you refer to?</li>
        <li>Equation 1 and 2 should switch position. Besides, what’s the definition of normalized parameter D?</li>
        <li>In Equation 4, what is o?</li>
        <li>It would be better to introduce section 2.3 together with Figure 2.</li>
        <li>Figure 4 is not even mentioned in the manuscript.</li>
        <li>Experiment:
     – No validation set is employed; what’s the criterion to stop training? How to avoid overfitting?
     – It looks like Mask R-CNN is a very big architecture. As the manuscript only has one object in each image, it’s not wise to use a multi-object detector.  It would better to clarify the number of model parameters and inference speed.
    – Table 2 lacks the baseline experiment without any orientation strategy.</li>
      </ul>

      <p>Other comments:</p>
      <ul>
        <li>Page 3: “a adaptive”-&gt;”an adaptive”</li>
        <li>Page 5: “Soomth”-&gt;”Smooth”</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The idea of addressing the boundary is novel.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Somewhat confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within object, achieving good results on four benchmarking datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The idea is interesting and novel. To the best of my knowledge, this is the first time that combines learned oriented derivative feature on object boundary and high-level semantic feature within object for object segmentation.</li>
        <li>Based on the experimental results, the proposed method is effective.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>Some important ablation study using the same network backbone and  metrics are missing.</li>
        <li>There is a MICCAI 2020 paper “Learning Directional Feature Maps for Cardiac MRI Segmentation” that shares similar idea by leveraging feature related to object boundary. Though the enhanced feature is very different, a comparison between them would still be appreciated.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors have released the code. Though I have not checked the code, I believe one can reproduce the results based on the released code.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Some of my suggestions are given in the following (see also weakness part)
I would like to suggest to show some qualitative illustrations in the paper.
Include the ablation study in the supplementary file to the main paper and use the same metrics.
Add the comparison the one related work sharing somehow similar idea.
Proofread the paper. Some typos:
a Adaptive –&gt; An adaptive 
Fig.Number –&gt; Fig. Number</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Interesting idea and good results (see the strengths)</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>Authors propose a Learnable Oriented-Derivative Network (LOD-Net) to refine the accuracy of boundary predictions for polyps. Specifically, it firstly calculates eight oriented derivatives at each pixel for a polyp. It then selects those pixels with large oriented-derivative values to constitute a candidate border region of a polyp. It finally refines boundary prediction by fusing border region features and also those high-level semantic features calculated by a backbone network.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>Novelty: This paper aims to enhance the representation around boundary and refine the boundary prediction. The proposed solution of highlighting border region in feature map is novel.</li>
        <li>Experiments: Authors utilize four public polyp datasets to evaluate the proposed method and conduct extensive experiments to demonstrate the effectiveness of the proposed method. Moreover, the source code is available, which is a positive aspect of this paper.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>In Figure 2, it seems that the ground truth is an input of network, since the data flow starting from ground truth is concatenated with high-level semantic features for further processing. I wonder how to input the ground truth of test image to the network to obtain final segmentation results during inference phase.</li>
        <li>The expression of oi,j in equation (4) has not been defined.</li>
        <li>The calculation of evaluation metrics utilized in this paper is inconsistent with that in SOTA methods, such that the comparison results displayed in Table I is not convincing. I have checked the evaluation code provided by authors and that of PraNet [8]. In the provided code, authors firstly calculate the total intersect and union of whole dataset and then calculate the score of mIoU and mDice. In the code of PraNet, the mIoU and mDice is calculated by the mean of IoU and Dice score for each image rather than the whole dataset. In practice, the former one usually leads to higher scores of mIoU and mDice. However, authors directly borrow results reported from PraNet [3], which is unfair.</li>
        <li>The ablation study is insufficient. The main missing experiment results is the quantitative result of baseline model (Mask R-CNN), which ablates all the proposed components compared with ‘ours’. Moreover, it is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Authors utilize four benchmark datasets to evaluate the proposed method, and the source code is available.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>The quantitative result of baseline model (Mask R-CNN) should be provided to demonstrate the effectiveness of the proposed metho.</li>
        <li>It is suggested that visualization of learned offset map or oriented derivatives should be presented to help reader better understand the proposed method.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Considering the novelty of paper and unconvincing experimental results, I suggest to ‘boderline reject’.</p>

      <p>This paper proposes an effective idea to boost the accurate prediction around boundary in polyp images. I am open to raise my rating if the authors can solve my questions.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>7</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper presents a novel method by fusing learned oriented derivative feature on object boundary and high-level semantic feature within the object, achieving good results on four benchmark datasets. However, some important ablation studies using the same network backbone and metrics are missing, such as the baseline model Mask R-CNN. Moreover, some descriptions of the manuscript are not clear, including the number of model parameters, parameter settings, criteria to stop the training.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank area chair and reviewers for their appreciation and suggestions of our work. Below please check our clarifications regarding their major concerns.</p>

  <p>For Reviewer #2, Reviewer #3, Reviewer #5, and meta-reviewer:
We provided more quantitative and qualitative results in our Github page,  https://github.com/ midsdsy/LOD-Net.</p>
  <ul>
    <li>Ablation studies with baseline Mask-RCNN. We put the suggested ablation studies in the supplemental materials due to the space limitation, for example, 78.5 vs. 76.0 in CVC-ClinicDB (seen) and 54.9 vs. 51.6 in ETIS-LaribPolypDB (unseen). Moreover, in terms of the metrics for polyp segmentation, our proposed method also performs better compared to Mask-RCNN, for example by mDice and mIoU with an improvement of 1.4% and 2.6% on Kvasir (seen) and an improvement of 4.1% and 7.0% on ETIS-LaribPolypDB (unseen), respectively.</li>
    <li>Descriptions of manuscript. To be specific, the normalized parameter D in Eq.2 and Eq.3 is the Euclidean distance between the current pixel and sampled pixel. The o_{ij} in Eq.4 is the predicted oriented derivative.</li>
    <li>Training Settings. We set the hyper-parameters like learning rate and batch size according to the commonly used settings of object detectors. All of parameters are open-sourced. We stop the training based on the convergence condition of loss function. The model achieves a total loss of about 0.16 in 7k iterations and stays relatively stable in following iterations. The total number of our model parameters is 15.28M, which is trivially more than Mask R-CNN (14.76M) and less than PraNet (30.49M) and HarDNet (17.42M).</li>
    <li>Visualization. We provided the visualization of learned oriented derivatives in our Github page.</li>
  </ul>

  <p>For Reviewer #2:</p>
  <ul>
    <li>Lightweight architecture. For datasets like Kvasir and CVC-ClinicDB, one can find there are multiple polyps in an image. A multi-object detector like Mask R-CNN is thus a suitable baseline model. In addition, it should be noted that our proposed oriented-derivative representation could be implemented in both single-object and multi-object detectors so long as we replace their mask head with ours.</li>
  </ul>

  <p>For Reviewer #5:</p>
  <ul>
    <li>GT of test images. Fig.2 shows the workflow of our proposed method during training. During inference, we do not use the ground truth of test images, but use the predicted pixel-based oriented-derivative to generate the feature map with size of 28x28x256 and also use it for adaptive thresholding module and the following steps.</li>
    <li>Evaluation metrics.  For the calculation of mDice and mIoU, we use the metric code of mmSegmentation which is an open-source project with 1.8k stars by OpenMMLab. Besides the difference mentioned by the reviewer, it should be noted that our code uses a simpler threshold selection policy compared to PraNet. The code from PraNet calculates a mean metric value of all images by mean of different thresholds in [1:-1/255:0], while our code only uses a fixed threshold 0.5 for evaluation. Here the results in the same metrics, for example, by mIoU we achieved 88.45% vs. 82.87% by PraNet in Kvasir (seen) and we achieved 88.37% vs. 72.71% by PraNet in ETIS (unseen). More results are shown in our Github page. In addition, we will update the results in our final manuscript.</li>
  </ul>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0167-12-31
      -->
      <!--
      
        ,
        updated at 
        0168-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Cheng, Mengjun"
        class="post-category">
        Cheng, Mengjun
      </a> |  
      
      <a href="kittywong/tags#Kong, Zishang"
        class="post-category">
        Kong, Zishang
      </a> |  
      
      <a href="kittywong/tags#Song, Guoli"
        class="post-category">
        Song, Guoli
      </a> |  
      
      <a href="kittywong/tags#Tian, Yonghong"
        class="post-category">
        Tian, Yonghong
      </a> |  
      
      <a href="kittywong/tags#Liang, Yongsheng"
        class="post-category">
        Liang, Yongsheng
      </a> |  
      
      <a href="kittywong/tags#Chen, Jie"
        class="post-category">
        Chen, Jie
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0168/12/31/Paper2447">
          LambdaUNet: 2.5D Stroke Lesion Segmentation of Diffusion-weighted MR Images
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0166/12/31/Paper2349">
          A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
