<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Source-Free Domain Adaptive Fundus Image Segmentation with Denoised Pseudo-Labeling | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Source-Free Domain Adaptive Fundus Image Segmentation with Denoised Pseudo-Labeling" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, Pheng-Ann Heng Abstract Domain adaptation typically requires to access source domain data to utilize their distribution information for domain alignment with the target data. However, in many real-world scenarios, the source data may not be accessible during the model adaptation in the target domain due to privacy issue. This paper studies the practical yet challenging source-free unsupervised domain adaptation problem, in which only an existing source model and the unlabeled target data are available for model adaptation. We present a novel denoised pseudo-labeling method for this problem, which effectively makes use of the source model and unlabeled target data to promote model self-adaptation from pseudo labels. Importantly, considering that the pseudo labels generated from source model are inevitably noisy due to domain shift, we further introduce two complementary pixel-level and class-level denoising schemes with uncertainty estimation and prototype estimation to reduce noisy pseudo labels and select reliable ones to enhance the pseudo-labeling efficacy. Experimental results on cross-domain fundus image segmentation show that without using any source images or altering source training, our approach achieves comparable or even higher performance than state-of-the-art source-dependent unsupervised domain adaptation methods. Link to paper https://doi.org/10.1007/978-3-030-87240-3_22 Link to the code repository https://github.com/cchen-cc/SFDA-DPL Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The authors propose a new setting for the unsupervised domain adaptation on fundus image segmentation. In this setting, we only have access to the pertained model on the source domain and the unlabeled data on the target domain. Secondly, this paper proposes a method to create the pseudo label from the target domain for self-training. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The new proposed setting is quite interesting and more realistic for real-life applications. The author applies the uncertainty method to de-noise pixel-level pseudo label and prototype feature for class level de-noise. The experiments are sufficient and achieve superior performance than the baseline methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The Monto-Carlo dropout uncertainty and the prototype de-noise are already proposed by the previous method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sufficient details for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The idea of this paper is quite interesting; more experiments on different datasets would be great. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good technical quality. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors introduce a new unsupervised domain adaptation (UDA) task, where source data can not be accessed nor can alter source training. They also present a self-training method for this task, and they further propose a denoising method, with a class-level and pixel-level denoising scheme, to denoise the pseudo labels in self-training and gain a better performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors introduce a new UDA task, which has high practical value under the data privacy and security issues in medical field. The authors propose a self-training method, which seems achieve a good performance in this task. The authors propose a denoising method to denoise the pseudo labels in the self-training, which helps gain better performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. The reasons to exploit the denoising method is not well discussed. In fact, the proposed denoising method can also serviced as post-processing. What is the advantage of exploiting it to denoise the pseudo labels rather than the final segmented results. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1.The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. 2.The proposed denoising method can be better justified by exploiting it as post-processing 3.In the first sentence of Ablation study, ‘complonent’ should be ‘component’ 4.In Fig. 3, it would be better to present the correct recognized noise and wrongly recognized noise. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors introduce a new and meaningful task, and they also proposed a method for this task with well performance. However, the proposed method is not well justified. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper tackles Source-Free Unsupervised Domain Adaptation for image segmentation, i.e. adaptation using only a model trained on unavailable source data and unlabeled target images. The adaptation is done through self-training in the target domain, generating pseudo-labels. This classical method improved by filtering out “unreliable” pseudo-labels, as measured by two distinct uncertainty measures. The first is calculated at the pixel-level, using the variance of prediction maps generated by stochastic dropout. The second is calculated at the class-level, using the distance of features to the estimated class centroid. Experiments are done on one application: retinal fundus images, using 3 datasets collected from different clinical centers with distribution shifts. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of source free domain adaptation (SFDA) is still novel in the medical imaging community and is valuable in practical settings, where source data is often unavailable. The paper is well written and easy to follow. The motivation and the method are well explained. The method draws from a combination of losses and concepts which have been proven effective in other settings, and their application and combination to SFDA is novel. 3.Sufficient experimental section: Although one application only is tackled, retinal fundus images, experiments are done on 2 different target datasets; Comparison to various SOTA methods; Ablation study is done to investigate the effect of each component in the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. There is an assumption of closeness in this paper between the source and target domain, that the domain shift is not too wide. Indeed, the experimental setting is one where both source and target datasets are from the same image modality, the shift comes from scanner differences, which, as authors not, is generally minor compared with cross-modality discrepancy (ex. CT to MRI). As a result, the lower baseline “no adaptation” is already very high, 83.2 Dice (for RIM-ONE-r3) and 93.84 (for Drishti-GS) respectively. In more general settings with bigger domain shifts, the method’s efficiency may not hold. This is not discussed in the paper. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has sufficient details about the framework, hyperparameters choosing, and evaluation. The datasets used are public fundus image datasets. However, the paper doesn’t mention any code available, which limits reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In settings with bigger domain shifts, it is common to that a network’s predictions are skewed towards the dominant class, ex. the background, resulting in “undersegmentations” (see, for ex, [1], Figure 3, Seg-CT-noDA). Could the proposed method “get out” of such a situation, if it only keeps to “non-noisy” pseudo labels ? Did authors see a general tendency to undersegmentation in the output segmentation masks, and if not so, how come ? [1] Dou et al, PnP-AdaNet: Plug-and-Play Adversarial Domain Adaptation Network with a Benchmark at Cross-modality Cardiac Segmentation, IEEE TMI. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper tackles an interesting and original problem,source free domain adaptation, and explores the potential quite simple and well motivated measures of uncertainty to improve classical self-training schemes. The paper is well written, easy to follow. The method is simple, easy to implement and well-motivated, with only one network to optimize, making it easier than SOTA adversarial methods. I find it particularly interesting to show that simple and sound uncertainty measures help select the best pixels to improve self-training. I believe this is an intersesting contribution to the MICCAI community. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All reviewers appreciated the novel experimental setting, i.e., source-free unsupervised domain adaptation. While reviewers provided positive comments (probably/borderline/probably accept), they gave some suggestions to improve the manuscript, e.g., clarify the necessity of using the denoising method for pseudo labels, discuss if the proposed method can handle big domain shifts, and provide a better illustration of Fig. 3. Please consider these suggestions when preparing the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank all the reviewers and meta-reviewer for the affirmative comments on recognizing the novel source free domain adaptation setting and sufficient experimental evaluation of our method. We will include the reviewers’ suggestions in our final version and carefully proofread our paper. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, Pheng-Ann Heng Abstract Domain adaptation typically requires to access source domain data to utilize their distribution information for domain alignment with the target data. However, in many real-world scenarios, the source data may not be accessible during the model adaptation in the target domain due to privacy issue. This paper studies the practical yet challenging source-free unsupervised domain adaptation problem, in which only an existing source model and the unlabeled target data are available for model adaptation. We present a novel denoised pseudo-labeling method for this problem, which effectively makes use of the source model and unlabeled target data to promote model self-adaptation from pseudo labels. Importantly, considering that the pseudo labels generated from source model are inevitably noisy due to domain shift, we further introduce two complementary pixel-level and class-level denoising schemes with uncertainty estimation and prototype estimation to reduce noisy pseudo labels and select reliable ones to enhance the pseudo-labeling efficacy. Experimental results on cross-domain fundus image segmentation show that without using any source images or altering source training, our approach achieves comparable or even higher performance than state-of-the-art source-dependent unsupervised domain adaptation methods. Link to paper https://doi.org/10.1007/978-3-030-87240-3_22 Link to the code repository https://github.com/cchen-cc/SFDA-DPL Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The authors propose a new setting for the unsupervised domain adaptation on fundus image segmentation. In this setting, we only have access to the pertained model on the source domain and the unlabeled data on the target domain. Secondly, this paper proposes a method to create the pseudo label from the target domain for self-training. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The new proposed setting is quite interesting and more realistic for real-life applications. The author applies the uncertainty method to de-noise pixel-level pseudo label and prototype feature for class level de-noise. The experiments are sufficient and achieve superior performance than the baseline methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The Monto-Carlo dropout uncertainty and the prototype de-noise are already proposed by the previous method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sufficient details for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The idea of this paper is quite interesting; more experiments on different datasets would be great. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good technical quality. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors introduce a new unsupervised domain adaptation (UDA) task, where source data can not be accessed nor can alter source training. They also present a self-training method for this task, and they further propose a denoising method, with a class-level and pixel-level denoising scheme, to denoise the pseudo labels in self-training and gain a better performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors introduce a new UDA task, which has high practical value under the data privacy and security issues in medical field. The authors propose a self-training method, which seems achieve a good performance in this task. The authors propose a denoising method to denoise the pseudo labels in the self-training, which helps gain better performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. The reasons to exploit the denoising method is not well discussed. In fact, the proposed denoising method can also serviced as post-processing. What is the advantage of exploiting it to denoise the pseudo labels rather than the final segmented results. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1.The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. 2.The proposed denoising method can be better justified by exploiting it as post-processing 3.In the first sentence of Ablation study, ‘complonent’ should be ‘component’ 4.In Fig. 3, it would be better to present the correct recognized noise and wrongly recognized noise. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors introduce a new and meaningful task, and they also proposed a method for this task with well performance. However, the proposed method is not well justified. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper tackles Source-Free Unsupervised Domain Adaptation for image segmentation, i.e. adaptation using only a model trained on unavailable source data and unlabeled target images. The adaptation is done through self-training in the target domain, generating pseudo-labels. This classical method improved by filtering out “unreliable” pseudo-labels, as measured by two distinct uncertainty measures. The first is calculated at the pixel-level, using the variance of prediction maps generated by stochastic dropout. The second is calculated at the class-level, using the distance of features to the estimated class centroid. Experiments are done on one application: retinal fundus images, using 3 datasets collected from different clinical centers with distribution shifts. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of source free domain adaptation (SFDA) is still novel in the medical imaging community and is valuable in practical settings, where source data is often unavailable. The paper is well written and easy to follow. The motivation and the method are well explained. The method draws from a combination of losses and concepts which have been proven effective in other settings, and their application and combination to SFDA is novel. 3.Sufficient experimental section: Although one application only is tackled, retinal fundus images, experiments are done on 2 different target datasets; Comparison to various SOTA methods; Ablation study is done to investigate the effect of each component in the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. There is an assumption of closeness in this paper between the source and target domain, that the domain shift is not too wide. Indeed, the experimental setting is one where both source and target datasets are from the same image modality, the shift comes from scanner differences, which, as authors not, is generally minor compared with cross-modality discrepancy (ex. CT to MRI). As a result, the lower baseline “no adaptation” is already very high, 83.2 Dice (for RIM-ONE-r3) and 93.84 (for Drishti-GS) respectively. In more general settings with bigger domain shifts, the method’s efficiency may not hold. This is not discussed in the paper. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has sufficient details about the framework, hyperparameters choosing, and evaluation. The datasets used are public fundus image datasets. However, the paper doesn’t mention any code available, which limits reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In settings with bigger domain shifts, it is common to that a network’s predictions are skewed towards the dominant class, ex. the background, resulting in “undersegmentations” (see, for ex, [1], Figure 3, Seg-CT-noDA). Could the proposed method “get out” of such a situation, if it only keeps to “non-noisy” pseudo labels ? Did authors see a general tendency to undersegmentation in the output segmentation masks, and if not so, how come ? [1] Dou et al, PnP-AdaNet: Plug-and-Play Adversarial Domain Adaptation Network with a Benchmark at Cross-modality Cardiac Segmentation, IEEE TMI. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper tackles an interesting and original problem,source free domain adaptation, and explores the potential quite simple and well motivated measures of uncertainty to improve classical self-training schemes. The paper is well written, easy to follow. The method is simple, easy to implement and well-motivated, with only one network to optimize, making it easier than SOTA adversarial methods. I find it particularly interesting to show that simple and sound uncertainty measures help select the best pixels to improve self-training. I believe this is an intersesting contribution to the MICCAI community. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All reviewers appreciated the novel experimental setting, i.e., source-free unsupervised domain adaptation. While reviewers provided positive comments (probably/borderline/probably accept), they gave some suggestions to improve the manuscript, e.g., clarify the necessity of using the denoising method for pseudo labels, discuss if the proposed method can handle big domain shifts, and provide a better illustration of Fig. 3. Please consider these suggestions when preparing the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank all the reviewers and meta-reviewer for the affirmative comments on recognizing the novel source free domain adaptation setting and sufficient experimental evaluation of our method. We will include the reviewers’ suggestions in our final version and carefully proofread our paper. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0521/12/31/Paper0715" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0521/12/31/Paper0715" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0521-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Source-Free Domain Adaptive Fundus Image Segmentation with Denoised Pseudo-Labeling" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0521/12/31/Paper0715"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0521/12/31/Paper0715","headline":"Source-Free Domain Adaptive Fundus Image Segmentation with Denoised Pseudo-Labeling","dateModified":"0522-01-03T00:00:00-05:17","datePublished":"0521-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, Pheng-Ann Heng Abstract Domain adaptation typically requires to access source domain data to utilize their distribution information for domain alignment with the target data. However, in many real-world scenarios, the source data may not be accessible during the model adaptation in the target domain due to privacy issue. This paper studies the practical yet challenging source-free unsupervised domain adaptation problem, in which only an existing source model and the unlabeled target data are available for model adaptation. We present a novel denoised pseudo-labeling method for this problem, which effectively makes use of the source model and unlabeled target data to promote model self-adaptation from pseudo labels. Importantly, considering that the pseudo labels generated from source model are inevitably noisy due to domain shift, we further introduce two complementary pixel-level and class-level denoising schemes with uncertainty estimation and prototype estimation to reduce noisy pseudo labels and select reliable ones to enhance the pseudo-labeling efficacy. Experimental results on cross-domain fundus image segmentation show that without using any source images or altering source training, our approach achieves comparable or even higher performance than state-of-the-art source-dependent unsupervised domain adaptation methods. Link to paper https://doi.org/10.1007/978-3-030-87240-3_22 Link to the code repository https://github.com/cchen-cc/SFDA-DPL Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The authors propose a new setting for the unsupervised domain adaptation on fundus image segmentation. In this setting, we only have access to the pertained model on the source domain and the unlabeled data on the target domain. Secondly, this paper proposes a method to create the pseudo label from the target domain for self-training. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The new proposed setting is quite interesting and more realistic for real-life applications. The author applies the uncertainty method to de-noise pixel-level pseudo label and prototype feature for class level de-noise. The experiments are sufficient and achieve superior performance than the baseline methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The Monto-Carlo dropout uncertainty and the prototype de-noise are already proposed by the previous method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sufficient details for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The idea of this paper is quite interesting; more experiments on different datasets would be great. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting idea and good technical quality. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The authors introduce a new unsupervised domain adaptation (UDA) task, where source data can not be accessed nor can alter source training. They also present a self-training method for this task, and they further propose a denoising method, with a class-level and pixel-level denoising scheme, to denoise the pseudo labels in self-training and gain a better performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors introduce a new UDA task, which has high practical value under the data privacy and security issues in medical field. The authors propose a self-training method, which seems achieve a good performance in this task. The authors propose a denoising method to denoise the pseudo labels in the self-training, which helps gain better performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. The reasons to exploit the denoising method is not well discussed. In fact, the proposed denoising method can also serviced as post-processing. What is the advantage of exploiting it to denoise the pseudo labels rather than the final segmented results. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1.The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed. 2.The proposed denoising method can be better justified by exploiting it as post-processing 3.In the first sentence of Ablation study, ‘complonent’ should be ‘component’ 4.In Fig. 3, it would be better to present the correct recognized noise and wrongly recognized noise. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors introduce a new and meaningful task, and they also proposed a method for this task with well performance. However, the proposed method is not well justified. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper tackles Source-Free Unsupervised Domain Adaptation for image segmentation, i.e. adaptation using only a model trained on unavailable source data and unlabeled target images. The adaptation is done through self-training in the target domain, generating pseudo-labels. This classical method improved by filtering out “unreliable” pseudo-labels, as measured by two distinct uncertainty measures. The first is calculated at the pixel-level, using the variance of prediction maps generated by stochastic dropout. The second is calculated at the class-level, using the distance of features to the estimated class centroid. Experiments are done on one application: retinal fundus images, using 3 datasets collected from different clinical centers with distribution shifts. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of source free domain adaptation (SFDA) is still novel in the medical imaging community and is valuable in practical settings, where source data is often unavailable. The paper is well written and easy to follow. The motivation and the method are well explained. The method draws from a combination of losses and concepts which have been proven effective in other settings, and their application and combination to SFDA is novel. 3.Sufficient experimental section: Although one application only is tackled, retinal fundus images, experiments are done on 2 different target datasets; Comparison to various SOTA methods; Ablation study is done to investigate the effect of each component in the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. There is an assumption of closeness in this paper between the source and target domain, that the domain shift is not too wide. Indeed, the experimental setting is one where both source and target datasets are from the same image modality, the shift comes from scanner differences, which, as authors not, is generally minor compared with cross-modality discrepancy (ex. CT to MRI). As a result, the lower baseline “no adaptation” is already very high, 83.2 Dice (for RIM-ONE-r3) and 93.84 (for Drishti-GS) respectively. In more general settings with bigger domain shifts, the method’s efficiency may not hold. This is not discussed in the paper. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has sufficient details about the framework, hyperparameters choosing, and evaluation. The datasets used are public fundus image datasets. However, the paper doesn’t mention any code available, which limits reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In settings with bigger domain shifts, it is common to that a network’s predictions are skewed towards the dominant class, ex. the background, resulting in “undersegmentations” (see, for ex, [1], Figure 3, Seg-CT-noDA). Could the proposed method “get out” of such a situation, if it only keeps to “non-noisy” pseudo labels ? Did authors see a general tendency to undersegmentation in the output segmentation masks, and if not so, how come ? [1] Dou et al, PnP-AdaNet: Plug-and-Play Adversarial Domain Adaptation Network with a Benchmark at Cross-modality Cardiac Segmentation, IEEE TMI. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper tackles an interesting and original problem,source free domain adaptation, and explores the potential quite simple and well motivated measures of uncertainty to improve classical self-training schemes. The paper is well written, easy to follow. The method is simple, easy to implement and well-motivated, with only one network to optimize, making it easier than SOTA adversarial methods. I find it particularly interesting to show that simple and sound uncertainty measures help select the best pixels to improve self-training. I believe this is an intersesting contribution to the MICCAI community. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All reviewers appreciated the novel experimental setting, i.e., source-free unsupervised domain adaptation. While reviewers provided positive comments (probably/borderline/probably accept), they gave some suggestions to improve the manuscript, e.g., clarify the necessity of using the denoising method for pseudo labels, discuss if the proposed method can handle big domain shifts, and provide a better illustration of Fig. 3. Please consider these suggestions when preparing the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank all the reviewers and meta-reviewer for the affirmative comments on recognizing the novel source free domain adaptation setting and sufficient experimental evaluation of our method. We will include the reviewers’ suggestions in our final version and carefully proofread our paper. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Chen, Cheng,Liu, Quande,Jin, Yueming,Dou, Qi,Heng, Pheng-Ann" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Source-Free Domain Adaptive Fundus Image Segmentation with Denoised Pseudo-Labeling</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a>
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Chen, Cheng"
        class="post-tags">
        Chen, Cheng
      </a> |  
      
      <a href="kittywong/tags#Liu, Quande"
        class="post-tags">
        Liu, Quande
      </a> |  
      
      <a href="kittywong/tags#Jin, Yueming"
        class="post-tags">
        Jin, Yueming
      </a> |  
      
      <a href="kittywong/tags#Dou, Qi"
        class="post-tags">
        Dou, Qi
      </a> |  
      
      <a href="kittywong/tags#Heng, Pheng-Ann"
        class="post-tags">
        Heng, Pheng-Ann
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Cheng Chen, Quande Liu, Yueming Jin, Qi Dou, Pheng-Ann Heng
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Domain adaptation typically requires to access source domain data to utilize their distribution information for domain alignment with the target data. However, in many real-world scenarios, the source data may not be accessible during the model adaptation in the target domain due to privacy issue. This paper studies the practical yet challenging source-free unsupervised domain adaptation problem, in which only an existing source model and the unlabeled target data are available for model adaptation. We present a novel denoised pseudo-labeling method for this problem, which effectively makes use of the source model and unlabeled target data to promote model self-adaptation from pseudo labels. Importantly, considering that the pseudo labels generated from source model are inevitably noisy due to domain shift, we further introduce two complementary pixel-level and class-level denoising schemes with uncertainty estimation and prototype estimation to reduce noisy pseudo labels and select reliable ones to enhance the pseudo-labeling efficacy. Experimental results on cross-domain fundus image segmentation show that without using any source images or altering source training, our approach achieves comparable or even higher performance than state-of-the-art source-dependent unsupervised domain adaptation methods.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87240-3_22">https://doi.org/10.1007/978-3-030-87240-3_22</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/cchen-cc/SFDA-DPL
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors propose a new setting for the unsupervised domain adaptation on fundus image segmentation. In this setting, we only have access to the pertained model on the source domain and the unlabeled data on the target domain. Secondly, this paper proposes a method to create the pseudo label from the target domain for self-training.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The new proposed setting is quite interesting and more realistic for real-life applications.</li>
        <li>The author applies the uncertainty method to de-noise pixel-level pseudo label and prototype feature for class level de-noise.</li>
        <li>The experiments are sufficient and achieve superior performance than the baseline methods.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>The Monto-Carlo dropout uncertainty and the prototype de-noise are already proposed by the previous method.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Sufficient details for reproducibility.</p>

    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>The idea of this paper is quite interesting; more experiments on different datasets would be great.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Interesting idea and good technical quality.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors introduce a new unsupervised domain adaptation (UDA) task, where source data can not be accessed nor can alter source training. They also present a self-training method for this task, and they further propose a denoising method, with a class-level and pixel-level denoising scheme, to denoise the pseudo labels in self-training and gain a better performance.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The authors introduce a new UDA task, which has high practical value under the data privacy and security issues in medical field.</li>
        <li>The authors propose a self-training method, which seems achieve a good performance in this task.</li>
        <li>The authors propose a denoising method to denoise the pseudo labels in the self-training, which helps gain better performance.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>
          <p>The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed.</p>
        </li>
        <li>
          <p>The reasons to exploit the denoising method is not well discussed. In fact, the proposed denoising method can also serviced as post-processing. What is the advantage of exploiting it to denoise the pseudo labels rather than the final segmented results.</p>
        </li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Can be reproduced</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>1.The effectiveness of the self-training scheme is not clear, an ablation study compare the model with/ without self-training is needed.
2.The proposed denoising method can be better justified by exploiting it as post-processing
3.In the first sentence of Ablation study, ‘complonent’ should be ‘component’
4.In Fig. 3, it would be better to present the correct recognized noise and wrongly recognized noise.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The authors introduce a new and meaningful task, and they also proposed a method for this task with well performance. However, the proposed method is not well justified.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper tackles Source-Free Unsupervised Domain Adaptation for image segmentation, i.e. adaptation using only a model trained on unavailable source data and unlabeled target images. The adaptation is done through self-training in the target domain, generating pseudo-labels. This classical method improved by filtering out “unreliable” pseudo-labels, as measured by two distinct uncertainty measures. The first is calculated at the pixel-level, using the variance of prediction maps generated by stochastic dropout. The second is calculated at the class-level, using the distance of features to the estimated class centroid. Experiments are done on one application: retinal fundus images, using 3 datasets collected from different clinical centers with distribution shifts.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The idea of source free domain adaptation (SFDA) is still novel in the medical imaging community and is valuable in practical settings, where source data is often unavailable.</li>
        <li>The paper is well written and easy to follow. The motivation and the method are well explained. The method draws from a combination of losses and concepts which have been proven effective in other settings, and their application and combination to SFDA is novel.
3.Sufficient experimental section: Although one application only is tackled, retinal fundus images, experiments are done on 2 different target datasets; Comparison to various SOTA methods; Ablation study is done to investigate the effect of each
component in the proposed method.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>There is an assumption of closeness in this paper between the source and target domain, that the domain shift is not too wide. Indeed, the experimental setting is one where both source and target datasets are from the same image modality, the shift comes from scanner differences, which, as authors not, is generally minor compared with cross-modality discrepancy (ex. CT to MRI). As a result, the lower baseline “no adaptation” is already very high, 83.2 Dice (for RIM-ONE-r3) and 93.84 (for Drishti-GS) respectively. In more general settings with bigger domain shifts, the method’s efficiency may not hold. This is not discussed in the paper.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The paper has sufficient details about the framework, hyperparameters choosing, and evaluation. The datasets used are public fundus image datasets. However, the paper doesn’t mention any code available, which limits reproducibility.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>In settings with bigger domain shifts, it is common to that a network’s predictions are skewed towards the dominant class, ex. the background, resulting in “undersegmentations” (see, for ex, [1], Figure 3, Seg-CT-noDA). Could the proposed method “get out” of such a situation, if it only keeps to “non-noisy” pseudo labels ? Did authors see a general tendency to undersegmentation in the output segmentation masks, and if not so, how come ?</p>

      <p>[1] Dou et al, PnP-AdaNet: Plug-and-Play Adversarial Domain Adaptation Network with a Benchmark at Cross-modality Cardiac Segmentation, IEEE TMI.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The paper tackles an interesting and original problem,source free domain adaptation, and explores the potential quite simple and well motivated measures of uncertainty to improve classical self-training schemes. The paper is well written, easy to follow. The method is simple, easy to implement and well-motivated, with only one network to optimize, making it easier than SOTA adversarial methods. I find it particularly interesting to show that simple and sound uncertainty measures help select the best pixels to improve self-training. I believe this is an intersesting contribution to the MICCAI community.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>All reviewers appreciated the novel experimental setting, i.e., source-free unsupervised domain adaptation. While reviewers provided positive comments (probably/borderline/probably accept), they gave some suggestions to improve the manuscript, e.g., clarify the necessity of using the denoising method for pseudo labels, discuss if the proposed method can handle big domain shifts, and provide a better illustration of Fig. 3. Please consider these suggestions when preparing the final version.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank all the reviewers and meta-reviewer for the affirmative comments on recognizing the novel source free domain adaptation setting and sufficient experimental evaluation of our method.</p>

  <p>We will include the reviewers’ suggestions in our final version and carefully proofread our paper.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0521-12-31
      -->
      <!--
      
        ,
        updated at 
        0522-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Chen, Cheng"
        class="post-category">
        Chen, Cheng
      </a> |  
      
      <a href="kittywong/tags#Liu, Quande"
        class="post-category">
        Liu, Quande
      </a> |  
      
      <a href="kittywong/tags#Jin, Yueming"
        class="post-category">
        Jin, Yueming
      </a> |  
      
      <a href="kittywong/tags#Dou, Qi"
        class="post-category">
        Dou, Qi
      </a> |  
      
      <a href="kittywong/tags#Heng, Pheng-Ann"
        class="post-category">
        Heng, Pheng-Ann
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0522/12/31/Paper0734">
          ASC-Net: Adversarial-based Selective Network for Unsupervised Anomaly Segmentation
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0520/12/31/Paper0635">
          Stochastic 4D Flow Vector-Field Signatures: A new approach for comprehensive 4D Flow MRI quantification
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
