<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Multi-modal Multi-instance Learning using Weakly Correlated Histopathological Images and Tabular Clinical Information | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Multi-modal Multi-instance Learning using Weakly Correlated Histopathological Images and Tabular Clinical Information" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Hang Li, Fan Yang, Xiaohan Xing, Yu Zhao, Jun Zhang, Yueping Liu, Mengxue Han, Junzhou Huang, Liansheng Wang, Jianhua Yao Abstract The fusion of heterogeneous medical data is essential in precision medicine to assist medical experts in treatment decision-making. However, there is often little explicit correlation between data from different modalities such as histopathological images and tabular clinical data. Besides, attention-based multi-instance learning (MIL) often lacks sufficient supervision to assign appropriate attention weights for informative image patches and thus generates a good global representation for the whole image. In this paper, we propose a novel multi-modal multi-instance joint learning method, which fuses different modalities and magnification scales as a cross-modal representation to capture the potential complementary information and recalibrate the features in each modality. Furthermore, we leverage the information from tabular clinical data to optimize the MIL bag representation in the imaging modality. The proposed method is evaluated on a challenging medical task, i.e., lymph node metastasis (LNM) prediction of breast cancer, and achieves the state-of-the-art performance with AUC of 0.8844, outperforming the AUC of 0.7111 using histopathological images or the AUC of 0.8312 using tabular clinical data alone. An open-source implementation of our approach can be found at https://github.com/yfzon/Multi-modal-Multi- instance-Learning. Link to paper https://doi.org/10.1007/978-3-030-87237-3_51 Link to the code repository https://github.com/yfzon/Multi-modal-Multi-instance-Learning Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper is focused on learning fusion from multi-modal data. A new multi-modal learning technique is provided that can integrate information from image data and text information. A particularly interesting contribution is that the images used are whole slide images (WSI), which often need to be analysed as patches (treated as multiple instances). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Learning from multi-modal data is an important motivation, particularly in precision medicine where data may come from a variety of sources. The paper is hence solving an important problem. A logical formulation of the instance learning process i as a weakly supervised learning problem that accumulated the information learned from each patch of the WSI. This allows the representation of each WSI image as a bag of patch-based image information. Thorough experimental protocol with held out validation and test data, an ablation study, and comparison with other work from the literature. Multiple metrics were used. Good use of figures to support text - conceptual methodology is clearly communicated. The results show that the method achieves its goals. For example, Fig 3 shows spatially varying attention, which indicates that the model is learning by considering different aspects from different parts of the WSI Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The results, while thorough, could benefit from some additional statistical information (standard deviation of the metrics, confidence intervals, p values). The text in the figures are difficult to read at standard magnification. Some errors of expression throughout the text. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors will provide the code. The dataset used was acquired from a collaborating hospital. Labelled was done by the consensus of two observers. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Overall, a clear paper that addresses an important problem. A few suggestions for improvement: While there is a good link of the first technical contribution to the challenges for multi-modal learning, there isn’t much related work listed. Data fusion has been an important research goal in the last few years and one suggestion would be to indicate recent work in this domain (not necessarily in depth but references so that an interested reader can see more broadly). For clinical information it would be good to state the text pattern matching algorithm used to generate a structured representation, and justify the reason why it was chosen. The text in Fig 2 is difficult to see at 100% magnification. In particular the white text in the orange boxes. Suggest that the image is resized (perhaps lay out the image again using the full width). A confidence interval or p value should be included. Please a quick proof reading pass to fix up some errors of expression. For example: modal training -&gt; model training Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper is solving an important problem of data fusion from medical imaging data. It presents a deep learning methodology to in sufficient detail that attempts to address this problem in a novel way. The experimental results demonstrate that the methodology works as intended. There are a few minor issues that can be addressed, but overall the intellectual quality of the work means that with a bit of extension this could be a journal paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposed a multi-modal and multi-instance learning network for lymph node metastasis prediction of breast cancer. There are two contributions: (1) combining the histopathological images and tabular clinical Information (2) combining images from different magnification scales Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The strengths of the paper include: (1) propose a multi-modal multi-instance fusion module to generate a cross-modal representation of different modalities. (2) utilize an attention based method to facilitate the informative instances. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The weaknesses include: (1) This paper lacks novelty, the combination of image and non-image modality seems to be very common. And, the feature fusion methods are generally based on concatenation and attention, which are also very common. (2) The introduction part is a little unclear and lacks logic, should find the key points. For example, combining histopathological images and tabular clinical Information (not stressed in the contribution part)。 Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance (1) How to get the images of different magnification scales? (2) The authors mentioned that the number of instances are dynamic, which may cause unstable model training. It is unclear how the author to avoid that. (3) The feature extractors for images of different scales are shared? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html (1) Figure out the focus of the paper, especially in the Introduction part. (2) Explain clearly the data used. All WSIs are scanned at 20x magnification, how to get the 10x and 5x images? resize? (3) Why using different learning rates for different parts, is there any experimental evidence to verify that? (4) More feature fusion methods should be explored. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? (1) The novelty, (2) clearness of Introduction part, and (3) the completeness of experiment What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This work explores the use of multi-instance learning (MIL) for lymph node metastasis (LNM) prediction. By incorporating clinical information, the authors hope to better guide the MIL model to discover what’s important for the LNM prediction. Further, they make use of multiple scales to capture the information from the multiple scales of the histology image to get better representations. The authors also make use of a tabular model to process the clinical data prior to the fusion. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper targets building a complete model, which makes use of all the available information, different modalities and scales, to comprehensively combine them for prediction tasks. Each of the key modules are separately described, making it intuitive to follow. A thorough experimental evaluation and comparison with different state of the art baselines is presented. The multi-scale MIL framework can naturally be extended to allow post-hoc interpretability by understanding importance of the different locations. This allows for an understanding of what the model is focusing on, yielding some interpretability. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The rationale behind the use of a separate clinical-based prediction model is unclear. How are the outputs of the two classifiers combined? The tabular model is not described sufficiently. How is this different from regular networks? What’s the intuition behind these models? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Some details of the model training is described, including number and type of GPUs used, optimization algorithm etc. Initialization of the model not mentioned. The tabular model is not sufficiently described, and cannot be reproduced as is. What are the 18 clinical attributes extracted? Was the best model chosen with early stopping, or at the best epoch on the validation set, or after a fixed number of epochs on the validation set? How were the models initialized? Were the models trained end-to-end, or module-wise? How long does it take for the model to converge? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The aggregation of the patch-level features across all selected patches of the WSI results in the loss of spatial information, which could prove useful in a complex task like LNM prediction. The performance of the different methods across different runs/folds is critical to completely evaluated and compare them. How are the patches selected for experimentation? Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Despite the mentioned weaknesses, the paper presents a novel idea which tries to take in all the available information across modalities and scales in an effort to build a comprehensive model. Such efforts are crucial to improve performance of machine learning models. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses an important problem to take advantage of all available information across modalities and scales for lymph node metastasis (LNM) prediction. Major concerns include: 1) To include some additional statistical information (such as standard deviation and confidence intervals; 2) not clear on how to avoid the variance caused by the dynamic number of instances; 3) lack of details in model training and experimental setup; and 4) typo/grammar errors. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. All major concerns have been well addressed. This paper deserves to be published in MICCAI. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The author has clarified the main issues raised by the reviewers. Considering the proposed methodological contributions, such as learning fusion from cross-modal data and combining images from different magnification scales, I think this paper is acceptable. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Reviewers have consensus about some merits of this paper. The rebuttal has also clarified some concerns about the model training, experiment setting, and the results. The major argument is about the significance of the novelty of this paper, which, however, is somewhat mild. The clarification about the novelty in the rebuttal sounds acceptable to me for MICCAI publication. There is just a minor point for the authors’ consideration. In introduction, the advantages of the proposed method were discussed against MMCNN-MIML[17]. It would be more convincing for this discussion if the comparison with MMCNN-MIML is also reported. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their constructive comments and will address major concerns in the following. AC&amp;R#1&amp;R#3: Include some additional statistical information. We calculated 95% confidence intervals (CI) for the proposed method. The 95% CIs of our method are AUC (0.8605-0.9083), F1-score (0.7645-0.8280), Precision (0.7122-0.7967), Recall (0.8001-0.8774). We will complete the statistics of all methods in the final version. AC&amp;R#2: How to avoid the variance caused by dynamic number of instances? For a dynamic number of instances, each instance is assigned with an attention value, and then aggregated by this value to generate a global embedding. During this process, the dimension representing the numbers vanishes and therefore has no significant impact on the aggregation process. AC&amp;R#3: Details in model training and experimental setup. The model was initiated with Xavier Initialization, and the best model was chosen at the best epoch on the validation set. The parameters of the image feature extraction part are fixed, and the rest of the model is trained end-to-end. The training process takes about 10 hours to converge. R#1: Details about text pattern matching algorithm used to generate a structured representation. The original medical records are given in semi-structured natural language descriptions in Chinese. We wrote a set of matching rules based on regular expressions to extract the structured information, eg., age, tumor side, histological classification, etc. R#2: Lack novelty and clearness of Introduction part. We respectfully disagree. Due to the super large dimensions, the multi-magnification nature of WSI images, and the domain disparity of WSI and tabular data, conventional multi-instance learning (MIL) methods were not designed for this specific scenario and thus resulted in limited performance. We proposed a multi-modal multi-instance method to handle the cross-modality fusion of pathological images and tabular data. The novelty of our proposed method lies in four aspects: 1) A well-designed module employing cross-modal learning to integrate complementary information between imaging and tabular data. Multi-modality fusion helps pathologists to simultaneously identify useful information in different modalities during diagnosis. 2) A multi-scale mechanism to fuse global and local features from large pathological images. 3) A novel MIL framework that aggregates instances at different scales. 4) A visualization module to interpret multi-modal multi-scale results. These novel components are validated by extensive ablation studies and outperform the state-of-the-art methods (AUC 88.44% vs 85.70%). Both R#1 and R#3 agree with the novelty of our approach and rate the clarity and organization as very good. R#2: How to get the 10x and 5x images? Digital pathology images are in pyramidal structures, and the files are internally organized with multiple magnifications. The 20x images mentioned in the paper refers to the highest magnification, and the 5x and 10x images can also be retrieved from the source file and not obtained by resizing. R#2: Why using different learning rates for different parts? Different modules in our proposed method are responsible for the feature extraction of different modalities. The MIL module is for processing image-based features, and the tabular module is for processing table base features. Our method allows different modal components to have different learning rates, which is verified by experiments to be beneficial for the network to efficiently select optimal parameters and improve convergence speed. R#3: The rationale behind the use of a separate clinical-based prediction model. The separate prediction model is inspired by Deeply Supervised Nets and can help improve the stability of the model training process. This separate classifier G_aux is only used during the training process, and only the multi-modal branching classifier is used for the inference. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Hang Li, Fan Yang, Xiaohan Xing, Yu Zhao, Jun Zhang, Yueping Liu, Mengxue Han, Junzhou Huang, Liansheng Wang, Jianhua Yao Abstract The fusion of heterogeneous medical data is essential in precision medicine to assist medical experts in treatment decision-making. However, there is often little explicit correlation between data from different modalities such as histopathological images and tabular clinical data. Besides, attention-based multi-instance learning (MIL) often lacks sufficient supervision to assign appropriate attention weights for informative image patches and thus generates a good global representation for the whole image. In this paper, we propose a novel multi-modal multi-instance joint learning method, which fuses different modalities and magnification scales as a cross-modal representation to capture the potential complementary information and recalibrate the features in each modality. Furthermore, we leverage the information from tabular clinical data to optimize the MIL bag representation in the imaging modality. The proposed method is evaluated on a challenging medical task, i.e., lymph node metastasis (LNM) prediction of breast cancer, and achieves the state-of-the-art performance with AUC of 0.8844, outperforming the AUC of 0.7111 using histopathological images or the AUC of 0.8312 using tabular clinical data alone. An open-source implementation of our approach can be found at https://github.com/yfzon/Multi-modal-Multi- instance-Learning. Link to paper https://doi.org/10.1007/978-3-030-87237-3_51 Link to the code repository https://github.com/yfzon/Multi-modal-Multi-instance-Learning Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper is focused on learning fusion from multi-modal data. A new multi-modal learning technique is provided that can integrate information from image data and text information. A particularly interesting contribution is that the images used are whole slide images (WSI), which often need to be analysed as patches (treated as multiple instances). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Learning from multi-modal data is an important motivation, particularly in precision medicine where data may come from a variety of sources. The paper is hence solving an important problem. A logical formulation of the instance learning process i as a weakly supervised learning problem that accumulated the information learned from each patch of the WSI. This allows the representation of each WSI image as a bag of patch-based image information. Thorough experimental protocol with held out validation and test data, an ablation study, and comparison with other work from the literature. Multiple metrics were used. Good use of figures to support text - conceptual methodology is clearly communicated. The results show that the method achieves its goals. For example, Fig 3 shows spatially varying attention, which indicates that the model is learning by considering different aspects from different parts of the WSI Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The results, while thorough, could benefit from some additional statistical information (standard deviation of the metrics, confidence intervals, p values). The text in the figures are difficult to read at standard magnification. Some errors of expression throughout the text. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors will provide the code. The dataset used was acquired from a collaborating hospital. Labelled was done by the consensus of two observers. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Overall, a clear paper that addresses an important problem. A few suggestions for improvement: While there is a good link of the first technical contribution to the challenges for multi-modal learning, there isn’t much related work listed. Data fusion has been an important research goal in the last few years and one suggestion would be to indicate recent work in this domain (not necessarily in depth but references so that an interested reader can see more broadly). For clinical information it would be good to state the text pattern matching algorithm used to generate a structured representation, and justify the reason why it was chosen. The text in Fig 2 is difficult to see at 100% magnification. In particular the white text in the orange boxes. Suggest that the image is resized (perhaps lay out the image again using the full width). A confidence interval or p value should be included. Please a quick proof reading pass to fix up some errors of expression. For example: modal training -&gt; model training Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper is solving an important problem of data fusion from medical imaging data. It presents a deep learning methodology to in sufficient detail that attempts to address this problem in a novel way. The experimental results demonstrate that the methodology works as intended. There are a few minor issues that can be addressed, but overall the intellectual quality of the work means that with a bit of extension this could be a journal paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposed a multi-modal and multi-instance learning network for lymph node metastasis prediction of breast cancer. There are two contributions: (1) combining the histopathological images and tabular clinical Information (2) combining images from different magnification scales Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The strengths of the paper include: (1) propose a multi-modal multi-instance fusion module to generate a cross-modal representation of different modalities. (2) utilize an attention based method to facilitate the informative instances. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The weaknesses include: (1) This paper lacks novelty, the combination of image and non-image modality seems to be very common. And, the feature fusion methods are generally based on concatenation and attention, which are also very common. (2) The introduction part is a little unclear and lacks logic, should find the key points. For example, combining histopathological images and tabular clinical Information (not stressed in the contribution part)。 Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance (1) How to get the images of different magnification scales? (2) The authors mentioned that the number of instances are dynamic, which may cause unstable model training. It is unclear how the author to avoid that. (3) The feature extractors for images of different scales are shared? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html (1) Figure out the focus of the paper, especially in the Introduction part. (2) Explain clearly the data used. All WSIs are scanned at 20x magnification, how to get the 10x and 5x images? resize? (3) Why using different learning rates for different parts, is there any experimental evidence to verify that? (4) More feature fusion methods should be explored. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? (1) The novelty, (2) clearness of Introduction part, and (3) the completeness of experiment What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This work explores the use of multi-instance learning (MIL) for lymph node metastasis (LNM) prediction. By incorporating clinical information, the authors hope to better guide the MIL model to discover what’s important for the LNM prediction. Further, they make use of multiple scales to capture the information from the multiple scales of the histology image to get better representations. The authors also make use of a tabular model to process the clinical data prior to the fusion. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper targets building a complete model, which makes use of all the available information, different modalities and scales, to comprehensively combine them for prediction tasks. Each of the key modules are separately described, making it intuitive to follow. A thorough experimental evaluation and comparison with different state of the art baselines is presented. The multi-scale MIL framework can naturally be extended to allow post-hoc interpretability by understanding importance of the different locations. This allows for an understanding of what the model is focusing on, yielding some interpretability. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The rationale behind the use of a separate clinical-based prediction model is unclear. How are the outputs of the two classifiers combined? The tabular model is not described sufficiently. How is this different from regular networks? What’s the intuition behind these models? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Some details of the model training is described, including number and type of GPUs used, optimization algorithm etc. Initialization of the model not mentioned. The tabular model is not sufficiently described, and cannot be reproduced as is. What are the 18 clinical attributes extracted? Was the best model chosen with early stopping, or at the best epoch on the validation set, or after a fixed number of epochs on the validation set? How were the models initialized? Were the models trained end-to-end, or module-wise? How long does it take for the model to converge? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The aggregation of the patch-level features across all selected patches of the WSI results in the loss of spatial information, which could prove useful in a complex task like LNM prediction. The performance of the different methods across different runs/folds is critical to completely evaluated and compare them. How are the patches selected for experimentation? Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Despite the mentioned weaknesses, the paper presents a novel idea which tries to take in all the available information across modalities and scales in an effort to build a comprehensive model. Such efforts are crucial to improve performance of machine learning models. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses an important problem to take advantage of all available information across modalities and scales for lymph node metastasis (LNM) prediction. Major concerns include: 1) To include some additional statistical information (such as standard deviation and confidence intervals; 2) not clear on how to avoid the variance caused by the dynamic number of instances; 3) lack of details in model training and experimental setup; and 4) typo/grammar errors. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. All major concerns have been well addressed. This paper deserves to be published in MICCAI. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The author has clarified the main issues raised by the reviewers. Considering the proposed methodological contributions, such as learning fusion from cross-modal data and combining images from different magnification scales, I think this paper is acceptable. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Reviewers have consensus about some merits of this paper. The rebuttal has also clarified some concerns about the model training, experiment setting, and the results. The major argument is about the significance of the novelty of this paper, which, however, is somewhat mild. The clarification about the novelty in the rebuttal sounds acceptable to me for MICCAI publication. There is just a minor point for the authors’ consideration. In introduction, the advantages of the proposed method were discussed against MMCNN-MIML[17]. It would be more convincing for this discussion if the comparison with MMCNN-MIML is also reported. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their constructive comments and will address major concerns in the following. AC&amp;R#1&amp;R#3: Include some additional statistical information. We calculated 95% confidence intervals (CI) for the proposed method. The 95% CIs of our method are AUC (0.8605-0.9083), F1-score (0.7645-0.8280), Precision (0.7122-0.7967), Recall (0.8001-0.8774). We will complete the statistics of all methods in the final version. AC&amp;R#2: How to avoid the variance caused by dynamic number of instances? For a dynamic number of instances, each instance is assigned with an attention value, and then aggregated by this value to generate a global embedding. During this process, the dimension representing the numbers vanishes and therefore has no significant impact on the aggregation process. AC&amp;R#3: Details in model training and experimental setup. The model was initiated with Xavier Initialization, and the best model was chosen at the best epoch on the validation set. The parameters of the image feature extraction part are fixed, and the rest of the model is trained end-to-end. The training process takes about 10 hours to converge. R#1: Details about text pattern matching algorithm used to generate a structured representation. The original medical records are given in semi-structured natural language descriptions in Chinese. We wrote a set of matching rules based on regular expressions to extract the structured information, eg., age, tumor side, histological classification, etc. R#2: Lack novelty and clearness of Introduction part. We respectfully disagree. Due to the super large dimensions, the multi-magnification nature of WSI images, and the domain disparity of WSI and tabular data, conventional multi-instance learning (MIL) methods were not designed for this specific scenario and thus resulted in limited performance. We proposed a multi-modal multi-instance method to handle the cross-modality fusion of pathological images and tabular data. The novelty of our proposed method lies in four aspects: 1) A well-designed module employing cross-modal learning to integrate complementary information between imaging and tabular data. Multi-modality fusion helps pathologists to simultaneously identify useful information in different modalities during diagnosis. 2) A multi-scale mechanism to fuse global and local features from large pathological images. 3) A novel MIL framework that aggregates instances at different scales. 4) A visualization module to interpret multi-modal multi-scale results. These novel components are validated by extensive ablation studies and outperform the state-of-the-art methods (AUC 88.44% vs 85.70%). Both R#1 and R#3 agree with the novelty of our approach and rate the clarity and organization as very good. R#2: How to get the 10x and 5x images? Digital pathology images are in pyramidal structures, and the files are internally organized with multiple magnifications. The 20x images mentioned in the paper refers to the highest magnification, and the 5x and 10x images can also be retrieved from the source file and not obtained by resizing. R#2: Why using different learning rates for different parts? Different modules in our proposed method are responsible for the feature extraction of different modalities. The MIL module is for processing image-based features, and the tabular module is for processing table base features. Our method allows different modal components to have different learning rates, which is verified by experiments to be beneficial for the network to efficiently select optimal parameters and improve convergence speed. R#3: The rationale behind the use of a separate clinical-based prediction model. The separate prediction model is inspired by Deeply Supervised Nets and can help improve the stability of the model training process. This separate classifier G_aux is only used during the training process, and only the multi-modal branching classifier is used for the inference. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0850/12/31/Paper0937" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0850/12/31/Paper0937" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0850-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Multi-modal Multi-instance Learning using Weakly Correlated Histopathological Images and Tabular Clinical Information" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0850/12/31/Paper0937"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0850/12/31/Paper0937","headline":"Multi-modal Multi-instance Learning using Weakly Correlated Histopathological Images and Tabular Clinical Information","dateModified":"0851-01-05T00:00:00-05:17","datePublished":"0850-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Hang Li, Fan Yang, Xiaohan Xing, Yu Zhao, Jun Zhang, Yueping Liu, Mengxue Han, Junzhou Huang, Liansheng Wang, Jianhua Yao Abstract The fusion of heterogeneous medical data is essential in precision medicine to assist medical experts in treatment decision-making. However, there is often little explicit correlation between data from different modalities such as histopathological images and tabular clinical data. Besides, attention-based multi-instance learning (MIL) often lacks sufficient supervision to assign appropriate attention weights for informative image patches and thus generates a good global representation for the whole image. In this paper, we propose a novel multi-modal multi-instance joint learning method, which fuses different modalities and magnification scales as a cross-modal representation to capture the potential complementary information and recalibrate the features in each modality. Furthermore, we leverage the information from tabular clinical data to optimize the MIL bag representation in the imaging modality. The proposed method is evaluated on a challenging medical task, i.e., lymph node metastasis (LNM) prediction of breast cancer, and achieves the state-of-the-art performance with AUC of 0.8844, outperforming the AUC of 0.7111 using histopathological images or the AUC of 0.8312 using tabular clinical data alone. An open-source implementation of our approach can be found at https://github.com/yfzon/Multi-modal-Multi- instance-Learning. Link to paper https://doi.org/10.1007/978-3-030-87237-3_51 Link to the code repository https://github.com/yfzon/Multi-modal-Multi-instance-Learning Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper is focused on learning fusion from multi-modal data. A new multi-modal learning technique is provided that can integrate information from image data and text information. A particularly interesting contribution is that the images used are whole slide images (WSI), which often need to be analysed as patches (treated as multiple instances). Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Learning from multi-modal data is an important motivation, particularly in precision medicine where data may come from a variety of sources. The paper is hence solving an important problem. A logical formulation of the instance learning process i as a weakly supervised learning problem that accumulated the information learned from each patch of the WSI. This allows the representation of each WSI image as a bag of patch-based image information. Thorough experimental protocol with held out validation and test data, an ablation study, and comparison with other work from the literature. Multiple metrics were used. Good use of figures to support text - conceptual methodology is clearly communicated. The results show that the method achieves its goals. For example, Fig 3 shows spatially varying attention, which indicates that the model is learning by considering different aspects from different parts of the WSI Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The results, while thorough, could benefit from some additional statistical information (standard deviation of the metrics, confidence intervals, p values). The text in the figures are difficult to read at standard magnification. Some errors of expression throughout the text. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors will provide the code. The dataset used was acquired from a collaborating hospital. Labelled was done by the consensus of two observers. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Overall, a clear paper that addresses an important problem. A few suggestions for improvement: While there is a good link of the first technical contribution to the challenges for multi-modal learning, there isn’t much related work listed. Data fusion has been an important research goal in the last few years and one suggestion would be to indicate recent work in this domain (not necessarily in depth but references so that an interested reader can see more broadly). For clinical information it would be good to state the text pattern matching algorithm used to generate a structured representation, and justify the reason why it was chosen. The text in Fig 2 is difficult to see at 100% magnification. In particular the white text in the orange boxes. Suggest that the image is resized (perhaps lay out the image again using the full width). A confidence interval or p value should be included. Please a quick proof reading pass to fix up some errors of expression. For example: modal training -&gt; model training Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper is solving an important problem of data fusion from medical imaging data. It presents a deep learning methodology to in sufficient detail that attempts to address this problem in a novel way. The experimental results demonstrate that the methodology works as intended. There are a few minor issues that can be addressed, but overall the intellectual quality of the work means that with a bit of extension this could be a journal paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposed a multi-modal and multi-instance learning network for lymph node metastasis prediction of breast cancer. There are two contributions: (1) combining the histopathological images and tabular clinical Information (2) combining images from different magnification scales Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The strengths of the paper include: (1) propose a multi-modal multi-instance fusion module to generate a cross-modal representation of different modalities. (2) utilize an attention based method to facilitate the informative instances. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The weaknesses include: (1) This paper lacks novelty, the combination of image and non-image modality seems to be very common. And, the feature fusion methods are generally based on concatenation and attention, which are also very common. (2) The introduction part is a little unclear and lacks logic, should find the key points. For example, combining histopathological images and tabular clinical Information (not stressed in the contribution part)。 Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance (1) How to get the images of different magnification scales? (2) The authors mentioned that the number of instances are dynamic, which may cause unstable model training. It is unclear how the author to avoid that. (3) The feature extractors for images of different scales are shared? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html (1) Figure out the focus of the paper, especially in the Introduction part. (2) Explain clearly the data used. All WSIs are scanned at 20x magnification, how to get the 10x and 5x images? resize? (3) Why using different learning rates for different parts, is there any experimental evidence to verify that? (4) More feature fusion methods should be explored. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? (1) The novelty, (2) clearness of Introduction part, and (3) the completeness of experiment What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This work explores the use of multi-instance learning (MIL) for lymph node metastasis (LNM) prediction. By incorporating clinical information, the authors hope to better guide the MIL model to discover what’s important for the LNM prediction. Further, they make use of multiple scales to capture the information from the multiple scales of the histology image to get better representations. The authors also make use of a tabular model to process the clinical data prior to the fusion. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. This paper targets building a complete model, which makes use of all the available information, different modalities and scales, to comprehensively combine them for prediction tasks. Each of the key modules are separately described, making it intuitive to follow. A thorough experimental evaluation and comparison with different state of the art baselines is presented. The multi-scale MIL framework can naturally be extended to allow post-hoc interpretability by understanding importance of the different locations. This allows for an understanding of what the model is focusing on, yielding some interpretability. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The rationale behind the use of a separate clinical-based prediction model is unclear. How are the outputs of the two classifiers combined? The tabular model is not described sufficiently. How is this different from regular networks? What’s the intuition behind these models? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Some details of the model training is described, including number and type of GPUs used, optimization algorithm etc. Initialization of the model not mentioned. The tabular model is not sufficiently described, and cannot be reproduced as is. What are the 18 clinical attributes extracted? Was the best model chosen with early stopping, or at the best epoch on the validation set, or after a fixed number of epochs on the validation set? How were the models initialized? Were the models trained end-to-end, or module-wise? How long does it take for the model to converge? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The aggregation of the patch-level features across all selected patches of the WSI results in the loss of spatial information, which could prove useful in a complex task like LNM prediction. The performance of the different methods across different runs/folds is critical to completely evaluated and compare them. How are the patches selected for experimentation? Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Despite the mentioned weaknesses, the paper presents a novel idea which tries to take in all the available information across modalities and scales in an effort to build a comprehensive model. Such efforts are crucial to improve performance of machine learning models. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses an important problem to take advantage of all available information across modalities and scales for lymph node metastasis (LNM) prediction. Major concerns include: 1) To include some additional statistical information (such as standard deviation and confidence intervals; 2) not clear on how to avoid the variance caused by the dynamic number of instances; 3) lack of details in model training and experimental setup; and 4) typo/grammar errors. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. All major concerns have been well addressed. This paper deserves to be published in MICCAI. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The author has clarified the main issues raised by the reviewers. Considering the proposed methodological contributions, such as learning fusion from cross-modal data and combining images from different magnification scales, I think this paper is acceptable. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Reviewers have consensus about some merits of this paper. The rebuttal has also clarified some concerns about the model training, experiment setting, and the results. The major argument is about the significance of the novelty of this paper, which, however, is somewhat mild. The clarification about the novelty in the rebuttal sounds acceptable to me for MICCAI publication. There is just a minor point for the authors’ consideration. In introduction, the advantages of the proposed method were discussed against MMCNN-MIML[17]. It would be more convincing for this discussion if the comparison with MMCNN-MIML is also reported. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their constructive comments and will address major concerns in the following. AC&amp;R#1&amp;R#3: Include some additional statistical information. We calculated 95% confidence intervals (CI) for the proposed method. The 95% CIs of our method are AUC (0.8605-0.9083), F1-score (0.7645-0.8280), Precision (0.7122-0.7967), Recall (0.8001-0.8774). We will complete the statistics of all methods in the final version. AC&amp;R#2: How to avoid the variance caused by dynamic number of instances? For a dynamic number of instances, each instance is assigned with an attention value, and then aggregated by this value to generate a global embedding. During this process, the dimension representing the numbers vanishes and therefore has no significant impact on the aggregation process. AC&amp;R#3: Details in model training and experimental setup. The model was initiated with Xavier Initialization, and the best model was chosen at the best epoch on the validation set. The parameters of the image feature extraction part are fixed, and the rest of the model is trained end-to-end. The training process takes about 10 hours to converge. R#1: Details about text pattern matching algorithm used to generate a structured representation. The original medical records are given in semi-structured natural language descriptions in Chinese. We wrote a set of matching rules based on regular expressions to extract the structured information, eg., age, tumor side, histological classification, etc. R#2: Lack novelty and clearness of Introduction part. We respectfully disagree. Due to the super large dimensions, the multi-magnification nature of WSI images, and the domain disparity of WSI and tabular data, conventional multi-instance learning (MIL) methods were not designed for this specific scenario and thus resulted in limited performance. We proposed a multi-modal multi-instance method to handle the cross-modality fusion of pathological images and tabular data. The novelty of our proposed method lies in four aspects: 1) A well-designed module employing cross-modal learning to integrate complementary information between imaging and tabular data. Multi-modality fusion helps pathologists to simultaneously identify useful information in different modalities during diagnosis. 2) A multi-scale mechanism to fuse global and local features from large pathological images. 3) A novel MIL framework that aggregates instances at different scales. 4) A visualization module to interpret multi-modal multi-scale results. These novel components are validated by extensive ablation studies and outperform the state-of-the-art methods (AUC 88.44% vs 85.70%). Both R#1 and R#3 agree with the novelty of our approach and rate the clarity and organization as very good. R#2: How to get the 10x and 5x images? Digital pathology images are in pyramidal structures, and the files are internally organized with multiple magnifications. The 20x images mentioned in the paper refers to the highest magnification, and the 5x and 10x images can also be retrieved from the source file and not obtained by resizing. R#2: Why using different learning rates for different parts? Different modules in our proposed method are responsible for the feature extraction of different modalities. The MIL module is for processing image-based features, and the tabular module is for processing table base features. Our method allows different modal components to have different learning rates, which is verified by experiments to be beneficial for the network to efficiently select optimal parameters and improve convergence speed. R#3: The rationale behind the use of a separate clinical-based prediction model. The separate prediction model is inspired by Deeply Supervised Nets and can help improve the stability of the model training process. This separate classifier G_aux is only used during the training process, and only the multi-modal branching classifier is used for the inference. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Li, Hang,Yang, Fan,Xing, Xiaohan,Zhao, Yu,Zhang, Jun,Liu, Yueping,Han, Mengxue,Huang, Junzhou,Wang, Liansheng,Yao, Jianhua" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Multi-modal Multi-instance Learning using Weakly Correlated Histopathological Images and Tabular Clinical Information</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Integration of Imaging with Non-Imaging Biomarkers"
        class="post-category">
        Integration of Imaging with Non-Imaging Biomarkers
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Weakly supervised learning"
        class="post-category">
        Machine Learning - Weakly supervised learning
      </a>
      
      <a 
        href="kittywong/categories#Modalities - Histopathology"
        class="post-category">
        Modalities - Histopathology
      </a>
      
      <a 
        href="kittywong/categories#Modalities - Text (clinical/radiology reports)"
        class="post-category">
        Modalities - Text (clinical/radiology reports)
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Li, Hang"
        class="post-tags">
        Li, Hang
      </a> |  
      
      <a href="kittywong/tags#Yang, Fan"
        class="post-tags">
        Yang, Fan
      </a> |  
      
      <a href="kittywong/tags#Xing, Xiaohan"
        class="post-tags">
        Xing, Xiaohan
      </a> |  
      
      <a href="kittywong/tags#Zhao, Yu"
        class="post-tags">
        Zhao, Yu
      </a> |  
      
      <a href="kittywong/tags#Zhang, Jun"
        class="post-tags">
        Zhang, Jun
      </a> |  
      
      <a href="kittywong/tags#Liu, Yueping"
        class="post-tags">
        Liu, Yueping
      </a> |  
      
      <a href="kittywong/tags#Han, Mengxue"
        class="post-tags">
        Han, Mengxue
      </a> |  
      
      <a href="kittywong/tags#Huang, Junzhou"
        class="post-tags">
        Huang, Junzhou
      </a> |  
      
      <a href="kittywong/tags#Wang, Liansheng"
        class="post-tags">
        Wang, Liansheng
      </a> |  
      
      <a href="kittywong/tags#Yao, Jianhua"
        class="post-tags">
        Yao, Jianhua
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Hang Li, Fan Yang, Xiaohan Xing, Yu Zhao, Jun Zhang, Yueping Liu, Mengxue Han, Junzhou Huang, Liansheng Wang, Jianhua Yao
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>The fusion of heterogeneous medical data is essential in precision medicine to assist medical experts in treatment decision-making. However, there is often little explicit correlation between data from different modalities such as histopathological images and tabular clinical data. Besides, attention-based multi-instance learning (MIL) often lacks sufficient supervision to assign appropriate attention weights for informative image patches and thus generates a good global representation for the whole image. In this paper, we propose a novel multi-modal multi-instance joint learning method, which fuses different modalities and magnification scales as a cross-modal representation to capture the potential complementary information and recalibrate the features in each modality. Furthermore, we leverage the information from tabular clinical data to optimize the MIL bag representation in the imaging modality. The proposed method is evaluated on a challenging medical task, i.e., lymph node metastasis (LNM) prediction of breast cancer, and achieves the state-of-the-art performance with AUC of 0.8844, outperforming the AUC of 0.7111 using histopathological images or the AUC of 0.8312 using tabular clinical data alone. An open-source implementation of our approach can be found at https://github.com/yfzon/Multi-modal-Multi- instance-Learning.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87237-3_51">https://doi.org/10.1007/978-3-030-87237-3_51</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/yfzon/Multi-modal-Multi-instance-Learning
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper is focused on learning fusion from multi-modal data. A new multi-modal learning technique is provided that can integrate information from image data and text information. A particularly interesting contribution is that the images used are whole slide images (WSI), which often need to be analysed as patches (treated as multiple instances).</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Learning from multi-modal data is an important motivation, particularly in precision medicine where data may come from a variety of sources. The paper is hence solving an important problem.</p>

      <p>A logical formulation of the instance learning process i as a weakly supervised learning problem that accumulated the information learned from each patch of the WSI. This allows the representation of each WSI image as a bag of patch-based image information.</p>

      <p>Thorough experimental protocol with held out validation and test data, an ablation study, and comparison with other work from the literature. Multiple metrics were used.</p>

      <p>Good use of figures to support text - conceptual methodology is clearly communicated.</p>

      <p>The results show that the method achieves its goals. For example, Fig 3 shows spatially varying attention, which indicates that the model is learning by considering different aspects from different parts of the WSI</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The results, while thorough, could benefit from some additional statistical information (standard deviation of the metrics, confidence intervals, p values).</p>

      <p>The text in the figures are difficult to read at standard magnification.</p>

      <p>Some errors of expression throughout the text.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors will provide the code. The dataset used was acquired from a collaborating hospital. Labelled was done by the consensus of two observers.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Overall, a clear paper that addresses an important problem. A few suggestions for improvement:</p>

      <ol>
        <li>
          <p>While there is a good link of the first technical contribution to the challenges for multi-modal learning, there isn’t much related work listed. Data fusion has been an important research goal in the last few years and one suggestion would be to indicate recent work in this domain (not necessarily in depth but references so that an interested reader can see more broadly).</p>
        </li>
        <li>
          <p>For clinical information it would be good to state the text pattern matching algorithm used to generate a structured representation, and justify the reason why it was chosen.</p>
        </li>
        <li>
          <p>The text in Fig 2 is difficult to see at 100% magnification. In particular the white text in the orange boxes. Suggest that the image is resized (perhaps lay out the image again using the full width).</p>
        </li>
        <li>
          <p>A confidence interval or p value should be included.</p>
        </li>
        <li>
          <p>Please a quick proof reading pass to fix up some errors of expression. For example: modal training -&gt; model training</p>
        </li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This paper is solving an important problem of data fusion from medical imaging data. It presents a deep learning methodology to in sufficient detail that attempts to address this problem in a novel way. The experimental results demonstrate that the methodology works as intended. There are a few minor issues that can be addressed, but overall the intellectual quality of the work means that with a bit of extension this could be a journal paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposed a multi-modal and multi-instance learning network for lymph node metastasis prediction of breast cancer. 
There are two contributions:
(1) combining the histopathological images and tabular clinical Information 
(2) combining images from different magnification scales</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The strengths of the paper include:
(1) propose a multi-modal multi-instance fusion module to generate a cross-modal representation of different modalities.
(2) utilize an attention based method to facilitate the informative instances.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The weaknesses include:
(1) This paper lacks novelty, the combination of image and non-image modality seems to be very common. And, the feature fusion methods are generally based on concatenation and attention, which are also very common.
(2) The introduction part is a little unclear and lacks logic, should find the key points. For example, combining histopathological images and tabular clinical Information (not stressed in the contribution part)。</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>(1) How to get the images of different magnification scales?
(2) The authors mentioned that the number of instances are dynamic, which may cause unstable model training. It is unclear how the author to avoid that.
(3) The feature extractors for images of different scales are shared?</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>(1) Figure out the focus of the paper, especially in the Introduction part. 
(2) Explain clearly the data used. All WSIs are scanned at 20x magnification, how to get the 10x and 5x images? resize?
(3) Why using different learning rates for different parts, is there any experimental evidence to verify that?
(4) More feature fusion methods should be explored.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>(1) The novelty, (2) clearness of Introduction part, and (3) the completeness of experiment</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <ul>
        <li>This work explores the use of multi-instance learning (MIL) for lymph node metastasis (LNM) prediction. By incorporating clinical information, the authors hope to better guide the MIL model to discover what’s important for the LNM prediction.</li>
        <li>Further, they make use of multiple scales to capture the information from the multiple scales of the histology image to get better representations.</li>
        <li>The authors also make use of a tabular model to process the clinical data prior to the fusion.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>This paper targets building a complete model, which makes use of all the available information, different modalities and scales, to comprehensively combine them for prediction tasks.</li>
        <li>Each of the key modules are separately described, making it intuitive to follow.</li>
        <li>A thorough experimental evaluation and comparison with different state of the art baselines is presented.</li>
        <li>The multi-scale MIL framework can naturally be extended to allow post-hoc interpretability by understanding importance of the different locations. This allows for an understanding of what the model is focusing on, yielding some interpretability.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The rationale behind the use of a separate clinical-based prediction model is unclear. How are the outputs of the two classifiers combined?</li>
        <li>The tabular model is not described sufficiently. How is this different from regular networks? What’s the intuition behind these models?</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>

      <ul>
        <li>Some details of the model training is described, including number and type of GPUs used, optimization algorithm etc. Initialization of the model not mentioned.</li>
        <li>The tabular model is not sufficiently described, and cannot be reproduced as is. What are the 18 clinical attributes extracted?</li>
        <li>Was the best model chosen with early stopping, or at the best epoch on the validation set, or after a fixed number of epochs on the validation set? How were the models initialized? Were the models trained end-to-end, or module-wise?</li>
        <li>How long does it take for the model to converge?</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>

      <ul>
        <li>The aggregation of the patch-level features across all selected patches of the WSI results in the loss of spatial information, which could prove useful in a complex task like LNM prediction.</li>
        <li>The performance of the different methods across different runs/folds is critical to completely evaluated and compare them.</li>
        <li>How are the patches selected for experimentation?</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ul>
        <li>Despite the mentioned weaknesses, the paper presents a novel idea which tries to take in all the available information across modalities and scales in an effort to build a comprehensive model. Such efforts are crucial to improve performance of machine learning models.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper addresses an important problem to take advantage of all available information across modalities and scales for lymph node metastasis (LNM) prediction. Major concerns include: 1) To include some additional statistical information (such as standard deviation and confidence intervals; 2) not clear on how to avoid the variance caused by the dynamic number of instances; 3) lack of details in model training and experimental setup; and 4) typo/grammar errors.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>All major concerns have been well addressed. This paper deserves to be published in MICCAI.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The author has clarified the main issues raised by the reviewers. Considering the proposed methodological contributions, such as learning fusion from cross-modal data and combining images from different magnification scales, I think this paper is acceptable.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>Reviewers have consensus about some merits of this paper. The rebuttal has also clarified some concerns about the model training, experiment setting, and the results. The major argument is about the significance of the novelty of this paper, which, however, is somewhat mild. The clarification about the novelty in the rebuttal sounds acceptable to me for MICCAI publication. There is just a minor point for the authors’ consideration. In introduction, the advantages of the proposed method were discussed against MMCNN-MIML[17]. It would be more convincing for this discussion if the comparison with MMCNN-MIML is also reported.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We sincerely thank all the reviewers and ACs for their constructive comments and will address major concerns in the following.</p>

  <p>AC&amp;R#1&amp;R#3: Include some additional statistical information.
We calculated 95% confidence intervals (CI) for the proposed method. The 95% CIs of our method are AUC (0.8605-0.9083), F1-score (0.7645-0.8280), Precision (0.7122-0.7967), Recall (0.8001-0.8774). We will complete the statistics of all methods in the final version.</p>

  <p>AC&amp;R#2: How to avoid the variance caused by dynamic number of instances?
For a dynamic number of instances, each instance is assigned with an attention value, and then aggregated by this value to generate a global embedding. During this process, the dimension representing the numbers vanishes and therefore has no significant impact on the aggregation process.</p>

  <p>AC&amp;R#3: Details in model training and experimental setup.
The model was initiated with Xavier Initialization, and the best model was chosen at the best epoch on the validation set. The parameters of the image feature extraction part are fixed, and the rest of the model is trained end-to-end. The training process takes about 10 hours to converge.</p>

  <p>R#1: Details about text pattern matching algorithm used to generate a structured representation.
The original medical records are given in semi-structured natural language descriptions in Chinese. We wrote a set of matching rules based on regular expressions to extract the structured information, eg., age, tumor side, histological classification, etc.</p>

  <p>R#2: Lack novelty and clearness of Introduction part.
We respectfully disagree. Due to the super large dimensions, the multi-magnification nature of WSI images, and the domain disparity of WSI and tabular data, conventional multi-instance learning (MIL) methods were not designed for this specific scenario and thus resulted in limited performance. We proposed a multi-modal multi-instance method to handle the cross-modality fusion of pathological images and tabular data. The novelty of our proposed method lies in four aspects:
1) A well-designed module employing cross-modal learning to integrate complementary information between imaging and tabular data. Multi-modality fusion helps pathologists to simultaneously identify useful information in different modalities during diagnosis.
2) A multi-scale mechanism to fuse global and local features from large pathological images.
3) A novel MIL framework that aggregates instances at different scales.
4) A visualization module to interpret multi-modal multi-scale results.
These novel components are validated by extensive ablation studies and outperform the state-of-the-art methods (AUC 88.44% vs 85.70%).
Both R#1 and R#3 agree with the novelty of our approach and rate the clarity and organization as very good.</p>

  <p>R#2: How to get the 10x and 5x images?
Digital pathology images are in pyramidal structures, and the files are internally organized with multiple magnifications. The 20x images mentioned in the paper refers to the highest magnification, and the 5x and 10x images can also be retrieved from the source file and not obtained by resizing.</p>

  <p>R#2: Why using different learning rates for different parts?
Different modules in our proposed method are responsible for the feature extraction of different modalities. The MIL module is for processing image-based features, and the tabular module is for processing table base features. Our method allows different modal components to have different learning rates, which is verified by experiments to be beneficial for the network to efficiently select optimal parameters and improve convergence speed.</p>

  <p>R#3: The rationale behind the use of a separate clinical-based prediction model.
The separate prediction model is inspired by Deeply Supervised Nets and can help improve the stability of the model training process. This separate classifier G_aux is only used during the training process, and only the multi-modal branching classifier is used for the inference.</p>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0850-12-31
      -->
      <!--
      
        ,
        updated at 
        0851-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Integration of Imaging with Non-Imaging Biomarkers"
        class="post-category">
        Integration of Imaging with Non-Imaging Biomarkers
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Weakly supervised learning"
        class="post-category">
        Machine Learning - Weakly supervised learning
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - Histopathology"
        class="post-category">
        Modalities - Histopathology
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - Text (clinical/radiology reports)"
        class="post-category">
        Modalities - Text (clinical/radiology reports)
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Li, Hang"
        class="post-category">
        Li, Hang
      </a> |  
      
      <a href="kittywong/tags#Yang, Fan"
        class="post-category">
        Yang, Fan
      </a> |  
      
      <a href="kittywong/tags#Xing, Xiaohan"
        class="post-category">
        Xing, Xiaohan
      </a> |  
      
      <a href="kittywong/tags#Zhao, Yu"
        class="post-category">
        Zhao, Yu
      </a> |  
      
      <a href="kittywong/tags#Zhang, Jun"
        class="post-category">
        Zhang, Jun
      </a> |  
      
      <a href="kittywong/tags#Liu, Yueping"
        class="post-category">
        Liu, Yueping
      </a> |  
      
      <a href="kittywong/tags#Han, Mengxue"
        class="post-category">
        Han, Mengxue
      </a> |  
      
      <a href="kittywong/tags#Huang, Junzhou"
        class="post-category">
        Huang, Junzhou
      </a> |  
      
      <a href="kittywong/tags#Wang, Liansheng"
        class="post-category">
        Wang, Liansheng
      </a> |  
      
      <a href="kittywong/tags#Yao, Jianhua"
        class="post-category">
        Yao, Jianhua
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0851/12/31/Paper1075">
          Ranking loss: A ranking-based deep neural network for colorectal cancer grading in pathology images
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0849/12/31/Paper0740">
          GloFlow: Whole Slide Image Stitching from Video using Optical Flow and Global Image Alignment
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
