<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Progressively Normalized Self-Attention Network for Video Polyp Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Progressively Normalized Self-Attention Network for Video Polyp Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Ge-Peng Ji, Yu-Cheng Chou, Deng-Ping Fan, Geng Chen, Huazhu Fu, Debesh Jha, Ling Shao Abstract Existing video polyp segmentation (VPS) models typically employ convolutional neural networks (CNNs) to extract features. However, due to their limited receptive fields, CNNs cannot fully exploit the global temporal and spatial information in successive video frames, resulting in false positive segmentation results. In this paper, we propose the novel PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed (\textbf{$\sim$140fps}) on a single RTX 2080 GPU and no post-processing. Our PNS-Net is based solely on a basic normalized self-attention block, equipping with recurrence and CNNs entirely. Experiments on challenging VPS datasets demonstrate that the proposed PNS-Net achieves state-of-the-art performance. We also conduct extensive experiments to study the effectiveness of the channel split, soft-attention, and progressive learning strategy. We find that our PNS-Net works well under different settings, making it a promising solution to the VPS task. Link to paper https://doi.org/10.1007/978-3-030-87193-2_14 Link to the code repository https://github.com/GewelsJI/PNS-Net Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes the PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed. Attention mechanism is effectively introduced for polyp segmentation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Main strength of this paper is to introduce self-attention mechanism to segment colonic polyp regions from colonoscopic video images. Simple normalized self-attention block is new idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The proposed method was examined by using only public database. I think this is ok for segmentation performance comparison. I would expect more real-data are used for evaluation to consider real clinical problem. But this comment does not affect my overall decision. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Detailed parameters are shown in the supplemental file. I think reproducibility is fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper shows a method to segment poly regions from video colonoscopic images. Paper is well-written and is clear to understand. My clinical side question is how do your treat vague boundary of a polyp. How can you segment flat polyp or concave polyp regions from videos? How about segmentation performance for such polyps? In nature of medical imaging, the boundary cannot be defined clearly. If you ask several medical doctors, they return different answers. How do you treat such cases? `Regressive NS Can you demonstrate the effect of “Progressive” NS? 3 Illustration of NS block I think the arrow of X is opposite in the magnified illustration of NS. I think that is simple mistake in drawing. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The methods and the results shown in the paper is very convincing. Technical background is ok. These are basis my judgement. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A novel Progressively Normalized Self-attention Network is proposed, for video polyp segmentation in polyp videos in real time. The critical component is a normalized self-attention block to learn efficient spatio-temporal representations of polyps. Experiments on multiple datasets, reporting on multiple metrics and good ablation tests are presented. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting training protocol: Pre-training on still images + video frames, after removing normalized self-attention block. Then fine-tuning with NS block and video data Very impressive results, on multiple metrics and datasets, and different SOTA comparisons and good ablation experiments. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The entire subsection 2.1 on normalised self-attention is math heavy, with no intuitive explanation of the approach. This is the only section that I would recommend rewriting- it is very dense and gives no help to the reader on why it makes sense and is worth a novelty tick. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Appears to be reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html see section 4 Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? see section 3 What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces a video polyp segmentation model PNS-Net. It contains (1) a normalized self-attention (NS) bloack consists of non-local attentions with channel splits, restricted attentions capturing spatial-temporal relationships, and normalized query Q (2) a progressive learning strategy to maintain high-level semantic features from the proposed NS blocks. Detailed quantitative, qualitative and ablative studies are given on 3 datasets. The proposed method achieve state-of-the-art performance including a much higher inference speed of 140 fps vs 108 fps. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) the proposed method is new in this task. The authors adopt and improve the widely adopted self-attention mechanisms in this video segmentation task with the proposed two mechanisms and proved the effectiveness through ablative studies and comparisions with previous methods. (2) the proposed method not only achieve state-of-the-art performance in segmentation measurements, e.g. IoU, but also achieve faster speed 140 fps, especially for medical domain where training data is usually limited. This could be benefitial for other similar video segmentation tasks. (3) the paper is well written and demonstated clearly. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) Channel split v.s. Multi-head. One of the contribution introduced in this paper is the Channel Split mechanism. It is very similar to the multi-head attention originally proposed in the Transformer paper (cite in this paper as [21]). The authors should discuss the difference between them. (2) Query-Dependent Rule: How does the kernel size k selected? The authors mention that various k are selected but in the paper only k=3 is selected and no ablative studies for k. The authors may include an ablative study on k. (3) How long does it take to train the model including pre-training and fine-tuning? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors mentioned that ‘all the training data, models, results, and eval- uation tools will be released.’ Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to previous comments. For the pre-training part, a common approach in video segmentation in natural images is to train the Non-local blocks as well as the backbone, e.g. STM, Video Object Segmentation using Space-Time Memory Networks by Wug Oh et al. The authors may give it a try. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The method proposed in this paper is new in this task. Qualitative and quantitative results show the effectiveness of the proposed method. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a new method for polyp segmentation based on self-attention network. The paper is well-written, experimental details and comparison are thorough and convincing showing the effectiveness of the proposed method. All minor comments raised by the reviewers should be addressed in the camera-ready. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the meta-reviewer for handling our submission and the reviewers for their unanimously positive ratings (9,7,7). We are encouraged that they find our model is technically sound (R1), our training protocol is interesting (R2), our paper is well written with convincing results (R1, R4). We respond (Re) to each comment below. Reviewer #1 (R1) Q1. Real data for a real clinical problem. Re. Thanks. We plan to construct the large-scale densely annotated dataset for the VPS task in the journal extension, containing diverse clinical data from multiple centers. Q2. How to treat vague boundaries and flat or concave polyp regions? How about the performance? Re. We address these problems via mining the spatial-temporal correlations, and thus, the unnoticeable/concealed polyp is detected due to its movement patterns. We achieve 0.801 Dice and 0.846 Dice for vague (5 clips) and flat (3 clips) cases. Q3. Different medical doctors return a different answer. Re. In general medical datasets, each polyp is labeled by multiple clinicians, and the final mask is determined by voting. Our model is trained using the standard ground-truth labels provided by the public dataset. Q4. Effectiveness of ‘Progressive’ NS. Re. We have discussed the effectiveness of ‘progressive’ in sec. 3.3 (last part) and table 2 (#7, #8, #9). The concept of ‘progressive’ is equivalent to the re-optimization process (coarse-to-fine). Reviewer #2 (R2) Q1. No intuitive explanation of the approach Re. We apologize for causing this confusion due to page limitations. Per your suggestion, we will add more intuitive visualization to our journal version as well as the website. Reviewer #4 (R4) Q1. Channel split VS. Multi-head. Re. They share the same spirit to an extent. Indeed, the specific implementation manner of multi-head in the transformer is channel split. This operation can ensemble different attention regions in the network because various heads may focus on a different region in the feature map. Q2. How does the kernel size k select? Re. We adopt the dilated convolution with a 3x3 kernel size due to the performance-efficiency trade-off. The motivation is that a large kernel with large dilation rates may damage the integrity in the spatial-temporal representation. In our previous attempts, this may degrade the performance and increase the computational burden. Our journal extension will further investigate the synergy effect between the kernel size and dilation rate. Q3. The pre-training/fine-tuning time. Re: It takes about 10 hours (pre-training) on Kvasir and positive part of ASU-Mayo and 35 minutes (fine-tuning) on training set of CVC-300 and CVC-612, respectively. Q4. The improvement of pre-training strategy. Re: We are pleased to apply this fantastic training strategy to our model. We will cite this work in the final version. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Ge-Peng Ji, Yu-Cheng Chou, Deng-Ping Fan, Geng Chen, Huazhu Fu, Debesh Jha, Ling Shao Abstract Existing video polyp segmentation (VPS) models typically employ convolutional neural networks (CNNs) to extract features. However, due to their limited receptive fields, CNNs cannot fully exploit the global temporal and spatial information in successive video frames, resulting in false positive segmentation results. In this paper, we propose the novel PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed (\textbf{$\sim$140fps}) on a single RTX 2080 GPU and no post-processing. Our PNS-Net is based solely on a basic normalized self-attention block, equipping with recurrence and CNNs entirely. Experiments on challenging VPS datasets demonstrate that the proposed PNS-Net achieves state-of-the-art performance. We also conduct extensive experiments to study the effectiveness of the channel split, soft-attention, and progressive learning strategy. We find that our PNS-Net works well under different settings, making it a promising solution to the VPS task. Link to paper https://doi.org/10.1007/978-3-030-87193-2_14 Link to the code repository https://github.com/GewelsJI/PNS-Net Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes the PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed. Attention mechanism is effectively introduced for polyp segmentation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Main strength of this paper is to introduce self-attention mechanism to segment colonic polyp regions from colonoscopic video images. Simple normalized self-attention block is new idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The proposed method was examined by using only public database. I think this is ok for segmentation performance comparison. I would expect more real-data are used for evaluation to consider real clinical problem. But this comment does not affect my overall decision. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Detailed parameters are shown in the supplemental file. I think reproducibility is fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper shows a method to segment poly regions from video colonoscopic images. Paper is well-written and is clear to understand. My clinical side question is how do your treat vague boundary of a polyp. How can you segment flat polyp or concave polyp regions from videos? How about segmentation performance for such polyps? In nature of medical imaging, the boundary cannot be defined clearly. If you ask several medical doctors, they return different answers. How do you treat such cases? `Regressive NS Can you demonstrate the effect of “Progressive” NS? 3 Illustration of NS block I think the arrow of X is opposite in the magnified illustration of NS. I think that is simple mistake in drawing. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The methods and the results shown in the paper is very convincing. Technical background is ok. These are basis my judgement. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A novel Progressively Normalized Self-attention Network is proposed, for video polyp segmentation in polyp videos in real time. The critical component is a normalized self-attention block to learn efficient spatio-temporal representations of polyps. Experiments on multiple datasets, reporting on multiple metrics and good ablation tests are presented. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting training protocol: Pre-training on still images + video frames, after removing normalized self-attention block. Then fine-tuning with NS block and video data Very impressive results, on multiple metrics and datasets, and different SOTA comparisons and good ablation experiments. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The entire subsection 2.1 on normalised self-attention is math heavy, with no intuitive explanation of the approach. This is the only section that I would recommend rewriting- it is very dense and gives no help to the reader on why it makes sense and is worth a novelty tick. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Appears to be reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html see section 4 Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? see section 3 What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces a video polyp segmentation model PNS-Net. It contains (1) a normalized self-attention (NS) bloack consists of non-local attentions with channel splits, restricted attentions capturing spatial-temporal relationships, and normalized query Q (2) a progressive learning strategy to maintain high-level semantic features from the proposed NS blocks. Detailed quantitative, qualitative and ablative studies are given on 3 datasets. The proposed method achieve state-of-the-art performance including a much higher inference speed of 140 fps vs 108 fps. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) the proposed method is new in this task. The authors adopt and improve the widely adopted self-attention mechanisms in this video segmentation task with the proposed two mechanisms and proved the effectiveness through ablative studies and comparisions with previous methods. (2) the proposed method not only achieve state-of-the-art performance in segmentation measurements, e.g. IoU, but also achieve faster speed 140 fps, especially for medical domain where training data is usually limited. This could be benefitial for other similar video segmentation tasks. (3) the paper is well written and demonstated clearly. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) Channel split v.s. Multi-head. One of the contribution introduced in this paper is the Channel Split mechanism. It is very similar to the multi-head attention originally proposed in the Transformer paper (cite in this paper as [21]). The authors should discuss the difference between them. (2) Query-Dependent Rule: How does the kernel size k selected? The authors mention that various k are selected but in the paper only k=3 is selected and no ablative studies for k. The authors may include an ablative study on k. (3) How long does it take to train the model including pre-training and fine-tuning? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors mentioned that ‘all the training data, models, results, and eval- uation tools will be released.’ Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to previous comments. For the pre-training part, a common approach in video segmentation in natural images is to train the Non-local blocks as well as the backbone, e.g. STM, Video Object Segmentation using Space-Time Memory Networks by Wug Oh et al. The authors may give it a try. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The method proposed in this paper is new in this task. Qualitative and quantitative results show the effectiveness of the proposed method. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a new method for polyp segmentation based on self-attention network. The paper is well-written, experimental details and comparison are thorough and convincing showing the effectiveness of the proposed method. All minor comments raised by the reviewers should be addressed in the camera-ready. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the meta-reviewer for handling our submission and the reviewers for their unanimously positive ratings (9,7,7). We are encouraged that they find our model is technically sound (R1), our training protocol is interesting (R2), our paper is well written with convincing results (R1, R4). We respond (Re) to each comment below. Reviewer #1 (R1) Q1. Real data for a real clinical problem. Re. Thanks. We plan to construct the large-scale densely annotated dataset for the VPS task in the journal extension, containing diverse clinical data from multiple centers. Q2. How to treat vague boundaries and flat or concave polyp regions? How about the performance? Re. We address these problems via mining the spatial-temporal correlations, and thus, the unnoticeable/concealed polyp is detected due to its movement patterns. We achieve 0.801 Dice and 0.846 Dice for vague (5 clips) and flat (3 clips) cases. Q3. Different medical doctors return a different answer. Re. In general medical datasets, each polyp is labeled by multiple clinicians, and the final mask is determined by voting. Our model is trained using the standard ground-truth labels provided by the public dataset. Q4. Effectiveness of ‘Progressive’ NS. Re. We have discussed the effectiveness of ‘progressive’ in sec. 3.3 (last part) and table 2 (#7, #8, #9). The concept of ‘progressive’ is equivalent to the re-optimization process (coarse-to-fine). Reviewer #2 (R2) Q1. No intuitive explanation of the approach Re. We apologize for causing this confusion due to page limitations. Per your suggestion, we will add more intuitive visualization to our journal version as well as the website. Reviewer #4 (R4) Q1. Channel split VS. Multi-head. Re. They share the same spirit to an extent. Indeed, the specific implementation manner of multi-head in the transformer is channel split. This operation can ensemble different attention regions in the network because various heads may focus on a different region in the feature map. Q2. How does the kernel size k select? Re. We adopt the dilated convolution with a 3x3 kernel size due to the performance-efficiency trade-off. The motivation is that a large kernel with large dilation rates may damage the integrity in the spatial-temporal representation. In our previous attempts, this may degrade the performance and increase the computational burden. Our journal extension will further investigate the synergy effect between the kernel size and dilation rate. Q3. The pre-training/fine-tuning time. Re: It takes about 10 hours (pre-training) on Kvasir and positive part of ASU-Mayo and 35 minutes (fine-tuning) on training set of CVC-300 and CVC-612, respectively. Q4. The improvement of pre-training strategy. Re: We are pleased to apply this fantastic training strategy to our model. We will cite this work in the final version. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0113/12/31/Paper0320" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0113/12/31/Paper0320" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0113-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Progressively Normalized Self-Attention Network for Video Polyp Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0113/12/31/Paper0320"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0113/12/31/Paper0320","headline":"Progressively Normalized Self-Attention Network for Video Polyp Segmentation","dateModified":"0113-12-31T00:00:00-05:17","datePublished":"0113-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Ge-Peng Ji, Yu-Cheng Chou, Deng-Ping Fan, Geng Chen, Huazhu Fu, Debesh Jha, Ling Shao Abstract Existing video polyp segmentation (VPS) models typically employ convolutional neural networks (CNNs) to extract features. However, due to their limited receptive fields, CNNs cannot fully exploit the global temporal and spatial information in successive video frames, resulting in false positive segmentation results. In this paper, we propose the novel PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed (\\textbf{$\\sim$140fps}) on a single RTX 2080 GPU and no post-processing. Our PNS-Net is based solely on a basic normalized self-attention block, equipping with recurrence and CNNs entirely. Experiments on challenging VPS datasets demonstrate that the proposed PNS-Net achieves state-of-the-art performance. We also conduct extensive experiments to study the effectiveness of the channel split, soft-attention, and progressive learning strategy. We find that our PNS-Net works well under different settings, making it a promising solution to the VPS task. Link to paper https://doi.org/10.1007/978-3-030-87193-2_14 Link to the code repository https://github.com/GewelsJI/PNS-Net Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes the PNS-Net (Progressively Normalized Self-attention Net\u0002work), which can efficiently learn representations from polyp videos with real-time speed. Attention mechanism is effectively introduced for polyp segmentation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Main strength of this paper is to introduce self-attention mechanism to segment colonic polyp regions from colonoscopic video images. Simple normalized self-attention block is new idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The proposed method was examined by using only public database. I think this is ok for segmentation performance comparison. I would expect more real-data are used for evaluation to consider real clinical problem. But this comment does not affect my overall decision. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Detailed parameters are shown in the supplemental file. I think reproducibility is fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper shows a method to segment poly regions from video colonoscopic images. Paper is well-written and is clear to understand. My clinical side question is how do your treat vague boundary of a polyp. How can you segment flat polyp or concave polyp regions from videos? How about segmentation performance for such polyps? In nature of medical imaging, the boundary cannot be defined clearly. If you ask several medical doctors, they return different answers. How do you treat such cases? `Regressive NS Can you demonstrate the effect of “Progressive” NS? 3 Illustration of NS block I think the arrow of X is opposite in the magnified illustration of NS. I think that is simple mistake in drawing. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The methods and the results shown in the paper is very convincing. Technical background is ok. These are basis my judgement. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper A novel Progressively Normalized Self-attention Network is proposed, for video polyp segmentation in polyp videos in real time. The critical component is a normalized self-attention block to learn efficient spatio-temporal representations of polyps. Experiments on multiple datasets, reporting on multiple metrics and good ablation tests are presented. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Interesting training protocol: Pre-training on still images + video frames, after removing normalized self-attention block. Then fine-tuning with NS block and video data Very impressive results, on multiple metrics and datasets, and different SOTA comparisons and good ablation experiments. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The entire subsection 2.1 on normalised self-attention is math heavy, with no intuitive explanation of the approach. This is the only section that I would recommend rewriting- it is very dense and gives no help to the reader on why it makes sense and is worth a novelty tick. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Appears to be reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html see section 4 Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? see section 3 What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper introduces a video polyp segmentation model PNS-Net. It contains (1) a normalized self-attention (NS) bloack consists of non-local attentions with channel splits, restricted attentions capturing spatial-temporal relationships, and normalized query Q (2) a progressive learning strategy to maintain high-level semantic features from the proposed NS blocks. Detailed quantitative, qualitative and ablative studies are given on 3 datasets. The proposed method achieve state-of-the-art performance including a much higher inference speed of 140 fps vs 108 fps. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) the proposed method is new in this task. The authors adopt and improve the widely adopted self-attention mechanisms in this video segmentation task with the proposed two mechanisms and proved the effectiveness through ablative studies and comparisions with previous methods. (2) the proposed method not only achieve state-of-the-art performance in segmentation measurements, e.g. IoU, but also achieve faster speed 140 fps, especially for medical domain where training data is usually limited. This could be benefitial for other similar video segmentation tasks. (3) the paper is well written and demonstated clearly. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) Channel split v.s. Multi-head. One of the contribution introduced in this paper is the Channel Split mechanism. It is very similar to the multi-head attention originally proposed in the Transformer paper (cite in this paper as [21]). The authors should discuss the difference between them. (2) Query-Dependent Rule: How does the kernel size k selected? The authors mention that various k are selected but in the paper only k=3 is selected and no ablative studies for k. The authors may include an ablative study on k. (3) How long does it take to train the model including pre-training and fine-tuning? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors mentioned that ‘all the training data, models, results, and eval- uation tools will be released.’ Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please refer to previous comments. For the pre-training part, a common approach in video segmentation in natural images is to train the Non-local blocks as well as the backbone, e.g. STM, Video Object Segmentation using Space-Time Memory Networks by Wug Oh et al. The authors may give it a try. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The method proposed in this paper is new in this task. Qualitative and quantitative results show the effectiveness of the proposed method. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a new method for polyp segmentation based on self-attention network. The paper is well-written, experimental details and comparison are thorough and convincing showing the effectiveness of the proposed method. All minor comments raised by the reviewers should be addressed in the camera-ready. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the meta-reviewer for handling our submission and the reviewers for their unanimously positive ratings (9,7,7). We are encouraged that they find our model is technically sound (R1), our training protocol is interesting (R2), our paper is well written with convincing results (R1, R4). We respond (Re) to each comment below. Reviewer #1 (R1) Q1. Real data for a real clinical problem. Re. Thanks. We plan to construct the large-scale densely annotated dataset for the VPS task in the journal extension, containing diverse clinical data from multiple centers. Q2. How to treat vague boundaries and flat or concave polyp regions? How about the performance? Re. We address these problems via mining the spatial-temporal correlations, and thus, the unnoticeable/concealed polyp is detected due to its movement patterns. We achieve 0.801 Dice and 0.846 Dice for vague (5 clips) and flat (3 clips) cases. Q3. Different medical doctors return a different answer. Re. In general medical datasets, each polyp is labeled by multiple clinicians, and the final mask is determined by voting. Our model is trained using the standard ground-truth labels provided by the public dataset. Q4. Effectiveness of ‘Progressive’ NS. Re. We have discussed the effectiveness of ‘progressive’ in sec. 3.3 (last part) and table 2 (#7, #8, #9). The concept of ‘progressive’ is equivalent to the re-optimization process (coarse-to-fine). Reviewer #2 (R2) Q1. No intuitive explanation of the approach Re. We apologize for causing this confusion due to page limitations. Per your suggestion, we will add more intuitive visualization to our journal version as well as the website. Reviewer #4 (R4) Q1. Channel split VS. Multi-head. Re. They share the same spirit to an extent. Indeed, the specific implementation manner of multi-head in the transformer is channel split. This operation can ensemble different attention regions in the network because various heads may focus on a different region in the feature map. Q2. How does the kernel size k select? Re. We adopt the dilated convolution with a 3x3 kernel size due to the performance-efficiency trade-off. The motivation is that a large kernel with large dilation rates may damage the integrity in the spatial-temporal representation. In our previous attempts, this may degrade the performance and increase the computational burden. Our journal extension will further investigate the synergy effect between the kernel size and dilation rate. Q3. The pre-training/fine-tuning time. Re: It takes about 10 hours (pre-training) on Kvasir and positive part of ASU-Mayo and 35 minutes (fine-tuning) on training set of CVC-300 and CVC-612, respectively. Q4. The improvement of pre-training strategy. Re: We are pleased to apply this fantastic training strategy to our model. We will cite this work in the final version. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Ji, Ge-Peng,Chou, Yu-Cheng,Fan, Deng-Ping,Chen, Geng,Fu, Huazhu,Jha, Debesh,Shao, Ling" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Progressively Normalized Self-Attention Network for Video Polyp Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Ji, Ge-Peng"
        class="post-tags">
        Ji, Ge-Peng
      </a> |  
      
      <a href="kittywong/tags#Chou, Yu-Cheng"
        class="post-tags">
        Chou, Yu-Cheng
      </a> |  
      
      <a href="kittywong/tags#Fan, Deng-Ping"
        class="post-tags">
        Fan, Deng-Ping
      </a> |  
      
      <a href="kittywong/tags#Chen, Geng"
        class="post-tags">
        Chen, Geng
      </a> |  
      
      <a href="kittywong/tags#Fu, Huazhu"
        class="post-tags">
        Fu, Huazhu
      </a> |  
      
      <a href="kittywong/tags#Jha, Debesh"
        class="post-tags">
        Jha, Debesh
      </a> |  
      
      <a href="kittywong/tags#Shao, Ling"
        class="post-tags">
        Shao, Ling
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Ge-Peng Ji, Yu-Cheng Chou, Deng-Ping Fan, Geng Chen, Huazhu Fu, Debesh Jha, Ling Shao
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Existing video polyp segmentation (VPS) models typically employ convolutional neural networks (CNNs) to extract features. However, due to their limited receptive fields, CNNs cannot fully exploit the global temporal and spatial information in successive video frames, resulting in false positive segmentation results. In this paper, we propose the novel PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with real-time speed (\textbf{$\sim$140fps}) on a single RTX 2080 GPU and no post-processing.  Our PNS-Net is based solely on a basic normalized self-attention block, equipping with recurrence and CNNs entirely. Experiments on challenging VPS datasets demonstrate that the proposed PNS-Net achieves state-of-the-art performance. We also conduct extensive experiments to study the effectiveness of the channel split, soft-attention, and progressive learning strategy. We find that our PNS-Net works well under different settings, making it a promising solution to the VPS task.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87193-2_14">https://doi.org/10.1007/978-3-030-87193-2_14</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/GewelsJI/PNS-Net
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes the PNS-Net (Progressively Normalized Self-attention Network), which can efficiently learn representations from polyp videos with
real-time speed. Attention mechanism is effectively introduced for polyp segmentation.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Main strength of this paper is to introduce self-attention mechanism to segment colonic polyp regions from colonoscopic video images.  Simple normalized self-attention block is new idea.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The proposed method was examined by using only public database. I think this is ok for segmentation performance comparison. I would expect more real-data are used for evaluation to consider real clinical problem. But this comment does not affect my overall decision.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Detailed parameters are shown in the supplemental file. I think reproducibility is fine.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>This paper shows a method to segment poly regions from video colonoscopic images. Paper is well-written and is clear to understand.</p>

      <ol>
        <li>
          <p>My clinical side question is how do your treat vague boundary of a polyp. How can you segment flat polyp or concave polyp regions from videos? How about segmentation performance for such polyps? In nature of medical imaging, the boundary cannot be defined clearly. If you ask several medical doctors, they return different answers. How do you treat such cases?</p>
        </li>
        <li>
          <p>`Regressive NS
Can you demonstrate the effect of “Progressive” NS?</p>
        </li>
      </ol>

      <p>3 Illustration of NS block
I think the arrow of X is opposite in the magnified illustration of NS. I think that is simple mistake in drawing.</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The methods and the results shown in the paper is very convincing. Technical background is ok. These are basis my judgement.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>A novel Progressively Normalized Self-attention Network is proposed, for video polyp segmentation in polyp videos in real time. The critical component is a normalized self-attention block to learn efficient spatio-temporal representations of polyps. Experiments on multiple datasets, reporting on multiple metrics and good ablation tests are presented.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Interesting training protocol: Pre-training on still images + video frames, after removing normalized self-attention block. Then fine-tuning with NS block and video data
Very impressive results, on multiple metrics and datasets, and different SOTA comparisons and good ablation experiments.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The entire subsection 2.1 on normalised self-attention is math heavy, with no intuitive explanation of the approach.  This is the only section that I would recommend rewriting- it is very dense and gives no help to the reader on why it makes sense and is worth a novelty tick.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Appears to be reproducible</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>see section 4</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>see section 3</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper introduces a video polyp segmentation model PNS-Net. It contains (1) a  normalized self-attention (NS) bloack consists of non-local attentions with channel splits, restricted attentions capturing spatial-temporal relationships, and normalized query Q (2)  a progressive learning strategy to maintain high-level semantic features from the proposed NS blocks. Detailed quantitative, qualitative and ablative studies are given on 3 datasets. The proposed method achieve state-of-the-art performance including a much higher inference speed of 140 fps vs 108 fps.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>(1) the proposed method is new in this task. The authors adopt and improve the widely adopted self-attention mechanisms in this video segmentation task with the proposed two mechanisms and proved the effectiveness through ablative studies and comparisions with previous methods.</p>

      <p>(2) the proposed method not only achieve state-of-the-art performance in segmentation measurements, e.g. IoU, but also achieve faster speed 140 fps, especially for medical domain where training data is usually limited. This could be benefitial for other similar video segmentation tasks.</p>

      <p>(3) the paper is well written and demonstated clearly.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>(1) Channel split v.s. Multi-head. One of the contribution introduced in this paper is the Channel Split mechanism. It is very similar to the multi-head attention originally proposed in the Transformer paper (cite in this paper as [21]). The authors should discuss the difference between them.</p>

      <p>(2) Query-Dependent Rule: How does the kernel size k selected? The authors mention that various k are selected but in the paper only k=3 is selected and no ablative studies for k. The authors may include an ablative study on k.</p>

      <p>(3) How long does it take to train the model including pre-training and fine-tuning?</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors mentioned that ‘all the training data, models, results, and eval-
uation tools will be released.’</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please refer to previous comments.</p>

      <p>For the pre-training part, a common approach in video segmentation in natural images is to train the Non-local blocks as well as the backbone, e.g. STM, Video Object Segmentation using Space-Time Memory Networks by Wug Oh et al. The authors may give it a try.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The method proposed in this paper is new in this task. Qualitative and quantitative results show the effectiveness of the proposed method.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The paper proposes a new method for polyp segmentation based on self-attention network. The paper is well-written, experimental details and comparison are thorough and convincing showing the effectiveness of the proposed method. All minor comments raised by the reviewers should be addressed in the camera-ready.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the meta-reviewer for handling our submission and the reviewers for their unanimously positive ratings (9,7,7). We are encouraged that they find our model is technically sound (R1), our training protocol is interesting (R2), our paper is well written with convincing results (R1, R4). We respond (Re) to each comment below.</p>

  <p>Reviewer #1 (R1)
Q1. Real data for a real clinical problem.
Re. Thanks. We plan to construct the large-scale densely annotated dataset for the VPS task in the journal extension, containing diverse clinical data from multiple centers.</p>

  <p>Q2. How to treat vague boundaries and flat or concave polyp regions? How about the performance?
Re. We address these problems via mining the spatial-temporal correlations, and thus, the unnoticeable/concealed polyp is detected due to its movement patterns. We achieve 0.801 Dice and 0.846 Dice for vague (5 clips) and flat (3 clips) cases.</p>

  <p>Q3. Different medical doctors return a different answer. 
Re. In general medical datasets, each polyp is labeled by multiple clinicians, and the final mask is determined by voting. Our model is trained using the standard ground-truth labels provided by the public dataset.</p>

  <p>Q4. Effectiveness of ‘Progressive’ NS.
Re. We have discussed the effectiveness of ‘progressive’ in sec. 3.3 (last part) and table 2 (#7, #8, #9). The concept of ‘progressive’ is equivalent to the re-optimization process (coarse-to-fine).</p>

  <p>Reviewer #2 (R2)
Q1. No intuitive explanation of the approach
Re. We apologize for causing this confusion due to page limitations. Per your suggestion, we will add more intuitive visualization to our journal version as well as the website.</p>

  <p>Reviewer #4 (R4)
Q1. Channel split VS. Multi-head.
Re. They share the same spirit to an extent. Indeed, the specific implementation manner of multi-head in the transformer is channel split. This operation can ensemble different attention regions in the network because various heads may focus on a different region in the feature map.</p>

  <p>Q2. How does the kernel size k select?
Re. We adopt the dilated convolution with a 3x3 kernel size due to the performance-efficiency trade-off. The motivation is that a large kernel with large dilation rates may damage the integrity in the spatial-temporal representation. In our previous attempts, this may degrade the performance and increase the computational burden. Our journal extension will further investigate the synergy effect between the kernel size and dilation rate.</p>

  <p>Q3. The pre-training/fine-tuning time.
Re: It takes about 10 hours (pre-training) on Kvasir and positive part of ASU-Mayo and 35 minutes (fine-tuning) on training set of CVC-300 and CVC-612, respectively.</p>

  <p>Q4. The improvement of pre-training strategy.
Re: We are pleased to apply this fantastic training strategy to our model. We will cite this work in the final version.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0113-12-31
      -->
      <!--
      
        ,
        updated at 
        0114-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Ji, Ge-Peng"
        class="post-category">
        Ji, Ge-Peng
      </a> |  
      
      <a href="kittywong/tags#Chou, Yu-Cheng"
        class="post-category">
        Chou, Yu-Cheng
      </a> |  
      
      <a href="kittywong/tags#Fan, Deng-Ping"
        class="post-category">
        Fan, Deng-Ping
      </a> |  
      
      <a href="kittywong/tags#Chen, Geng"
        class="post-category">
        Chen, Geng
      </a> |  
      
      <a href="kittywong/tags#Fu, Huazhu"
        class="post-category">
        Fu, Huazhu
      </a> |  
      
      <a href="kittywong/tags#Jha, Debesh"
        class="post-category">
        Jha, Debesh
      </a> |  
      
      <a href="kittywong/tags#Shao, Ling"
        class="post-category">
        Shao, Ling
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0114/12/31/Paper0423">
          SGNet: Structure-aware Graph-based Network for Airway Semantic Segmentation
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0112/12/31/Paper0315">
          Patch-Free 3D Medical Image Segmentation Driven by Super-Resolution Technique and Self-Supervised Guidance
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
