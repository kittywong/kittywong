<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Co-Graph Attention Reasoning based Imaging and Clinical Features Integration for Lymph Node Metastasis Prediction | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Co-Graph Attention Reasoning based Imaging and Clinical Features Integration for Lymph Node Metastasis Prediction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Hui Cui, Ping Xuan, Qiangguo Jin, Mingjun Ding, Butuo Li, Bing Zou, Yiyue Xu, Bingjie Fan, Wanlong Li, Jinming Yu, Linlin Wang, Been-Lirn Duh Abstract Lymph node metastasis (LNM) is the most critical prognosis factor in esophageal squamous cell carcinoma (ESCC). Effective and adaptive integration of preoperative CT images and multi-sourced non-imaging clinical factors is a challenging issue. In this work, we propose a graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction. Given CT, general, diagnostic, pathological, and hematological clinical information, we firstly propose a graph construction strategy with category-wise contextual attention to embed multi-categorical features as graph node attributes. Secondly, we introduce a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations. Corr-GAT complements con-GAT by difference-based correlations across image regions in global spectral space. Experimental results of ablation studies and comparison with others over 924 lymph nodes demonstrated improved performance and contributions of our major innovations. Our model has the potential to foster early prognosis and personalized surgery or radiotherapy planning in ESCC patients. Link to paper https://doi.org/10.1007/978-3-030-87240-3_63 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes a graph neural network architecture to use both imaging and non-imaging feature for a better decision making on lymph node metastasis. This introduces a combination of GAT and correlation based GAT along with a category-wise attention module for better integration of information. The authors showed state of the art performance compared to the existing methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using graph NN to correlate non-imaging features with imaging features and improve clinical features is interesting and promising. The co-graph and category wise attention module for more effective fusion of information from different categories is a novel idea. paper is well written and sufficient ablation studies are done Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. None Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance In my opinion the results are reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One question that I have is authors tried to correlate the non-imaging features with different regions of images through the way they concatenated the node embedding and created the graph. Did the authors observe any correlations with abnormality regions through some sort of saliency visualization potentially? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of the paper is novel, the contribution level is at MICCAI level and the results and experiments support the claims. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed a new co-graph attention layer and category-wise attention to integrate image and non-image (multi-categorical clinical factors) information for LNM prediction. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) This paper is written well, and the logic is clear. (2) Different from other fusion methods, the proposed method is novel for image and non-image features integration. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) some unclear description for the notation. for example, how to get the F_m, each row in F_m for each clinical images is equal? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is well written, and is good for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The experiments comparison should be more complete. For example, other fusion methods for image and non-image integration (only concat their features? or other approaches). Are there results for non-imaging clinical data only? Did you try other methods for combining F_ct and f_rp? Since, in the paper, repeat f_rp and concatenate with F_ct, the f_rp is in the patient level and the F_ct is a region in the image. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty for image and non-image fusion. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper A graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction was proposed. Also, a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A category-wise attention module to adaptively adjust the weights of imaging, general, diagnostic, pathological and hematological clinical factors when constructing graph node attributes has potential in predicting metastases in CT images. The introduced co-graph attention layer which is composed of a conventional GAT and correlation-based GAT could benefit in improving performance of DL imaging models. The proposed architectures were tested on relatively large dataset (~900 images from ~400 patients). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on some public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? Why not to report an experiment on some publicly available data? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sharing the source code would have helped for reproducibility. There are no validation on public data so hard to evaluate how reproducible are the results. Maybe testing/training/transfer learning the proposed models on public data (for example, https://wiki.cancerimagingarchive.net/display/Public/CT+Lymph+Nodes) could help the results to be more convincing and reproducible? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting graph-based attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced, could be an interesting architecture to explore more. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a co-graph of imaging and non-imaging parameters, jointly embedded in graph nodes and fed in two graph attention networks that learns new node representations. This is used to predict lymph node metastasis classification. The originality resides in using a category attention modules for the integration of joint information. One reviewer indicates novelty in using a co-graph and category-wise attention module for an improved fusion of imaging and non-imaging information. A second reviewer indicates the method as being different from other fusion methods, also highlighting novelty, but also indicates a lack of sufficient comparison with other fusion approaches for imaging and non-imaging, without suggesting references. Perhaps the authors could prepare a response whether to why no other fusion method, beyond its own variants, has been chosen? A third reviewer also highlights the benefits of the proposed integration of imaging and non-imaging data via a graph attention mechanism, but would have preferred a comparison on a public dataset for reproducibility, and illustrations on CT images. All three reviewers have a general consensus of appreciated novelty of fusing imaging and non-imaging data via a graph attention mechanism. Two also indicate the concepts of the category-wise attention module as novel. However, one concern to be addressed is the choice of their comparison setting. Improvements could be on improving the comparison with other fusing methods of imaging and non-imaging data. For these reasons, I believe the paper proposes a contribution to the field with a new method fusing imaging and non-imaging data via a co-graph with a graph attention mechanism, but doubts should be lifted with a response on the motivation of the comparison choices. Recommendation is towards an invitation for a Rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have clarified concerns on the choice of comparisons, on using non-imaging data as well as other minor misunderstandings. These clarifications should be integrated in the text. The authors proposes to add an illustration on CT, which would be beneficial, perhaps by remodeling the blank spaces in all three tables, but without sacrificing the clarification on the comparisons. This is a realistic touch up in my opinion. For these reasons, recommendation is toward Acceptance. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviewers all think positively about this paper. The novelty includes using co-graph for fusion and using categorical attention. The major concern is about the comparison setting and the rebuttal seems to be addressing the concern to a satisfying degree. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have addressed all the minor concerns. The paper is well written and interesting. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank the Area Chair and reviewers R1-R3 for appreciating the novelty and providing constructive comments. We first respond to R2 about the comparison choices (as requested by the Area Chair), followed by responses to other comments from all reviewers. Comparisons with other fusion models are given in Table 3 and discussed in the first paragraph on Page 8. We chose model [7] because it is a widely used benchmark Radiomics model that integrates imaging features and clinical parameters by multivariable logistic regression. Model [9] is a deep learning model which transforms non-imaging clinical data to an image before fusion with imaging data by CNN. Our model uses a graph neural network to derive new representations in an irregular domain. The comparison can demonstrate the effectiveness of novel feature learning in non-rigid like feature space. R2 suggested adding results using non-imaging clinical data only. For our dataset, non-imaging clinical data is at the patient level instead of the lymph node (LN) level. Since each patient has 1 to 6 LNs (as noted in Line 6 Section 2) with different class labels, the identical patient-level class label can not be obtained. Thus, we did not perform non-imaging clinical data only experiments. R3 questioned why not report experiments on a public dataset. As far as we know, there are no public LN prediction datasets with both imaging and non-imaging data. Hence, we did not perform this in the current paper. We thank R3 for providing a public CT LN dataset. Since the dataset has CT images only, we are pursuing a future investigation to pre-train our image encoder using the provided public data. Other comments: R3 also asked for more information on samples, patient demographics and LN. In our paper, such statistical information is provided by Section 2, Paragraph 3. We will add a figure with CT samples to Section 2 as requested by R3. The first line following Eq (1) explains the notation F_m requested by R2. F is explained by the second line on Page 5 and illustrated by Figure 1(c). We confirm that the number of rows in F_m, which is the number of graph nodes, for each clinical image is equal. R2 asked whether we tried other methods to combine F_ct and F_rp. We acknowledge that we have not tried other approaches because this is beyond the focus of the technical contributions of this paper. However, we appreciate the suggestion and leave this for future explorations. We appreciate R1’s suggestion to observe correlations between non-imaging features and different regions of images. We will investigate the visualization in future work. Thank you! back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Hui Cui, Ping Xuan, Qiangguo Jin, Mingjun Ding, Butuo Li, Bing Zou, Yiyue Xu, Bingjie Fan, Wanlong Li, Jinming Yu, Linlin Wang, Been-Lirn Duh Abstract Lymph node metastasis (LNM) is the most critical prognosis factor in esophageal squamous cell carcinoma (ESCC). Effective and adaptive integration of preoperative CT images and multi-sourced non-imaging clinical factors is a challenging issue. In this work, we propose a graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction. Given CT, general, diagnostic, pathological, and hematological clinical information, we firstly propose a graph construction strategy with category-wise contextual attention to embed multi-categorical features as graph node attributes. Secondly, we introduce a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations. Corr-GAT complements con-GAT by difference-based correlations across image regions in global spectral space. Experimental results of ablation studies and comparison with others over 924 lymph nodes demonstrated improved performance and contributions of our major innovations. Our model has the potential to foster early prognosis and personalized surgery or radiotherapy planning in ESCC patients. Link to paper https://doi.org/10.1007/978-3-030-87240-3_63 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes a graph neural network architecture to use both imaging and non-imaging feature for a better decision making on lymph node metastasis. This introduces a combination of GAT and correlation based GAT along with a category-wise attention module for better integration of information. The authors showed state of the art performance compared to the existing methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using graph NN to correlate non-imaging features with imaging features and improve clinical features is interesting and promising. The co-graph and category wise attention module for more effective fusion of information from different categories is a novel idea. paper is well written and sufficient ablation studies are done Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. None Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance In my opinion the results are reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One question that I have is authors tried to correlate the non-imaging features with different regions of images through the way they concatenated the node embedding and created the graph. Did the authors observe any correlations with abnormality regions through some sort of saliency visualization potentially? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of the paper is novel, the contribution level is at MICCAI level and the results and experiments support the claims. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed a new co-graph attention layer and category-wise attention to integrate image and non-image (multi-categorical clinical factors) information for LNM prediction. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) This paper is written well, and the logic is clear. (2) Different from other fusion methods, the proposed method is novel for image and non-image features integration. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) some unclear description for the notation. for example, how to get the F_m, each row in F_m for each clinical images is equal? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is well written, and is good for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The experiments comparison should be more complete. For example, other fusion methods for image and non-image integration (only concat their features? or other approaches). Are there results for non-imaging clinical data only? Did you try other methods for combining F_ct and f_rp? Since, in the paper, repeat f_rp and concatenate with F_ct, the f_rp is in the patient level and the F_ct is a region in the image. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty for image and non-image fusion. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper A graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction was proposed. Also, a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A category-wise attention module to adaptively adjust the weights of imaging, general, diagnostic, pathological and hematological clinical factors when constructing graph node attributes has potential in predicting metastases in CT images. The introduced co-graph attention layer which is composed of a conventional GAT and correlation-based GAT could benefit in improving performance of DL imaging models. The proposed architectures were tested on relatively large dataset (~900 images from ~400 patients). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on some public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? Why not to report an experiment on some publicly available data? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sharing the source code would have helped for reproducibility. There are no validation on public data so hard to evaluate how reproducible are the results. Maybe testing/training/transfer learning the proposed models on public data (for example, https://wiki.cancerimagingarchive.net/display/Public/CT+Lymph+Nodes) could help the results to be more convincing and reproducible? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting graph-based attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced, could be an interesting architecture to explore more. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a co-graph of imaging and non-imaging parameters, jointly embedded in graph nodes and fed in two graph attention networks that learns new node representations. This is used to predict lymph node metastasis classification. The originality resides in using a category attention modules for the integration of joint information. One reviewer indicates novelty in using a co-graph and category-wise attention module for an improved fusion of imaging and non-imaging information. A second reviewer indicates the method as being different from other fusion methods, also highlighting novelty, but also indicates a lack of sufficient comparison with other fusion approaches for imaging and non-imaging, without suggesting references. Perhaps the authors could prepare a response whether to why no other fusion method, beyond its own variants, has been chosen? A third reviewer also highlights the benefits of the proposed integration of imaging and non-imaging data via a graph attention mechanism, but would have preferred a comparison on a public dataset for reproducibility, and illustrations on CT images. All three reviewers have a general consensus of appreciated novelty of fusing imaging and non-imaging data via a graph attention mechanism. Two also indicate the concepts of the category-wise attention module as novel. However, one concern to be addressed is the choice of their comparison setting. Improvements could be on improving the comparison with other fusing methods of imaging and non-imaging data. For these reasons, I believe the paper proposes a contribution to the field with a new method fusing imaging and non-imaging data via a co-graph with a graph attention mechanism, but doubts should be lifted with a response on the motivation of the comparison choices. Recommendation is towards an invitation for a Rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have clarified concerns on the choice of comparisons, on using non-imaging data as well as other minor misunderstandings. These clarifications should be integrated in the text. The authors proposes to add an illustration on CT, which would be beneficial, perhaps by remodeling the blank spaces in all three tables, but without sacrificing the clarification on the comparisons. This is a realistic touch up in my opinion. For these reasons, recommendation is toward Acceptance. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviewers all think positively about this paper. The novelty includes using co-graph for fusion and using categorical attention. The major concern is about the comparison setting and the rebuttal seems to be addressing the concern to a satisfying degree. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have addressed all the minor concerns. The paper is well written and interesting. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank the Area Chair and reviewers R1-R3 for appreciating the novelty and providing constructive comments. We first respond to R2 about the comparison choices (as requested by the Area Chair), followed by responses to other comments from all reviewers. Comparisons with other fusion models are given in Table 3 and discussed in the first paragraph on Page 8. We chose model [7] because it is a widely used benchmark Radiomics model that integrates imaging features and clinical parameters by multivariable logistic regression. Model [9] is a deep learning model which transforms non-imaging clinical data to an image before fusion with imaging data by CNN. Our model uses a graph neural network to derive new representations in an irregular domain. The comparison can demonstrate the effectiveness of novel feature learning in non-rigid like feature space. R2 suggested adding results using non-imaging clinical data only. For our dataset, non-imaging clinical data is at the patient level instead of the lymph node (LN) level. Since each patient has 1 to 6 LNs (as noted in Line 6 Section 2) with different class labels, the identical patient-level class label can not be obtained. Thus, we did not perform non-imaging clinical data only experiments. R3 questioned why not report experiments on a public dataset. As far as we know, there are no public LN prediction datasets with both imaging and non-imaging data. Hence, we did not perform this in the current paper. We thank R3 for providing a public CT LN dataset. Since the dataset has CT images only, we are pursuing a future investigation to pre-train our image encoder using the provided public data. Other comments: R3 also asked for more information on samples, patient demographics and LN. In our paper, such statistical information is provided by Section 2, Paragraph 3. We will add a figure with CT samples to Section 2 as requested by R3. The first line following Eq (1) explains the notation F_m requested by R2. F is explained by the second line on Page 5 and illustrated by Figure 1(c). We confirm that the number of rows in F_m, which is the number of graph nodes, for each clinical image is equal. R2 asked whether we tried other methods to combine F_ct and F_rp. We acknowledge that we have not tried other approaches because this is beyond the focus of the technical contributions of this paper. However, we appreciate the suggestion and leave this for future explorations. We appreciate R1’s suggestion to observe correlations between non-imaging features and different regions of images. We will investigate the visualization in future work. Thank you! back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0562/12/31/Paper0153" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0562/12/31/Paper0153" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0562-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Co-Graph Attention Reasoning based Imaging and Clinical Features Integration for Lymph Node Metastasis Prediction" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0562/12/31/Paper0153"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0562/12/31/Paper0153","headline":"Co-Graph Attention Reasoning based Imaging and Clinical Features Integration for Lymph Node Metastasis Prediction","dateModified":"0563-01-03T00:00:00-05:17","datePublished":"0562-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Hui Cui, Ping Xuan, Qiangguo Jin, Mingjun Ding, Butuo Li, Bing Zou, Yiyue Xu, Bingjie Fan, Wanlong Li, Jinming Yu, Linlin Wang, Been-Lirn Duh Abstract Lymph node metastasis (LNM) is the most critical prognosis factor in esophageal squamous cell carcinoma (ESCC). Effective and adaptive integration of preoperative CT images and multi-sourced non-imaging clinical factors is a challenging issue. In this work, we propose a graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction. Given CT, general, diagnostic, pathological, and hematological clinical information, we firstly propose a graph construction strategy with category-wise contextual attention to embed multi-categorical features as graph node attributes. Secondly, we introduce a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations. Corr-GAT complements con-GAT by difference-based correlations across image regions in global spectral space. Experimental results of ablation studies and comparison with others over 924 lymph nodes demonstrated improved performance and contributions of our major innovations. Our model has the potential to foster early prognosis and personalized surgery or radiotherapy planning in ESCC patients. Link to paper https://doi.org/10.1007/978-3-030-87240-3_63 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper proposes a graph neural network architecture to use both imaging and non-imaging feature for a better decision making on lymph node metastasis. This introduces a combination of GAT and correlation based GAT along with a category-wise attention module for better integration of information. The authors showed state of the art performance compared to the existing methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea of using graph NN to correlate non-imaging features with imaging features and improve clinical features is interesting and promising. The co-graph and category wise attention module for more effective fusion of information from different categories is a novel idea. paper is well written and sufficient ablation studies are done Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. None Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance In my opinion the results are reproducible Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One question that I have is authors tried to correlate the non-imaging features with different regions of images through the way they concatenated the node embedding and created the graph. Did the authors observe any correlations with abnormality regions through some sort of saliency visualization potentially? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The idea of the paper is novel, the contribution level is at MICCAI level and the results and experiments support the claims. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed a new co-graph attention layer and category-wise attention to integrate image and non-image (multi-categorical clinical factors) information for LNM prediction. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. (1) This paper is written well, and the logic is clear. (2) Different from other fusion methods, the proposed method is novel for image and non-image features integration. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. (1) some unclear description for the notation. for example, how to get the F_m, each row in F_m for each clinical images is equal? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is well written, and is good for reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The experiments comparison should be more complete. For example, other fusion methods for image and non-image integration (only concat their features? or other approaches). Are there results for non-imaging clinical data only? Did you try other methods for combining F_ct and f_rp? Since, in the paper, repeat f_rp and concatenate with F_ct, the f_rp is in the patient level and the F_ct is a region in the image. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty for image and non-image fusion. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper A graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction was proposed. Also, a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A category-wise attention module to adaptively adjust the weights of imaging, general, diagnostic, pathological and hematological clinical factors when constructing graph node attributes has potential in predicting metastases in CT images. The introduced co-graph attention layer which is composed of a conventional GAT and correlation-based GAT could benefit in improving performance of DL imaging models. The proposed architectures were tested on relatively large dataset (~900 images from ~400 patients). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on some public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? Why not to report an experiment on some publicly available data? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Sharing the source code would have helped for reproducibility. There are no validation on public data so hard to evaluate how reproducible are the results. Maybe testing/training/transfer learning the proposed models on public data (for example, https://wiki.cancerimagingarchive.net/display/Public/CT+Lymph+Nodes) could help the results to be more convincing and reproducible? Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix. Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Interesting graph-based attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced, could be an interesting architecture to explore more. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposes a co-graph of imaging and non-imaging parameters, jointly embedded in graph nodes and fed in two graph attention networks that learns new node representations. This is used to predict lymph node metastasis classification. The originality resides in using a category attention modules for the integration of joint information. One reviewer indicates novelty in using a co-graph and category-wise attention module for an improved fusion of imaging and non-imaging information. A second reviewer indicates the method as being different from other fusion methods, also highlighting novelty, but also indicates a lack of sufficient comparison with other fusion approaches for imaging and non-imaging, without suggesting references. Perhaps the authors could prepare a response whether to why no other fusion method, beyond its own variants, has been chosen? A third reviewer also highlights the benefits of the proposed integration of imaging and non-imaging data via a graph attention mechanism, but would have preferred a comparison on a public dataset for reproducibility, and illustrations on CT images. All three reviewers have a general consensus of appreciated novelty of fusing imaging and non-imaging data via a graph attention mechanism. Two also indicate the concepts of the category-wise attention module as novel. However, one concern to be addressed is the choice of their comparison setting. Improvements could be on improving the comparison with other fusing methods of imaging and non-imaging data. For these reasons, I believe the paper proposes a contribution to the field with a new method fusing imaging and non-imaging data via a co-graph with a graph attention mechanism, but doubts should be lifted with a response on the motivation of the comparison choices. Recommendation is towards an invitation for a Rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have clarified concerns on the choice of comparisons, on using non-imaging data as well as other minor misunderstandings. These clarifications should be integrated in the text. The authors proposes to add an illustration on CT, which would be beneficial, perhaps by remodeling the blank spaces in all three tables, but without sacrificing the clarification on the comparisons. This is a realistic touch up in my opinion. For these reasons, recommendation is toward Acceptance. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviewers all think positively about this paper. The novelty includes using co-graph for fusion and using categorical attention. The major concern is about the comparison setting and the rebuttal seems to be addressing the concern to a satisfying degree. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have addressed all the minor concerns. The paper is well written and interesting. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We thank the Area Chair and reviewers R1-R3 for appreciating the novelty and providing constructive comments. We first respond to R2 about the comparison choices (as requested by the Area Chair), followed by responses to other comments from all reviewers. Comparisons with other fusion models are given in Table 3 and discussed in the first paragraph on Page 8. We chose model [7] because it is a widely used benchmark Radiomics model that integrates imaging features and clinical parameters by multivariable logistic regression. Model [9] is a deep learning model which transforms non-imaging clinical data to an image before fusion with imaging data by CNN. Our model uses a graph neural network to derive new representations in an irregular domain. The comparison can demonstrate the effectiveness of novel feature learning in non-rigid like feature space. R2 suggested adding results using non-imaging clinical data only. For our dataset, non-imaging clinical data is at the patient level instead of the lymph node (LN) level. Since each patient has 1 to 6 LNs (as noted in Line 6 Section 2) with different class labels, the identical patient-level class label can not be obtained. Thus, we did not perform non-imaging clinical data only experiments. R3 questioned why not report experiments on a public dataset. As far as we know, there are no public LN prediction datasets with both imaging and non-imaging data. Hence, we did not perform this in the current paper. We thank R3 for providing a public CT LN dataset. Since the dataset has CT images only, we are pursuing a future investigation to pre-train our image encoder using the provided public data. Other comments: R3 also asked for more information on samples, patient demographics and LN. In our paper, such statistical information is provided by Section 2, Paragraph 3. We will add a figure with CT samples to Section 2 as requested by R3. The first line following Eq (1) explains the notation F_m requested by R2. F is explained by the second line on Page 5 and illustrated by Figure 1(c). We confirm that the number of rows in F_m, which is the number of graph nodes, for each clinical image is equal. R2 asked whether we tried other methods to combine F_ct and F_rp. We acknowledge that we have not tried other approaches because this is beyond the focus of the technical contributions of this paper. However, we appreciate the suggestion and leave this for future explorations. We appreciate R1’s suggestion to observe correlations between non-imaging features and different regions of images. We will investigate the visualization in future work. Thank you! back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Cui, Hui,Xuan, Ping,Jin, Qiangguo,Ding, Mingjun,Li, Butuo,Zou, Bing,Xu, Yiyue,Fan, Bingjie,Li, Wanlong,Yu, Jinming,Wang, Linlin,Duh, Been-Lirn" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Co-Graph Attention Reasoning based Imaging and Clinical Features Integration for Lymph Node Metastasis Prediction</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Integration of Imaging with Non-Imaging Biomarkers"
        class="post-category">
        Integration of Imaging with Non-Imaging Biomarkers
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Oncology"
        class="post-category">
        Clinical applications - Oncology
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a>
      
      <a 
        href="kittywong/categories#Outcome/disease prediction"
        class="post-category">
        Outcome/disease prediction
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Cui, Hui"
        class="post-tags">
        Cui, Hui
      </a> |  
      
      <a href="kittywong/tags#Xuan, Ping"
        class="post-tags">
        Xuan, Ping
      </a> |  
      
      <a href="kittywong/tags#Jin, Qiangguo"
        class="post-tags">
        Jin, Qiangguo
      </a> |  
      
      <a href="kittywong/tags#Ding, Mingjun"
        class="post-tags">
        Ding, Mingjun
      </a> |  
      
      <a href="kittywong/tags#Li, Butuo"
        class="post-tags">
        Li, Butuo
      </a> |  
      
      <a href="kittywong/tags#Zou, Bing"
        class="post-tags">
        Zou, Bing
      </a> |  
      
      <a href="kittywong/tags#Xu, Yiyue"
        class="post-tags">
        Xu, Yiyue
      </a> |  
      
      <a href="kittywong/tags#Fan, Bingjie"
        class="post-tags">
        Fan, Bingjie
      </a> |  
      
      <a href="kittywong/tags#Li, Wanlong"
        class="post-tags">
        Li, Wanlong
      </a> |  
      
      <a href="kittywong/tags#Yu, Jinming"
        class="post-tags">
        Yu, Jinming
      </a> |  
      
      <a href="kittywong/tags#Wang, Linlin"
        class="post-tags">
        Wang, Linlin
      </a> |  
      
      <a href="kittywong/tags#Duh, Been-Lirn"
        class="post-tags">
        Duh, Been-Lirn
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Hui Cui, Ping Xuan, Qiangguo Jin, Mingjun Ding, Butuo Li, Bing Zou, Yiyue Xu, Bingjie Fan, Wanlong Li, Jinming Yu, Linlin Wang, Been-Lirn Duh
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Lymph node metastasis (LNM) is the most critical prognosis factor in esophageal squamous cell carcinoma (ESCC). Effective and adaptive integration of preoperative CT images and multi-sourced non-imaging clinical factors is a challenging issue. In this work, we propose a graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction. Given CT, general, diagnostic, pathological, and hematological clinical information, we firstly propose a graph construction strategy with category-wise contextual attention to embed multi-categorical features as graph node attributes. Secondly, we introduce a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations. Corr-GAT complements con-GAT by difference-based correlations across image regions in global spectral space. Experimental results of ablation studies and comparison with others over 924 lymph nodes demonstrated improved performance and contributions of our major innovations. Our model has the potential to foster early prognosis and personalized surgery or radiotherapy planning in ESCC patients. 
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87240-3_63">https://doi.org/10.1007/978-3-030-87240-3_63</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes a graph neural network architecture to use both imaging and non-imaging feature for a better decision making on lymph node metastasis. This introduces a combination of GAT and correlation based GAT along with a category-wise attention module for better integration of information. The authors showed state of the art performance compared to the existing methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The idea of using graph NN to correlate non-imaging features with imaging features and improve clinical features is interesting and promising. 
The co-graph and category wise attention module for more effective fusion of information from different categories is a novel idea.
paper is well written and sufficient ablation studies are done</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>None</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>In my opinion the results are reproducible</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>One question that I have is authors tried to correlate the non-imaging features with different regions of images through the way they concatenated the node embedding and created the graph. Did the authors observe any correlations with abnormality regions through some sort of saliency visualization potentially?</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The idea of the paper is novel, the contribution level is at MICCAI level and the results and experiments support the claims.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposed a new co-graph attention layer and category-wise attention to integrate image and non-image (multi-categorical clinical factors) information for LNM prediction.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>(1) This paper is written well, and the logic is clear.
(2) Different from other fusion methods, the proposed method is novel for image and non-image features integration.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>(1) some unclear description for the notation. for example, how to get the F_m, each row in F_m for each clinical images is equal?</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>This paper is well written, and is good for reproducibility.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>The experiments comparison should be more complete. For example, other fusion methods for image and non-image integration (only concat their features? or other approaches).</li>
        <li>Are there results for non-imaging clinical data only?</li>
        <li>Did you try other methods for combining F_ct and f_rp? Since, in the paper, repeat f_rp and concatenate with F_ct, the f_rp is in the patient level and the F_ct is a region in the image.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The novelty for image and non-image fusion.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>A graph-based reasoning model to learn new representations from multi-categorical clinical parameters for LNM prediction was proposed. Also, a co-graph attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>
          <p>A category-wise attention module to adaptively adjust the weights of imaging, general, diagnostic, pathological and hematological clinical factors when constructing graph node attributes has potential in predicting metastases in CT images.</p>
        </li>
        <li>
          <p>The introduced co-graph attention layer which is composed of a conventional GAT and correlation-based GAT could benefit in improving performance of DL imaging models.</p>
        </li>
        <li>
          <p>The proposed architectures were tested on relatively large dataset (~900 images from ~400 patients).</p>
        </li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on some public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc? Why not to report an experiment on some publicly available data?</li>
        <li>It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix.</li>
        <li>Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes?</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Sharing the source code would have helped for reproducibility. There are no validation on public data so hard to evaluate how reproducible are the results. Maybe testing/training/transfer learning the proposed models on public data (for example, https://wiki.cancerimagingarchive.net/display/Public/CT+Lymph+Nodes) could help the results to be more convincing and reproducible?</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>Sharing the source code would have helped for reproducibility. More importantly, demonstrating the efficacy of the proposed method on public data? I guess the method should be promising on CT images in general, maybe WSIs, IHC etc?</li>
        <li>It’d be beneficial to report confidence intervals for the ablation studies. Also, maybe adding AUC curves in Appendix.</li>
        <li>Maybe adding a few CT examples, if possible? More information on the samples, patients demographics, lymph nodes?</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Interesting graph-based attention layer composed of a conventional graph attention network (con-GAT) and a correlation-based GAT (corr-GAT) to learn new representations was introduced, could be an interesting architecture to explore more.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The paper proposes a co-graph of imaging and non-imaging parameters, jointly embedded in graph nodes and fed in two graph attention networks that learns new node representations. This is used to predict lymph node metastasis classification. The originality resides in using a category attention modules for the integration of joint information.</p>

      <p>One reviewer indicates novelty in using a co-graph and category-wise attention module for an improved fusion of imaging and non-imaging information.</p>

      <p>A second reviewer indicates the method as being different from other fusion methods, also highlighting novelty, but also indicates a lack of sufficient comparison with other fusion approaches for imaging and non-imaging, without suggesting references. Perhaps the authors could prepare a response whether to why no other fusion method, beyond its own variants, has been chosen?</p>

      <p>A third reviewer also highlights the benefits of the proposed integration of imaging and non-imaging data via a graph attention mechanism, but would have preferred a comparison on a public dataset for reproducibility, and illustrations on CT images.</p>

      <p>All three reviewers have a general consensus of appreciated novelty of fusing imaging and non-imaging data via a graph attention mechanism. Two also indicate the concepts of the category-wise attention module as novel. However, one concern to be addressed is the choice of their comparison setting. Improvements could be on improving the comparison with other fusing methods of imaging and non-imaging data.</p>

      <p>For these reasons, I believe the paper proposes a contribution to the field with a new method fusing imaging and non-imaging data via a co-graph with a graph attention mechanism, but doubts should be lifted with a response on the motivation of the comparison choices. Recommendation is towards an invitation for a Rebuttal.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors have clarified concerns on the choice of comparisons, on using non-imaging data as well as other minor misunderstandings. These clarifications should be integrated in the text. The authors proposes to add an illustration on CT, which would be beneficial, perhaps by remodeling the blank spaces in all three tables, but without sacrificing the clarification on the comparisons. This is a realistic touch up in my opinion.</p>

      <p>For these reasons, recommendation is toward Acceptance.</p>

    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The reviewers all think positively about this paper. The novelty includes using co-graph for fusion and using categorical attention. The major concern is about the comparison setting and the rebuttal seems to be addressing the concern to a satisfying degree.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors have addressed all the minor concerns. The paper is well written and interesting.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the Area Chair and reviewers R1-R3 for appreciating the novelty and providing constructive comments. We first respond to R2 about the comparison choices (as requested by the Area Chair), followed by responses to other comments from all reviewers.</p>

  <p>Comparisons with other fusion models are given in Table 3 and discussed in the first paragraph on Page 8. We chose model [7] because it is a widely used benchmark Radiomics model that integrates imaging features and clinical parameters by multivariable logistic regression. Model [9] is a deep learning model which transforms non-imaging clinical data to an image before fusion with imaging data by CNN. Our model uses a graph neural network to derive new representations in an irregular domain. The comparison can demonstrate the effectiveness of novel feature learning in non-rigid like feature space.</p>

  <p>R2 suggested adding results using non-imaging clinical data only. For our dataset, non-imaging clinical data is at the patient level instead of the lymph node (LN) level. Since each patient has 1 to 6 LNs (as noted in Line 6 Section 2) with different class labels, the identical patient-level class label can not be obtained. Thus, we did not perform non-imaging clinical data only experiments.</p>

  <p>R3 questioned why not report experiments on a public dataset. As far as we know, there are no public LN prediction datasets with both imaging and non-imaging data. Hence, we did not perform this in the current paper. We thank R3 for providing a public CT LN dataset. Since the dataset has CT images only, we are pursuing a future investigation to pre-train our image encoder using the provided public data.</p>

  <p>Other comments:</p>

  <p>R3 also asked for more information on samples, patient demographics and LN. In our paper, such statistical information is provided by Section 2, Paragraph 3. We will add a figure with CT samples to Section 2 as requested by R3.</p>

  <p>The first line following Eq (1) explains the notation F_m requested by R2. F is explained by the second line on Page 5 and illustrated by Figure 1(c). We confirm that the number of rows in F_m, which is the number of graph nodes, for each clinical image is equal.</p>

  <p>R2 asked whether we tried other methods to combine F_ct and F_rp. We acknowledge that we have not tried other approaches because this is beyond the focus of the technical contributions of this paper. However, we appreciate the suggestion and leave this for future explorations.</p>

  <p>We appreciate R1’s suggestion to observe correlations between non-imaging features and different regions of images. We will investigate the visualization in future work.</p>

  <p>Thank you!</p>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0562-12-31
      -->
      <!--
      
        ,
        updated at 
        0563-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Integration of Imaging with Non-Imaging Biomarkers"
        class="post-category">
        Integration of Imaging with Non-Imaging Biomarkers
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Oncology"
        class="post-category">
        Clinical applications - Oncology
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a> |
      
      <a 
        href="kittywong/categories#Outcome/disease prediction"
        class="post-category">
        Outcome/disease prediction
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Cui, Hui"
        class="post-category">
        Cui, Hui
      </a> |  
      
      <a href="kittywong/tags#Xuan, Ping"
        class="post-category">
        Xuan, Ping
      </a> |  
      
      <a href="kittywong/tags#Jin, Qiangguo"
        class="post-category">
        Jin, Qiangguo
      </a> |  
      
      <a href="kittywong/tags#Ding, Mingjun"
        class="post-category">
        Ding, Mingjun
      </a> |  
      
      <a href="kittywong/tags#Li, Butuo"
        class="post-category">
        Li, Butuo
      </a> |  
      
      <a href="kittywong/tags#Zou, Bing"
        class="post-category">
        Zou, Bing
      </a> |  
      
      <a href="kittywong/tags#Xu, Yiyue"
        class="post-category">
        Xu, Yiyue
      </a> |  
      
      <a href="kittywong/tags#Fan, Bingjie"
        class="post-category">
        Fan, Bingjie
      </a> |  
      
      <a href="kittywong/tags#Li, Wanlong"
        class="post-category">
        Li, Wanlong
      </a> |  
      
      <a href="kittywong/tags#Yu, Jinming"
        class="post-category">
        Yu, Jinming
      </a> |  
      
      <a href="kittywong/tags#Wang, Linlin"
        class="post-category">
        Wang, Linlin
      </a> |  
      
      <a href="kittywong/tags#Duh, Been-Lirn"
        class="post-category">
        Duh, Been-Lirn
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0563/12/31/Paper0234">
          Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0561/12/31/Paper0117">
          Lung Cancer Risk Estimation with Incomplete Data: A Joint Missing Imputation Perspective
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
