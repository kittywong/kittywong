<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Self-Supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Self-Supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Baoru Huang, Jian-Qing Zheng, Anh Nguyen, David Tuch, Kunal Vyas, Stamatia Giannarou, Daniel S. Elson Abstract Dense depth estimation and 3D reconstruction of a surgical scene are crucial steps in computer assisted surgery. Recent work has shown that depth estimation from a stereo images pair could be solved with convolutional neural networks. However, most recent depth estimation models were trained on datasets with per-pixel ground truth. Such data is especially rare for laparoscopic imaging, making it hard to apply supervised depth estimation to real surgical applications. To overcome this limitation, we propose SADepth, a new self-supervised depth estimation method based on Generative Adversarial Networks. It consists of an encoder-decoder generator and a discriminator to incorporate geometry constraints during training. Multi-scale outputs from the generator help to solve the local minima caused by the photometric reprojection loss, while the adversarial learning improves the framework generation quality. Extensive experiments on two public datasets show that SADepth outperforms recent state-of-the-art unsupervised methods by a large margin, and reduces the gap between supervised and unsupervised depth estimation in laparoscopic images. Link to paper https://doi.org/10.1007/978-3-030-87202-1_22 Link to the code repository N/A Link to the dataset(s) http://hamlyn.doc.ic.ac.uk/vision/ https://endovissub2019-scared.grand-challenge.org/Home/ Reviews Review #1 Please describe the contribution of the paper The authors proposed a novel method for self-supervised adversarial depth estimation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors proposed a self-supervised adversarial depth estimation. They also applied the disparity smoothness loss and formed the network across multiple scales. Two public endoscopic datasets were used to prove the effectivity of the proposed algorithm. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The evaluation metrics for two datasets are different, Why? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance There is no code or data available, and it is not easy for the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The novelty of paper is good. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty of the proposed algorithm for depth estimation is good. The experiment results based on two datasets are better than others. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed an end_to_end self-supervised network for depth estimation in laparoscopic Images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. They use re-projective sampler to reconstruct stereo images for self-supervised and adversarial learning Two datasets have been used to evaluate the proposed network. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is not reproducible as they won’t provide code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Is it possible to create ground truth for this task by mounting other scanning devices onto the laparoscope and calibrating them? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Comparisons with non-learning methods were not performed. The comparison methods in [8] and [9] are for monocular camera. Qualitative evaluation results are missing What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper presents an unsupervised depth estimation algorithm using generative adversarial networks (GANs). The generator is trained to estimate disparity maps between the input image pairs, which is then used to estimate depth. Depth estimates are projected onto the image planes and the discriminator tries to determine whether the image generated is the original input image or that generated by projecting estimated depth onto the image plane. Results show improvements over other unsupervised depth estimation methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Reasoning behind the type of neural network and use of the different loss functions is intuitively explained and results are compared against several other methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper was fairly hard to read and follow. Once the reader is through the methods section, the reasoning makes sense. However, getting through the methods section was tough even though the actual technical method, from my understanding, is not too complicated. The methods section would benefit from a more straightforward explanation of steps. The main weakness of the paper, however, is the lack of network details. While authors do include several parameter settings in the main paper, details about the network architecture are left to supplementary material, which unfortunately is not published along with the main paper. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Due to the network architecture details being left to supplementary materials, the method as it is explained in the paper alone may be hard to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One thing that would really help in clarity is to explain the method step by step as the data travels through the network. Currently, the methods section seems overly complicated. While the number of methods compared against is definitely a positive, there are a few methods that are referenced but not compared against. Is there a reason why? Finally, although the large number of quantitative comparisons is great, it would be nice to see at least one qualitative result. How does an SSIM of ~80 translate in terms of depth estimates? Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My recommendation is based mostly on the lack of network details in the main paper. The clarity of the methods is also a contributor although less important than network details. If the authors can include network details in the paper and better organize their methods section, this could be bumped up to borderline accept. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 6 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers agreed that the paper has some merits. However, two reviewers pointed out problems in the experiment section, e.g. the evaluation metrics for two datasets are different, the comparison is unfair, etc. In addition, R3 thinks the description of the method, in particular the network details are missing. Please clarify these points in the rebuttal letter. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have explained the reason of using different metric for evaluation of the two datasets. That is becase SCARED provides the per-pixel depth ground truth, while dPVN does not. The authors also clarified that they did compare their method with non-deep learning methods as requested by R2 and explained the reasons of not generating ground truth data by mounting other scanning devices. Regarding the qualitative results requested by R2 and R3, the authors would add some in the revised version if the space is allowed. In general, the AC is satisfied with the authors responses as the major concerns have been addressed and clarified in this rebuttal letter. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The initial reviews pointed out some weaknesses of the paper, including comparisons to previous work and clarity. The authors used the rebuttal to address these critics in a reasonable way. The task at hand – 3D reconstruction in laparoscopy – is yet a difficult and unresolved task. Even if the paper doesn’t bring a strong technical contribution, it’s still a useful one, as an early attempt of GANs for this problem. I would thus recommend acceptance of the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The paper proposes a method for self-supervised depth estimation in laparoscopic images using generative adversarial networks. The novelty of the approach is adequate, and the paper presents experimental results of two public datasets. The rebuttal promises to release public code, which assuages concerns about reproducibility and technical clarity. It also clarifies that empirical comparisons are conducted against the stereo versions of [8,9] methods, which is essential to ensure the fairness of the evaluation. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Author Feedback We would like to thank all of the reviewers for their constructive comments. We have addressed all the points raised, including: i) our source code will be released, ii) comparison with non-learning methods, iii) clarification of stereo laparoscope settings, iv) adding qualitative results, and v) re-organizing Methodology section and provide more network details in the manuscript. Reviewer 1 Evaluation metrics: The evaluation metrics for the two datasets are different because SCARED provides the per-pixel depth ground truth, while dPVN does not. Therefore, for the SCARED dataset we use the mean absolute error to compare the predicted depth map with the ground truth depth image. For the dPVN dataset, we used the SSfIM metric to compare the reconstructed image with the original image which is a standard process in unsupervised depth estimation. Dataset and code: Both SCARED and dVPN datasets are available online. We will also release our code. Reviewer 2 Comparison to non-learning methods: In Table 1, we did compare our framework with two non-learning methods namely, ELAS and SPS. Following this suggestion we have also reproduced the results of ELAS and SPS in Table 2. Comparison to monocular methods: In [8] and [9], an extension of the proposed monocular reconstruction framework was proposed for stereo reconstruction, with publicly available code. In our work, for fair comparison, we compared our framework to the stereo implementation of [8] and [9]. Qualitative results are missing: This was mainly due to page length limitations but we have created qualitative results and we have added them to the main paper by compressing the references to save space. Generate ground truth data by mounting other scanning devices: This is a good suggestion but challenging to achieve in practice. We — and other research groups — have previously used commercial RGB-D cameras to attempt this, primarily in a laboratory or pre-clinical setting. However, the working distance of the laparoscope is shorter than most depth cameras, resulting in sparse and noisy depth maps. Another strategy is to build a system with a structured lighting device that can project an encoded pattern onto the tissue but it is difficult to generate significant amounts of accurate data in endoscopic applications. We continue to work on this problem including designing new hardware and exploring more efficient algorithms to overcome some of these limitations. Reviewer 3 Clarity of method explanation: We have restructured the Methodology section in the main paper and present a step-by-step explanation of how the data travels through the network. A more straightforward description of the method has been given to show network details. Compared methods: We compared our method with recent methods that satisfy the following conditions: i) they used stereo datasets; ii) they provided stereo training settings; iii) they had executable code released. We referenced other papers where the ideas were valuable to this work, even where a direct data comparison was not possible based on these criteria. Qualitative results and SSIM score comparison to depth accuracy: Please refer to our response to Reviewer 2 question 3. We have generated and visualized the reconstructed image, depth image, and input image size-by-size, together with the associated SSIM score. These are separate metrics that can be used to understand the model performance, and the qualitative results now complement the quantitative ones to help illustrate the relationship. More network details: We accept this critique and have now improved the description of the network and clarified the approach in the methods section. We have also moved the network figure from supplementary materials to the main body to improve the explanation of the method. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Baoru Huang, Jian-Qing Zheng, Anh Nguyen, David Tuch, Kunal Vyas, Stamatia Giannarou, Daniel S. Elson Abstract Dense depth estimation and 3D reconstruction of a surgical scene are crucial steps in computer assisted surgery. Recent work has shown that depth estimation from a stereo images pair could be solved with convolutional neural networks. However, most recent depth estimation models were trained on datasets with per-pixel ground truth. Such data is especially rare for laparoscopic imaging, making it hard to apply supervised depth estimation to real surgical applications. To overcome this limitation, we propose SADepth, a new self-supervised depth estimation method based on Generative Adversarial Networks. It consists of an encoder-decoder generator and a discriminator to incorporate geometry constraints during training. Multi-scale outputs from the generator help to solve the local minima caused by the photometric reprojection loss, while the adversarial learning improves the framework generation quality. Extensive experiments on two public datasets show that SADepth outperforms recent state-of-the-art unsupervised methods by a large margin, and reduces the gap between supervised and unsupervised depth estimation in laparoscopic images. Link to paper https://doi.org/10.1007/978-3-030-87202-1_22 Link to the code repository N/A Link to the dataset(s) http://hamlyn.doc.ic.ac.uk/vision/ https://endovissub2019-scared.grand-challenge.org/Home/ Reviews Review #1 Please describe the contribution of the paper The authors proposed a novel method for self-supervised adversarial depth estimation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors proposed a self-supervised adversarial depth estimation. They also applied the disparity smoothness loss and formed the network across multiple scales. Two public endoscopic datasets were used to prove the effectivity of the proposed algorithm. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The evaluation metrics for two datasets are different, Why? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance There is no code or data available, and it is not easy for the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The novelty of paper is good. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty of the proposed algorithm for depth estimation is good. The experiment results based on two datasets are better than others. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed an end_to_end self-supervised network for depth estimation in laparoscopic Images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. They use re-projective sampler to reconstruct stereo images for self-supervised and adversarial learning Two datasets have been used to evaluate the proposed network. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is not reproducible as they won’t provide code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Is it possible to create ground truth for this task by mounting other scanning devices onto the laparoscope and calibrating them? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Comparisons with non-learning methods were not performed. The comparison methods in [8] and [9] are for monocular camera. Qualitative evaluation results are missing What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper presents an unsupervised depth estimation algorithm using generative adversarial networks (GANs). The generator is trained to estimate disparity maps between the input image pairs, which is then used to estimate depth. Depth estimates are projected onto the image planes and the discriminator tries to determine whether the image generated is the original input image or that generated by projecting estimated depth onto the image plane. Results show improvements over other unsupervised depth estimation methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Reasoning behind the type of neural network and use of the different loss functions is intuitively explained and results are compared against several other methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper was fairly hard to read and follow. Once the reader is through the methods section, the reasoning makes sense. However, getting through the methods section was tough even though the actual technical method, from my understanding, is not too complicated. The methods section would benefit from a more straightforward explanation of steps. The main weakness of the paper, however, is the lack of network details. While authors do include several parameter settings in the main paper, details about the network architecture are left to supplementary material, which unfortunately is not published along with the main paper. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Due to the network architecture details being left to supplementary materials, the method as it is explained in the paper alone may be hard to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One thing that would really help in clarity is to explain the method step by step as the data travels through the network. Currently, the methods section seems overly complicated. While the number of methods compared against is definitely a positive, there are a few methods that are referenced but not compared against. Is there a reason why? Finally, although the large number of quantitative comparisons is great, it would be nice to see at least one qualitative result. How does an SSIM of ~80 translate in terms of depth estimates? Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My recommendation is based mostly on the lack of network details in the main paper. The clarity of the methods is also a contributor although less important than network details. If the authors can include network details in the paper and better organize their methods section, this could be bumped up to borderline accept. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 6 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers agreed that the paper has some merits. However, two reviewers pointed out problems in the experiment section, e.g. the evaluation metrics for two datasets are different, the comparison is unfair, etc. In addition, R3 thinks the description of the method, in particular the network details are missing. Please clarify these points in the rebuttal letter. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have explained the reason of using different metric for evaluation of the two datasets. That is becase SCARED provides the per-pixel depth ground truth, while dPVN does not. The authors also clarified that they did compare their method with non-deep learning methods as requested by R2 and explained the reasons of not generating ground truth data by mounting other scanning devices. Regarding the qualitative results requested by R2 and R3, the authors would add some in the revised version if the space is allowed. In general, the AC is satisfied with the authors responses as the major concerns have been addressed and clarified in this rebuttal letter. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The initial reviews pointed out some weaknesses of the paper, including comparisons to previous work and clarity. The authors used the rebuttal to address these critics in a reasonable way. The task at hand – 3D reconstruction in laparoscopy – is yet a difficult and unresolved task. Even if the paper doesn’t bring a strong technical contribution, it’s still a useful one, as an early attempt of GANs for this problem. I would thus recommend acceptance of the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The paper proposes a method for self-supervised depth estimation in laparoscopic images using generative adversarial networks. The novelty of the approach is adequate, and the paper presents experimental results of two public datasets. The rebuttal promises to release public code, which assuages concerns about reproducibility and technical clarity. It also clarifies that empirical comparisons are conducted against the stereo versions of [8,9] methods, which is essential to ensure the fairness of the evaluation. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Author Feedback We would like to thank all of the reviewers for their constructive comments. We have addressed all the points raised, including: i) our source code will be released, ii) comparison with non-learning methods, iii) clarification of stereo laparoscope settings, iv) adding qualitative results, and v) re-organizing Methodology section and provide more network details in the manuscript. Reviewer 1 Evaluation metrics: The evaluation metrics for the two datasets are different because SCARED provides the per-pixel depth ground truth, while dPVN does not. Therefore, for the SCARED dataset we use the mean absolute error to compare the predicted depth map with the ground truth depth image. For the dPVN dataset, we used the SSfIM metric to compare the reconstructed image with the original image which is a standard process in unsupervised depth estimation. Dataset and code: Both SCARED and dVPN datasets are available online. We will also release our code. Reviewer 2 Comparison to non-learning methods: In Table 1, we did compare our framework with two non-learning methods namely, ELAS and SPS. Following this suggestion we have also reproduced the results of ELAS and SPS in Table 2. Comparison to monocular methods: In [8] and [9], an extension of the proposed monocular reconstruction framework was proposed for stereo reconstruction, with publicly available code. In our work, for fair comparison, we compared our framework to the stereo implementation of [8] and [9]. Qualitative results are missing: This was mainly due to page length limitations but we have created qualitative results and we have added them to the main paper by compressing the references to save space. Generate ground truth data by mounting other scanning devices: This is a good suggestion but challenging to achieve in practice. We — and other research groups — have previously used commercial RGB-D cameras to attempt this, primarily in a laboratory or pre-clinical setting. However, the working distance of the laparoscope is shorter than most depth cameras, resulting in sparse and noisy depth maps. Another strategy is to build a system with a structured lighting device that can project an encoded pattern onto the tissue but it is difficult to generate significant amounts of accurate data in endoscopic applications. We continue to work on this problem including designing new hardware and exploring more efficient algorithms to overcome some of these limitations. Reviewer 3 Clarity of method explanation: We have restructured the Methodology section in the main paper and present a step-by-step explanation of how the data travels through the network. A more straightforward description of the method has been given to show network details. Compared methods: We compared our method with recent methods that satisfy the following conditions: i) they used stereo datasets; ii) they provided stereo training settings; iii) they had executable code released. We referenced other papers where the ideas were valuable to this work, even where a direct data comparison was not possible based on these criteria. Qualitative results and SSIM score comparison to depth accuracy: Please refer to our response to Reviewer 2 question 3. We have generated and visualized the reconstructed image, depth image, and input image size-by-size, together with the associated SSIM score. These are separate metrics that can be used to understand the model performance, and the qualitative results now complement the quantitative ones to help illustrate the relationship. More network details: We accept this critique and have now improved the description of the network and clarified the approach in the methods section. We have also moved the network figure from supplementary materials to the main body to improve the explanation of the method. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0421/12/31/Paper0036" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0421/12/31/Paper0036" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0421-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Self-Supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0421/12/31/Paper0036"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0421/12/31/Paper0036","headline":"Self-Supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images","dateModified":"0422-01-02T00:00:00-05:17","datePublished":"0421-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Baoru Huang, Jian-Qing Zheng, Anh Nguyen, David Tuch, Kunal Vyas, Stamatia Giannarou, Daniel S. Elson Abstract Dense depth estimation and 3D reconstruction of a surgical scene are crucial steps in computer assisted surgery. Recent work has shown that depth estimation from a stereo images pair could be solved with convolutional neural networks. However, most recent depth estimation models were trained on datasets with per-pixel ground truth. Such data is especially rare for laparoscopic imaging, making it hard to apply supervised depth estimation to real surgical applications. To overcome this limitation, we propose SADepth, a new self-supervised depth estimation method based on Generative Adversarial Networks. It consists of an encoder-decoder generator and a discriminator to incorporate geometry constraints during training. Multi-scale outputs from the generator help to solve the local minima caused by the photometric reprojection loss, while the adversarial learning improves the framework generation quality. Extensive experiments on two public datasets show that SADepth outperforms recent state-of-the-art unsupervised methods by a large margin, and reduces the gap between supervised and unsupervised depth estimation in laparoscopic images. Link to paper https://doi.org/10.1007/978-3-030-87202-1_22 Link to the code repository N/A Link to the dataset(s) http://hamlyn.doc.ic.ac.uk/vision/ https://endovissub2019-scared.grand-challenge.org/Home/ Reviews Review #1 Please describe the contribution of the paper The authors proposed a novel method for self-supervised adversarial depth estimation. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors proposed a self-supervised adversarial depth estimation. They also applied the disparity smoothness loss and formed the network across multiple scales. Two public endoscopic datasets were used to prove the effectivity of the proposed algorithm. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The evaluation metrics for two datasets are different, Why? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance There is no code or data available, and it is not easy for the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The novelty of paper is good. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The novelty of the proposed algorithm for depth estimation is good. The experiment results based on two datasets are better than others. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper proposed an end_to_end self-supervised network for depth estimation in laparoscopic Images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. They use re-projective sampler to reconstruct stereo images for self-supervised and adversarial learning Two datasets have been used to evaluate the proposed network. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance This paper is not reproducible as they won’t provide code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well. The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images. The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works. Is it possible to create ground truth for this task by mounting other scanning devices onto the laparoscope and calibrating them? Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Comparisons with non-learning methods were not performed. The comparison methods in [8] and [9] are for monocular camera. Qualitative evaluation results are missing What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper presents an unsupervised depth estimation algorithm using generative adversarial networks (GANs). The generator is trained to estimate disparity maps between the input image pairs, which is then used to estimate depth. Depth estimates are projected onto the image planes and the discriminator tries to determine whether the image generated is the original input image or that generated by projecting estimated depth onto the image plane. Results show improvements over other unsupervised depth estimation methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Reasoning behind the type of neural network and use of the different loss functions is intuitively explained and results are compared against several other methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper was fairly hard to read and follow. Once the reader is through the methods section, the reasoning makes sense. However, getting through the methods section was tough even though the actual technical method, from my understanding, is not too complicated. The methods section would benefit from a more straightforward explanation of steps. The main weakness of the paper, however, is the lack of network details. While authors do include several parameter settings in the main paper, details about the network architecture are left to supplementary material, which unfortunately is not published along with the main paper. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Due to the network architecture details being left to supplementary materials, the method as it is explained in the paper alone may be hard to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html One thing that would really help in clarity is to explain the method step by step as the data travels through the network. Currently, the methods section seems overly complicated. While the number of methods compared against is definitely a positive, there are a few methods that are referenced but not compared against. Is there a reason why? Finally, although the large number of quantitative comparisons is great, it would be nice to see at least one qualitative result. How does an SSIM of ~80 translate in terms of depth estimates? Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My recommendation is based mostly on the lack of network details in the main paper. The clarity of the methods is also a contributor although less important than network details. If the authors can include network details in the paper and better organize their methods section, this could be bumped up to borderline accept. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 6 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The reviewers agreed that the paper has some merits. However, two reviewers pointed out problems in the experiment section, e.g. the evaluation metrics for two datasets are different, the comparison is unfair, etc. In addition, R3 thinks the description of the method, in particular the network details are missing. Please clarify these points in the rebuttal letter. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have explained the reason of using different metric for evaluation of the two datasets. That is becase SCARED provides the per-pixel depth ground truth, while dPVN does not. The authors also clarified that they did compare their method with non-deep learning methods as requested by R2 and explained the reasons of not generating ground truth data by mounting other scanning devices. Regarding the qualitative results requested by R2 and R3, the authors would add some in the revised version if the space is allowed. In general, the AC is satisfied with the authors responses as the major concerns have been addressed and clarified in this rebuttal letter. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The initial reviews pointed out some weaknesses of the paper, including comparisons to previous work and clarity. The authors used the rebuttal to address these critics in a reasonable way. The task at hand – 3D reconstruction in laparoscopy – is yet a difficult and unresolved task. Even if the paper doesn’t bring a strong technical contribution, it’s still a useful one, as an early attempt of GANs for this problem. I would thus recommend acceptance of the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The paper proposes a method for self-supervised depth estimation in laparoscopic images using generative adversarial networks. The novelty of the approach is adequate, and the paper presents experimental results of two public datasets. The rebuttal promises to release public code, which assuages concerns about reproducibility and technical clarity. It also clarifies that empirical comparisons are conducted against the stereo versions of [8,9] methods, which is essential to ensure the fairness of the evaluation. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Author Feedback We would like to thank all of the reviewers for their constructive comments. We have addressed all the points raised, including: i) our source code will be released, ii) comparison with non-learning methods, iii) clarification of stereo laparoscope settings, iv) adding qualitative results, and v) re-organizing Methodology section and provide more network details in the manuscript. Reviewer 1 Evaluation metrics: The evaluation metrics for the two datasets are different because SCARED provides the per-pixel depth ground truth, while dPVN does not. Therefore, for the SCARED dataset we use the mean absolute error to compare the predicted depth map with the ground truth depth image. For the dPVN dataset, we used the SSfIM metric to compare the reconstructed image with the original image which is a standard process in unsupervised depth estimation. Dataset and code: Both SCARED and dVPN datasets are available online. We will also release our code. Reviewer 2 Comparison to non-learning methods: In Table 1, we did compare our framework with two non-learning methods namely, ELAS and SPS. Following this suggestion we have also reproduced the results of ELAS and SPS in Table 2. Comparison to monocular methods: In [8] and [9], an extension of the proposed monocular reconstruction framework was proposed for stereo reconstruction, with publicly available code. In our work, for fair comparison, we compared our framework to the stereo implementation of [8] and [9]. Qualitative results are missing: This was mainly due to page length limitations but we have created qualitative results and we have added them to the main paper by compressing the references to save space. Generate ground truth data by mounting other scanning devices: This is a good suggestion but challenging to achieve in practice. We — and other research groups — have previously used commercial RGB-D cameras to attempt this, primarily in a laboratory or pre-clinical setting. However, the working distance of the laparoscope is shorter than most depth cameras, resulting in sparse and noisy depth maps. Another strategy is to build a system with a structured lighting device that can project an encoded pattern onto the tissue but it is difficult to generate significant amounts of accurate data in endoscopic applications. We continue to work on this problem including designing new hardware and exploring more efficient algorithms to overcome some of these limitations. Reviewer 3 Clarity of method explanation: We have restructured the Methodology section in the main paper and present a step-by-step explanation of how the data travels through the network. A more straightforward description of the method has been given to show network details. Compared methods: We compared our method with recent methods that satisfy the following conditions: i) they used stereo datasets; ii) they provided stereo training settings; iii) they had executable code released. We referenced other papers where the ideas were valuable to this work, even where a direct data comparison was not possible based on these criteria. Qualitative results and SSIM score comparison to depth accuracy: Please refer to our response to Reviewer 2 question 3. We have generated and visualized the reconstructed image, depth image, and input image size-by-size, together with the associated SSIM score. These are separate metrics that can be used to understand the model performance, and the qualitative results now complement the quantitative ones to help illustrate the relationship. More network details: We accept this critique and have now improved the description of the network and clarified the approach in the methods section. We have also moved the network figure from supplementary materials to the main body to improve the explanation of the method. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Huang, Baoru,Zheng, Jian-Qing,Nguyen, Anh,Tuch, David,Vyas, Kunal,Giannarou, Stamatia,Elson, Daniel S." />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Self-Supervised Generative Adversarial Network for Depth Estimation in Laparoscopic Images</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Huang, Baoru"
        class="post-tags">
        Huang, Baoru
      </a> |  
      
      <a href="kittywong/tags#Zheng, Jian-Qing"
        class="post-tags">
        Zheng, Jian-Qing
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Anh"
        class="post-tags">
        Nguyen, Anh
      </a> |  
      
      <a href="kittywong/tags#Tuch, David"
        class="post-tags">
        Tuch, David
      </a> |  
      
      <a href="kittywong/tags#Vyas, Kunal"
        class="post-tags">
        Vyas, Kunal
      </a> |  
      
      <a href="kittywong/tags#Giannarou, Stamatia"
        class="post-tags">
        Giannarou, Stamatia
      </a> |  
      
      <a href="kittywong/tags#Elson, Daniel S."
        class="post-tags">
        Elson, Daniel S.
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Baoru Huang, Jian-Qing Zheng, Anh Nguyen, David Tuch, Kunal Vyas, Stamatia Giannarou, Daniel S. Elson
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Dense depth estimation and 3D reconstruction of a surgical scene are crucial steps in computer assisted surgery. Recent work has shown that depth estimation from a stereo images pair could be solved with convolutional neural networks. However, most recent depth estimation models were trained on datasets with per-pixel ground truth. Such data is especially rare for laparoscopic imaging, making it hard to apply supervised depth estimation to real surgical applications. To overcome this limitation, we propose SADepth, a new self-supervised depth estimation method based on Generative Adversarial Networks. It consists of an encoder-decoder generator and a discriminator to incorporate geometry constraints during training. Multi-scale outputs from the generator help to solve the local minima caused by the photometric reprojection loss, while the adversarial learning improves the framework generation quality. Extensive experiments on two public datasets show that SADepth outperforms recent state-of-the-art unsupervised methods by a large margin, and reduces the gap between supervised and unsupervised depth estimation in laparoscopic images.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87202-1_22">https://doi.org/10.1007/978-3-030-87202-1_22</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>http://hamlyn.doc.ic.ac.uk/vision/
https://endovissub2019-scared.grand-challenge.org/Home/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors proposed a novel method for self-supervised adversarial depth estimation.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The authors proposed a self-supervised adversarial depth estimation. They also applied the disparity smoothness loss and formed the network across multiple scales. Two public endoscopic datasets were used to prove the effectivity of the proposed algorithm.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The evaluation metrics for two datasets are different, Why?</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>There is no code or data available, and it is not easy for the reproducibility of the paper.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The novelty of paper is good.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The novelty of the proposed algorithm for depth estimation is good. The experiment results based on two datasets are better than others.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposed an end_to_end self-supervised network for depth estimation in laparoscopic Images.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>They use re-projective sampler to reconstruct stereo images for self-supervised and adversarial learning</li>
        <li>Two datasets have been used to evaluate the proposed network.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well.</li>
        <li>The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images.</li>
        <li>The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>This paper is not reproducible as they won’t provide code.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>In evaluation, they should compare their results with the non-learning based methods too. For the depth estimation of the stereo images, many non-learning based methods performs well.</li>
        <li>The two comparison methods described in [8] and [9] are both for the depth estimation of monocular camera. As we know, the depth estimation of monocular images is much more challenging than that of stereo images. This comparisons were not fair. In the meantime, the proposed network only works for the depth estimation of stereo laparoscopic images.</li>
        <li>The qualitative results are missing, which make the evaluation results unimpressive. Without the intermediate results, It’s difficult for readers to understand how the network works and how well it works.</li>
        <li>Is it possible to create ground truth for this task by mounting other scanning devices onto the laparoscope and calibrating them?</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ol>
        <li>Comparisons with non-learning methods were not performed.</li>
        <li>The comparison methods in [8] and [9] are for monocular camera.</li>
        <li>Qualitative evaluation results are missing</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper presents an unsupervised depth estimation algorithm using generative adversarial networks (GANs). The generator is trained to estimate disparity maps between the input image pairs, which is then used to estimate depth. Depth estimates are projected onto the image planes and the discriminator tries to determine whether the image generated is the original input image or that generated by projecting estimated depth onto the image plane. Results show improvements over other unsupervised depth estimation methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Reasoning behind the type of neural network and use of the different loss functions is intuitively explained and results are compared against several other methods.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The paper was fairly hard to read and follow. Once the reader is through the methods section, the reasoning makes sense. However, getting through the methods section was tough even though the actual technical method, from my understanding, is not too complicated. The methods section would benefit from a more straightforward explanation of steps.</p>

      <p>The main weakness of the paper, however, is the lack of network details. While authors do include several parameter settings in the main paper, details about the network architecture are left to supplementary material, which unfortunately is not published along with the main paper.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Due to the network architecture details being left to supplementary materials, the method as it is explained in the paper alone may be hard to reproduce.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>One thing that would really help in clarity is to explain the method step by step as the data travels through the network. Currently, the methods section seems overly complicated.</p>

      <p>While the number of methods compared against is definitely a positive, there are a few methods that are referenced but not compared against. Is there a reason why?</p>

      <p>Finally, although the large number of quantitative comparisons is great, it would be nice to see at least one qualitative result. How does an SSIM of ~80 translate in terms of depth estimates?</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>My recommendation is based mostly on the lack of network details in the main paper. The clarity of the methods is also a contributor although less important than network details. If the authors can include network details in the paper and better organize their methods section, this could be bumped up to borderline accept.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The reviewers agreed that the paper has some merits. However, two reviewers pointed out problems in the experiment section, e.g. the evaluation metrics for two datasets are different, the comparison is unfair, etc. In addition, R3 thinks the description of the method, in particular the network details are missing.  Please clarify these points in the rebuttal letter.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors have explained the reason of using different metric for evaluation of the two datasets. That is becase SCARED provides the per-pixel depth ground truth, while dPVN does not. The authors also clarified that they did compare their method with non-deep learning methods as requested by R2 and explained the reasons of not generating ground truth data by mounting other scanning devices. Regarding the qualitative results requested by R2 and R3, the authors would add some in the revised version if the space is allowed. In general, the AC is satisfied with the authors responses as the major concerns have been addressed and clarified in this rebuttal letter.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>8</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The initial reviews pointed out some weaknesses of the paper, including comparisons to previous work and clarity. The authors used the rebuttal to address these critics in a reasonable way. The task at hand – 3D reconstruction in laparoscopy – is yet a difficult and unresolved task. Even if the paper doesn’t bring a strong technical contribution, it’s still a useful one, as an early attempt of GANs for this problem. I would thus recommend acceptance of the paper.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The paper proposes a method for self-supervised depth estimation in laparoscopic images using generative adversarial networks. The novelty of the approach is adequate, and the paper presents experimental results of two public datasets. The rebuttal promises to release public code, which assuages concerns about reproducibility and technical clarity. It also clarifies that empirical comparisons are conducted against the stereo versions of [8,9] methods, which is essential to ensure the fairness of the evaluation.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>

  <p>We would like to thank all of the reviewers for their constructive comments. We have addressed all the points raised, including: i) our source code will be released, ii) comparison with non-learning methods, iii) clarification of stereo laparoscope settings, iv) adding qualitative results, and v) re-organizing Methodology section and provide more network details in the manuscript.</p>

  <p>Reviewer 1</p>

  <ol>
    <li>
      <p>Evaluation metrics: The evaluation metrics for the two datasets are different because SCARED provides the per-pixel depth ground truth, while dPVN does not. Therefore, for the SCARED dataset we use the mean absolute error to compare the predicted depth map with the ground truth depth image. For the dPVN dataset, we used the SSfIM metric to compare the reconstructed image with the original image which is a standard process in unsupervised depth estimation.</p>
    </li>
    <li>
      <p>Dataset and code: Both SCARED and dVPN datasets are available online. We will also release our code.</p>
    </li>
  </ol>

  <p>Reviewer 2</p>

  <ol>
    <li>
      <p>Comparison to non-learning methods: In Table 1, we did compare our framework with two non-learning methods namely, ELAS and SPS. Following this suggestion we have also reproduced the results of ELAS and SPS in Table 2.</p>
    </li>
    <li>
      <p>Comparison to monocular methods: In [8] and [9], an extension of the proposed monocular reconstruction framework was proposed for stereo reconstruction, with publicly available code. In our work, for fair comparison, we compared our framework to the stereo implementation of [8] and [9].</p>
    </li>
    <li>
      <p>Qualitative results are missing: This was mainly due to page length limitations but we have created qualitative results and we have added them to the main paper by compressing the references to save space.</p>
    </li>
    <li>
      <p>Generate ground truth data by mounting other scanning devices: This is a good suggestion but challenging to achieve in practice. We — and other research groups — have previously used commercial RGB-D cameras to attempt this, primarily in a laboratory or pre-clinical setting.  However, the working distance of the laparoscope is shorter than most depth cameras, resulting in sparse and noisy depth maps. Another strategy is to build a system with a structured lighting device that can project an encoded pattern onto the tissue but it is difficult to generate significant amounts of accurate data in endoscopic applications. We continue to work on this problem including designing new hardware and exploring more efficient algorithms to overcome some of these limitations.</p>
    </li>
  </ol>

  <p>Reviewer 3</p>

  <ol>
    <li>
      <p>Clarity of method explanation: We have restructured the Methodology section in the main paper and present a step-by-step explanation of how the data travels through the network. A more straightforward description of the method has been given to show network details.</p>
    </li>
    <li>
      <p>Compared methods: We compared our method with recent methods that satisfy the following conditions: i) they used stereo datasets; ii) they provided stereo training settings; iii) they had executable code released. We referenced other papers where the ideas were valuable to this work, even where a direct data comparison was not possible based on these criteria.</p>
    </li>
    <li>
      <p>Qualitative results and SSIM score comparison to depth accuracy: Please refer to our response to Reviewer 2 question 3. We have generated and visualized the reconstructed image, depth image, and input image size-by-size, together with the associated SSIM score. These are separate metrics that can be used to understand the model performance, and the qualitative results now complement the quantitative ones to help illustrate the relationship.</p>
    </li>
    <li>
      <p>More network details: We accept this critique and have now improved the description of the network and clarified the approach in the methods section. We have also moved the network figure from supplementary materials to the main body to improve the explanation of the method.</p>
    </li>
  </ol>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0421-12-31
      -->
      <!--
      
        ,
        updated at 
        0422-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Huang, Baoru"
        class="post-category">
        Huang, Baoru
      </a> |  
      
      <a href="kittywong/tags#Zheng, Jian-Qing"
        class="post-category">
        Zheng, Jian-Qing
      </a> |  
      
      <a href="kittywong/tags#Nguyen, Anh"
        class="post-category">
        Nguyen, Anh
      </a> |  
      
      <a href="kittywong/tags#Tuch, David"
        class="post-category">
        Tuch, David
      </a> |  
      
      <a href="kittywong/tags#Vyas, Kunal"
        class="post-category">
        Vyas, Kunal
      </a> |  
      
      <a href="kittywong/tags#Giannarou, Stamatia"
        class="post-category">
        Giannarou, Stamatia
      </a> |  
      
      <a href="kittywong/tags#Elson, Daniel S."
        class="post-category">
        Elson, Daniel S.
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0422/12/31/Paper0291">
          Personalized Respiratory Motion Model Using Conditional Generative Networks for MR-Guided Radiotherapy
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0420/12/31/Paper2598">
          Multi-scale Neural ODEs for 3D Medical Image Registration
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
