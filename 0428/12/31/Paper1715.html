<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Mert Asim Karaoglu, Nikolas Brasch, Marijn Stollenga, Wolfgang Wein, Nassir Navab, Federico Tombari, Alexander Ladikos Abstract Depth estimation from monocular images is an important task in localization and 3D reconstruction pipelines for bronchoscopic navigation. Various supervised and self-supervised deep learning-based approaches have proven themselves on this task for natural images. However, the lack of labeled data and the bronchial tissue’s feature-scarce texture make the utilization of these methods ineffective on bronchoscopic scenes. In this work, we propose an alternative domain-adaptive approach. Our novel two-step structure first trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. The results of our experiments show that the proposed method improves the network’s performance on real images by a considerable margin and can be employed in 3D reconstruction pipelines. Link to paper https://doi.org/10.1007/978-3-030-87202-1_29 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper studies depth estimation from single laparoscopy image. A two step framework is proposed, which are (1) supervised training from synthetic data and (2) a GAN-based feature domain transfer method. Experiments show it can obtain accurate results. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea to first perform training on synthetic data and then transfer it to the real-world data is interesting. This paper is well written and easy to follow. Experiments include 3D modeling and manual registration, which look good. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. More details about the domain adaptation method is needed. A figure that shows the details of the CNN structures will be very helpful. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Need experienced researcher in this field to reproduce the method. No details of the CNN structures are given. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html None Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Clear structure, the idea is novel and the experiments can support the claims. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper propose an alternative domain-adaptive approach. The two-step structure trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The topic is interesting and the authors put a lot of effort in the paper Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper presents little modification to well established methods (REF[23,6,16,13, 11]) to solve the presented problem. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please compare your method to other state of the art that work on the same problem instead of comparing to different configuration or learned models. Th caption of Table 1 should be above the table. The text in Fig. 3 is very tiny and cannot be read Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The comparison and contribution is limited. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper A bronchoscopic depth estimation method is proposed which includes two steps: first, an U-Net based supervised network is trained based on synthetic images. Then, an unsupervised adversarial domain feature adaptation scheme adopted from [29] is employed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Obtaining the groundtruth for bronchoscopic depth estimation is difficult. This paper provides a self-supervised method for bronchoscopic depth estimation, which is valuable. The experiments illustrate the encouraging performance of the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While experiments are important to validate the effectiveness of deep learning methods. The paper does not provide ablation studies of the important module of the approach. Besides, the existing depth estimation methods are not compared. And the original domain feature adaptation method [29] is not compared. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Private data is used for training and validation. Code and the data will not make available. Those create difficulties or the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be necessary to add comparison with SOTA depth estimation methods. Please add the unit of the values in the Table. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A self supervised bronchoscopic depth estimation method is proposed. The proposed method is finely presented. However, the technical novelty of the proposed method needs clarity. Besides, ablation studies and comparison to SOTA methods are necessary. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper was well-reviewed by three experts. The author would provide more details about the domain adaptation and CNN structures. The novelty of this paper should be further clarified since the proposed method was similar to the currently available method. Additionally, it would strengthen this paper if the authors provide ablation studies and comparison to the existing depth estimation methods. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This AC was satisfied with the rebuttal addressed most of the main questions raised by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This paper proposes a domain adaptation on features to estimate depth in bronchoscope endoscopic images, using a contributed adversarial strategy. One reviewer finds the pipeline interesting, but lacks sufficient details on the domain adaptation. A second reviewer finds limited novelty compared to existing methods with lack of comparison. A third reviewer also mentions a lack of comparative study on depth estimations. A consensus is raised on missing comparison with a state-of-the-art. The rebuttal indicate an evaluation against [19] and [29] (the basis of this paper), as well as an ablation study, but I do fail to see them in the manuscript. From my understanding, these are promised additional post-submission experiments, which was failed to have been provided at submission time. As is, the paper, in my opinion, lacks a minimal comparison with at least [29], their source of inspiration. This is to understand how the proposed novelty contributes compared to the state-of-the-art. For these reasons, Recommendation is toward Rejection. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 26 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded the major concerns raised by the reviewers and AC. The main contributions and differences compared with the SOTA in computer vision domain have been emphasized in the rebuttal letter. Issues related to experiments (i.e. evaluation against other methods, ablation study and reproducibility) have been clarified. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their positive feedback. We are highly motivated by the fact that they found our work novel [R1], well-structured [R1, R2, R3], and acknowledge the challenging nature of the problem [R3]. We would like to clarify a set of points: Novelty: In our work, we target improving an existing approach [29] to the problem of monocular depth estimation in bronchoscopic images, which is a crucial open problem in the field. In [29] the domain-feature adaptation approach is utilized for day to night-time adaptation of a depth estimation network in natural scenes. In our studies, we augment this method with additional improvements, such as the combination with Coordinate Convolution layers [16] at the adapted embedding levels for synthetic to real-image adaptation, tailoring the network specifically for our targeted application. Furthermore and in contrast to other works we assess the usability of our approach in a SLAM-based navigation scenario. References [23, 16, 6, 13] are various fundamental computer vision papers that have inspired our architecture but none of them could provide specific solutions for bronchoscopy environment without major adoption. [11] is an explicit image-level domain-transfer approach which we use only in the experimental comparison. Description of domain adaptation approach: In Section 1 we describe the fundamental issues regarding monocular bronchoscopic scenes and the current literature and reason why training on synthetic images is a valuable alternative. Furthermore, we discuss how the domain gap between the synthetic and real images causes non-negligible performance drops when the model is deployed. Elaborating more on this, we introduce our solution referring to the work [29] that inspired us. In Section 2.2 and Figure 1, we provide the technical details of our improved network with the implementation details in Section 3. Evaluation against other methods: As described in Section 1 recent publications in monocular endoscopic depth estimation either require a depth-ground truth [2] or pose-labels [25] for training which we lack in our setup. Developed for sinus-endoscopy scenes, which are more feature-rich compared to bronchoscopic images, [17, 18] utilizes features extracted with structure from motion (SfM) for a self-supervised training scheme. We tested various SfM frameworks on our bronchoscopic data but failed to extract adequate useful information due to the small number of visual features in the images. We therefore couldn’t compare against these architectures. Instead, we decided to compare against an extended version of [19] which utilizes an outdated architecture for explicit domain transfer by developing a more advanced CycleGAN based structure and testing our model against it. We also compared against [29] improved with adding one more discriminator which we found to work better for bronchoscopic images. Ablation studies: We performed two ablation studies. First, we compared our proposed domain feature adaptation against a direct domain transfer method and second, we compared the effect of the coordinate convolution layers [16], which is one of the major changes we added on top of [29]. We found that both the adaptation at the feature level and the coordinate convolutions are essential for the performance of our method. Reproducibility: In Section 2 and 3 we describe the configuration and training setup of the architecture with references to the original publications where their implementation details are further explained. We decided not to add a figure of the network architecture to the main paper due to space constraints. To make the paper more self-contained we will add a network architecture diagram to the paper or its supplementary material if for completeness. We also make sure that the paper contains all the necessary information to reproduce our results. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Mert Asim Karaoglu, Nikolas Brasch, Marijn Stollenga, Wolfgang Wein, Nassir Navab, Federico Tombari, Alexander Ladikos Abstract Depth estimation from monocular images is an important task in localization and 3D reconstruction pipelines for bronchoscopic navigation. Various supervised and self-supervised deep learning-based approaches have proven themselves on this task for natural images. However, the lack of labeled data and the bronchial tissue’s feature-scarce texture make the utilization of these methods ineffective on bronchoscopic scenes. In this work, we propose an alternative domain-adaptive approach. Our novel two-step structure first trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. The results of our experiments show that the proposed method improves the network’s performance on real images by a considerable margin and can be employed in 3D reconstruction pipelines. Link to paper https://doi.org/10.1007/978-3-030-87202-1_29 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper studies depth estimation from single laparoscopy image. A two step framework is proposed, which are (1) supervised training from synthetic data and (2) a GAN-based feature domain transfer method. Experiments show it can obtain accurate results. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea to first perform training on synthetic data and then transfer it to the real-world data is interesting. This paper is well written and easy to follow. Experiments include 3D modeling and manual registration, which look good. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. More details about the domain adaptation method is needed. A figure that shows the details of the CNN structures will be very helpful. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Need experienced researcher in this field to reproduce the method. No details of the CNN structures are given. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html None Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Clear structure, the idea is novel and the experiments can support the claims. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper propose an alternative domain-adaptive approach. The two-step structure trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The topic is interesting and the authors put a lot of effort in the paper Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper presents little modification to well established methods (REF[23,6,16,13, 11]) to solve the presented problem. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please compare your method to other state of the art that work on the same problem instead of comparing to different configuration or learned models. Th caption of Table 1 should be above the table. The text in Fig. 3 is very tiny and cannot be read Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The comparison and contribution is limited. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper A bronchoscopic depth estimation method is proposed which includes two steps: first, an U-Net based supervised network is trained based on synthetic images. Then, an unsupervised adversarial domain feature adaptation scheme adopted from [29] is employed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Obtaining the groundtruth for bronchoscopic depth estimation is difficult. This paper provides a self-supervised method for bronchoscopic depth estimation, which is valuable. The experiments illustrate the encouraging performance of the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While experiments are important to validate the effectiveness of deep learning methods. The paper does not provide ablation studies of the important module of the approach. Besides, the existing depth estimation methods are not compared. And the original domain feature adaptation method [29] is not compared. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Private data is used for training and validation. Code and the data will not make available. Those create difficulties or the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be necessary to add comparison with SOTA depth estimation methods. Please add the unit of the values in the Table. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A self supervised bronchoscopic depth estimation method is proposed. The proposed method is finely presented. However, the technical novelty of the proposed method needs clarity. Besides, ablation studies and comparison to SOTA methods are necessary. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper was well-reviewed by three experts. The author would provide more details about the domain adaptation and CNN structures. The novelty of this paper should be further clarified since the proposed method was similar to the currently available method. Additionally, it would strengthen this paper if the authors provide ablation studies and comparison to the existing depth estimation methods. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This AC was satisfied with the rebuttal addressed most of the main questions raised by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This paper proposes a domain adaptation on features to estimate depth in bronchoscope endoscopic images, using a contributed adversarial strategy. One reviewer finds the pipeline interesting, but lacks sufficient details on the domain adaptation. A second reviewer finds limited novelty compared to existing methods with lack of comparison. A third reviewer also mentions a lack of comparative study on depth estimations. A consensus is raised on missing comparison with a state-of-the-art. The rebuttal indicate an evaluation against [19] and [29] (the basis of this paper), as well as an ablation study, but I do fail to see them in the manuscript. From my understanding, these are promised additional post-submission experiments, which was failed to have been provided at submission time. As is, the paper, in my opinion, lacks a minimal comparison with at least [29], their source of inspiration. This is to understand how the proposed novelty contributes compared to the state-of-the-art. For these reasons, Recommendation is toward Rejection. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 26 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded the major concerns raised by the reviewers and AC. The main contributions and differences compared with the SOTA in computer vision domain have been emphasized in the rebuttal letter. Issues related to experiments (i.e. evaluation against other methods, ablation study and reproducibility) have been clarified. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their positive feedback. We are highly motivated by the fact that they found our work novel [R1], well-structured [R1, R2, R3], and acknowledge the challenging nature of the problem [R3]. We would like to clarify a set of points: Novelty: In our work, we target improving an existing approach [29] to the problem of monocular depth estimation in bronchoscopic images, which is a crucial open problem in the field. In [29] the domain-feature adaptation approach is utilized for day to night-time adaptation of a depth estimation network in natural scenes. In our studies, we augment this method with additional improvements, such as the combination with Coordinate Convolution layers [16] at the adapted embedding levels for synthetic to real-image adaptation, tailoring the network specifically for our targeted application. Furthermore and in contrast to other works we assess the usability of our approach in a SLAM-based navigation scenario. References [23, 16, 6, 13] are various fundamental computer vision papers that have inspired our architecture but none of them could provide specific solutions for bronchoscopy environment without major adoption. [11] is an explicit image-level domain-transfer approach which we use only in the experimental comparison. Description of domain adaptation approach: In Section 1 we describe the fundamental issues regarding monocular bronchoscopic scenes and the current literature and reason why training on synthetic images is a valuable alternative. Furthermore, we discuss how the domain gap between the synthetic and real images causes non-negligible performance drops when the model is deployed. Elaborating more on this, we introduce our solution referring to the work [29] that inspired us. In Section 2.2 and Figure 1, we provide the technical details of our improved network with the implementation details in Section 3. Evaluation against other methods: As described in Section 1 recent publications in monocular endoscopic depth estimation either require a depth-ground truth [2] or pose-labels [25] for training which we lack in our setup. Developed for sinus-endoscopy scenes, which are more feature-rich compared to bronchoscopic images, [17, 18] utilizes features extracted with structure from motion (SfM) for a self-supervised training scheme. We tested various SfM frameworks on our bronchoscopic data but failed to extract adequate useful information due to the small number of visual features in the images. We therefore couldn’t compare against these architectures. Instead, we decided to compare against an extended version of [19] which utilizes an outdated architecture for explicit domain transfer by developing a more advanced CycleGAN based structure and testing our model against it. We also compared against [29] improved with adding one more discriminator which we found to work better for bronchoscopic images. Ablation studies: We performed two ablation studies. First, we compared our proposed domain feature adaptation against a direct domain transfer method and second, we compared the effect of the coordinate convolution layers [16], which is one of the major changes we added on top of [29]. We found that both the adaptation at the feature level and the coordinate convolutions are essential for the performance of our method. Reproducibility: In Section 2 and 3 we describe the configuration and training setup of the architecture with references to the original publications where their implementation details are further explained. We decided not to add a figure of the network architecture to the main paper due to space constraints. To make the paper more self-contained we will add a network architecture diagram to the paper or its supplementary material if for completeness. We also make sure that the paper contains all the necessary information to reproduce our results. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0428/12/31/Paper1715" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0428/12/31/Paper1715" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0428-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0428/12/31/Paper1715"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0428/12/31/Paper1715","headline":"Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation","dateModified":"0429-01-02T00:00:00-05:17","datePublished":"0428-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Mert Asim Karaoglu, Nikolas Brasch, Marijn Stollenga, Wolfgang Wein, Nassir Navab, Federico Tombari, Alexander Ladikos Abstract Depth estimation from monocular images is an important task in localization and 3D reconstruction pipelines for bronchoscopic navigation. Various supervised and self-supervised deep learning-based approaches have proven themselves on this task for natural images. However, the lack of labeled data and the bronchial tissue’s feature-scarce texture make the utilization of these methods ineffective on bronchoscopic scenes. In this work, we propose an alternative domain-adaptive approach. Our novel two-step structure first trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. The results of our experiments show that the proposed method improves the network’s performance on real images by a considerable margin and can be employed in 3D reconstruction pipelines. Link to paper https://doi.org/10.1007/978-3-030-87202-1_29 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper This paper studies depth estimation from single laparoscopy image. A two step framework is proposed, which are (1) supervised training from synthetic data and (2) a GAN-based feature domain transfer method. Experiments show it can obtain accurate results. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The idea to first perform training on synthetic data and then transfer it to the real-world data is interesting. This paper is well written and easy to follow. Experiments include 3D modeling and manual registration, which look good. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. More details about the domain adaptation method is needed. A figure that shows the details of the CNN structures will be very helpful. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Need experienced researcher in this field to reproduce the method. No details of the CNN structures are given. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html None Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Clear structure, the idea is novel and the experiments can support the claims. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This paper propose an alternative domain-adaptive approach. The two-step structure trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The topic is interesting and the authors put a lot of effort in the paper Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The paper presents little modification to well established methods (REF[23,6,16,13, 11]) to solve the presented problem. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance can be reproduced Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please compare your method to other state of the art that work on the same problem instead of comparing to different configuration or learned models. Th caption of Table 1 should be above the table. The text in Fig. 3 is very tiny and cannot be read Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The comparison and contribution is limited. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper A bronchoscopic depth estimation method is proposed which includes two steps: first, an U-Net based supervised network is trained based on synthetic images. Then, an unsupervised adversarial domain feature adaptation scheme adopted from [29] is employed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Obtaining the groundtruth for bronchoscopic depth estimation is difficult. This paper provides a self-supervised method for bronchoscopic depth estimation, which is valuable. The experiments illustrate the encouraging performance of the idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While experiments are important to validate the effectiveness of deep learning methods. The paper does not provide ablation studies of the important module of the approach. Besides, the existing depth estimation methods are not compared. And the original domain feature adaptation method [29] is not compared. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Private data is used for training and validation. Code and the data will not make available. Those create difficulties or the reproducibility of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It would be necessary to add comparison with SOTA depth estimation methods. Please add the unit of the values in the Table. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A self supervised bronchoscopic depth estimation method is proposed. The proposed method is finely presented. However, the technical novelty of the proposed method needs clarity. Besides, ablation studies and comparison to SOTA methods are necessary. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper was well-reviewed by three experts. The author would provide more details about the domain adaptation and CNN structures. The novelty of this paper should be further clarified since the proposed method was similar to the currently available method. Additionally, it would strengthen this paper if the authors provide ablation studies and comparison to the existing depth estimation methods. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This AC was satisfied with the rebuttal addressed most of the main questions raised by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This paper proposes a domain adaptation on features to estimate depth in bronchoscope endoscopic images, using a contributed adversarial strategy. One reviewer finds the pipeline interesting, but lacks sufficient details on the domain adaptation. A second reviewer finds limited novelty compared to existing methods with lack of comparison. A third reviewer also mentions a lack of comparative study on depth estimations. A consensus is raised on missing comparison with a state-of-the-art. The rebuttal indicate an evaluation against [19] and [29] (the basis of this paper), as well as an ablation study, but I do fail to see them in the manuscript. From my understanding, these are promised additional post-submission experiments, which was failed to have been provided at submission time. As is, the paper, in my opinion, lacks a minimal comparison with at least [29], their source of inspiration. This is to understand how the proposed novelty contributes compared to the state-of-the-art. For these reasons, Recommendation is toward Rejection. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 26 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded the major concerns raised by the reviewers and AC. The main contributions and differences compared with the SOTA in computer vision domain have been emphasized in the rebuttal letter. Issues related to experiments (i.e. evaluation against other methods, ablation study and reproducibility) have been clarified. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their positive feedback. We are highly motivated by the fact that they found our work novel [R1], well-structured [R1, R2, R3], and acknowledge the challenging nature of the problem [R3]. We would like to clarify a set of points: Novelty: In our work, we target improving an existing approach [29] to the problem of monocular depth estimation in bronchoscopic images, which is a crucial open problem in the field. In [29] the domain-feature adaptation approach is utilized for day to night-time adaptation of a depth estimation network in natural scenes. In our studies, we augment this method with additional improvements, such as the combination with Coordinate Convolution layers [16] at the adapted embedding levels for synthetic to real-image adaptation, tailoring the network specifically for our targeted application. Furthermore and in contrast to other works we assess the usability of our approach in a SLAM-based navigation scenario. References [23, 16, 6, 13] are various fundamental computer vision papers that have inspired our architecture but none of them could provide specific solutions for bronchoscopy environment without major adoption. [11] is an explicit image-level domain-transfer approach which we use only in the experimental comparison. Description of domain adaptation approach: In Section 1 we describe the fundamental issues regarding monocular bronchoscopic scenes and the current literature and reason why training on synthetic images is a valuable alternative. Furthermore, we discuss how the domain gap between the synthetic and real images causes non-negligible performance drops when the model is deployed. Elaborating more on this, we introduce our solution referring to the work [29] that inspired us. In Section 2.2 and Figure 1, we provide the technical details of our improved network with the implementation details in Section 3. Evaluation against other methods: As described in Section 1 recent publications in monocular endoscopic depth estimation either require a depth-ground truth [2] or pose-labels [25] for training which we lack in our setup. Developed for sinus-endoscopy scenes, which are more feature-rich compared to bronchoscopic images, [17, 18] utilizes features extracted with structure from motion (SfM) for a self-supervised training scheme. We tested various SfM frameworks on our bronchoscopic data but failed to extract adequate useful information due to the small number of visual features in the images. We therefore couldn’t compare against these architectures. Instead, we decided to compare against an extended version of [19] which utilizes an outdated architecture for explicit domain transfer by developing a more advanced CycleGAN based structure and testing our model against it. We also compared against [29] improved with adding one more discriminator which we found to work better for bronchoscopic images. Ablation studies: We performed two ablation studies. First, we compared our proposed domain feature adaptation against a direct domain transfer method and second, we compared the effect of the coordinate convolution layers [16], which is one of the major changes we added on top of [29]. We found that both the adaptation at the feature level and the coordinate convolutions are essential for the performance of our method. Reproducibility: In Section 2 and 3 we describe the configuration and training setup of the architecture with references to the original publications where their implementation details are further explained. We decided not to add a figure of the network architecture to the main paper due to space constraints. To make the paper more self-contained we will add a network architecture diagram to the paper or its supplementary material if for completeness. We also make sure that the paper contains all the necessary information to reproduce our results. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Karaoglu, Mert Asim,Brasch, Nikolas,Stollenga, Marijn,Wein, Wolfgang,Navab, Nassir,Tombari, Federico,Ladikos, Alexander" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Modalities - Video"
        class="post-category">
        Modalities - Video
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a>
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Karaoglu, Mert Asim"
        class="post-tags">
        Karaoglu, Mert Asim
      </a> |  
      
      <a href="kittywong/tags#Brasch, Nikolas"
        class="post-tags">
        Brasch, Nikolas
      </a> |  
      
      <a href="kittywong/tags#Stollenga, Marijn"
        class="post-tags">
        Stollenga, Marijn
      </a> |  
      
      <a href="kittywong/tags#Wein, Wolfgang"
        class="post-tags">
        Wein, Wolfgang
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-tags">
        Navab, Nassir
      </a> |  
      
      <a href="kittywong/tags#Tombari, Federico"
        class="post-tags">
        Tombari, Federico
      </a> |  
      
      <a href="kittywong/tags#Ladikos, Alexander"
        class="post-tags">
        Ladikos, Alexander
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Mert Asim Karaoglu, Nikolas Brasch, Marijn Stollenga, Wolfgang Wein, Nassir Navab, Federico Tombari, Alexander Ladikos
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Depth estimation from monocular images is an important task in localization and 3D reconstruction pipelines for bronchoscopic navigation. Various supervised and self-supervised deep learning-based approaches have proven themselves on this task for natural images. However, the lack of labeled data and the bronchial tissue’s feature-scarce texture make the utilization of these methods ineffective on bronchoscopic scenes. In this work, we propose an alternative domain-adaptive approach. Our novel two-step structure first trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images. The results of our experiments show that the proposed method improves the network’s performance on real images by a considerable margin and can be employed in 3D reconstruction pipelines.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87202-1_29">https://doi.org/10.1007/978-3-030-87202-1_29</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper studies depth estimation from single laparoscopy image. A two step framework is proposed, which are (1) supervised training from synthetic data and (2) a GAN-based feature domain transfer method. Experiments show it can obtain accurate results.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The idea to first perform training on synthetic data and then transfer it to the real-world data is interesting.</p>

      <p>This paper is well written and easy to follow.</p>

      <p>Experiments include 3D modeling and manual registration, which look good.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>More details about the domain adaptation method is needed. A figure that shows the details of the CNN structures will be very helpful.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Need experienced researcher in this field to reproduce the method. No details of the CNN structures are given.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>None</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Clear structure, the idea is novel and the experiments can support the claims.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Somewhat confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper propose an alternative domain-adaptive approach. The two-step structure trains a depth estimation network with labeled synthetic images in a supervised manner; then adopts an unsupervised adversarial domain feature adaptation scheme to improve the performance on real images.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The topic is interesting and the authors put a lot of effort in the paper</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The paper presents little modification to well established methods (REF[23,6,16,13, 11]) to solve the presented problem.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>can be reproduced</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please compare your method to other state of the art that work on the same problem instead of comparing to different configuration or learned models.</p>

      <p>Th caption of Table 1 should be above the table.
The text in Fig. 3 is very tiny and cannot be read</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The comparison and contribution is limited.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>A bronchoscopic depth estimation method is proposed which includes two steps: first, an U-Net based supervised network is trained based on synthetic images. Then, an unsupervised adversarial domain feature adaptation scheme adopted from [29] is employed.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Obtaining the groundtruth for bronchoscopic depth estimation is difficult. This paper provides a self-supervised method for bronchoscopic depth estimation, which is valuable. The experiments illustrate the encouraging performance of the idea.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>While experiments are important to validate the effectiveness of deep learning methods. The paper does not provide ablation studies of the important module of the approach. Besides, the existing depth estimation methods are not compared. And the original domain feature adaptation method [29] is not compared.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Private data is used for training and validation. Code and the data will not make available. Those create difficulties or the reproducibility of the paper.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>It would be necessary to add comparison with SOTA depth estimation methods.</li>
        <li>Please add the unit of the values in the Table.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>A self supervised bronchoscopic depth estimation method is proposed. The proposed method is finely presented. However, the technical novelty of the proposed method needs clarity. Besides, ablation studies and comparison to SOTA methods are necessary.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper was well-reviewed by three experts. The author would provide more details about the domain adaptation and CNN structures. The novelty of this paper should be further clarified since the proposed method was similar to the currently available method. Additionally, it would strengthen this paper if the authors provide ablation studies and comparison to the existing depth estimation methods.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>This AC was satisfied with the rebuttal addressed most of the main questions raised by the reviewers.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>This paper proposes a domain adaptation on features to estimate depth in bronchoscope endoscopic images, using a contributed adversarial strategy.</p>

      <p>One reviewer finds the pipeline interesting, but lacks sufficient details on the domain adaptation.</p>

      <p>A second reviewer finds limited novelty compared to existing methods with lack of comparison.</p>

      <p>A third reviewer also mentions a lack of comparative study on depth estimations.</p>

      <p>A consensus is raised on missing comparison with a state-of-the-art. The rebuttal indicate an evaluation against [19] and [29] (the basis of this paper), as well as an ablation study, but I do fail to see them in the manuscript. From my understanding, these are promised additional post-submission experiments, which was failed to have been provided at submission time. As is, the paper, in my opinion, lacks a minimal comparison with at least [29], their source of inspiration. This is to understand how the proposed novelty contributes compared to the state-of-the-art.</p>

      <p>For these reasons, Recommendation is toward Rejection.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Reject</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>26</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors have responded the major concerns raised by the reviewers and AC. The main contributions and differences compared with the SOTA in computer vision domain have been emphasized in the rebuttal letter. Issues related to experiments (i.e. evaluation against other methods, ablation study and reproducibility) have been clarified.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the reviewers for their positive feedback. We are highly motivated by the fact that they found our work novel [R1], well-structured [R1, R2, R3], and acknowledge the challenging nature of the problem [R3].</p>

  <p>We would like to clarify a set of points:</p>

  <p>Novelty:</p>

  <p>In our work, we target improving an existing approach [29] to the problem of monocular depth estimation in bronchoscopic images, which is a crucial open problem in the field. In [29] the domain-feature adaptation approach is utilized for day to night-time adaptation of a depth estimation network in natural scenes. In our studies, we augment this method with additional improvements, such as the combination with Coordinate Convolution layers [16] at the adapted embedding levels for synthetic to real-image adaptation, tailoring the network specifically for our targeted application. Furthermore and in contrast to other works we assess the usability of our approach in a SLAM-based navigation scenario. References [23, 16, 6, 13] are various fundamental computer vision papers that have inspired our architecture but none of them could provide specific solutions for bronchoscopy environment without major adoption. [11] is an explicit image-level domain-transfer approach which we use only in the experimental comparison.</p>

  <p>Description of domain adaptation approach:</p>

  <p>In Section 1 we describe the fundamental issues regarding monocular bronchoscopic scenes and the current literature and reason why training on synthetic images is a valuable alternative. Furthermore, we discuss how the domain gap between the synthetic and real images causes non-negligible performance drops when the model is deployed. Elaborating more on this, we introduce our solution referring to the work [29] that inspired us. In Section 2.2 and Figure 1, we provide the technical details of our improved network with the implementation details in Section 3.</p>

  <p>Evaluation against other methods:</p>

  <p>As described in Section 1 recent publications in monocular endoscopic depth estimation either require a depth-ground truth [2] or pose-labels [25] for training which we lack in our setup. Developed for sinus-endoscopy scenes, which are more feature-rich compared to bronchoscopic images, [17, 18] utilizes features extracted with structure from motion (SfM) for a self-supervised training scheme. We tested various SfM frameworks on our bronchoscopic data but failed to extract adequate useful information due to the small number of visual features in the images. We therefore couldn’t compare against these architectures. Instead, we decided to compare against an extended version of [19] which utilizes an outdated architecture for explicit domain transfer by developing a more advanced CycleGAN based structure and testing our model against it. We also compared against [29] improved with adding one more discriminator which we found to work better for bronchoscopic images.</p>

  <p>Ablation studies:</p>

  <p>We performed two ablation studies. First, we compared our proposed domain feature adaptation against a direct domain transfer method and second, we compared the effect of the coordinate convolution layers [16], which is one of the major changes we added on top of [29]. We found that both the adaptation at the feature level and the coordinate convolutions are essential for the performance of our method.</p>

  <p>Reproducibility:</p>

  <p>In Section 2 and 3 we describe the configuration and training setup of the architecture with references to the original publications where their implementation details are further explained. We decided not to add a figure of the network architecture to the main paper due to space constraints. To make the paper more self-contained we will add a network architecture diagram to the paper or its supplementary material if for completeness. We also make sure that the paper contains all the necessary information to reproduce our results.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0428-12-31
      -->
      <!--
      
        ,
        updated at 
        0429-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Modalities - Video"
        class="post-category">
        Modalities - Video
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a> |
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Karaoglu, Mert Asim"
        class="post-category">
        Karaoglu, Mert Asim
      </a> |  
      
      <a href="kittywong/tags#Brasch, Nikolas"
        class="post-category">
        Brasch, Nikolas
      </a> |  
      
      <a href="kittywong/tags#Stollenga, Marijn"
        class="post-category">
        Stollenga, Marijn
      </a> |  
      
      <a href="kittywong/tags#Wein, Wolfgang"
        class="post-category">
        Wein, Wolfgang
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-category">
        Navab, Nassir
      </a> |  
      
      <a href="kittywong/tags#Tombari, Federico"
        class="post-category">
        Tombari, Federico
      </a> |  
      
      <a href="kittywong/tags#Ladikos, Alexander"
        class="post-category">
        Ladikos, Alexander
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0429/12/31/Paper1891">
          2.5D Thermometry Maps for MRI-guided Tumor Ablation
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0427/12/31/Paper1509">
          Surgical Instruction Generation with Transformers
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
