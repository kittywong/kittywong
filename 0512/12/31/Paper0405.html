<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yu Tian, Guansong Pang, Fengbei Liu, Yuanhong Chen, Seon Ho Shin, Johan W. Verjans, Rajvinder Singh, Gustavo Carneiro Abstract Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns. UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. To address this challenge, we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Extensive experiment results show that our method outperforms current state-of-the-art UAD approaches on three different colonoscopy and fundus screening datasets. Link to paper https://doi.org/10.1007/978-3-030-87240-3_13 Link to the code repository https://github.com/tianyu0207/CCD Link to the dataset(s) https://www.nature.com/articles/s41597-020-00622-y https://github.com/smilell/AG-CNN Reviews Review #1 Please describe the contribution of the paper This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. The use for U-AMD is moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novel formulation of the loss function for the pretrained model based on contrastive distribution loss, classification loss for strong augmentation and position loss. The anomaly detection formula in Eq. (5)-(7), though some details are lacking. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The experiments seem not so well designed and solid; lacking of parameter tuning and explanation of how to select the threshold for determining abnormality. Comparison with SOTA methods seem arbitrary chosen without explanation. Reference is not complete, some recent unsupervised AMD methods for medical images are not included. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance reproducibility of the paper is moderate, some experiments and implementation settings are lacking, e.g. threshold, parameters. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. This is feasible with the use of large health screening datasets to avoid the large annotation burden imposed to the radiologist; and potential to detect and localize any type of lesions. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. While this may not be novel in the literature, but its use for U-AMD is still moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Some detailed questions are listed below: 2) Some recent anomaly detection methods for medical images are not referenced. Please see the following: • H. Uzunova, S. Schultz, et al., “Unsupervised pathology detection in medical images using conditional variational autoencoders,” International journal of computer assisted radiology and surgery, vol. 14, no. 3, pp. 451–461, 2019. • X. Chen, S. You, et al., Unsupervised lesion detection via image restoration with a normative prior. Medical Image Anal. 64: 101713 (2020) • X Li, H Yang et al. Transfer Learning with Joint Optimization for Label-Efficient Medical Image Anomaly Detection. MICCAI’20 workshop, LNCS, pp. 145-154. • Khalil Ouardini et al. Towards Practical Unsupervised Anomaly Detection on Retinal Images, MICCAI’19, DART 2019, MIL3ID 2019, LNCS, vol. 11795, pp. 225-234. 3) We understand that the proposed method works as a self-supervised pretraining model, however, it is not very clear from the first read of the paper. It would be helpful to add in explanation/block diagram to show how the proposed method works. 4) How to select the pretext to be used for contrastive learning (Section 2.1 of page 3), and based on what data? 5) Please explain why the three SOTA methods (references 7, 32 and 41) are selected for the comparison, please see last line 5-6 of the 1st paragraph of Section I. From the description in Section 2.2, page 5, the proposed method is based on fine-tuning the three SOTA methods of IGD, F_anoGAN and MS-SSIM. Is this the main reason that only these three methods are used for comparison? Why not compare with some of the unsupervised AMD method for medical images? We noted the localization performance has been compared with CAVGA-Ru [39]. How about [12], which is a geometric transformation-based anomaly detection method? 6) Do you need to tune the parameters for training IGD, F-anoGan, MS-SSIM for the data used in this paper instead of using the parameters used in the original paper? 7) Please give more details on how to determine the abnormality of the sample when Eq. (5)(6)(7) is computed. Is there any threshold chose involved? Considering the model is trained only based on normal data, whereas no abnormal data are used, how to determine the abnormality of an image? Also noted that only train data is used for model training, whereas no validation data are used. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The formulation of the loss for pretrained models based pretext tasks. The ablation study that demonstrates the improvement made by incorporating the pretrained model. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The paper presents a self-supervised learning method, named Constrained Contrastive Distribution Learning (CCD), for unsupervised anomaly detection (UAD) and localization in 2 different types of medical images. The authors proposed to combine contrastive learning with image transformation prediction tasks (i.e., pretext tasks) to further improve the quality of image features. The proposed method was evaluated using 3 public datasets and the results show that it had higher area under the curve (AUC) scores compared to other state-of-the-art UAD methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The combination of contrastive learning with two additional pretext tasks which use data augmentation. The pre-training process does not need label information and can be easily applied to different types of models to further improve the feature representation of medical images. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The motivation of combining of contrastive learning and pretext tasks were not clearly explained. The authors need to clearly explain how the combination benefits to the learning outcome. Similarly, the definition of ‘Strong’ and ‘Weak’ augmentation was not clear. The description of method lacks detailed explanations. Please see below detailed comments. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance May be able to replicate the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Introduction The terms ‘transformation prediction’ and ‘contrastive learning’ were not clearly explained in the Introduction. The differences between two terms also need to be discussed. Method Fig 1 is not meaningful to me. Where is the combination? Why is the combination good? What are positive and negative samples in the authors’ contrastive learning? The description of overall training procedure was not clear. Need more explanation on the design of Equation (2). Why does this work better than cosine similarity [6]? It appears that different ‘strong’ augmentations are unusually treated as negative samples during the contrastive learning. Experiments / Results It would be interesting to see how the proposed method perform in comparison to other self-supervised methods such as SimCLR or MoCo. There is a still a big performance gap between the proposed method and other supervised methods in localisation tasks. It would be good to specifically discuss some future work on this. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses an important problem and the authors provided comprehesive experiment results to support the proposed method. The descriptions of method was, however, problematic and this needs to be fixed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection, which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is well written and easy to follow. The experimental results show that the proposed method has strong performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The model seems a mechanical combination of two existing methods and it would be better to discussed further on the novelty of this work. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance No source code is provided but they claim that the code will be available upon paper acceptance. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see “4. main weaknesses” Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My main concerns are about the novelty of this paper. It seems a mechniacl combination of two existing method: transformation prediction and contrastive feature learning. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is agreement amongst the reviewers that the paper is weak on experimental results. R1 specifically mentioned weak methodological novelty and I agree. There are also issues with explanation of key concepts and motivation for using the specified baselines is not clear. Authors focus primarily on these issues in the rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors, in their rebuttal, address many of the key points in the reviews especially those of Reviewer 1. In light of the rebuttal I believe that the novel contribution is good, and the additional results are convincing. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 12 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. I think the task of identifying self-supervised learning strategies suitable for anomaly detection is very pertinent. In particular, the proposed approach is relevant as it can be used on-top of existing anomaly detection approaches. I found the experiments and the ablation sufficiently convincing, especially after the clarification in the rebuttal that SimCLR pretraining has actually been featured in the ablation study After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Before rebuttal, there was a consensus among the reivewers and the metareviewer that the paper lacks enough novelty and not strong experimental results. They authors provided a rebuttal that partially addressed most of the comments. But it did not add new info about the novelties. Also, reading through the paper, it is clear that the authors have not seen all the relevant prior work. So it is very hard to recommend acceptance for the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 18 Author Feedback Novelty, motivation, key concepts: -We propose Constrained Contrastive Distribution (CCD), a new self-supervised representation learning designed specifically to learn normality information from exclusively normal training images. The novelties of CCD are: a)contrastive distribution learning, and b)two pretext learning constraints, both of which are customised for anomaly detection (AD). Unlike modern self-supervised learning (SSL)[6,15,40] that focuses on learning generic semantic representations for enabling diverse downstream tasks, CCD instead contrasts the distributions of strongly augmented images (Eq.2). The strongly augmented images resemble some types of abnormal images, so CCD is enforced to learn discriminative normality representations by its contrastive distribution learning. The two pretext learning constraints on augmentation and location prediction are added to learn fine-grained normality representations for the detection of subtle abnormalities. These two unique components result in significantly improved self-supervised AD-oriented representation learning, substantially outperforming those general-purpose SOTA SSL approaches [6,15,34,40], as shown in Tab.1. -Another important contribution of CCD is that it is agnostic to downstream anomaly classifiers. In the paper, we show that our CCD improves the performance of three diverse anomaly detectors (f-anogan, IGD, MS-SSIM), and ultimately produces SOTA results on three datasets. -To show that CCD is not a simple combination of SSL and transformation prediction, we train a representation learning method that combines transformation prediction [12] and contrastive learning [6]. Without contrasting the distribution of strong augmentations, as shown in Eq.2, this simple combination only achieves 88.3 AUC with IGD on Hyper-Kvasir, which is significantly worse than our 97.2 AUC. -In the ablation studies, differently from modern SSL approaches[6,15] that rely on large batch sizes, we reveal for the first time that for anomaly detection in medical image analysis, we need batches of medium size instead, as illustrated in Fig.2(left). Moreover, we show that for medical images, the performance of strong augmentations is quite different from natural images[2,12]. For instance, unlike the rotation prediction used in natural images [2,12], colonoscopy images cannot use the rotation as strong augmentation because it will produce extremely similar images after the transformation. Fig.2(right) shows the results using different strong augmentations. These empirical results provide important insights into the adaptation of advanced SSL techniques for AD in medical images. Selection of SOTA methods and comparison with [12] and SimCLR: Tab. 3 shows a comprehensive comparison of SOTA UAD methods (CAVGA-Ru, ADGAN and OCGAN). The three methods that used our CCD (IGD, f-anogan, and MS-SSIM) were selected because IGD is the SOTA on several natural image datasets, f-anogan is a prevalent UAD method, and MS-SSIM is a common baseline. We pretrained the geometric transformation-based anomaly detection [12] using IGD as the UAD method, which achieved 90.47% AUC and 27.6% IoU. Hence, our CCD pretraining surpasses [12] by 7% and 10% for anomaly detection and localisation, respectively. We have shown the result of SimCLR pretraining in the first row of Tab.1, with a 91.3% detection AUC on Hyper-Kvasir, which is 6% lower than with our approach. Parameter and threshold tuning: We followed the parameter settings in [6,7,15,32], which will be available from our code to be published. The threshold is estimated from the mean scores on a validation set containing 100 normal training samples [23,25,32]. Reference to compare: We run Chen, et al.,MedIA’20, which achieves 89.3% on Hyper-Kvasir (8% worse than our CCD+IGD). Applying our CCD to their approach improves their result to 94.9%, indicating that our CCD can be adopted to empower different SOTA approaches. We’ll cite R1’s references. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yu Tian, Guansong Pang, Fengbei Liu, Yuanhong Chen, Seon Ho Shin, Johan W. Verjans, Rajvinder Singh, Gustavo Carneiro Abstract Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns. UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. To address this challenge, we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Extensive experiment results show that our method outperforms current state-of-the-art UAD approaches on three different colonoscopy and fundus screening datasets. Link to paper https://doi.org/10.1007/978-3-030-87240-3_13 Link to the code repository https://github.com/tianyu0207/CCD Link to the dataset(s) https://www.nature.com/articles/s41597-020-00622-y https://github.com/smilell/AG-CNN Reviews Review #1 Please describe the contribution of the paper This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. The use for U-AMD is moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novel formulation of the loss function for the pretrained model based on contrastive distribution loss, classification loss for strong augmentation and position loss. The anomaly detection formula in Eq. (5)-(7), though some details are lacking. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The experiments seem not so well designed and solid; lacking of parameter tuning and explanation of how to select the threshold for determining abnormality. Comparison with SOTA methods seem arbitrary chosen without explanation. Reference is not complete, some recent unsupervised AMD methods for medical images are not included. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance reproducibility of the paper is moderate, some experiments and implementation settings are lacking, e.g. threshold, parameters. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. This is feasible with the use of large health screening datasets to avoid the large annotation burden imposed to the radiologist; and potential to detect and localize any type of lesions. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. While this may not be novel in the literature, but its use for U-AMD is still moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Some detailed questions are listed below: 2) Some recent anomaly detection methods for medical images are not referenced. Please see the following: • H. Uzunova, S. Schultz, et al., “Unsupervised pathology detection in medical images using conditional variational autoencoders,” International journal of computer assisted radiology and surgery, vol. 14, no. 3, pp. 451–461, 2019. • X. Chen, S. You, et al., Unsupervised lesion detection via image restoration with a normative prior. Medical Image Anal. 64: 101713 (2020) • X Li, H Yang et al. Transfer Learning with Joint Optimization for Label-Efficient Medical Image Anomaly Detection. MICCAI’20 workshop, LNCS, pp. 145-154. • Khalil Ouardini et al. Towards Practical Unsupervised Anomaly Detection on Retinal Images, MICCAI’19, DART 2019, MIL3ID 2019, LNCS, vol. 11795, pp. 225-234. 3) We understand that the proposed method works as a self-supervised pretraining model, however, it is not very clear from the first read of the paper. It would be helpful to add in explanation/block diagram to show how the proposed method works. 4) How to select the pretext to be used for contrastive learning (Section 2.1 of page 3), and based on what data? 5) Please explain why the three SOTA methods (references 7, 32 and 41) are selected for the comparison, please see last line 5-6 of the 1st paragraph of Section I. From the description in Section 2.2, page 5, the proposed method is based on fine-tuning the three SOTA methods of IGD, F_anoGAN and MS-SSIM. Is this the main reason that only these three methods are used for comparison? Why not compare with some of the unsupervised AMD method for medical images? We noted the localization performance has been compared with CAVGA-Ru [39]. How about [12], which is a geometric transformation-based anomaly detection method? 6) Do you need to tune the parameters for training IGD, F-anoGan, MS-SSIM for the data used in this paper instead of using the parameters used in the original paper? 7) Please give more details on how to determine the abnormality of the sample when Eq. (5)(6)(7) is computed. Is there any threshold chose involved? Considering the model is trained only based on normal data, whereas no abnormal data are used, how to determine the abnormality of an image? Also noted that only train data is used for model training, whereas no validation data are used. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The formulation of the loss for pretrained models based pretext tasks. The ablation study that demonstrates the improvement made by incorporating the pretrained model. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The paper presents a self-supervised learning method, named Constrained Contrastive Distribution Learning (CCD), for unsupervised anomaly detection (UAD) and localization in 2 different types of medical images. The authors proposed to combine contrastive learning with image transformation prediction tasks (i.e., pretext tasks) to further improve the quality of image features. The proposed method was evaluated using 3 public datasets and the results show that it had higher area under the curve (AUC) scores compared to other state-of-the-art UAD methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The combination of contrastive learning with two additional pretext tasks which use data augmentation. The pre-training process does not need label information and can be easily applied to different types of models to further improve the feature representation of medical images. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The motivation of combining of contrastive learning and pretext tasks were not clearly explained. The authors need to clearly explain how the combination benefits to the learning outcome. Similarly, the definition of ‘Strong’ and ‘Weak’ augmentation was not clear. The description of method lacks detailed explanations. Please see below detailed comments. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance May be able to replicate the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Introduction The terms ‘transformation prediction’ and ‘contrastive learning’ were not clearly explained in the Introduction. The differences between two terms also need to be discussed. Method Fig 1 is not meaningful to me. Where is the combination? Why is the combination good? What are positive and negative samples in the authors’ contrastive learning? The description of overall training procedure was not clear. Need more explanation on the design of Equation (2). Why does this work better than cosine similarity [6]? It appears that different ‘strong’ augmentations are unusually treated as negative samples during the contrastive learning. Experiments / Results It would be interesting to see how the proposed method perform in comparison to other self-supervised methods such as SimCLR or MoCo. There is a still a big performance gap between the proposed method and other supervised methods in localisation tasks. It would be good to specifically discuss some future work on this. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses an important problem and the authors provided comprehesive experiment results to support the proposed method. The descriptions of method was, however, problematic and this needs to be fixed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection, which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is well written and easy to follow. The experimental results show that the proposed method has strong performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The model seems a mechanical combination of two existing methods and it would be better to discussed further on the novelty of this work. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance No source code is provided but they claim that the code will be available upon paper acceptance. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see “4. main weaknesses” Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My main concerns are about the novelty of this paper. It seems a mechniacl combination of two existing method: transformation prediction and contrastive feature learning. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is agreement amongst the reviewers that the paper is weak on experimental results. R1 specifically mentioned weak methodological novelty and I agree. There are also issues with explanation of key concepts and motivation for using the specified baselines is not clear. Authors focus primarily on these issues in the rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors, in their rebuttal, address many of the key points in the reviews especially those of Reviewer 1. In light of the rebuttal I believe that the novel contribution is good, and the additional results are convincing. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 12 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. I think the task of identifying self-supervised learning strategies suitable for anomaly detection is very pertinent. In particular, the proposed approach is relevant as it can be used on-top of existing anomaly detection approaches. I found the experiments and the ablation sufficiently convincing, especially after the clarification in the rebuttal that SimCLR pretraining has actually been featured in the ablation study After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Before rebuttal, there was a consensus among the reivewers and the metareviewer that the paper lacks enough novelty and not strong experimental results. They authors provided a rebuttal that partially addressed most of the comments. But it did not add new info about the novelties. Also, reading through the paper, it is clear that the authors have not seen all the relevant prior work. So it is very hard to recommend acceptance for the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 18 Author Feedback Novelty, motivation, key concepts: -We propose Constrained Contrastive Distribution (CCD), a new self-supervised representation learning designed specifically to learn normality information from exclusively normal training images. The novelties of CCD are: a)contrastive distribution learning, and b)two pretext learning constraints, both of which are customised for anomaly detection (AD). Unlike modern self-supervised learning (SSL)[6,15,40] that focuses on learning generic semantic representations for enabling diverse downstream tasks, CCD instead contrasts the distributions of strongly augmented images (Eq.2). The strongly augmented images resemble some types of abnormal images, so CCD is enforced to learn discriminative normality representations by its contrastive distribution learning. The two pretext learning constraints on augmentation and location prediction are added to learn fine-grained normality representations for the detection of subtle abnormalities. These two unique components result in significantly improved self-supervised AD-oriented representation learning, substantially outperforming those general-purpose SOTA SSL approaches [6,15,34,40], as shown in Tab.1. -Another important contribution of CCD is that it is agnostic to downstream anomaly classifiers. In the paper, we show that our CCD improves the performance of three diverse anomaly detectors (f-anogan, IGD, MS-SSIM), and ultimately produces SOTA results on three datasets. -To show that CCD is not a simple combination of SSL and transformation prediction, we train a representation learning method that combines transformation prediction [12] and contrastive learning [6]. Without contrasting the distribution of strong augmentations, as shown in Eq.2, this simple combination only achieves 88.3 AUC with IGD on Hyper-Kvasir, which is significantly worse than our 97.2 AUC. -In the ablation studies, differently from modern SSL approaches[6,15] that rely on large batch sizes, we reveal for the first time that for anomaly detection in medical image analysis, we need batches of medium size instead, as illustrated in Fig.2(left). Moreover, we show that for medical images, the performance of strong augmentations is quite different from natural images[2,12]. For instance, unlike the rotation prediction used in natural images [2,12], colonoscopy images cannot use the rotation as strong augmentation because it will produce extremely similar images after the transformation. Fig.2(right) shows the results using different strong augmentations. These empirical results provide important insights into the adaptation of advanced SSL techniques for AD in medical images. Selection of SOTA methods and comparison with [12] and SimCLR: Tab. 3 shows a comprehensive comparison of SOTA UAD methods (CAVGA-Ru, ADGAN and OCGAN). The three methods that used our CCD (IGD, f-anogan, and MS-SSIM) were selected because IGD is the SOTA on several natural image datasets, f-anogan is a prevalent UAD method, and MS-SSIM is a common baseline. We pretrained the geometric transformation-based anomaly detection [12] using IGD as the UAD method, which achieved 90.47% AUC and 27.6% IoU. Hence, our CCD pretraining surpasses [12] by 7% and 10% for anomaly detection and localisation, respectively. We have shown the result of SimCLR pretraining in the first row of Tab.1, with a 91.3% detection AUC on Hyper-Kvasir, which is 6% lower than with our approach. Parameter and threshold tuning: We followed the parameter settings in [6,7,15,32], which will be available from our code to be published. The threshold is estimated from the mean scores on a validation set containing 100 normal training samples [23,25,32]. Reference to compare: We run Chen, et al.,MedIA’20, which achieves 89.3% on Hyper-Kvasir (8% worse than our CCD+IGD). Applying our CCD to their approach improves their result to 94.9%, indicating that our CCD can be adopted to empower different SOTA approaches. We’ll cite R1’s references. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0512/12/31/Paper0405" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0512/12/31/Paper0405" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0512-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0512/12/31/Paper0405"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0512/12/31/Paper0405","headline":"Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images","dateModified":"0513-01-03T00:00:00-05:17","datePublished":"0512-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Yu Tian, Guansong Pang, Fengbei Liu, Yuanhong Chen, Seon Ho Shin, Johan W. Verjans, Rajvinder Singh, Gustavo Carneiro Abstract Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns. UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. To address this challenge, we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Extensive experiment results show that our method outperforms current state-of-the-art UAD approaches on three different colonoscopy and fundus screening datasets. Link to paper https://doi.org/10.1007/978-3-030-87240-3_13 Link to the code repository https://github.com/tianyu0207/CCD Link to the dataset(s) https://www.nature.com/articles/s41597-020-00622-y https://github.com/smilell/AG-CNN Reviews Review #1 Please describe the contribution of the paper This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. The use for U-AMD is moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novel formulation of the loss function for the pretrained model based on contrastive distribution loss, classification loss for strong augmentation and position loss. The anomaly detection formula in Eq. (5)-(7), though some details are lacking. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The experiments seem not so well designed and solid; lacking of parameter tuning and explanation of how to select the threshold for determining abnormality. Comparison with SOTA methods seem arbitrary chosen without explanation. Reference is not complete, some recent unsupervised AMD methods for medical images are not included. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance reproducibility of the paper is moderate, some experiments and implementation settings are lacking, e.g. threshold, parameters. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. This is feasible with the use of large health screening datasets to avoid the large annotation burden imposed to the radiologist; and potential to detect and localize any type of lesions. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context. The method is a combination of self-supervised learning, transformation prediction and contrast learning. While this may not be novel in the literature, but its use for U-AMD is still moderately novel. Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Some detailed questions are listed below: 2) Some recent anomaly detection methods for medical images are not referenced. Please see the following: • H. Uzunova, S. Schultz, et al., “Unsupervised pathology detection in medical images using conditional variational autoencoders,” International journal of computer assisted radiology and surgery, vol. 14, no. 3, pp. 451–461, 2019. • X. Chen, S. You, et al., Unsupervised lesion detection via image restoration with a normative prior. Medical Image Anal. 64: 101713 (2020) • X Li, H Yang et al. Transfer Learning with Joint Optimization for Label-Efficient Medical Image Anomaly Detection. MICCAI’20 workshop, LNCS, pp. 145-154. • Khalil Ouardini et al. Towards Practical Unsupervised Anomaly Detection on Retinal Images, MICCAI’19, DART 2019, MIL3ID 2019, LNCS, vol. 11795, pp. 225-234. 3) We understand that the proposed method works as a self-supervised pretraining model, however, it is not very clear from the first read of the paper. It would be helpful to add in explanation/block diagram to show how the proposed method works. 4) How to select the pretext to be used for contrastive learning (Section 2.1 of page 3), and based on what data? 5) Please explain why the three SOTA methods (references 7, 32 and 41) are selected for the comparison, please see last line 5-6 of the 1st paragraph of Section I. From the description in Section 2.2, page 5, the proposed method is based on fine-tuning the three SOTA methods of IGD, F_anoGAN and MS-SSIM. Is this the main reason that only these three methods are used for comparison? Why not compare with some of the unsupervised AMD method for medical images? We noted the localization performance has been compared with CAVGA-Ru [39]. How about [12], which is a geometric transformation-based anomaly detection method? 6) Do you need to tune the parameters for training IGD, F-anoGan, MS-SSIM for the data used in this paper instead of using the parameters used in the original paper? 7) Please give more details on how to determine the abnormality of the sample when Eq. (5)(6)(7) is computed. Is there any threshold chose involved? Considering the model is trained only based on normal data, whereas no abnormal data are used, how to determine the abnormality of an image? Also noted that only train data is used for model training, whereas no validation data are used. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The formulation of the loss for pretrained models based pretext tasks. The ablation study that demonstrates the improvement made by incorporating the pretrained model. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper The paper presents a self-supervised learning method, named Constrained Contrastive Distribution Learning (CCD), for unsupervised anomaly detection (UAD) and localization in 2 different types of medical images. The authors proposed to combine contrastive learning with image transformation prediction tasks (i.e., pretext tasks) to further improve the quality of image features. The proposed method was evaluated using 3 public datasets and the results show that it had higher area under the curve (AUC) scores compared to other state-of-the-art UAD methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The combination of contrastive learning with two additional pretext tasks which use data augmentation. The pre-training process does not need label information and can be easily applied to different types of models to further improve the feature representation of medical images. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The motivation of combining of contrastive learning and pretext tasks were not clearly explained. The authors need to clearly explain how the combination benefits to the learning outcome. Similarly, the definition of ‘Strong’ and ‘Weak’ augmentation was not clear. The description of method lacks detailed explanations. Please see below detailed comments. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance May be able to replicate the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Introduction The terms ‘transformation prediction’ and ‘contrastive learning’ were not clearly explained in the Introduction. The differences between two terms also need to be discussed. Method Fig 1 is not meaningful to me. Where is the combination? Why is the combination good? What are positive and negative samples in the authors’ contrastive learning? The description of overall training procedure was not clear. Need more explanation on the design of Equation (2). Why does this work better than cosine similarity [6]? It appears that different ‘strong’ augmentations are unusually treated as negative samples during the contrastive learning. Experiments / Results It would be interesting to see how the proposed method perform in comparison to other self-supervised methods such as SimCLR or MoCo. There is a still a big performance gap between the proposed method and other supervised methods in localisation tasks. It would be good to specifically discuss some future work on this. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses an important problem and the authors provided comprehesive experiment results to support the proposed method. The descriptions of method was, however, problematic and this needs to be fixed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection, which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is well written and easy to follow. The experimental results show that the proposed method has strong performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The model seems a mechanical combination of two existing methods and it would be better to discussed further on the novelty of this work. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance No source code is provided but they claim that the code will be available upon paper acceptance. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see “4. main weaknesses” Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? My main concerns are about the novelty of this paper. It seems a mechniacl combination of two existing method: transformation prediction and contrastive feature learning. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is agreement amongst the reviewers that the paper is weak on experimental results. R1 specifically mentioned weak methodological novelty and I agree. There are also issues with explanation of key concepts and motivation for using the specified baselines is not clear. Authors focus primarily on these issues in the rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors, in their rebuttal, address many of the key points in the reviews especially those of Reviewer 1. In light of the rebuttal I believe that the novel contribution is good, and the additional results are convincing. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 12 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. I think the task of identifying self-supervised learning strategies suitable for anomaly detection is very pertinent. In particular, the proposed approach is relevant as it can be used on-top of existing anomaly detection approaches. I found the experiments and the ablation sufficiently convincing, especially after the clarification in the rebuttal that SimCLR pretraining has actually been featured in the ablation study After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 8 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Before rebuttal, there was a consensus among the reivewers and the metareviewer that the paper lacks enough novelty and not strong experimental results. They authors provided a rebuttal that partially addressed most of the comments. But it did not add new info about the novelties. Also, reading through the paper, it is clear that the authors have not seen all the relevant prior work. So it is very hard to recommend acceptance for the paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 18 Author Feedback Novelty, motivation, key concepts: -We propose Constrained Contrastive Distribution (CCD), a new self-supervised representation learning designed specifically to learn normality information from exclusively normal training images. The novelties of CCD are: a)contrastive distribution learning, and b)two pretext learning constraints, both of which are customised for anomaly detection (AD). Unlike modern self-supervised learning (SSL)[6,15,40] that focuses on learning generic semantic representations for enabling diverse downstream tasks, CCD instead contrasts the distributions of strongly augmented images (Eq.2). The strongly augmented images resemble some types of abnormal images, so CCD is enforced to learn discriminative normality representations by its contrastive distribution learning. The two pretext learning constraints on augmentation and location prediction are added to learn fine-grained normality representations for the detection of subtle abnormalities. These two unique components result in significantly improved self-supervised AD-oriented representation learning, substantially outperforming those general-purpose SOTA SSL approaches [6,15,34,40], as shown in Tab.1. -Another important contribution of CCD is that it is agnostic to downstream anomaly classifiers. In the paper, we show that our CCD improves the performance of three diverse anomaly detectors (f-anogan, IGD, MS-SSIM), and ultimately produces SOTA results on three datasets. -To show that CCD is not a simple combination of SSL and transformation prediction, we train a representation learning method that combines transformation prediction [12] and contrastive learning [6]. Without contrasting the distribution of strong augmentations, as shown in Eq.2, this simple combination only achieves 88.3 AUC with IGD on Hyper-Kvasir, which is significantly worse than our 97.2 AUC. -In the ablation studies, differently from modern SSL approaches[6,15] that rely on large batch sizes, we reveal for the first time that for anomaly detection in medical image analysis, we need batches of medium size instead, as illustrated in Fig.2(left). Moreover, we show that for medical images, the performance of strong augmentations is quite different from natural images[2,12]. For instance, unlike the rotation prediction used in natural images [2,12], colonoscopy images cannot use the rotation as strong augmentation because it will produce extremely similar images after the transformation. Fig.2(right) shows the results using different strong augmentations. These empirical results provide important insights into the adaptation of advanced SSL techniques for AD in medical images. Selection of SOTA methods and comparison with [12] and SimCLR: Tab. 3 shows a comprehensive comparison of SOTA UAD methods (CAVGA-Ru, ADGAN and OCGAN). The three methods that used our CCD (IGD, f-anogan, and MS-SSIM) were selected because IGD is the SOTA on several natural image datasets, f-anogan is a prevalent UAD method, and MS-SSIM is a common baseline. We pretrained the geometric transformation-based anomaly detection [12] using IGD as the UAD method, which achieved 90.47% AUC and 27.6% IoU. Hence, our CCD pretraining surpasses [12] by 7% and 10% for anomaly detection and localisation, respectively. We have shown the result of SimCLR pretraining in the first row of Tab.1, with a 91.3% detection AUC on Hyper-Kvasir, which is 6% lower than with our approach. Parameter and threshold tuning: We followed the parameter settings in [6,7,15,32], which will be available from our code to be published. The threshold is estimated from the mean scores on a validation set containing 100 normal training samples [23,25,32]. Reference to compare: We run Chen, et al.,MedIA’20, which achieves 89.3% on Hyper-Kvasir (8% worse than our CCD+IGD). Applying our CCD to their approach improves their result to 94.9%, indicating that our CCD can be adopted to empower different SOTA approaches. We’ll cite R1’s references. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Tian, Yu,Pang, Guansong,Liu, Fengbei,Chen, Yuanhong,Shin, Seon Ho,Verjans, Johan W.,Singh, Rajvinder,Carneiro, Gustavo" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Abdomen"
        class="post-category">
        Clinical applications - Abdomen
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a>
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Tian, Yu"
        class="post-tags">
        Tian, Yu
      </a> |  
      
      <a href="kittywong/tags#Pang, Guansong"
        class="post-tags">
        Pang, Guansong
      </a> |  
      
      <a href="kittywong/tags#Liu, Fengbei"
        class="post-tags">
        Liu, Fengbei
      </a> |  
      
      <a href="kittywong/tags#Chen, Yuanhong"
        class="post-tags">
        Chen, Yuanhong
      </a> |  
      
      <a href="kittywong/tags#Shin, Seon Ho"
        class="post-tags">
        Shin, Seon Ho
      </a> |  
      
      <a href="kittywong/tags#Verjans, Johan W."
        class="post-tags">
        Verjans, Johan W.
      </a> |  
      
      <a href="kittywong/tags#Singh, Rajvinder"
        class="post-tags">
        Singh, Rajvinder
      </a> |  
      
      <a href="kittywong/tags#Carneiro, Gustavo"
        class="post-tags">
        Carneiro, Gustavo
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Yu Tian, Guansong Pang, Fengbei Liu, Yuanhong Chen, Seon Ho Shin, Johan W. Verjans, Rajvinder Singh, Gustavo Carneiro
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Unsupervised anomaly detection (UAD) learns one-class classifiers exclusively with normal (i.e., healthy) images to detect any abnormal (i.e., unhealthy) samples that do not conform to the expected normal patterns. UAD has two main advantages over its fully supervised counterpart. Firstly, it is able to directly leverage large datasets available from health screening programs that contain mostly normal image samples, avoiding the costly manual labelling of abnormal samples and the subsequent issues involved in training with extremely class-imbalanced data. Further, UAD approaches can potentially detect and localise any type of lesions that deviate from the normal patterns. One significant challenge faced by UAD methods is how to learn effective low-dimensional image representations to detect and localise subtle abnormalities, generally consisting of small lesions. To address this challenge, we propose a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection (CCD), which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models. Extensive experiment results show that our method outperforms current state-of-the-art UAD approaches on three different colonoscopy and fundus screening datasets.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87240-3_13">https://doi.org/10.1007/978-3-030-87240-3_13</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/tianyu0207/CCD
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://www.nature.com/articles/s41597-020-00622-y
https://github.com/smilell/AG-CNN
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context.  The method is a combination of self-supervised learning, transformation prediction and contrast learning. The use for U-AMD is moderately novel.</p>

      <p>Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The novel formulation of the loss function for the pretrained model based on contrastive distribution loss, classification loss for strong augmentation and position loss. 
The anomaly detection formula in Eq. (5)-(7), though some details are lacking.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The experiments seem not so well designed and solid; lacking of parameter tuning and explanation of how to select the threshold for determining abnormality. 
Comparison with SOTA methods seem arbitrary chosen without explanation.
Reference is not complete, some recent unsupervised AMD methods for medical images are not included.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>reproducibility of the paper is moderate, some experiments and implementation settings are lacking, e.g. threshold, parameters.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>1)	This paper proposes an unsupervised anomaly detection (U-AMD) pretraining method for lesion detection and localization based on only normal images. This is feasible with the use of large health screening datasets to avoid the large annotation burden imposed to the radiologist; and potential to detect and localize any type of lesions. The method learns fine-grained feature representations with contrast learning to constrain the prediction of the distribution of the augmented data and image context.  The method is a combination of self-supervised learning, transformation prediction and contrast learning. While this may not be novel in the literature, but its use for U-AMD is still moderately novel.</p>

      <p>Three colonoscopy and fundus screening datasets are used in evaluation and the results show improved performance. Some detailed questions are listed below:</p>

      <p>2)	Some recent anomaly detection methods for medical images are not referenced. Please see the following:</p>

      <p>•	H. Uzunova, S. Schultz, et al., “Unsupervised pathology detection in medical images using conditional variational autoencoders,” International journal of computer assisted radiology and surgery, vol. 14, no. 3, pp. 451–461, 2019.
•	X. Chen, S. You, et al., Unsupervised lesion detection via image restoration with a normative prior. Medical Image Anal. 64: 101713 (2020)
•	X Li, H Yang et al. Transfer Learning with Joint Optimization for Label-Efficient Medical Image Anomaly Detection. MICCAI’20 workshop, LNCS, pp. 145-154.
•	Khalil Ouardini et al. Towards Practical Unsupervised Anomaly Detection on Retinal Images, MICCAI’19, DART 2019, MIL3ID 2019, LNCS, vol. 11795, pp. 225-234.
3)	We understand that the proposed method works as a self-supervised pretraining model, however, it is not very clear from the first read of the paper. It would be helpful to add in explanation/block diagram to show how the proposed method works.<br />
4)	How to select the pretext to be used for contrastive learning (Section 2.1 of page 3), and based on what data?
5)	Please explain why the three SOTA methods (references 7, 32 and 41) are selected for the comparison, please see last line 5-6 of the 1st paragraph of Section I. From the description in Section 2.2, page 5, the proposed method is based on fine-tuning the three SOTA methods of IGD, F_anoGAN and MS-SSIM. Is this the main reason that only these three methods are used for comparison? Why not compare with some of the unsupervised AMD method for medical images? We noted the localization performance has been compared with CAVGA-Ru [39]. How about [12], which is a geometric transformation-based anomaly detection method?
6)	Do you need to tune the parameters for training IGD, F-anoGan, MS-SSIM for the data used in this paper instead of using the parameters used in the original paper?
7)	Please give more details on how to determine the abnormality of the sample when Eq. (5)(6)(7) is computed. Is there any threshold chose involved? Considering the model is trained only based on normal data, whereas no abnormal data are used, how to determine the abnormality of an image? Also noted that only train data is used for model training, whereas no validation data are used.</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The formulation of the loss for pretrained models based pretext tasks. 
The ablation study that demonstrates the improvement made by incorporating the pretrained model.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper presents a self-supervised learning method, named Constrained Contrastive Distribution Learning (CCD), for unsupervised anomaly detection (UAD) and localization in 2 different types of medical images. The authors proposed to combine contrastive learning with image transformation prediction tasks (i.e., pretext tasks) to further improve the quality of image features. The proposed method was evaluated using 3 public datasets and the results show that it had higher area under the curve (AUC) scores compared to other state-of-the-art UAD methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The combination of contrastive learning with two additional pretext tasks which use data augmentation.</li>
        <li>The pre-training process does not need label information and can be easily applied to different types of models to further improve the feature representation of medical images.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>The motivation of combining of contrastive learning and pretext tasks were not clearly explained. The authors need to clearly explain how the combination benefits to the learning outcome.</li>
        <li>Similarly, the definition of ‘Strong’ and ‘Weak’ augmentation was not clear.</li>
        <li>The description of method lacks detailed explanations. Please see below detailed comments.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>May be able to replicate the results.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Introduction</p>

      <ol>
        <li>The terms ‘transformation prediction’ and ‘contrastive learning’ were not clearly explained in the Introduction. The differences between two terms also need to be discussed.</li>
      </ol>

      <p>Method</p>

      <ol>
        <li>Fig 1 is not meaningful to me. Where is the combination? Why is the combination good?</li>
        <li>What are positive and negative samples in the authors’ contrastive learning? The description of overall training procedure was not clear.</li>
        <li>Need more explanation on the design of Equation (2). Why does this work better than cosine similarity [6]?</li>
        <li>It appears that different ‘strong’ augmentations are unusually treated as negative samples during the contrastive learning.</li>
      </ol>

      <p>Experiments / Results</p>

      <ol>
        <li>It would be interesting to see how the proposed method perform in comparison to other self-supervised methods such as SimCLR or MoCo.</li>
        <li>There is a still a big performance gap between the proposed method and other supervised methods in localisation tasks. It would be good to specifically discuss some future work on this.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The paper addresses an important problem and the authors provided comprehesive experiment results to support the proposed method. The descriptions of method was, however, problematic and this needs to be fixed.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes a novel self-supervised representation learning method, called Constrained Contrastive Distribution learning for anomaly detection, which learns fine-grained feature representations by simultaneously predicting the distribution of augmented data and image contexts using contrastive learning with pretext constraints. The learned representations can be leveraged to train more anomaly-sensitive detection models.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The paper is well written and easy to follow.</li>
        <li>The experimental results show that the proposed method has strong performance.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The model seems a mechanical combination of two existing methods and it would be better to discussed further on the novelty of this work.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>No source code is provided but they claim that the code will be available upon paper acceptance.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please see “4.  main weaknesses”</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>My main concerns are about the novelty of this paper. It seems a mechniacl combination of two existing method: transformation prediction and contrastive feature learning.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>There is agreement amongst the reviewers that the paper is weak on experimental results. R1 specifically mentioned weak methodological novelty and I agree. There are also issues with explanation of key concepts and motivation for using the specified baselines is not clear. Authors focus primarily on these issues in the rebuttal.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>7</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors, in their rebuttal, address many of the key points in the reviews especially those of Reviewer 1. In light of the rebuttal I believe that the novel contribution is good, and the additional results are convincing.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>12</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>I think the task of identifying self-supervised learning strategies suitable for anomaly detection is very pertinent. In particular, the proposed approach is relevant as it can be used on-top of existing anomaly detection approaches. I found the experiments and the ablation sufficiently convincing, especially after the clarification in the rebuttal that SimCLR pretraining has actually been featured in the ablation study</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>8</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>Before rebuttal, there was a consensus among the reivewers and the metareviewer that the paper lacks enough novelty and not strong experimental results. They authors provided a rebuttal that partially addressed most of the comments. But it did not add new info about the novelties. Also, reading through the paper, it is clear that the authors have not seen all the relevant prior work. So it is very hard to recommend acceptance for the paper.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Reject</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>18</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>Novelty, motivation, key concepts:
-We propose Constrained Contrastive Distribution (CCD), a new self-supervised representation learning designed specifically to learn normality information from exclusively  normal training images. The novelties of CCD are: a)contrastive distribution learning, and b)two pretext learning constraints, both of which are customised for anomaly detection (AD). Unlike modern self-supervised learning (SSL)[6,15,40] that focuses on learning generic semantic representations for enabling diverse downstream tasks, CCD instead contrasts the distributions of strongly augmented images (Eq.2). The strongly augmented images resemble some types of abnormal images, so CCD is enforced to learn discriminative normality representations by its contrastive distribution learning. The two pretext learning constraints on augmentation and location prediction are added to learn fine-grained normality representations for the detection of subtle abnormalities. These two unique components result in significantly improved self-supervised AD-oriented representation learning, substantially outperforming those general-purpose SOTA SSL approaches [6,15,34,40], as shown in Tab.1.</p>

  <p>-Another important contribution of CCD is that it is agnostic to downstream anomaly classifiers. In the paper, we show that our CCD improves the performance of three diverse anomaly detectors (f-anogan, IGD, MS-SSIM), and ultimately produces SOTA results on three datasets.</p>

  <p>-To show that CCD is not a simple combination of SSL and transformation prediction, we train a representation learning method that combines transformation prediction [12] and contrastive learning [6]. Without contrasting the distribution of strong augmentations, as shown in Eq.2, this simple combination only achieves 88.3 AUC with IGD on Hyper-Kvasir, which is significantly worse than our 97.2 AUC.</p>

  <p>-In the ablation studies, differently from modern SSL approaches[6,15] that rely on large batch sizes, we reveal for the first time that for anomaly detection in medical image analysis, we need batches of medium size instead, as illustrated in  Fig.2(left). Moreover, we show that for medical images, the performance of strong augmentations is quite different from natural images[2,12]. For instance, unlike the rotation prediction used in natural images [2,12], colonoscopy images cannot use the rotation as strong augmentation because it will produce extremely similar images after the transformation. Fig.2(right) shows the results using different strong augmentations. These empirical results provide important insights into the adaptation of advanced SSL techniques for AD in medical images.</p>

  <p>Selection of SOTA methods and comparison with [12] and SimCLR:
Tab. 3 shows a comprehensive comparison of SOTA UAD methods (CAVGA-Ru, ADGAN and OCGAN). The three methods that used our CCD (IGD,  f-anogan, and MS-SSIM) were selected because IGD is the SOTA on several natural image datasets, f-anogan is a prevalent UAD method, and MS-SSIM is a common baseline. We pretrained the geometric transformation-based anomaly detection [12] using IGD as the UAD method, which achieved 90.47% AUC and 27.6% IoU.  Hence, our CCD pretraining surpasses [12] by 7% and 10% for anomaly detection and localisation, respectively.  We have shown the result of SimCLR pretraining in the first row of Tab.1, with a 91.3% detection AUC on Hyper-Kvasir, which is 6% lower than with our approach.</p>

  <p>Parameter and threshold tuning:
We followed the parameter settings in [6,7,15,32], which will be available from our code to be published.  The threshold is estimated from the mean scores on a validation set containing 100 normal training samples [23,25,32].</p>

  <p>Reference to compare:
We run Chen, et al.,MedIA’20, which achieves 89.3% on Hyper-Kvasir (8% worse than our CCD+IGD). Applying our CCD to their approach improves their result to 94.9%, indicating that our CCD can be adopted to empower different SOTA approaches. We’ll cite R1’s references.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0512-12-31
      -->
      <!--
      
        ,
        updated at 
        0513-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Abdomen"
        class="post-category">
        Clinical applications - Abdomen
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Tian, Yu"
        class="post-category">
        Tian, Yu
      </a> |  
      
      <a href="kittywong/tags#Pang, Guansong"
        class="post-category">
        Pang, Guansong
      </a> |  
      
      <a href="kittywong/tags#Liu, Fengbei"
        class="post-category">
        Liu, Fengbei
      </a> |  
      
      <a href="kittywong/tags#Chen, Yuanhong"
        class="post-category">
        Chen, Yuanhong
      </a> |  
      
      <a href="kittywong/tags#Shin, Seon Ho"
        class="post-category">
        Shin, Seon Ho
      </a> |  
      
      <a href="kittywong/tags#Verjans, Johan W."
        class="post-category">
        Verjans, Johan W.
      </a> |  
      
      <a href="kittywong/tags#Singh, Rajvinder"
        class="post-category">
        Singh, Rajvinder
      </a> |  
      
      <a href="kittywong/tags#Carneiro, Gustavo"
        class="post-category">
        Carneiro, Gustavo
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0513/12/31/Paper0487">
          Conditional Training with Bounding Map for Universal Lesion Detection
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0511/12/31/Paper0324">
          A Segmentation-Assisted Model for Universal Lesion Detection with Partial Labels
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
