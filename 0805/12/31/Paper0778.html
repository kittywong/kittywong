<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Local-global Dual Perception based Deep Multiple Instance Learning for Retinal Disease Classification | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Local-global Dual Perception based Deep Multiple Instance Learning for Retinal Disease Classification" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Qi Bi, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng Abstract With the rapidly growing number of people affected by various retinal diseases, there is a strong clinical interest for fully automatic and accurate retinal disease recognition. The unique characteristics of how retinal diseases are manifested on the fundus images pose a major challenge for automatic recognition. In order to better tackle the challenges, we propose a local-global dual perception (LGDP) based deep multiple instance learning (MIL) module that integrates the instance contribution from both local scale and global scale. The proposed module consists of a local pyramid perception module (LPPM) that emphasizes the key instances from the local scale, and a global perception module (GPM) that provides a spatial weight distribution from a global scale. Extensive experiments on three major retinal disease benchmarks demonstrate that our framework outperforms many state-of-the-art deep MIL methods, especially for recognizing the pathological images. In addition, the proposed module is also validated on multiple backbones and achieves substantively superior performance, indicating the effectiveness and generalization capability. Last but not least, the proposed deep MIL module can be conveniently embedded into any convolutional backbones via a plug-and-play manner and effectively boost the performance. Link to paper https://doi.org/10.1007/978-3-030-87237-3_6 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper suggests an approach for automatic retinal disease screening approaches based on deep learning techniques. It proposes a standardized deep MIL scheme for retinal disease recognition and claims to be adopted to any convolution neural networks (CNN). It suggests a local-global dual perception based machine instance learning (MIL) module. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1- The paper supposes a fully automatic retinal disease screening ap- proaches based on deep learning techniques which is a novel approach 2- The suggest approach can be conveniently adapted to any CNN backbones in a plug-and-play manner and substantively boost the performance by a large margin. 3- he proposed module could e ectively boost the recognition performance which may empower the diagnosing approaches for some retinal diseases Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1- The authorys should provide some details regarding why their approach outoerformes other benchmark approaches that are stated in the literature review. 2- The literature review needs some improvement to cover more state of the art current approaches in the field of retinal diseases diagnsing Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance some cutrrent paper do exist in the same area of research but unable to confirm reproducibility Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1- some statistical analysis regarding the accuracy and performance of the suggested ML based approach should be provided 2- The literature review need to be comperhensive to ensure the completenes and novelty of the research work introduced in the paper. 3- The MIL based approach should be detailed more for small researches to understand the criteria and fooundations hehind such research work Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper is somewhat well organized The paper technically sounds but with some simple comments the topic of research is of unmet needs for humanity What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper The authors propose a novel approach for an automatic retinal diseases screening from fundus images. The proposed framework is based on a local-global dual perception (LGDP) combined with multiple instance learning to integrate the instance from both local and global scales. The proposed framework was validated on two public datasets and one private dataset to evaluate its performance in the screening of Diabetic retinopathy, glaucoma and age-related macular degeneration from fundus images. Different metrics were computed to compare the performance of the proposed framework to state of the art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is clear, well structured and easy to follow. Results are clearly discussed, the approach is tested on multiples datasets and provides consistent performance improvement on each dataset. An ablation study is conducted to justify the introduction of the LPPM and the GPM branches. Table 3 indicates that the proposed framework can bee embedded in different CNN architectures, which is also an interesting contribution. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The MIL formulation might give a miss-leading sense of originality. In the paper, each pixel in the last feature maps is considered as an instance. Two types of aggregation are then done across instances (local-one with the LPPM followed by a weighted sum in the Local-global Perception Fusion). This is not different from any classical CNN-classification formulation. Moreover, here, instances are not permutation-invariant, which is usually assumed in the MIL approach. With this regard, the main contribution is the LPPM module and particularly the top-k max-pooling operator. However, table 1. indicates that GPM (which is just a 1x1 convolution) consistently (but marginally) outperform LPPM alone. It is therefore slightly unclear why the combination of both would provide such a boost in performance and further experiments should be conducted, in particular on multi-class problem (not just binary). It is unfortunate that the SOTA comparison is mostly limited to two public datasets. Diabetic Retinopathy has been widely researched and numerous recent papers have proposed methodologies tested on APTOS. In addition, there are many more DR-related dataset (FGADR, Messidor, EyePacs…) that could have been used to evaluate the proposed approach. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The private AMD dataset is not well described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The LPPM module and particularly the top-k max-pooling operator is an interesting contribution. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Extensive experiments were performed to compare the performance of the proposed framework to state of the art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper In this paper, the authors proposed a local-global dual perception deep MIL module for retinal disease recognition. Instance responses from both local and global scales are considered and integrated, so as to better tackle the challenge of how various pathologies are presented on the retinal image. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The challenges of fundus images diseases classification are well discussed and analyzed. Appling multiple instances learning (MIL) to fundus images diseases classification is reasonable. Based on MIL, the authors proposed a local-global dual perception. The proposed module can be adapted in a plug-and-play manner. Experiments are conducted on two publicly available datasets and one private dataset. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The related work about applying multiple instances learning to retinal fundus images is missing. The proposed GPM is a little simple. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance / Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html What dose the detailed implementation of SOTA deep MIL methods, including [25,16,21,22]? The proposed GPM is a little simple since the GPM only contains a Conv1 layer and a Relu layer. Also, the motivation of why design GPM in this manner is missing. The related work about applying multiple instances learning to retinal fundus images is missing. It would be better to introduce the related work to support the contributions as claimed. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is well-motivated and the experimetns are sufficient. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes a retinal disease classification using multiple instance learning. The contribution resides in a global+local scale pyramidal module. One reviewer appreciates the possible versatility of the method in other CNN architecture, invites authors for more recent work on retinal diagnosis, but without suggesting refs. A second reviewer also appreciate the plug-n-play nature of the MIL contribution, but questions the originality of the MIL formulation. A third reviewers further notice the plug-n-play advantage, but also wants more refs on fundus segmentation. All reviewers agrees on a well-written, well-evaluated method, with a highlighted appreciation of the plug-n-play nature of the proposed global+local module. Two note a lack of related refs on retinal diagnosis. The complexity of the method is described as simple, which is an advantage in my opinion in this context, which merit to be emphasized in a different wording. For these reasons, this paper constitutes a notable contribution in the MIL literature, with an easy reusable local+global dual perception module that has been extensively evaluated. Recommendation is towards Early Acceptance. Oral: All three reviewers has recommended an oral podium as well as a young scientist award. I believe the potential impact of this dual module can contribute to the field by further popularizing MIL approaches. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We appreciate the meta-reviewer and reviewers’ effort in reviewing our submission, along with the positive comments. Still, it is important to clarify some issues raised by the reviewers. Please see below for details. #To meta-reviewer. Q1: We will cite more recent references on retinal diagnosis in our camera-ready manuscript. Q2: Although deep MIL relies on convolution operations, in terms of the problem formulation, granularity of feature representation, and generation of probability distribution, they are quite different. For details, please refer to our reply to the 1st comment of Reviewer2. Q3: We will cover references on fundus segmentation in our camera-ready manuscript. #To R1. Q1: We will provide more details on statistical analysis. However, we would like to stress that, all of our experiments on the MIL based approaches are conducted under the same parameter settings, and five-fold cross validation results are reported, which is fair enough to demonstrate their different performances. Q2: We will cover more references on retinal diagnosis and fundus image processing in our camera-ready version. Q3: The details of MIL formulation and methodology has been provided in our supplementary materials. #To R2. Q1: It is actually different from the classic CNN, and the reasons are listed as follows. (1) For last feature maps, in classic CNN, the channel number is usually quite large, such as 512. However, in MIL, the instance representation must be converted from the last feature maps. Specifically, if there are N categories, the instance representation has only N channels, which is much smaller than classic CNN feature maps. (2)For the aggregation, in classic CNNs, the last feature map is fed into several fully connected layers and then generate the probability distribution. However, in MIL, the aggregation can directly produce the probability distribution. In this way, fully-connected layers in classic CNNs, which usually occupy a lot of parameters and are likely to be over-fitting, are removed. (3) For the granularity of feature representation, each instance corresponds to a N-dimension vector, and describes its response on each of the N scene categories. This is also different from existing CNNs. Q2: (1) The motivation and objective of our work is to recognize the retina diseases, not to grade them to different classes. Hence, it is more proper to formulate this task as a binary classification, rather than multi-class classification. The validation of our method on other DR multi-class tasks is our future work. (2) Compared with traditional CNNs, which preserves the global semantic information, our GPM assigns different weights to the instances and highlight the feature responses for key instances, while our LPPM highlights the responses in each local window. Hence, both our GPM and LPPM leads to a performance gain. On the other hand, as the combination of both GPM and LPPM highlights the feature responses of key instances from both the global and local perspective, the performance gain is more. We will provide this discussion in our camera-ready version. Q3: Indeed there are many other DR-related benchmarks, but they focus on the retinal disease grading task. However, as the objective of our work is to recognize the disease, rather than grade the disease into several different patterns, it may be not that proper to directly utilize such benchmarks. Adapting our MIL in such tasks and validating its effectiveness can be our future work. #To R3. Q1: To the best of our knowledge, this is the first work to investigate deep MIL for retinal recognition. We will cover more references on classic MIL and its application in retinal images. Q2:As the objective of our GPM is to acquire a spatial weight matrix for the importance of each instance, we solve this by using a convolution layer. It can be easy to use more complicated network structures for further performance gain, which is interesting for further investigation. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Qi Bi, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng Abstract With the rapidly growing number of people affected by various retinal diseases, there is a strong clinical interest for fully automatic and accurate retinal disease recognition. The unique characteristics of how retinal diseases are manifested on the fundus images pose a major challenge for automatic recognition. In order to better tackle the challenges, we propose a local-global dual perception (LGDP) based deep multiple instance learning (MIL) module that integrates the instance contribution from both local scale and global scale. The proposed module consists of a local pyramid perception module (LPPM) that emphasizes the key instances from the local scale, and a global perception module (GPM) that provides a spatial weight distribution from a global scale. Extensive experiments on three major retinal disease benchmarks demonstrate that our framework outperforms many state-of-the-art deep MIL methods, especially for recognizing the pathological images. In addition, the proposed module is also validated on multiple backbones and achieves substantively superior performance, indicating the effectiveness and generalization capability. Last but not least, the proposed deep MIL module can be conveniently embedded into any convolutional backbones via a plug-and-play manner and effectively boost the performance. Link to paper https://doi.org/10.1007/978-3-030-87237-3_6 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper suggests an approach for automatic retinal disease screening approaches based on deep learning techniques. It proposes a standardized deep MIL scheme for retinal disease recognition and claims to be adopted to any convolution neural networks (CNN). It suggests a local-global dual perception based machine instance learning (MIL) module. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1- The paper supposes a fully automatic retinal disease screening ap- proaches based on deep learning techniques which is a novel approach 2- The suggest approach can be conveniently adapted to any CNN backbones in a plug-and-play manner and substantively boost the performance by a large margin. 3- he proposed module could e ectively boost the recognition performance which may empower the diagnosing approaches for some retinal diseases Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1- The authorys should provide some details regarding why their approach outoerformes other benchmark approaches that are stated in the literature review. 2- The literature review needs some improvement to cover more state of the art current approaches in the field of retinal diseases diagnsing Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance some cutrrent paper do exist in the same area of research but unable to confirm reproducibility Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1- some statistical analysis regarding the accuracy and performance of the suggested ML based approach should be provided 2- The literature review need to be comperhensive to ensure the completenes and novelty of the research work introduced in the paper. 3- The MIL based approach should be detailed more for small researches to understand the criteria and fooundations hehind such research work Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper is somewhat well organized The paper technically sounds but with some simple comments the topic of research is of unmet needs for humanity What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper The authors propose a novel approach for an automatic retinal diseases screening from fundus images. The proposed framework is based on a local-global dual perception (LGDP) combined with multiple instance learning to integrate the instance from both local and global scales. The proposed framework was validated on two public datasets and one private dataset to evaluate its performance in the screening of Diabetic retinopathy, glaucoma and age-related macular degeneration from fundus images. Different metrics were computed to compare the performance of the proposed framework to state of the art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is clear, well structured and easy to follow. Results are clearly discussed, the approach is tested on multiples datasets and provides consistent performance improvement on each dataset. An ablation study is conducted to justify the introduction of the LPPM and the GPM branches. Table 3 indicates that the proposed framework can bee embedded in different CNN architectures, which is also an interesting contribution. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The MIL formulation might give a miss-leading sense of originality. In the paper, each pixel in the last feature maps is considered as an instance. Two types of aggregation are then done across instances (local-one with the LPPM followed by a weighted sum in the Local-global Perception Fusion). This is not different from any classical CNN-classification formulation. Moreover, here, instances are not permutation-invariant, which is usually assumed in the MIL approach. With this regard, the main contribution is the LPPM module and particularly the top-k max-pooling operator. However, table 1. indicates that GPM (which is just a 1x1 convolution) consistently (but marginally) outperform LPPM alone. It is therefore slightly unclear why the combination of both would provide such a boost in performance and further experiments should be conducted, in particular on multi-class problem (not just binary). It is unfortunate that the SOTA comparison is mostly limited to two public datasets. Diabetic Retinopathy has been widely researched and numerous recent papers have proposed methodologies tested on APTOS. In addition, there are many more DR-related dataset (FGADR, Messidor, EyePacs…) that could have been used to evaluate the proposed approach. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The private AMD dataset is not well described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The LPPM module and particularly the top-k max-pooling operator is an interesting contribution. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Extensive experiments were performed to compare the performance of the proposed framework to state of the art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper In this paper, the authors proposed a local-global dual perception deep MIL module for retinal disease recognition. Instance responses from both local and global scales are considered and integrated, so as to better tackle the challenge of how various pathologies are presented on the retinal image. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The challenges of fundus images diseases classification are well discussed and analyzed. Appling multiple instances learning (MIL) to fundus images diseases classification is reasonable. Based on MIL, the authors proposed a local-global dual perception. The proposed module can be adapted in a plug-and-play manner. Experiments are conducted on two publicly available datasets and one private dataset. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The related work about applying multiple instances learning to retinal fundus images is missing. The proposed GPM is a little simple. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance / Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html What dose the detailed implementation of SOTA deep MIL methods, including [25,16,21,22]? The proposed GPM is a little simple since the GPM only contains a Conv1 layer and a Relu layer. Also, the motivation of why design GPM in this manner is missing. The related work about applying multiple instances learning to retinal fundus images is missing. It would be better to introduce the related work to support the contributions as claimed. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is well-motivated and the experimetns are sufficient. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes a retinal disease classification using multiple instance learning. The contribution resides in a global+local scale pyramidal module. One reviewer appreciates the possible versatility of the method in other CNN architecture, invites authors for more recent work on retinal diagnosis, but without suggesting refs. A second reviewer also appreciate the plug-n-play nature of the MIL contribution, but questions the originality of the MIL formulation. A third reviewers further notice the plug-n-play advantage, but also wants more refs on fundus segmentation. All reviewers agrees on a well-written, well-evaluated method, with a highlighted appreciation of the plug-n-play nature of the proposed global+local module. Two note a lack of related refs on retinal diagnosis. The complexity of the method is described as simple, which is an advantage in my opinion in this context, which merit to be emphasized in a different wording. For these reasons, this paper constitutes a notable contribution in the MIL literature, with an easy reusable local+global dual perception module that has been extensively evaluated. Recommendation is towards Early Acceptance. Oral: All three reviewers has recommended an oral podium as well as a young scientist award. I believe the potential impact of this dual module can contribute to the field by further popularizing MIL approaches. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We appreciate the meta-reviewer and reviewers’ effort in reviewing our submission, along with the positive comments. Still, it is important to clarify some issues raised by the reviewers. Please see below for details. #To meta-reviewer. Q1: We will cite more recent references on retinal diagnosis in our camera-ready manuscript. Q2: Although deep MIL relies on convolution operations, in terms of the problem formulation, granularity of feature representation, and generation of probability distribution, they are quite different. For details, please refer to our reply to the 1st comment of Reviewer2. Q3: We will cover references on fundus segmentation in our camera-ready manuscript. #To R1. Q1: We will provide more details on statistical analysis. However, we would like to stress that, all of our experiments on the MIL based approaches are conducted under the same parameter settings, and five-fold cross validation results are reported, which is fair enough to demonstrate their different performances. Q2: We will cover more references on retinal diagnosis and fundus image processing in our camera-ready version. Q3: The details of MIL formulation and methodology has been provided in our supplementary materials. #To R2. Q1: It is actually different from the classic CNN, and the reasons are listed as follows. (1) For last feature maps, in classic CNN, the channel number is usually quite large, such as 512. However, in MIL, the instance representation must be converted from the last feature maps. Specifically, if there are N categories, the instance representation has only N channels, which is much smaller than classic CNN feature maps. (2)For the aggregation, in classic CNNs, the last feature map is fed into several fully connected layers and then generate the probability distribution. However, in MIL, the aggregation can directly produce the probability distribution. In this way, fully-connected layers in classic CNNs, which usually occupy a lot of parameters and are likely to be over-fitting, are removed. (3) For the granularity of feature representation, each instance corresponds to a N-dimension vector, and describes its response on each of the N scene categories. This is also different from existing CNNs. Q2: (1) The motivation and objective of our work is to recognize the retina diseases, not to grade them to different classes. Hence, it is more proper to formulate this task as a binary classification, rather than multi-class classification. The validation of our method on other DR multi-class tasks is our future work. (2) Compared with traditional CNNs, which preserves the global semantic information, our GPM assigns different weights to the instances and highlight the feature responses for key instances, while our LPPM highlights the responses in each local window. Hence, both our GPM and LPPM leads to a performance gain. On the other hand, as the combination of both GPM and LPPM highlights the feature responses of key instances from both the global and local perspective, the performance gain is more. We will provide this discussion in our camera-ready version. Q3: Indeed there are many other DR-related benchmarks, but they focus on the retinal disease grading task. However, as the objective of our work is to recognize the disease, rather than grade the disease into several different patterns, it may be not that proper to directly utilize such benchmarks. Adapting our MIL in such tasks and validating its effectiveness can be our future work. #To R3. Q1: To the best of our knowledge, this is the first work to investigate deep MIL for retinal recognition. We will cover more references on classic MIL and its application in retinal images. Q2:As the objective of our GPM is to acquire a spatial weight matrix for the importance of each instance, we solve this by using a convolution layer. It can be easy to use more complicated network structures for further performance gain, which is interesting for further investigation. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0805/12/31/Paper0778" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0805/12/31/Paper0778" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0805-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Local-global Dual Perception based Deep Multiple Instance Learning for Retinal Disease Classification" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0805/12/31/Paper0778"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0805/12/31/Paper0778","headline":"Local-global Dual Perception based Deep Multiple Instance Learning for Retinal Disease Classification","dateModified":"0806-01-05T00:00:00-05:17","datePublished":"0805-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Qi Bi, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng Abstract With the rapidly growing number of people affected by various retinal diseases, there is a strong clinical interest for fully automatic and accurate retinal disease recognition. The unique characteristics of how retinal diseases are manifested on the fundus images pose a major challenge for automatic recognition. In order to better tackle the challenges, we propose a local-global dual perception (LGDP) based deep multiple instance learning (MIL) module that integrates the instance contribution from both local scale and global scale. The proposed module consists of a local pyramid perception module (LPPM) that emphasizes the key instances from the local scale, and a global perception module (GPM) that provides a spatial weight distribution from a global scale. Extensive experiments on three major retinal disease benchmarks demonstrate that our framework outperforms many state-of-the-art deep MIL methods, especially for recognizing the pathological images. In addition, the proposed module is also validated on multiple backbones and achieves substantively superior performance, indicating the effectiveness and generalization capability. Last but not least, the proposed deep MIL module can be conveniently embedded into any convolutional backbones via a plug-and-play manner and effectively boost the performance. Link to paper https://doi.org/10.1007/978-3-030-87237-3_6 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper The paper suggests an approach for automatic retinal disease screening approaches based on deep learning techniques. It proposes a standardized deep MIL scheme for retinal disease recognition and claims to be adopted to any convolution neural networks (CNN). It suggests a local-global dual perception based machine instance learning (MIL) module. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1- The paper supposes a fully automatic retinal disease screening ap- proaches based on deep learning techniques which is a novel approach 2- The suggest approach can be conveniently adapted to any CNN backbones in a plug-and-play manner and substantively boost the performance by a large margin. 3- he proposed module could e ectively boost the recognition performance which may empower the diagnosing approaches for some retinal diseases Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1- The authorys should provide some details regarding why their approach outoerformes other benchmark approaches that are stated in the literature review. 2- The literature review needs some improvement to cover more state of the art current approaches in the field of retinal diseases diagnsing Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance some cutrrent paper do exist in the same area of research but unable to confirm reproducibility Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1- some statistical analysis regarding the accuracy and performance of the suggested ML based approach should be provided 2- The literature review need to be comperhensive to ensure the completenes and novelty of the research work introduced in the paper. 3- The MIL based approach should be detailed more for small researches to understand the criteria and fooundations hehind such research work Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper is somewhat well organized The paper technically sounds but with some simple comments the topic of research is of unmet needs for humanity What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper The authors propose a novel approach for an automatic retinal diseases screening from fundus images. The proposed framework is based on a local-global dual perception (LGDP) combined with multiple instance learning to integrate the instance from both local and global scales. The proposed framework was validated on two public datasets and one private dataset to evaluate its performance in the screening of Diabetic retinopathy, glaucoma and age-related macular degeneration from fundus images. Different metrics were computed to compare the performance of the proposed framework to state of the art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is clear, well structured and easy to follow. Results are clearly discussed, the approach is tested on multiples datasets and provides consistent performance improvement on each dataset. An ablation study is conducted to justify the introduction of the LPPM and the GPM branches. Table 3 indicates that the proposed framework can bee embedded in different CNN architectures, which is also an interesting contribution. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The MIL formulation might give a miss-leading sense of originality. In the paper, each pixel in the last feature maps is considered as an instance. Two types of aggregation are then done across instances (local-one with the LPPM followed by a weighted sum in the Local-global Perception Fusion). This is not different from any classical CNN-classification formulation. Moreover, here, instances are not permutation-invariant, which is usually assumed in the MIL approach. With this regard, the main contribution is the LPPM module and particularly the top-k max-pooling operator. However, table 1. indicates that GPM (which is just a 1x1 convolution) consistently (but marginally) outperform LPPM alone. It is therefore slightly unclear why the combination of both would provide such a boost in performance and further experiments should be conducted, in particular on multi-class problem (not just binary). It is unfortunate that the SOTA comparison is mostly limited to two public datasets. Diabetic Retinopathy has been widely researched and numerous recent papers have proposed methodologies tested on APTOS. In addition, there are many more DR-related dataset (FGADR, Messidor, EyePacs…) that could have been used to evaluate the proposed approach. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The private AMD dataset is not well described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The LPPM module and particularly the top-k max-pooling operator is an interesting contribution. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Extensive experiments were performed to compare the performance of the proposed framework to state of the art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper In this paper, the authors proposed a local-global dual perception deep MIL module for retinal disease recognition. Instance responses from both local and global scales are considered and integrated, so as to better tackle the challenge of how various pathologies are presented on the retinal image. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The challenges of fundus images diseases classification are well discussed and analyzed. Appling multiple instances learning (MIL) to fundus images diseases classification is reasonable. Based on MIL, the authors proposed a local-global dual perception. The proposed module can be adapted in a plug-and-play manner. Experiments are conducted on two publicly available datasets and one private dataset. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The related work about applying multiple instances learning to retinal fundus images is missing. The proposed GPM is a little simple. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance / Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html What dose the detailed implementation of SOTA deep MIL methods, including [25,16,21,22]? The proposed GPM is a little simple since the GPM only contains a Conv1 layer and a Relu layer. Also, the motivation of why design GPM in this manner is missing. The related work about applying multiple instances learning to retinal fundus images is missing. It would be better to introduce the related work to support the contributions as claimed. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The proposed method is well-motivated and the experimetns are sufficient. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes a retinal disease classification using multiple instance learning. The contribution resides in a global+local scale pyramidal module. One reviewer appreciates the possible versatility of the method in other CNN architecture, invites authors for more recent work on retinal diagnosis, but without suggesting refs. A second reviewer also appreciate the plug-n-play nature of the MIL contribution, but questions the originality of the MIL formulation. A third reviewers further notice the plug-n-play advantage, but also wants more refs on fundus segmentation. All reviewers agrees on a well-written, well-evaluated method, with a highlighted appreciation of the plug-n-play nature of the proposed global+local module. Two note a lack of related refs on retinal diagnosis. The complexity of the method is described as simple, which is an advantage in my opinion in this context, which merit to be emphasized in a different wording. For these reasons, this paper constitutes a notable contribution in the MIL literature, with an easy reusable local+global dual perception module that has been extensively evaluated. Recommendation is towards Early Acceptance. Oral: All three reviewers has recommended an oral podium as well as a young scientist award. I believe the potential impact of this dual module can contribute to the field by further popularizing MIL approaches. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We appreciate the meta-reviewer and reviewers’ effort in reviewing our submission, along with the positive comments. Still, it is important to clarify some issues raised by the reviewers. Please see below for details. #To meta-reviewer. Q1: We will cite more recent references on retinal diagnosis in our camera-ready manuscript. Q2: Although deep MIL relies on convolution operations, in terms of the problem formulation, granularity of feature representation, and generation of probability distribution, they are quite different. For details, please refer to our reply to the 1st comment of Reviewer2. Q3: We will cover references on fundus segmentation in our camera-ready manuscript. #To R1. Q1: We will provide more details on statistical analysis. However, we would like to stress that, all of our experiments on the MIL based approaches are conducted under the same parameter settings, and five-fold cross validation results are reported, which is fair enough to demonstrate their different performances. Q2: We will cover more references on retinal diagnosis and fundus image processing in our camera-ready version. Q3: The details of MIL formulation and methodology has been provided in our supplementary materials. #To R2. Q1: It is actually different from the classic CNN, and the reasons are listed as follows. (1) For last feature maps, in classic CNN, the channel number is usually quite large, such as 512. However, in MIL, the instance representation must be converted from the last feature maps. Specifically, if there are N categories, the instance representation has only N channels, which is much smaller than classic CNN feature maps. (2)For the aggregation, in classic CNNs, the last feature map is fed into several fully connected layers and then generate the probability distribution. However, in MIL, the aggregation can directly produce the probability distribution. In this way, fully-connected layers in classic CNNs, which usually occupy a lot of parameters and are likely to be over-fitting, are removed. (3) For the granularity of feature representation, each instance corresponds to a N-dimension vector, and describes its response on each of the N scene categories. This is also different from existing CNNs. Q2: (1) The motivation and objective of our work is to recognize the retina diseases, not to grade them to different classes. Hence, it is more proper to formulate this task as a binary classification, rather than multi-class classification. The validation of our method on other DR multi-class tasks is our future work. (2) Compared with traditional CNNs, which preserves the global semantic information, our GPM assigns different weights to the instances and highlight the feature responses for key instances, while our LPPM highlights the responses in each local window. Hence, both our GPM and LPPM leads to a performance gain. On the other hand, as the combination of both GPM and LPPM highlights the feature responses of key instances from both the global and local perspective, the performance gain is more. We will provide this discussion in our camera-ready version. Q3: Indeed there are many other DR-related benchmarks, but they focus on the retinal disease grading task. However, as the objective of our work is to recognize the disease, rather than grade the disease into several different patterns, it may be not that proper to directly utilize such benchmarks. Adapting our MIL in such tasks and validating its effectiveness can be our future work. #To R3. Q1: To the best of our knowledge, this is the first work to investigate deep MIL for retinal recognition. We will cover more references on classic MIL and its application in retinal images. Q2:As the objective of our GPM is to acquire a spatial weight matrix for the importance of each instance, we solve this by using a convolution layer. It can be easy to use more complicated network structures for further performance gain, which is interesting for further investigation. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Bi, Qi,Yu, Shuang,Ji, Wei,Bian, Cheng,Gong, Lijun,Liu, Hanruo,Ma, Kai,Zheng, Yefeng" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Local-global Dual Perception based Deep Multiple Instance Learning for Retinal Disease Classification</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Interpretability / Explainability"
        class="post-category">
        Machine Learning - Interpretability / Explainability
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Weakly supervised learning"
        class="post-category">
        Machine Learning - Weakly supervised learning
      </a>
      
      <a 
        href="kittywong/categories#Outcome/disease prediction"
        class="post-category">
        Outcome/disease prediction
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Bi, Qi"
        class="post-tags">
        Bi, Qi
      </a> |  
      
      <a href="kittywong/tags#Yu, Shuang"
        class="post-tags">
        Yu, Shuang
      </a> |  
      
      <a href="kittywong/tags#Ji, Wei"
        class="post-tags">
        Ji, Wei
      </a> |  
      
      <a href="kittywong/tags#Bian, Cheng"
        class="post-tags">
        Bian, Cheng
      </a> |  
      
      <a href="kittywong/tags#Gong, Lijun"
        class="post-tags">
        Gong, Lijun
      </a> |  
      
      <a href="kittywong/tags#Liu, Hanruo"
        class="post-tags">
        Liu, Hanruo
      </a> |  
      
      <a href="kittywong/tags#Ma, Kai"
        class="post-tags">
        Ma, Kai
      </a> |  
      
      <a href="kittywong/tags#Zheng, Yefeng"
        class="post-tags">
        Zheng, Yefeng
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Qi Bi, Shuang Yu, Wei Ji, Cheng Bian, Lijun Gong, Hanruo Liu, Kai Ma, Yefeng Zheng
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>With the rapidly growing number of people affected by various retinal diseases, there is a strong clinical interest for fully automatic and accurate retinal disease recognition. The unique characteristics of how retinal diseases are manifested on the fundus images pose a major challenge for automatic recognition. In order to better tackle the challenges, we propose a local-global dual perception (LGDP) based deep multiple instance learning (MIL) module that integrates the instance contribution from both local scale and global scale. The proposed module consists of a local pyramid perception module (LPPM) that emphasizes the key instances from the local scale, and a global perception module (GPM) that provides a spatial weight distribution from a global scale. Extensive experiments on three major retinal disease benchmarks demonstrate that our framework outperforms many state-of-the-art deep MIL methods, especially for recognizing the pathological images. In addition, the proposed module is also validated on multiple backbones and achieves substantively superior performance, indicating the effectiveness and generalization capability. Last but not least, the proposed deep MIL module can be conveniently embedded into any convolutional backbones via a plug-and-play manner and effectively boost the performance.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87237-3_6">https://doi.org/10.1007/978-3-030-87237-3_6</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper suggests an approach for automatic retinal disease screening approaches based on deep learning techniques. It proposes a standardized deep MIL scheme for retinal disease recognition and claims to be adopted to any convolution neural networks (CNN). It suggests a local-global dual perception based machine instance learning (MIL) module.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>1- The paper supposes a fully automatic retinal disease screening ap-
proaches based on deep learning techniques which is a novel approach
2-  The suggest approach can be conveniently adapted to any CNN backbones in a plug-and-play manner and substantively boost the performance by a large margin.
3- he proposed module could eectively boost the recognition performance which may empower the diagnosing approaches for some retinal diseases</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>1- The authorys should provide some details regarding why their approach outoerformes other benchmark approaches that are stated in the literature review.
2- The literature review needs some improvement to cover more state of the art current approaches in the field of retinal diseases diagnsing</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>some cutrrent paper do exist in the same area of research but unable to confirm reproducibility</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>1- some statistical analysis regarding the accuracy and performance of the suggested ML based approach should be provided
2- The literature review need to be comperhensive to ensure the completenes and novelty of the research work introduced in the paper.
3- The MIL based approach should be detailed more for small researches to understand the criteria and fooundations hehind such research work</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The paper is somewhat well organized
The paper technically sounds but with some simple comments
the topic of research is of unmet needs for humanity</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Somewhat confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors propose a novel approach for an automatic retinal diseases screening from fundus images. The proposed framework is based on a local-global dual perception (LGDP) combined with multiple instance learning to integrate the instance from both local and global scales. The proposed framework was validated on two public datasets and one private dataset to evaluate its performance in the screening of Diabetic retinopathy, glaucoma and age-related macular degeneration from fundus images. Different metrics were computed to compare the performance of the proposed framework to state of the art methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Overall, the paper is clear, well structured and easy to follow.</p>

      <p>Results are clearly discussed, the approach is tested on multiples datasets and provides consistent performance improvement on each dataset. An ablation study is conducted to justify the introduction of the LPPM and the GPM branches. 
Table 3 indicates that the proposed framework can bee embedded in different CNN architectures, which is also an interesting contribution.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The MIL formulation might give a miss-leading sense of  originality. In the paper, each pixel in the last feature maps is  considered as an instance. Two types of aggregation are then done across instances (local-one with the LPPM followed by a weighted sum in the Local-global Perception Fusion). This is not different from any classical CNN-classification formulation. Moreover, here, instances are not permutation-invariant, which is usually assumed in the MIL approach.</p>

      <p>With this regard, the main contribution is the LPPM module and  particularly the top-k max-pooling operator. However, table 1.  indicates that GPM (which is just a 1x1 convolution) consistently (but marginally) outperform LPPM alone. It is therefore slightly unclear why the combination of both would provide such a boost in performance and further experiments should be conducted, in particular on multi-class problem (not just binary).</p>

      <ul>
        <li>It is unfortunate that the SOTA comparison is mostly limited to two public datasets. Diabetic Retinopathy has been widely researched and numerous recent papers have proposed methodologies tested on APTOS. In addition, there are many more DR-related dataset (FGADR, Messidor, EyePacs…) that could have been used to evaluate the proposed approach.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The private AMD dataset is not well described.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The LPPM module and  particularly the top-k max-pooling operator is an interesting contribution.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Extensive experiments were performed to compare the performance of the proposed framework to state of the art methods.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>In this paper, the authors proposed a local-global dual perception deep MIL module for retinal disease recognition. Instance responses from both local and global scales are considered and integrated, so as to better tackle the challenge of how various pathologies are presented on the retinal image.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The challenges of fundus images diseases classification are well discussed and analyzed.</li>
        <li>Appling multiple instances learning (MIL) to fundus images diseases classification is reasonable.</li>
        <li>Based on MIL, the authors proposed a local-global dual perception. The proposed module can be adapted in a plug-and-play manner.</li>
        <li>Experiments are conducted on two publicly available datasets and one private dataset.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The related work about applying multiple instances learning to retinal fundus images is missing.</li>
        <li>The proposed GPM is a little simple.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>/</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>What dose the detailed implementation of SOTA deep MIL methods, including [25,16,21,22]?</li>
        <li>The proposed GPM is a little simple since the GPM only contains a Conv1 layer and a Relu layer. Also, the motivation of why design GPM in this manner is missing.</li>
        <li>The related work about applying multiple instances learning to retinal fundus images is missing. It would be better to introduce the related work to support the contributions as claimed.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The proposed method is well-motivated and the experimetns are sufficient.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper proposes a retinal disease classification using multiple instance learning. The contribution resides in a global+local scale pyramidal module.</p>

      <p>One reviewer appreciates the possible versatility of the method in other CNN architecture, invites authors for more recent work on retinal diagnosis, but without suggesting refs.</p>

      <p>A second reviewer also appreciate the plug-n-play nature of the MIL contribution, but questions the originality of the MIL formulation.</p>

      <p>A third reviewers further notice the plug-n-play advantage, but also wants more refs on fundus segmentation.</p>

      <p>All reviewers agrees on a well-written, well-evaluated method, with a highlighted appreciation of the plug-n-play nature of the proposed global+local module. Two note a lack of related refs on retinal diagnosis. The complexity of the method is described as simple, which is an advantage in my opinion in this context, which merit to be emphasized in a different wording.</p>

      <p>For these reasons, this paper constitutes a notable contribution in the MIL literature, with an easy reusable local+global dual perception module that has been extensively evaluated. Recommendation is towards Early Acceptance.</p>

      <p>Oral: All three reviewers has recommended an oral podium as well as a young scientist award. I believe the potential impact of this dual module can contribute to the field by further popularizing MIL approaches.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We appreciate the meta-reviewer and reviewers’ effort in reviewing our submission, along with the positive comments. Still, it is important to clarify some issues raised by the reviewers. Please see below for details.
#To meta-reviewer. Q1: We will cite more recent references on retinal diagnosis in our camera-ready manuscript.  Q2: Although deep MIL relies on convolution operations, in terms of the problem formulation, granularity of feature representation, and generation of probability distribution, they are quite different. For details, please refer to our reply to the 1st comment of Reviewer2. Q3: We will cover references on fundus segmentation in our camera-ready manuscript. 
#To R1. Q1: We will provide more details on statistical analysis. However, we would like to stress that, all of our experiments on the MIL based approaches are conducted under the same parameter settings, and five-fold cross validation results are reported, which is fair enough to demonstrate their different performances. Q2: We will cover more references on retinal diagnosis and fundus image processing in our camera-ready version.  Q3: The details of MIL formulation and methodology has been provided in our supplementary materials. 
#To R2. Q1: It is actually different from the classic CNN, and the reasons are listed as follows. (1) For last feature maps, in classic CNN, the channel number is usually quite large, such as 512. However, in MIL, the instance representation must be converted from the last feature maps. Specifically, if there are N categories, the instance representation has only N channels, which is much smaller than classic CNN feature maps. (2)For the aggregation, in classic CNNs, the last feature map is fed into several fully connected layers and then generate the probability distribution. However, in MIL, the aggregation can directly produce the probability distribution. In this way, fully-connected layers in classic CNNs, which usually occupy a lot of parameters and are likely to be over-fitting, are removed. (3) For the granularity of feature representation, each instance corresponds to a N-dimension vector, and describes its response on each of the N scene categories. This is also different from existing CNNs.
Q2: (1) The motivation and objective of our work is to recognize the retina diseases, not to grade them to different classes. Hence, it is more proper to formulate this task as a binary classification, rather than multi-class classification. The validation of our method on other DR multi-class tasks is our future work. (2) Compared with traditional CNNs, which preserves the global semantic information, our GPM assigns different weights to the instances and highlight the feature responses for key instances, while our LPPM highlights the responses in each local window. Hence, both our GPM and LPPM leads to a performance gain. On the other hand, as the combination of both GPM and LPPM highlights the feature responses of key instances from both the global and local perspective, the performance gain is more. We will provide this discussion in our camera-ready version. Q3: Indeed there are many other DR-related benchmarks, but they focus on the retinal disease grading task. However, as the objective of our work is to recognize the disease, rather than grade the disease into several different patterns, it may be not that proper to directly utilize such benchmarks. Adapting our MIL in such tasks and validating its effectiveness can be our future work.
#To R3. Q1: To the best of our knowledge, this is the first work to investigate deep MIL for retinal recognition. We will cover more references on classic MIL and its application in retinal images. Q2:As the objective of our GPM is to acquire a spatial weight matrix for the importance of each instance, we solve this by using a convolution layer. It can be easy to use more complicated network structures for further performance gain, which is interesting for further investigation.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0805-12-31
      -->
      <!--
      
        ,
        updated at 
        0806-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Interpretability / Explainability"
        class="post-category">
        Machine Learning - Interpretability / Explainability
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Weakly supervised learning"
        class="post-category">
        Machine Learning - Weakly supervised learning
      </a> |
      
      <a 
        href="kittywong/categories#Outcome/disease prediction"
        class="post-category">
        Outcome/disease prediction
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Bi, Qi"
        class="post-category">
        Bi, Qi
      </a> |  
      
      <a href="kittywong/tags#Yu, Shuang"
        class="post-category">
        Yu, Shuang
      </a> |  
      
      <a href="kittywong/tags#Ji, Wei"
        class="post-category">
        Ji, Wei
      </a> |  
      
      <a href="kittywong/tags#Bian, Cheng"
        class="post-category">
        Bian, Cheng
      </a> |  
      
      <a href="kittywong/tags#Gong, Lijun"
        class="post-category">
        Gong, Lijun
      </a> |  
      
      <a href="kittywong/tags#Liu, Hanruo"
        class="post-category">
        Liu, Hanruo
      </a> |  
      
      <a href="kittywong/tags#Ma, Kai"
        class="post-category">
        Ma, Kai
      </a> |  
      
      <a href="kittywong/tags#Zheng, Yefeng"
        class="post-category">
        Zheng, Yefeng
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0806/12/31/Paper0895">
          BSDA-Net: A Boundary Shape and Distance Aware Joint Learning Framework for Segmenting and Classifying OCTA Images
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0804/12/31/Paper0776">
          MIL-VT: Multiple Instance Learning Enhanced Vision Transformer for Fundus Image Classification
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
