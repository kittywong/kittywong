<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach, Isabel Kaltenborn, Anirban Mukhopadhyay Abstract Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly. Link to paper https://doi.org/10.1007/978-3-030-87234-2_29 Link to the code repository https://github.com/MECLabTUDA/Lifelong-nnUNet Link to the dataset(s) https://covid-segmentation.grand-challenge.org/; https://zenodo.org/record/3757476; https://mosmed.ai/datasets/covid19_1110/ Reviews Review #1 Please describe the contribution of the paper This paper presents a new approach for detection of neural network failures. Specifically, it focuses on COVID pneumonia classification, using the Mahalanobis distance between compressed representations of the data to detect OOB instances. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Deep neural network failure detection is very important for increased clinical translation and has received a lot of attention recently. Most work has focused on looking at the variance or entropy associated with ensembled predictions, but this paper takes a completely different approach and looks at downsampled latent space distances. The authors show that their approach does a great job of avoiding false negative predictions while also minimizing false positives. Importantly, there is a comparison with prior methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main weakness is the figures. There should have been a figure showing the uncertainty image and how that is converted to an uncertainty score. Fig. 1 seems totally wrong. z1 is further from z2 in a Euclidean sense? Maybe that is true in the high dimensional space, but it clearly ins’t true in the 2D space of the figure. What are the axes of that figure? I also would have liked to see a comparison with other distances such as Euclidean, which would have proven one of the hypotheses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The method seems simple enough, and they claim that they will release the nnUnet code on acceptance. However, it is unclear if the sklearn code will also be released. Open source datasets are used, but release of the annotations is not mentioned, so it will not be clear if those will be available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html -Figure 2 is not very compelling or easy to understand. It seems like this paper applies performs voxel-wise classification by using a encoder+linear layer in sliding window approach, which is not how a fully-convolutional network such as a U-Net typically works. Why is it called nnUNet if it isn’t fully-convolutional? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A new and simple method for failure detection will be a welcome addition to the current literature. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors present a method that detects out-of-distribution (OOD) data for a trained nnU-Net to avoid failing silently. The nnU-Net training does not have to be adapted thus the approach can be integrated seamlessly. They evaluate the method on publically available data and compare it to other state-of-the-art techniques. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. evaluation of publically available data comparison to state-of-the-art methods the authors plan to make the code publically available highly relevant topic: Trained models can fail on OOD data, that is not a big deal if the model also presents the uncertainty, but it is dangerous in the clinical practice if the method fails silently very good structure of the paper -nnU-Net is a very good approach itself. Extensions make the system even better Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I do not see a major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance nnU-net code is open source and the authors plan to make the proposed method of the paper available after acceptence they use mainly publicly available data in this paper Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors write “… we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”. I wonder if the subsets were randomly selected. Since there a only 4 validation data sets out of a heterogeneous data set the selection of the 4 validation data sets might have a strong influence. it would be nice to learn something about the experience of the authors in this matter. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Failing silently is a major issue that have to be adressed. There are several approaches in literature, but this one seems to be very promissing. It is integrated in a state-of-the art deep learning architecture. The paper has a great structure and is very well written. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper describes a method to detect out-of-distribution (OOD) data to understand and enhance the generalizability of segmentation methods when using data from different sites. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is very well written, the method is very relevant and general. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The generalizability could be better demonstrated by combining the proposed method with further methods than nnU-Net. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The model, datasets, and evaluation methods are clearly described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Table 1 summarizes results on the “ID validation data”, but according to Sec. 3, there are just 4 images in this set (“we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”). Is it a typo? It would make more sense if the data for Table 1 contains images from the other three datasets (Mosmed, Radiopedia, and in-house dataset). Fig. 1(b) demonstrates that using Euclidean distance, D(z_1)&gt;D(z_2), while using Mahalanobis distance, Dm(z_1)&lt;Dm(z_2). The case of Mahalanobis distance is only displayed inside the image, there is no description in either the figure caption or in the text. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Dealing with datasets from different sites is becoming more and more necessary, and it is essential to understand the relationships between the different data distributions. The proposed method is a very relevant contribution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper covers a very important topic to the community. All reviewers highlight the clarity and solidity of the work. Comments made by reviewers regarding figures and explanation details should be taken into account What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers and area chair for their thoughtful comments and for appreciating how our flexible approach for out-of-distribution detection can increase the usability of segmentation models in multiple sites. As several reviewers have highlighted, this is a timely topic for our community. We hope that our contribution to the popular nnU-Net framework results in both researchers and clinicians using our method. We will incorporate your valuable feedback when preparing the camera-ready version of the manuscript by improving the figures and captions and clarifying ambiguous statements. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach, Isabel Kaltenborn, Anirban Mukhopadhyay Abstract Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly. Link to paper https://doi.org/10.1007/978-3-030-87234-2_29 Link to the code repository https://github.com/MECLabTUDA/Lifelong-nnUNet Link to the dataset(s) https://covid-segmentation.grand-challenge.org/; https://zenodo.org/record/3757476; https://mosmed.ai/datasets/covid19_1110/ Reviews Review #1 Please describe the contribution of the paper This paper presents a new approach for detection of neural network failures. Specifically, it focuses on COVID pneumonia classification, using the Mahalanobis distance between compressed representations of the data to detect OOB instances. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Deep neural network failure detection is very important for increased clinical translation and has received a lot of attention recently. Most work has focused on looking at the variance or entropy associated with ensembled predictions, but this paper takes a completely different approach and looks at downsampled latent space distances. The authors show that their approach does a great job of avoiding false negative predictions while also minimizing false positives. Importantly, there is a comparison with prior methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main weakness is the figures. There should have been a figure showing the uncertainty image and how that is converted to an uncertainty score. Fig. 1 seems totally wrong. z1 is further from z2 in a Euclidean sense? Maybe that is true in the high dimensional space, but it clearly ins’t true in the 2D space of the figure. What are the axes of that figure? I also would have liked to see a comparison with other distances such as Euclidean, which would have proven one of the hypotheses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The method seems simple enough, and they claim that they will release the nnUnet code on acceptance. However, it is unclear if the sklearn code will also be released. Open source datasets are used, but release of the annotations is not mentioned, so it will not be clear if those will be available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html -Figure 2 is not very compelling or easy to understand. It seems like this paper applies performs voxel-wise classification by using a encoder+linear layer in sliding window approach, which is not how a fully-convolutional network such as a U-Net typically works. Why is it called nnUNet if it isn’t fully-convolutional? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A new and simple method for failure detection will be a welcome addition to the current literature. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors present a method that detects out-of-distribution (OOD) data for a trained nnU-Net to avoid failing silently. The nnU-Net training does not have to be adapted thus the approach can be integrated seamlessly. They evaluate the method on publically available data and compare it to other state-of-the-art techniques. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. evaluation of publically available data comparison to state-of-the-art methods the authors plan to make the code publically available highly relevant topic: Trained models can fail on OOD data, that is not a big deal if the model also presents the uncertainty, but it is dangerous in the clinical practice if the method fails silently very good structure of the paper -nnU-Net is a very good approach itself. Extensions make the system even better Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I do not see a major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance nnU-net code is open source and the authors plan to make the proposed method of the paper available after acceptence they use mainly publicly available data in this paper Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors write “… we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”. I wonder if the subsets were randomly selected. Since there a only 4 validation data sets out of a heterogeneous data set the selection of the 4 validation data sets might have a strong influence. it would be nice to learn something about the experience of the authors in this matter. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Failing silently is a major issue that have to be adressed. There are several approaches in literature, but this one seems to be very promissing. It is integrated in a state-of-the art deep learning architecture. The paper has a great structure and is very well written. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper describes a method to detect out-of-distribution (OOD) data to understand and enhance the generalizability of segmentation methods when using data from different sites. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is very well written, the method is very relevant and general. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The generalizability could be better demonstrated by combining the proposed method with further methods than nnU-Net. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The model, datasets, and evaluation methods are clearly described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Table 1 summarizes results on the “ID validation data”, but according to Sec. 3, there are just 4 images in this set (“we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”). Is it a typo? It would make more sense if the data for Table 1 contains images from the other three datasets (Mosmed, Radiopedia, and in-house dataset). Fig. 1(b) demonstrates that using Euclidean distance, D(z_1)&gt;D(z_2), while using Mahalanobis distance, Dm(z_1)&lt;Dm(z_2). The case of Mahalanobis distance is only displayed inside the image, there is no description in either the figure caption or in the text. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Dealing with datasets from different sites is becoming more and more necessary, and it is essential to understand the relationships between the different data distributions. The proposed method is a very relevant contribution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper covers a very important topic to the community. All reviewers highlight the clarity and solidity of the work. Comments made by reviewers regarding figures and explanation details should be taken into account What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers and area chair for their thoughtful comments and for appreciating how our flexible approach for out-of-distribution detection can increase the usability of segmentation models in multiple sites. As several reviewers have highlighted, this is a timely topic for our community. We hope that our contribution to the popular nnU-Net framework results in both researchers and clinicians using our method. We will incorporate your valuable feedback when preparing the camera-ready version of the manuscript by improving the figures and captions and clarifying ambiguous statements. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0728/12/31/Paper1378" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0728/12/31/Paper1378" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0728-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0728/12/31/Paper1378"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0728/12/31/Paper1378","headline":"Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation","dateModified":"0729-01-05T00:00:00-05:17","datePublished":"0728-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach, Isabel Kaltenborn, Anirban Mukhopadhyay Abstract Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly. Link to paper https://doi.org/10.1007/978-3-030-87234-2_29 Link to the code repository https://github.com/MECLabTUDA/Lifelong-nnUNet Link to the dataset(s) https://covid-segmentation.grand-challenge.org/; https://zenodo.org/record/3757476; https://mosmed.ai/datasets/covid19_1110/ Reviews Review #1 Please describe the contribution of the paper This paper presents a new approach for detection of neural network failures. Specifically, it focuses on COVID pneumonia classification, using the Mahalanobis distance between compressed representations of the data to detect OOB instances. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Deep neural network failure detection is very important for increased clinical translation and has received a lot of attention recently. Most work has focused on looking at the variance or entropy associated with ensembled predictions, but this paper takes a completely different approach and looks at downsampled latent space distances. The authors show that their approach does a great job of avoiding false negative predictions while also minimizing false positives. Importantly, there is a comparison with prior methods. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main weakness is the figures. There should have been a figure showing the uncertainty image and how that is converted to an uncertainty score. Fig. 1 seems totally wrong. z1 is further from z2 in a Euclidean sense? Maybe that is true in the high dimensional space, but it clearly ins’t true in the 2D space of the figure. What are the axes of that figure? I also would have liked to see a comparison with other distances such as Euclidean, which would have proven one of the hypotheses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The method seems simple enough, and they claim that they will release the nnUnet code on acceptance. However, it is unclear if the sklearn code will also be released. Open source datasets are used, but release of the annotations is not mentioned, so it will not be clear if those will be available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html -Figure 2 is not very compelling or easy to understand. It seems like this paper applies performs voxel-wise classification by using a encoder+linear layer in sliding window approach, which is not how a fully-convolutional network such as a U-Net typically works. Why is it called nnUNet if it isn’t fully-convolutional? Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? A new and simple method for failure detection will be a welcome addition to the current literature. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors present a method that detects out-of-distribution (OOD) data for a trained nnU-Net to avoid failing silently. The nnU-Net training does not have to be adapted thus the approach can be integrated seamlessly. They evaluate the method on publically available data and compare it to other state-of-the-art techniques. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. evaluation of publically available data comparison to state-of-the-art methods the authors plan to make the code publically available highly relevant topic: Trained models can fail on OOD data, that is not a big deal if the model also presents the uncertainty, but it is dangerous in the clinical practice if the method fails silently very good structure of the paper -nnU-Net is a very good approach itself. Extensions make the system even better Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I do not see a major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance nnU-net code is open source and the authors plan to make the proposed method of the paper available after acceptence they use mainly publicly available data in this paper Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The authors write “… we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”. I wonder if the subsets were randomly selected. Since there a only 4 validation data sets out of a heterogeneous data set the selection of the 4 validation data sets might have a strong influence. it would be nice to learn something about the experience of the authors in this matter. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Failing silently is a major issue that have to be adressed. There are several approaches in literature, but this one seems to be very promissing. It is integrated in a state-of-the art deep learning architecture. The paper has a great structure and is very well written. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper describes a method to detect out-of-distribution (OOD) data to understand and enhance the generalizability of segmentation methods when using data from different sites. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper is very well written, the method is very relevant and general. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The generalizability could be better demonstrated by combining the proposed method with further methods than nnU-Net. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The model, datasets, and evaluation methods are clearly described. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Table 1 summarizes results on the “ID validation data”, but according to Sec. 3, there are just 4 images in this set (“we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”). Is it a typo? It would make more sense if the data for Table 1 contains images from the other three datasets (Mosmed, Radiopedia, and in-house dataset). Fig. 1(b) demonstrates that using Euclidean distance, D(z_1)&gt;D(z_2), while using Mahalanobis distance, Dm(z_1)&lt;Dm(z_2). The case of Mahalanobis distance is only displayed inside the image, there is no description in either the figure caption or in the text. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Dealing with datasets from different sites is becoming more and more necessary, and it is essential to understand the relationships between the different data distributions. The proposed method is a very relevant contribution. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Very confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper covers a very important topic to the community. All reviewers highlight the clarity and solidity of the work. Comments made by reviewers regarding figures and explanation details should be taken into account What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback We thank the reviewers and area chair for their thoughtful comments and for appreciating how our flexible approach for out-of-distribution detection can increase the usability of segmentation models in multiple sites. As several reviewers have highlighted, this is a timely topic for our community. We hope that our contribution to the popular nnU-Net framework results in both researchers and clinicians using our method. We will incorporate your valuable feedback when preparing the camera-ready version of the manuscript by improving the figures and captions and clarifying ambiguous statements. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Gonzalez, Camila,Gotkowski, Karol,Bucher, Andreas,Fischbach, Ricarda,Kaltenborn, Isabel,Mukhopadhyay, Anirban" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Uncertainty"
        class="post-category">
        Machine Learning - Uncertainty
      </a>
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Gonzalez, Camila"
        class="post-tags">
        Gonzalez, Camila
      </a> |  
      
      <a href="kittywong/tags#Gotkowski, Karol"
        class="post-tags">
        Gotkowski, Karol
      </a> |  
      
      <a href="kittywong/tags#Bucher, Andreas"
        class="post-tags">
        Bucher, Andreas
      </a> |  
      
      <a href="kittywong/tags#Fischbach, Ricarda"
        class="post-tags">
        Fischbach, Ricarda
      </a> |  
      
      <a href="kittywong/tags#Kaltenborn, Isabel"
        class="post-tags">
        Kaltenborn, Isabel
      </a> |  
      
      <a href="kittywong/tags#Mukhopadhyay, Anirban"
        class="post-tags">
        Mukhopadhyay, Anirban
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach, Isabel Kaltenborn, Anirban Mukhopadhyay
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87234-2_29">https://doi.org/10.1007/978-3-030-87234-2_29</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/MECLabTUDA/Lifelong-nnUNet
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://covid-segmentation.grand-challenge.org/; https://zenodo.org/record/3757476; https://mosmed.ai/datasets/covid19_1110/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper presents a new approach for detection of neural network failures. Specifically, it focuses on COVID pneumonia classification, using the Mahalanobis distance between compressed representations of the data to detect OOB instances.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Deep neural network failure detection is very important for increased clinical translation and has received a lot of attention recently. Most work has focused on looking at the variance or entropy associated with ensembled predictions, but this paper takes a completely different approach and looks at downsampled latent space distances. The authors show that their approach does a great job of avoiding false negative predictions while also minimizing false positives. Importantly, there is a comparison with prior methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The main weakness is the figures. There should have been a figure showing the uncertainty image and how that is converted to an uncertainty score. Fig. 1 seems totally wrong. z1 is further from z2 in a Euclidean sense? Maybe that is true in the high dimensional space, but it clearly ins’t true in the 2D space of the figure. What are the axes of that figure?</p>

      <p>I also would have liked to see a comparison with other distances such as Euclidean, which would have proven one of the hypotheses.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The method seems simple enough, and they claim that they will release the nnUnet code on acceptance. However, it is unclear if the sklearn code will also be released. Open source datasets are used, but release of the annotations is not mentioned, so it will not be clear if those will be available.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>-Figure 2 is not very compelling or easy to understand.</p>

      <p>It seems like this paper applies performs voxel-wise classification by using a encoder+linear layer in sliding window approach, which is not how a fully-convolutional network such as a U-Net typically works. Why is it called nnUNet if it isn’t fully-convolutional?</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>A new and simple method for failure detection will be a welcome addition to the current literature.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors present a method that detects out-of-distribution (OOD) data for a trained nnU-Net to avoid failing silently. The nnU-Net training does not have to be adapted thus the approach can be integrated seamlessly. They evaluate the method on publically available data and compare it to other state-of-the-art techniques.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>evaluation of publically available data</li>
        <li>comparison to state-of-the-art methods</li>
        <li>the authors plan to make the code publically available</li>
        <li>highly relevant topic: Trained models can fail on OOD data, that is not a big deal if the model also presents the uncertainty, but it is dangerous in the clinical practice if the method fails silently</li>
        <li>very good structure of the paper
-nnU-Net is a very good approach itself. Extensions make the system even better</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>I do not see a major weakness.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <ul>
        <li>nnU-net code is open source and the authors plan to make the proposed method of the paper available after acceptence</li>
        <li>they use mainly publicly available data in this paper</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The authors write “… we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”. I wonder if the subsets were randomly selected. Since there a only 4 validation data sets out of a heterogeneous data set the selection of the 4 validation data sets might have a strong influence. it would be nice to learn something about the experience of the authors in this matter.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Failing silently is a major issue that have to be adressed. There are several approaches in literature, but this one seems to be very promissing. It is integrated in a state-of-the art deep learning architecture. 
The paper has a great structure and is very well written.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper describes a method to detect out-of-distribution (OOD) data to understand and enhance the generalizability of segmentation methods when using data from different sites.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The paper is very well written, the method is very relevant and general.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The generalizability could be better demonstrated by combining the proposed method with further methods than nnU-Net.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The model, datasets, and evaluation methods are clearly described.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>
          <p>Table 1 summarizes results on the “ID validation data”, but according to Sec. 3, there are just 4 images in this set (“we divide into 160 training cases to train the nnU-Net architecture, 4 validation cases and 35 cases for testing”). Is it a typo? It would make more sense if the data for Table 1 contains images from the other three datasets (Mosmed, Radiopedia, and in-house dataset).</p>
        </li>
        <li>
          <p>Fig. 1(b) demonstrates that using Euclidean distance, D(z_1)&gt;D(z_2), while using Mahalanobis distance, Dm(z_1)&lt;Dm(z_2). The case of Mahalanobis distance is only displayed inside the image, there is no description in either the figure caption or in the text.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Dealing with datasets from different sites is becoming more and more necessary, and it is essential to understand the relationships between the different data distributions. The proposed method is a very relevant contribution.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper covers a very important topic to the community. All reviewers highlight the clarity and solidity of the work. Comments made by reviewers regarding figures and explanation details should be taken into account</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the reviewers and area chair for their thoughtful comments and for appreciating how our flexible approach for out-of-distribution detection can increase the usability of segmentation models in multiple sites. As several reviewers have highlighted, this is a timely topic for our community. We hope that our contribution to the popular nnU-Net framework results in both researchers and clinicians using our method. We will incorporate your valuable feedback when preparing the camera-ready version of the manuscript by improving the figures and captions and clarifying ambiguous statements.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0728-12-31
      -->
      <!--
      
        ,
        updated at 
        0729-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a> |
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Uncertainty"
        class="post-category">
        Machine Learning - Uncertainty
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Gonzalez, Camila"
        class="post-category">
        Gonzalez, Camila
      </a> |  
      
      <a href="kittywong/tags#Gotkowski, Karol"
        class="post-category">
        Gotkowski, Karol
      </a> |  
      
      <a href="kittywong/tags#Bucher, Andreas"
        class="post-category">
        Bucher, Andreas
      </a> |  
      
      <a href="kittywong/tags#Fischbach, Ricarda"
        class="post-category">
        Fischbach, Ricarda
      </a> |  
      
      <a href="kittywong/tags#Kaltenborn, Isabel"
        class="post-category">
        Kaltenborn, Isabel
      </a> |  
      
      <a href="kittywong/tags#Mukhopadhyay, Anirban"
        class="post-category">
        Mukhopadhyay, Anirban
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0729/12/31/Paper1644">
          Perceptual Quality Assessment of Chest Radiograph
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0727/12/31/Paper1026">
          RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
