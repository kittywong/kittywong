<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>High-Resolution Hierarchical Adversarial Learning for OCT Speckle Noise Reduction | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="High-Resolution Hierarchical Adversarial Learning for OCT Speckle Noise Reduction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yi Zhou, Jiang Li, Meng Wang, Weifang Zhu, Yuanyuan Peng, Zhongyue Chen, Lianyu Wang, Tingting Wang, Chenpu Yao, Ting Wang, Xinjian Chen Abstract Raw optical coherence tomography (OCT) images typically are of low quality because speckle noise blurs retinal structures, severely compromising visual quality and degrading performances of subsequent image analysis tasks. In this paper, we propose a novel end-to-end cross-domain denoising framework for speckle noise suppression. We utilize high quality ground truth datasets produced by several commercial OCT scanners for training, and apply the trained model to datasets collected by our in-house OCT scanner for denoising. Our model uses the high-resolution network (HRNet) as backbone, which maintains high-resolution representations during the entire learning process to restore high fidelity images. In addition, we develop a hierarchical adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Experimental results show that the proposed model outperformed all the competing state-of-the-art methods. As compared to the best of our previous method, the proposed model improved the signal to noise ratio (SNR) metric by a huge margin of 18.13dB and only required 25ms for denoising one image in testing phase, achieving the real-time processing capability for the in-house OCT scanner. Link to paper https://doi.org/10.1007/978-3-030-87231-1_36 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper A novel end-to-end learning framework for optical coherence tomography (OCT) images speckle noise reduction has been proposed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed framework got significantly better results than state of the art OCT images speckle noise suppression methods and offer real-time processing capabilities. The proposed model can be trained and tested with OCT images collected by different scanners. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I don’t see any weaknesses of this paper. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I think that reproducibility checklist for this paper has been properly fulfilled. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This is a well written paper. The proposed hierarchical adversarial learning strategy for domain adaption is very interesting. A good ablation study has been performed. The shown qualitative and quantitative results obtained using the proposed method outperform state of the art requiring very short processing time. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Major factors that led me to propose this paper to be accepted has been its novelty and its good experimental section. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors propose a novel end-to-end cross domain denoising framework for speckle noise suppression in OCT images. The backbone architecture is HRNet that preserves high resolution information across different layers to preserve information. They also add adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A very well written paper with adequate literature review, standard evaluation metrics and enough experimentation to validate the model. My only concern is the dataset used which isn’t publicly available and therefore not reproducible. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Dataset does not seem to available to public for reproduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Might be difficult due to unavailability of dataset. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see weakness and strength. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I think the architecture is quite novel. My only concern is dataset availability for reproducing the result. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an end-to-end deep domain adaptation framework for speckle noise reduction from OCT images. The proposed method used “high- resolution network (HRNet)” during the denoising process and it also used a hierarchical adversarial learning to tackle the domain shift issue of data taken from different scanner. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper addresses a very clinically relevant problem which is domain shift. Often end-to-end models tend to be brittle. They fail to perform good enough with data taken from different camera or scanner settings. The paper is clearly written The paper clearly mentions several proposed novelties. The result section shows excellent improvement in performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors do not mention why they used a particular method (citation 16 in the paper), can you please mention why this particular method you found can perform well? Have you tried any other method? Regarding the dataset section, the paper does not mention the original dimension of the images. The images from 4 scanner- are they similar in dimension ? How many images from each scanner you used? In the ablation study section the table caption mentions : “on a disease OCT image”. Does that mean the result of the table is from only one image? If so, where do the mean and SD come from? Would you please elaborate? For the result section, are these the result only from the in house scanner? Would you please mention that in the table caption to help the reader’s to understand. Also “We also set aside three disease raw images and six normal raw images from the in-house scanner for testing.” , isn’t (3+6) = 9 is a very small number to conclude something? Is there any reason you did not consider to have more images? Was there any specific reason why disease images were introduced? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Upon release of the code, the reproducibility can be verified Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The reviewer believes that the problem addressed by the paper is scientifically very relevant. Domain shift is a common problem which hinders the clinical practice of many AI based algorithms and the papers aims to address that problem. Are the authors considering making both the datasets public? It would be a very good resource for the research community as currently we do not have many publicly available noisy-denoisy paired OCT images. As the authors claim to use clinically generated datasets, it will be a great resource for wider research community. Please note that this does not have any impact in the review decision. Other comments mentioned clearly in the strength and the weakness section of the papers. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The relevant weakness and comments are mentioned before but those are mostly minor and can be addressed quickly. The reviewer believes that the problems addressed in the paper is very clinically relevant and important. The paper can be accepted borderline given that the comments given in the weakness are addressed properly. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This is a strong paper that proposes a novel solution for OCT denoising and achieved superior performance. There is only minor concern about whether the dataset will be publicly shared. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback Meta-Reviews: Response: Thank you for the encouraging comments. We will revise the manuscript accordingly. Reviewer #1 Response: Thank you for the comments. Reviewer #2 Response: Thanks for your review. For your concern regarding the publicity of our datasets, unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. Reviewer #3 Response: Thank you for the constructive suggestions. Q1: The authors do not mention why they used a particular method (citation 16 in the paper), … Have you tried any other method? A1: This is a very good comment. The overall objective of our work is to leverage existing datasets with ground truth for OCT speckle noise reduction in datasets where ground truth data are difficult or expensive to collect. Different datasets were collected by different OCT scanners where data distribution shifts are very common, and a domain adaptation process is needed. In our previous work (Alg2, accepted for publication), we utilized the CycleGAN model to perform domain adaptation at image level and achieved satisfactory results. Method in [16] is a very good domain adaptation algorithm for image segmentation built upon the U-net model, where each layer was treated differently because different layers have different resolutions, thus the algorithm was named “Hierarchical”. Inspired by the method in [16], we redesigned the algorithm to fit to the high-resolution net (HRNet) for OCT speckle noise reduction. The new model presented in this paper obtained much better results than Alg2 and outperformed those competing state of the arts. Our results showed that layer by layer domain adaptation is superior to image level adaptation alone in deep models for OCT speckle noise reduction. In the camera-ready paper, we will reveal Alg2 and add this information. Q2: Regarding the dataset section, … How many images from each scanner you used? A2: Due to space limitation, we did not present specifications of the datasets. The image sizes of Topcon DRI-1 Atlantis, Topcon 3D OCT 2000, Topcon 3D OCT 1000 and Zeiss Cirrus 4000 are 512×992, 512×885, 512×480 and 512×1024, respectively. The training set is composed of 256 images from Topcon DRI-1 Atlantis and 256 images from Topcon 3D OCT 2000. We will refer readers to Alg2 for details of the datasets in the camera-ready paper. Q3: In the ablation study section the table caption mentions: … Would you please elaborate? A3: Thank you for pointing out this typo. The caption of Table 1 should be “Table 1. Ablation study performances on 9 images from in-house OCT scanner (mean ± standard).” Will be corrected. Q4: For the result section, … Was there any specific reason why disease images were introduced? A4: Validation results presented in this paper were on images collected by the in-house scanner only. We will change the Table caption to accurately reflect this information. The chosen performance metrics require manual selection of regions of interest and labeling retinal layers on OCT images, as shown in Fig. 2(a) and Fig. 3(a). These manual operations are complex and labor intensive, we currently just completed 9 images from the in-house OCT scanner for validation. The number of ‘9’ is relatively small but the validation was based on regions and all algorithms were evaluated on the same regions. We believe the evaluation process is relatively fair. As part of our future work, more images will be labeled, and the proposed method will be applied to other publicly available OCT datasets for denoising. In addition, OCT scanner is purposed for disease diagnosis so evaluation on disease images is clinically more relevant. Q5: Are the authors considering making both the datasets public? … Please note that this does not have any impact in the review decision. A5: Unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Yi Zhou, Jiang Li, Meng Wang, Weifang Zhu, Yuanyuan Peng, Zhongyue Chen, Lianyu Wang, Tingting Wang, Chenpu Yao, Ting Wang, Xinjian Chen Abstract Raw optical coherence tomography (OCT) images typically are of low quality because speckle noise blurs retinal structures, severely compromising visual quality and degrading performances of subsequent image analysis tasks. In this paper, we propose a novel end-to-end cross-domain denoising framework for speckle noise suppression. We utilize high quality ground truth datasets produced by several commercial OCT scanners for training, and apply the trained model to datasets collected by our in-house OCT scanner for denoising. Our model uses the high-resolution network (HRNet) as backbone, which maintains high-resolution representations during the entire learning process to restore high fidelity images. In addition, we develop a hierarchical adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Experimental results show that the proposed model outperformed all the competing state-of-the-art methods. As compared to the best of our previous method, the proposed model improved the signal to noise ratio (SNR) metric by a huge margin of 18.13dB and only required 25ms for denoising one image in testing phase, achieving the real-time processing capability for the in-house OCT scanner. Link to paper https://doi.org/10.1007/978-3-030-87231-1_36 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper A novel end-to-end learning framework for optical coherence tomography (OCT) images speckle noise reduction has been proposed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed framework got significantly better results than state of the art OCT images speckle noise suppression methods and offer real-time processing capabilities. The proposed model can be trained and tested with OCT images collected by different scanners. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I don’t see any weaknesses of this paper. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I think that reproducibility checklist for this paper has been properly fulfilled. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This is a well written paper. The proposed hierarchical adversarial learning strategy for domain adaption is very interesting. A good ablation study has been performed. The shown qualitative and quantitative results obtained using the proposed method outperform state of the art requiring very short processing time. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Major factors that led me to propose this paper to be accepted has been its novelty and its good experimental section. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors propose a novel end-to-end cross domain denoising framework for speckle noise suppression in OCT images. The backbone architecture is HRNet that preserves high resolution information across different layers to preserve information. They also add adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A very well written paper with adequate literature review, standard evaluation metrics and enough experimentation to validate the model. My only concern is the dataset used which isn’t publicly available and therefore not reproducible. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Dataset does not seem to available to public for reproduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Might be difficult due to unavailability of dataset. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see weakness and strength. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I think the architecture is quite novel. My only concern is dataset availability for reproducing the result. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an end-to-end deep domain adaptation framework for speckle noise reduction from OCT images. The proposed method used “high- resolution network (HRNet)” during the denoising process and it also used a hierarchical adversarial learning to tackle the domain shift issue of data taken from different scanner. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper addresses a very clinically relevant problem which is domain shift. Often end-to-end models tend to be brittle. They fail to perform good enough with data taken from different camera or scanner settings. The paper is clearly written The paper clearly mentions several proposed novelties. The result section shows excellent improvement in performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors do not mention why they used a particular method (citation 16 in the paper), can you please mention why this particular method you found can perform well? Have you tried any other method? Regarding the dataset section, the paper does not mention the original dimension of the images. The images from 4 scanner- are they similar in dimension ? How many images from each scanner you used? In the ablation study section the table caption mentions : “on a disease OCT image”. Does that mean the result of the table is from only one image? If so, where do the mean and SD come from? Would you please elaborate? For the result section, are these the result only from the in house scanner? Would you please mention that in the table caption to help the reader’s to understand. Also “We also set aside three disease raw images and six normal raw images from the in-house scanner for testing.” , isn’t (3+6) = 9 is a very small number to conclude something? Is there any reason you did not consider to have more images? Was there any specific reason why disease images were introduced? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Upon release of the code, the reproducibility can be verified Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The reviewer believes that the problem addressed by the paper is scientifically very relevant. Domain shift is a common problem which hinders the clinical practice of many AI based algorithms and the papers aims to address that problem. Are the authors considering making both the datasets public? It would be a very good resource for the research community as currently we do not have many publicly available noisy-denoisy paired OCT images. As the authors claim to use clinically generated datasets, it will be a great resource for wider research community. Please note that this does not have any impact in the review decision. Other comments mentioned clearly in the strength and the weakness section of the papers. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The relevant weakness and comments are mentioned before but those are mostly minor and can be addressed quickly. The reviewer believes that the problems addressed in the paper is very clinically relevant and important. The paper can be accepted borderline given that the comments given in the weakness are addressed properly. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This is a strong paper that proposes a novel solution for OCT denoising and achieved superior performance. There is only minor concern about whether the dataset will be publicly shared. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback Meta-Reviews: Response: Thank you for the encouraging comments. We will revise the manuscript accordingly. Reviewer #1 Response: Thank you for the comments. Reviewer #2 Response: Thanks for your review. For your concern regarding the publicity of our datasets, unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. Reviewer #3 Response: Thank you for the constructive suggestions. Q1: The authors do not mention why they used a particular method (citation 16 in the paper), … Have you tried any other method? A1: This is a very good comment. The overall objective of our work is to leverage existing datasets with ground truth for OCT speckle noise reduction in datasets where ground truth data are difficult or expensive to collect. Different datasets were collected by different OCT scanners where data distribution shifts are very common, and a domain adaptation process is needed. In our previous work (Alg2, accepted for publication), we utilized the CycleGAN model to perform domain adaptation at image level and achieved satisfactory results. Method in [16] is a very good domain adaptation algorithm for image segmentation built upon the U-net model, where each layer was treated differently because different layers have different resolutions, thus the algorithm was named “Hierarchical”. Inspired by the method in [16], we redesigned the algorithm to fit to the high-resolution net (HRNet) for OCT speckle noise reduction. The new model presented in this paper obtained much better results than Alg2 and outperformed those competing state of the arts. Our results showed that layer by layer domain adaptation is superior to image level adaptation alone in deep models for OCT speckle noise reduction. In the camera-ready paper, we will reveal Alg2 and add this information. Q2: Regarding the dataset section, … How many images from each scanner you used? A2: Due to space limitation, we did not present specifications of the datasets. The image sizes of Topcon DRI-1 Atlantis, Topcon 3D OCT 2000, Topcon 3D OCT 1000 and Zeiss Cirrus 4000 are 512×992, 512×885, 512×480 and 512×1024, respectively. The training set is composed of 256 images from Topcon DRI-1 Atlantis and 256 images from Topcon 3D OCT 2000. We will refer readers to Alg2 for details of the datasets in the camera-ready paper. Q3: In the ablation study section the table caption mentions: … Would you please elaborate? A3: Thank you for pointing out this typo. The caption of Table 1 should be “Table 1. Ablation study performances on 9 images from in-house OCT scanner (mean ± standard).” Will be corrected. Q4: For the result section, … Was there any specific reason why disease images were introduced? A4: Validation results presented in this paper were on images collected by the in-house scanner only. We will change the Table caption to accurately reflect this information. The chosen performance metrics require manual selection of regions of interest and labeling retinal layers on OCT images, as shown in Fig. 2(a) and Fig. 3(a). These manual operations are complex and labor intensive, we currently just completed 9 images from the in-house OCT scanner for validation. The number of ‘9’ is relatively small but the validation was based on regions and all algorithms were evaluated on the same regions. We believe the evaluation process is relatively fair. As part of our future work, more images will be labeled, and the proposed method will be applied to other publicly available OCT datasets for denoising. In addition, OCT scanner is purposed for disease diagnosis so evaluation on disease images is clinically more relevant. Q5: Are the authors considering making both the datasets public? … Please note that this does not have any impact in the review decision. A5: Unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0635/12/31/Paper1596" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0635/12/31/Paper1596" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0635-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="High-Resolution Hierarchical Adversarial Learning for OCT Speckle Noise Reduction" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0635/12/31/Paper1596"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0635/12/31/Paper1596","headline":"High-Resolution Hierarchical Adversarial Learning for OCT Speckle Noise Reduction","dateModified":"0636-01-04T00:00:00-05:17","datePublished":"0635-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Yi Zhou, Jiang Li, Meng Wang, Weifang Zhu, Yuanyuan Peng, Zhongyue Chen, Lianyu Wang, Tingting Wang, Chenpu Yao, Ting Wang, Xinjian Chen Abstract Raw optical coherence tomography (OCT) images typically are of low quality because speckle noise blurs retinal structures, severely compromising visual quality and degrading performances of subsequent image analysis tasks. In this paper, we propose a novel end-to-end cross-domain denoising framework for speckle noise suppression. We utilize high quality ground truth datasets produced by several commercial OCT scanners for training, and apply the trained model to datasets collected by our in-house OCT scanner for denoising. Our model uses the high-resolution network (HRNet) as backbone, which maintains high-resolution representations during the entire learning process to restore high fidelity images. In addition, we develop a hierarchical adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Experimental results show that the proposed model outperformed all the competing state-of-the-art methods. As compared to the best of our previous method, the proposed model improved the signal to noise ratio (SNR) metric by a huge margin of 18.13dB and only required 25ms for denoising one image in testing phase, achieving the real-time processing capability for the in-house OCT scanner. Link to paper https://doi.org/10.1007/978-3-030-87231-1_36 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper A novel end-to-end learning framework for optical coherence tomography (OCT) images speckle noise reduction has been proposed. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed framework got significantly better results than state of the art OCT images speckle noise suppression methods and offer real-time processing capabilities. The proposed model can be trained and tested with OCT images collected by different scanners. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I don’t see any weaknesses of this paper. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance I think that reproducibility checklist for this paper has been properly fulfilled. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This is a well written paper. The proposed hierarchical adversarial learning strategy for domain adaption is very interesting. A good ablation study has been performed. The shown qualitative and quantitative results obtained using the proposed method outperform state of the art requiring very short processing time. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Major factors that led me to propose this paper to be accepted has been its novelty and its good experimental section. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The authors propose a novel end-to-end cross domain denoising framework for speckle noise suppression in OCT images. The backbone architecture is HRNet that preserves high resolution information across different layers to preserve information. They also add adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A very well written paper with adequate literature review, standard evaluation metrics and enough experimentation to validate the model. My only concern is the dataset used which isn’t publicly available and therefore not reproducible. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Dataset does not seem to available to public for reproduction. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Might be difficult due to unavailability of dataset. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please see weakness and strength. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I think the architecture is quite novel. My only concern is dataset availability for reproducing the result. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper proposes an end-to-end deep domain adaptation framework for speckle noise reduction from OCT images. The proposed method used “high- resolution network (HRNet)” during the denoising process and it also used a hierarchical adversarial learning to tackle the domain shift issue of data taken from different scanner. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper addresses a very clinically relevant problem which is domain shift. Often end-to-end models tend to be brittle. They fail to perform good enough with data taken from different camera or scanner settings. The paper is clearly written The paper clearly mentions several proposed novelties. The result section shows excellent improvement in performance. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors do not mention why they used a particular method (citation 16 in the paper), can you please mention why this particular method you found can perform well? Have you tried any other method? Regarding the dataset section, the paper does not mention the original dimension of the images. The images from 4 scanner- are they similar in dimension ? How many images from each scanner you used? In the ablation study section the table caption mentions : “on a disease OCT image”. Does that mean the result of the table is from only one image? If so, where do the mean and SD come from? Would you please elaborate? For the result section, are these the result only from the in house scanner? Would you please mention that in the table caption to help the reader’s to understand. Also “We also set aside three disease raw images and six normal raw images from the in-house scanner for testing.” , isn’t (3+6) = 9 is a very small number to conclude something? Is there any reason you did not consider to have more images? Was there any specific reason why disease images were introduced? Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Upon release of the code, the reproducibility can be verified Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The reviewer believes that the problem addressed by the paper is scientifically very relevant. Domain shift is a common problem which hinders the clinical practice of many AI based algorithms and the papers aims to address that problem. Are the authors considering making both the datasets public? It would be a very good resource for the research community as currently we do not have many publicly available noisy-denoisy paired OCT images. As the authors claim to use clinically generated datasets, it will be a great resource for wider research community. Please note that this does not have any impact in the review decision. Other comments mentioned clearly in the strength and the weakness section of the papers. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The relevant weakness and comments are mentioned before but those are mostly minor and can be addressed quickly. The reviewer believes that the problems addressed in the paper is very clinically relevant and important. The paper can be accepted borderline given that the comments given in the weakness are addressed properly. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This is a strong paper that proposes a novel solution for OCT denoising and achieved superior performance. There is only minor concern about whether the dataset will be publicly shared. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Author Feedback Meta-Reviews: Response: Thank you for the encouraging comments. We will revise the manuscript accordingly. Reviewer #1 Response: Thank you for the comments. Reviewer #2 Response: Thanks for your review. For your concern regarding the publicity of our datasets, unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. Reviewer #3 Response: Thank you for the constructive suggestions. Q1: The authors do not mention why they used a particular method (citation 16 in the paper), … Have you tried any other method? A1: This is a very good comment. The overall objective of our work is to leverage existing datasets with ground truth for OCT speckle noise reduction in datasets where ground truth data are difficult or expensive to collect. Different datasets were collected by different OCT scanners where data distribution shifts are very common, and a domain adaptation process is needed. In our previous work (Alg2, accepted for publication), we utilized the CycleGAN model to perform domain adaptation at image level and achieved satisfactory results. Method in [16] is a very good domain adaptation algorithm for image segmentation built upon the U-net model, where each layer was treated differently because different layers have different resolutions, thus the algorithm was named “Hierarchical”. Inspired by the method in [16], we redesigned the algorithm to fit to the high-resolution net (HRNet) for OCT speckle noise reduction. The new model presented in this paper obtained much better results than Alg2 and outperformed those competing state of the arts. Our results showed that layer by layer domain adaptation is superior to image level adaptation alone in deep models for OCT speckle noise reduction. In the camera-ready paper, we will reveal Alg2 and add this information. Q2: Regarding the dataset section, … How many images from each scanner you used? A2: Due to space limitation, we did not present specifications of the datasets. The image sizes of Topcon DRI-1 Atlantis, Topcon 3D OCT 2000, Topcon 3D OCT 1000 and Zeiss Cirrus 4000 are 512×992, 512×885, 512×480 and 512×1024, respectively. The training set is composed of 256 images from Topcon DRI-1 Atlantis and 256 images from Topcon 3D OCT 2000. We will refer readers to Alg2 for details of the datasets in the camera-ready paper. Q3: In the ablation study section the table caption mentions: … Would you please elaborate? A3: Thank you for pointing out this typo. The caption of Table 1 should be “Table 1. Ablation study performances on 9 images from in-house OCT scanner (mean ± standard).” Will be corrected. Q4: For the result section, … Was there any specific reason why disease images were introduced? A4: Validation results presented in this paper were on images collected by the in-house scanner only. We will change the Table caption to accurately reflect this information. The chosen performance metrics require manual selection of regions of interest and labeling retinal layers on OCT images, as shown in Fig. 2(a) and Fig. 3(a). These manual operations are complex and labor intensive, we currently just completed 9 images from the in-house OCT scanner for validation. The number of ‘9’ is relatively small but the validation was based on regions and all algorithms were evaluated on the same regions. We believe the evaluation process is relatively fair. As part of our future work, more images will be labeled, and the proposed method will be applied to other publicly available OCT datasets for denoising. In addition, OCT scanner is purposed for disease diagnosis so evaluation on disease images is clinically more relevant. Q5: Are the authors considering making both the datasets public? … Please note that this does not have any impact in the review decision. A5: Unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Zhou, Yi,Li, Jiang,Wang, Meng,Zhu, Weifang,Peng, Yuanyuan,Chen, Zhongyue,Wang, Lianyu,Wang, Tingting,Yao, Chenpu,Wang, Ting,Chen, Xinjian" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>High-Resolution Hierarchical Adversarial Learning for OCT Speckle Noise Reduction</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Zhou, Yi"
        class="post-tags">
        Zhou, Yi
      </a> |  
      
      <a href="kittywong/tags#Li, Jiang"
        class="post-tags">
        Li, Jiang
      </a> |  
      
      <a href="kittywong/tags#Wang, Meng"
        class="post-tags">
        Wang, Meng
      </a> |  
      
      <a href="kittywong/tags#Zhu, Weifang"
        class="post-tags">
        Zhu, Weifang
      </a> |  
      
      <a href="kittywong/tags#Peng, Yuanyuan"
        class="post-tags">
        Peng, Yuanyuan
      </a> |  
      
      <a href="kittywong/tags#Chen, Zhongyue"
        class="post-tags">
        Chen, Zhongyue
      </a> |  
      
      <a href="kittywong/tags#Wang, Lianyu"
        class="post-tags">
        Wang, Lianyu
      </a> |  
      
      <a href="kittywong/tags#Wang, Tingting"
        class="post-tags">
        Wang, Tingting
      </a> |  
      
      <a href="kittywong/tags#Yao, Chenpu"
        class="post-tags">
        Yao, Chenpu
      </a> |  
      
      <a href="kittywong/tags#Wang, Ting"
        class="post-tags">
        Wang, Ting
      </a> |  
      
      <a href="kittywong/tags#Chen, Xinjian"
        class="post-tags">
        Chen, Xinjian
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Yi Zhou, Jiang Li, Meng Wang, Weifang Zhu, Yuanyuan Peng, Zhongyue Chen, Lianyu Wang, Tingting Wang, Chenpu Yao, Ting Wang, Xinjian Chen
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Raw optical coherence tomography (OCT) images typically are of low quality because speckle noise blurs retinal structures, severely compromising visual quality and degrading performances of subsequent image analysis tasks. In this paper, we propose a novel end-to-end cross-domain denoising framework for speckle noise suppression. We utilize high quality ground truth datasets produced by several commercial OCT scanners for training, and apply the trained model to datasets collected by our in-house OCT scanner for denoising. Our model uses the high-resolution network (HRNet) as backbone, which maintains high-resolution representations during the entire learning process to restore high fidelity images. In addition, we develop a hierarchical adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners. Experimental results show that the proposed model outperformed all the competing state-of-the-art methods. As compared to the best of our previous method, the proposed model improved the signal to noise ratio (SNR) metric by a huge margin of 18.13dB and only required 25ms for denoising one image in testing phase, achieving the real-time processing capability for the in-house OCT scanner.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87231-1_36">https://doi.org/10.1007/978-3-030-87231-1_36</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>A novel end-to-end learning framework for optical coherence tomography (OCT) images speckle noise reduction has been proposed.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The proposed framework got significantly better results than state of the art OCT images speckle noise suppression methods and offer real-time processing capabilities.
The proposed model can be trained and tested with OCT images collected by different scanners.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>I don’t see any weaknesses of this paper.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>I think that reproducibility checklist for this paper has been properly fulfilled.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>This is a well written paper. The proposed hierarchical adversarial learning strategy for domain adaption is very interesting.</p>

      <p>A good ablation study has been performed. The shown qualitative and quantitative results obtained using the proposed method outperform state of the art requiring very short processing time.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Major factors that led me to propose this paper to be accepted has been its novelty and its good experimental section.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors propose a novel end-to-end cross domain denoising framework for speckle noise suppression in OCT images. The backbone architecture is HRNet that preserves high resolution information across different layers to preserve information. They also add adversarial learning strategy for domain adaption to align distribution shift among datasets collected by different scanners.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>A very well written paper with adequate literature review, standard evaluation metrics and enough experimentation to validate the model. My only concern is the dataset used which isn’t publicly available and therefore not reproducible.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>Dataset does not seem to available to public for reproduction.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Might be difficult due to unavailability of dataset.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please see weakness and strength.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>I think the architecture is quite novel. My only concern is dataset availability for reproducing the result.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes an end-to-end deep domain adaptation framework for speckle noise reduction from OCT images. The proposed method used “high- resolution network (HRNet)” during the denoising process and it also used a hierarchical adversarial learning to tackle the domain shift issue of data taken from different scanner.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The paper addresses a very clinically relevant problem which is domain shift. Often end-to-end models tend to be brittle. They fail to perform good enough with data taken from different camera or scanner settings. 
The paper is clearly written
The paper clearly mentions several proposed novelties.
The result section shows excellent improvement in performance.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The authors do not mention why they used a particular method (citation 16 in the paper), can you please mention why this particular method you found can perform well? Have you tried any other method?
Regarding the dataset section, the paper does not mention the original dimension of the images. The images from 4 scanner- are they similar in dimension ? How many images from each scanner you used?
In the ablation study section the table caption mentions : “on a disease OCT image”. Does that mean the result of the table is from only one image? If so, where do the mean and SD come from? Would you please elaborate? 
For the result section, are these the result only from the in house scanner? Would you please mention that in the table caption to help the reader’s to understand. Also “We also set aside three disease raw images and six normal raw images from the in-house scanner for testing.” , isn’t (3+6) = 9 is a very small number to conclude something? Is there any reason you did not consider to have more images? Was there any specific reason why disease images were introduced?</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Upon release of the code, the reproducibility can be verified</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The reviewer believes that the problem addressed by the paper is scientifically very relevant. Domain shift is a common problem which hinders the clinical practice of many AI based algorithms and the papers aims to address that problem.</p>

      <p>Are the authors considering making both the datasets public? It would be a very good resource for the research community as currently we do not have many publicly available noisy-denoisy paired OCT images. As the authors claim to use clinically generated datasets, it will be a great resource for wider research community. Please note that this does not have any impact in the review decision.
Other comments mentioned clearly in the strength and the weakness section of the papers.</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The relevant weakness and comments are mentioned before but those are mostly minor and can be addressed quickly. The reviewer believes that the problems addressed in the paper is very clinically relevant and important. The paper can be accepted borderline given that the comments given in the weakness are addressed properly.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This is a strong paper that proposes a novel solution for OCT denoising and achieved superior performance.  There is only minor concern about whether the dataset will be publicly shared.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>Meta-Reviews:
Response: Thank you for the encouraging comments. We will revise the manuscript accordingly.</p>

  <p>Reviewer #1
Response: Thank you for the comments.</p>

  <p>Reviewer #2
Response: Thanks for your review. For your concern regarding the publicity of our datasets, unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future.</p>

  <p>Reviewer #3
Response: Thank you for the constructive suggestions.
Q1: The authors do not mention why they used a particular method (citation 16 in the paper), … Have you tried any other method?
A1: This is a very good comment. The overall objective of our work is to leverage existing datasets with ground truth for OCT speckle noise reduction in datasets where ground truth data are difficult or expensive to collect. Different datasets were collected by different OCT scanners where data distribution shifts are very common, and a domain adaptation process is needed. In our previous work (Alg2, accepted for publication), we utilized the CycleGAN model to perform domain adaptation at image level and achieved satisfactory results. Method in [16] is a very good domain adaptation algorithm for image segmentation built upon the U-net model, where each layer was treated differently because different layers have different resolutions, thus the algorithm was named “Hierarchical”. Inspired by the method in [16], we redesigned the algorithm to fit to the high-resolution net (HRNet) for OCT speckle noise reduction. The new model presented in this paper obtained much better results than Alg2 and outperformed those competing state of the arts. Our results showed that layer by layer domain adaptation is superior to image level adaptation alone in deep models for OCT speckle noise reduction. In the camera-ready paper, we will reveal Alg2 and add this information.</p>

  <p>Q2: Regarding the dataset section, … How many images from each scanner you used?
A2: Due to space limitation, we did not present specifications of the datasets. The image sizes of Topcon DRI-1 Atlantis, Topcon 3D OCT 2000, Topcon 3D OCT 1000 and Zeiss Cirrus 4000 are 512×992, 512×885, 512×480 and 512×1024, respectively. The training set is composed of 256 images from Topcon DRI-1 Atlantis and 256 images from Topcon 3D OCT 2000. We will refer readers to Alg2 for details of the datasets in the camera-ready paper.</p>

  <p>Q3: In the ablation study section the table caption mentions: … Would you please elaborate?
A3: Thank you for pointing out this typo. The caption of Table 1 should be “Table 1. Ablation study performances on 9 images from in-house OCT scanner (mean ± standard).” Will be corrected.</p>

  <p>Q4: For the result section, … Was there any specific reason why disease images were introduced?
A4: Validation results presented in this paper were on images collected by the in-house scanner only. We will change the Table caption to accurately reflect this information. The chosen performance metrics require manual selection of regions of interest and labeling retinal layers on OCT images, as shown in Fig. 2(a) and Fig. 3(a). These manual operations are complex and labor intensive, we currently just completed 9 images from the in-house OCT scanner for validation. The number of ‘9’ is relatively small but the validation was based on regions and all algorithms were evaluated on the same regions. We believe the evaluation process is relatively fair. As part of our future work, more images will be labeled, and the proposed method will be applied to other publicly available OCT datasets for denoising. In addition, OCT scanner is purposed for disease diagnosis so evaluation on disease images is clinically more relevant.</p>

  <p>Q5: Are the authors considering making both the datasets public? … Please note that this does not have any impact in the review decision.
A5: Unfortunately, we won’t release them at this moment due to certain commercial reasons, but it may change in the future.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0635-12-31
      -->
      <!--
      
        ,
        updated at 
        0636-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Zhou, Yi"
        class="post-category">
        Zhou, Yi
      </a> |  
      
      <a href="kittywong/tags#Li, Jiang"
        class="post-category">
        Li, Jiang
      </a> |  
      
      <a href="kittywong/tags#Wang, Meng"
        class="post-category">
        Wang, Meng
      </a> |  
      
      <a href="kittywong/tags#Zhu, Weifang"
        class="post-category">
        Zhu, Weifang
      </a> |  
      
      <a href="kittywong/tags#Peng, Yuanyuan"
        class="post-category">
        Peng, Yuanyuan
      </a> |  
      
      <a href="kittywong/tags#Chen, Zhongyue"
        class="post-category">
        Chen, Zhongyue
      </a> |  
      
      <a href="kittywong/tags#Wang, Lianyu"
        class="post-category">
        Wang, Lianyu
      </a> |  
      
      <a href="kittywong/tags#Wang, Tingting"
        class="post-category">
        Wang, Tingting
      </a> |  
      
      <a href="kittywong/tags#Yao, Chenpu"
        class="post-category">
        Yao, Chenpu
      </a> |  
      
      <a href="kittywong/tags#Wang, Ting"
        class="post-category">
        Wang, Ting
      </a> |  
      
      <a href="kittywong/tags#Chen, Xinjian"
        class="post-category">
        Chen, Xinjian
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0636/12/31/Paper1698">
          Self-Supervised Learning for MRI Reconstruction with a Parallel Network Training Framework
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0634/12/31/Paper1581">
          Label-Free Physics-Informed Image Sequence Reconstruction with Disentangled Spatial-Temporal Modeling
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
