<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-Ray for COVID19 | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-Ray for COVID19" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tao Tan, Bipul Das, Ravi Soni, Mate Fejes, Sohan Ranjan, Daniel Attila Szabo, Vikram Melapudi, K S Shriram, Utkarsh Agrawal, László Ruskó, Zita Herczeg, Barbara Darazs, Pal Tegzes, Lehel Ferenczi, Rakesh Mullick, Gopal Avinash Abstract The COVID-19 pandemic continues to spread and impact the well-being of the global population. The front-line modalities including computed tomography (CT) and X-ray play an important role for triaging COVID-19 patients. Considering the limited access of resources (both hardware and trained personnel) and decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based applications for triaging and monitoring COVID-19 patients in a timely manner and to further delineate the disease region boundary are seen as a promising solution. Our proposed solution differs from existing solutions by industry and academic communities, and demonstrates a functional AI model to triage by inferencing using a single X-ray image, while the deep-learning model is trained using both X-ray and CT data. We report on how such a multi-modal training improves the solution compared to X-ray only training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 and also positively impacts the Dice coefficient(0.59 to 0.62) for localizing the pathology. Link to paper https://doi.org/10.1007/978-3-030-87234-2_31 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper, a X-ray based triaging and monitoring COVID-19 approach is proposed. CT data is employed to generate the synthetic x-ray SXR to augment the training data. the AUC score has been improved from 0.89 to 0.93 for the triage classification task. Comparing to CT, portable X-ray units are cost and time effective. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A x-ray based triaging approach COVID-19 is introduced. With the augmented straining samples from the CT scan, the x-ray based performance has been improve. It shows a potential for the practical value for COVID screening. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Writing needs improvements abstract, the multi-modal solution increases AUC and dice coefficient for what? Please clarify the statements. sec2.1 HU terms should be clarified. sec2.3 what is “image level classification” . What do you mean the image level? Isn’t x-ray an image? The fig.1 may be problematic, why there are two lines from CT to SXR generation? Isn’t it redundant. For segmentation evaluation, which one is used as the ground truth? minor: page 3, “are still are added in the training pool.” ? sec2.2, To alleviate the problem of the during image registration, sec4.2, “likeli-hood of COVID-10”. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It is not clear if the in-house COVID-19 data will be released. Code no release. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html See weakness . Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This works presents a x-ray based COVID-19 triaging approach. It potential to employ X-ray for time and cost efficiency. The writing is not in high quality with multiple typos. Also, some concerns need to be addressed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper Following has been demonstrated: Multi-model training to inform about pathology in X-ray images Synthetic X-ray generation to bridge the information translation from CT images to X-ray. Training with multiple modality data but inference with the easier modality. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper proposes a strong method that could be theoretically used in triaging cases based on pathology evidence. The training setup is designed to use information from both chest CT and X-ray images. High clinical feasibility Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. No major weakness The method relies heavily on how well the synthetic X-ray generation. So, a stronger valdation for the generated images is necessary. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducible with the information provided. Pristine annotations usage requires adjustments which are not discussed further and this might hinder reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The validation of synthetic data generation could be stronger. Not sure how 48 hours was chosen as time-window. The transferred annotations on XR are further adjusted manually reviewed by trained sta to build our pristine mask ground-truth/annotations (see 2.2). - There is no information about these adjustments in 2.2 or elsewhere. How many required annotations and is this linked to the choice of 48 hours. Couple of sentences regarding why and what would be helpful in reproducing. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novelty clearly visible in approach and target application as well. Demonstration of how training using information from multi modality is demonstrated which can be translated to different problems. Reproducible and the idea is feasible to be realized in clinical setup with more development What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors created a multi-modal framework for COVID-19 diagnosis and segmentation that learns from both high-dimensional modality CT and X-ray images but infers from low-dimensional mono-modality X-ray images. The provided approach (multi-modal training) allowed authors to increase the AUC ROC metric from 0.89 to 0.93 and the Dice coefficient from 0.59 to 0.62. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors demonstrated not trivial training procedure and the proposed approach turned out to be pretty effective as it increased accuracy. The authors validated their idea not only for the classification task but also for the segmentation task. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors does not provide any description of how realistic synthetic X-ray images look like and what is the limitation of synthetic generation. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The trining procedure clearly described. Paper seems reproducibly despite using in-house datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The authors presented an interesting approach and good results were achieved using mult-modal training. 2) It would be useful to describe synthetic X-ray generation more detailed and specify features, limitations and differences from real X-ray images. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Relevance and novelty. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes X-ray-based triage and monitoring of covid-19, wherein CT images are used to simulate x-ray images for augmentation and training. Rich information from CT could benefit the network of X-Ray. The application and method are strong. The experimental results are sufficient to support the conclusion of the paper. Weakness needs to be addressed: 1) pls improve the writing and figures (make the lines straight); 2) make it clear about image-level annotation and ROI annotation and how they are used; 3) justify how well synthetic X-rays are. Additionally, suggest to address other comments raised by reviewers. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback The authors would like to thank the chair and all the reviewers for the precious comments and suggestions. The authors find the comments very insightful and have provided great feedback to improve both the readability and the interpretability of the presented work. We have taken the inputs very constructively to enhance the text and add any other meaningful content to ensure good comprehension of the content for possible reproduction or clinical experimentation. We have fixed the multiple-line issue of Fig 1, improved the writing and clarified regarding image-level annotations which are classification labels (COVID19, regular pneumonia and negative) and notation of ROI annotations to be pixel-level labels/annotations/markings of disease regions in this revision. We have also added details of the parameters used for generating realistic synthetic X-ray from the corresponding subject’s CT data. It should be noted that synthetic X-rays generated for our training have a lower spatial resolution compared to the corresponding X-rays (CR/DX) given the limitation that the original slice thickness of CT images ranges from 3mm to 6mm. Given the clinical nature of the data we have consciously adopted not to interpolate this data, yet maximally use the multi-modality content to enhance the model. Regarding paired data, X-rays and CTs were typically acquired within a small time-window (duration of patient hospital stay). We opted to use an empirical threshold of 48 hours to ensure that the clinical indication of pathology does not change significantly between the time of the X-ray and CT images. Since COVID-19 is a rapidly changing disease, including additional CTs or subjects for ground-truth (GT) transfer with a wider gap between the X-ray and CT images would misrepresent the training pool which aims to predict/triage the study and correlate to the RTPCR result. Although we have aimed to create an approximate spatial match between SXR and XR, we cannot directly use transferred GT from 3D CT onto 2D and consider that to be GT for XR. The disease can rapidly change even within 48 hours and so in our study the transferred GT can only be used as a directional guidance by a human expert to then precisely refine the annotation on the 2D X-rays. The general instruction to the annotators when adjusting the ROI annotation, to remove the CT-mapped regions where lesions are totally invisible on X-rays. On the other hand those regions which minimally overlap with clearly visible pathology on the X-ray are preserved. Similar complex situations were observed in the heart/diaphragm regions due to lesion masking by overlapping structure/organs in the projection image. We clarified these issues in the attached revision. Hope all changes improve the clarify of this paper. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tao Tan, Bipul Das, Ravi Soni, Mate Fejes, Sohan Ranjan, Daniel Attila Szabo, Vikram Melapudi, K S Shriram, Utkarsh Agrawal, László Ruskó, Zita Herczeg, Barbara Darazs, Pal Tegzes, Lehel Ferenczi, Rakesh Mullick, Gopal Avinash Abstract The COVID-19 pandemic continues to spread and impact the well-being of the global population. The front-line modalities including computed tomography (CT) and X-ray play an important role for triaging COVID-19 patients. Considering the limited access of resources (both hardware and trained personnel) and decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based applications for triaging and monitoring COVID-19 patients in a timely manner and to further delineate the disease region boundary are seen as a promising solution. Our proposed solution differs from existing solutions by industry and academic communities, and demonstrates a functional AI model to triage by inferencing using a single X-ray image, while the deep-learning model is trained using both X-ray and CT data. We report on how such a multi-modal training improves the solution compared to X-ray only training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 and also positively impacts the Dice coefficient(0.59 to 0.62) for localizing the pathology. Link to paper https://doi.org/10.1007/978-3-030-87234-2_31 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper, a X-ray based triaging and monitoring COVID-19 approach is proposed. CT data is employed to generate the synthetic x-ray SXR to augment the training data. the AUC score has been improved from 0.89 to 0.93 for the triage classification task. Comparing to CT, portable X-ray units are cost and time effective. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A x-ray based triaging approach COVID-19 is introduced. With the augmented straining samples from the CT scan, the x-ray based performance has been improve. It shows a potential for the practical value for COVID screening. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Writing needs improvements abstract, the multi-modal solution increases AUC and dice coefficient for what? Please clarify the statements. sec2.1 HU terms should be clarified. sec2.3 what is “image level classification” . What do you mean the image level? Isn’t x-ray an image? The fig.1 may be problematic, why there are two lines from CT to SXR generation? Isn’t it redundant. For segmentation evaluation, which one is used as the ground truth? minor: page 3, “are still are added in the training pool.” ? sec2.2, To alleviate the problem of the during image registration, sec4.2, “likeli-hood of COVID-10”. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It is not clear if the in-house COVID-19 data will be released. Code no release. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html See weakness . Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This works presents a x-ray based COVID-19 triaging approach. It potential to employ X-ray for time and cost efficiency. The writing is not in high quality with multiple typos. Also, some concerns need to be addressed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper Following has been demonstrated: Multi-model training to inform about pathology in X-ray images Synthetic X-ray generation to bridge the information translation from CT images to X-ray. Training with multiple modality data but inference with the easier modality. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper proposes a strong method that could be theoretically used in triaging cases based on pathology evidence. The training setup is designed to use information from both chest CT and X-ray images. High clinical feasibility Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. No major weakness The method relies heavily on how well the synthetic X-ray generation. So, a stronger valdation for the generated images is necessary. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducible with the information provided. Pristine annotations usage requires adjustments which are not discussed further and this might hinder reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The validation of synthetic data generation could be stronger. Not sure how 48 hours was chosen as time-window. The transferred annotations on XR are further adjusted manually reviewed by trained sta to build our pristine mask ground-truth/annotations (see 2.2). - There is no information about these adjustments in 2.2 or elsewhere. How many required annotations and is this linked to the choice of 48 hours. Couple of sentences regarding why and what would be helpful in reproducing. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novelty clearly visible in approach and target application as well. Demonstration of how training using information from multi modality is demonstrated which can be translated to different problems. Reproducible and the idea is feasible to be realized in clinical setup with more development What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors created a multi-modal framework for COVID-19 diagnosis and segmentation that learns from both high-dimensional modality CT and X-ray images but infers from low-dimensional mono-modality X-ray images. The provided approach (multi-modal training) allowed authors to increase the AUC ROC metric from 0.89 to 0.93 and the Dice coefficient from 0.59 to 0.62. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors demonstrated not trivial training procedure and the proposed approach turned out to be pretty effective as it increased accuracy. The authors validated their idea not only for the classification task but also for the segmentation task. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors does not provide any description of how realistic synthetic X-ray images look like and what is the limitation of synthetic generation. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The trining procedure clearly described. Paper seems reproducibly despite using in-house datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The authors presented an interesting approach and good results were achieved using mult-modal training. 2) It would be useful to describe synthetic X-ray generation more detailed and specify features, limitations and differences from real X-ray images. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Relevance and novelty. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes X-ray-based triage and monitoring of covid-19, wherein CT images are used to simulate x-ray images for augmentation and training. Rich information from CT could benefit the network of X-Ray. The application and method are strong. The experimental results are sufficient to support the conclusion of the paper. Weakness needs to be addressed: 1) pls improve the writing and figures (make the lines straight); 2) make it clear about image-level annotation and ROI annotation and how they are used; 3) justify how well synthetic X-rays are. Additionally, suggest to address other comments raised by reviewers. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback The authors would like to thank the chair and all the reviewers for the precious comments and suggestions. The authors find the comments very insightful and have provided great feedback to improve both the readability and the interpretability of the presented work. We have taken the inputs very constructively to enhance the text and add any other meaningful content to ensure good comprehension of the content for possible reproduction or clinical experimentation. We have fixed the multiple-line issue of Fig 1, improved the writing and clarified regarding image-level annotations which are classification labels (COVID19, regular pneumonia and negative) and notation of ROI annotations to be pixel-level labels/annotations/markings of disease regions in this revision. We have also added details of the parameters used for generating realistic synthetic X-ray from the corresponding subject’s CT data. It should be noted that synthetic X-rays generated for our training have a lower spatial resolution compared to the corresponding X-rays (CR/DX) given the limitation that the original slice thickness of CT images ranges from 3mm to 6mm. Given the clinical nature of the data we have consciously adopted not to interpolate this data, yet maximally use the multi-modality content to enhance the model. Regarding paired data, X-rays and CTs were typically acquired within a small time-window (duration of patient hospital stay). We opted to use an empirical threshold of 48 hours to ensure that the clinical indication of pathology does not change significantly between the time of the X-ray and CT images. Since COVID-19 is a rapidly changing disease, including additional CTs or subjects for ground-truth (GT) transfer with a wider gap between the X-ray and CT images would misrepresent the training pool which aims to predict/triage the study and correlate to the RTPCR result. Although we have aimed to create an approximate spatial match between SXR and XR, we cannot directly use transferred GT from 3D CT onto 2D and consider that to be GT for XR. The disease can rapidly change even within 48 hours and so in our study the transferred GT can only be used as a directional guidance by a human expert to then precisely refine the annotation on the 2D X-rays. The general instruction to the annotators when adjusting the ROI annotation, to remove the CT-mapped regions where lesions are totally invisible on X-rays. On the other hand those regions which minimally overlap with clearly visible pathology on the X-ray are preserved. Similar complex situations were observed in the heart/diaphragm regions due to lesion masking by overlapping structure/organs in the projection image. We clarified these issues in the attached revision. Hope all changes improve the clarify of this paper. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0730/12/31/Paper1741" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0730/12/31/Paper1741" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0730-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-Ray for COVID19" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0730/12/31/Paper1741"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0730/12/31/Paper1741","headline":"Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-Ray for COVID19","dateModified":"0731-01-05T00:00:00-05:17","datePublished":"0730-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Tao Tan, Bipul Das, Ravi Soni, Mate Fejes, Sohan Ranjan, Daniel Attila Szabo, Vikram Melapudi, K S Shriram, Utkarsh Agrawal, László Ruskó, Zita Herczeg, Barbara Darazs, Pal Tegzes, Lehel Ferenczi, Rakesh Mullick, Gopal Avinash Abstract The COVID-19 pandemic continues to spread and impact the well-being of the global population. The front-line modalities including computed tomography (CT) and X-ray play an important role for triaging COVID-19 patients. Considering the limited access of resources (both hardware and trained personnel) and decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based applications for triaging and monitoring COVID-19 patients in a timely manner and to further delineate the disease region boundary are seen as a promising solution. Our proposed solution differs from existing solutions by industry and academic communities, and demonstrates a functional AI model to triage by inferencing using a single X-ray image, while the deep-learning model is trained using both X-ray and CT data. We report on how such a multi-modal training improves the solution compared to X-ray only training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 and also positively impacts the Dice coefficient(0.59 to 0.62) for localizing the pathology. Link to paper https://doi.org/10.1007/978-3-030-87234-2_31 Link to the code repository N/A Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper, a X-ray based triaging and monitoring COVID-19 approach is proposed. CT data is employed to generate the synthetic x-ray SXR to augment the training data. the AUC score has been improved from 0.89 to 0.93 for the triage classification task. Comparing to CT, portable X-ray units are cost and time effective. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A x-ray based triaging approach COVID-19 is introduced. With the augmented straining samples from the CT scan, the x-ray based performance has been improve. It shows a potential for the practical value for COVID screening. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Writing needs improvements abstract, the multi-modal solution increases AUC and dice coefficient for what? Please clarify the statements. sec2.1 HU terms should be clarified. sec2.3 what is “image level classification” . What do you mean the image level? Isn’t x-ray an image? The fig.1 may be problematic, why there are two lines from CT to SXR generation? Isn’t it redundant. For segmentation evaluation, which one is used as the ground truth? minor: page 3, “are still are added in the training pool.” ? sec2.2, To alleviate the problem of the during image registration, sec4.2, “likeli-hood of COVID-10”. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It is not clear if the in-house COVID-19 data will be released. Code no release. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html See weakness . Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This works presents a x-ray based COVID-19 triaging approach. It potential to employ X-ray for time and cost efficiency. The writing is not in high quality with multiple typos. Also, some concerns need to be addressed. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper Following has been demonstrated: Multi-model training to inform about pathology in X-ray images Synthetic X-ray generation to bridge the information translation from CT images to X-ray. Training with multiple modality data but inference with the easier modality. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper proposes a strong method that could be theoretically used in triaging cases based on pathology evidence. The training setup is designed to use information from both chest CT and X-ray images. High clinical feasibility Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. No major weakness The method relies heavily on how well the synthetic X-ray generation. So, a stronger valdation for the generated images is necessary. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Reproducible with the information provided. Pristine annotations usage requires adjustments which are not discussed further and this might hinder reproducibility. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The validation of synthetic data generation could be stronger. Not sure how 48 hours was chosen as time-window. The transferred annotations on XR are further adjusted manually reviewed by trained sta to build our pristine mask ground-truth/annotations (see 2.2). - There is no information about these adjustments in 2.2 or elsewhere. How many required annotations and is this linked to the choice of 48 hours. Couple of sentences regarding why and what would be helpful in reproducing. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novelty clearly visible in approach and target application as well. Demonstration of how training using information from multi modality is demonstrated which can be translated to different problems. Reproducible and the idea is feasible to be realized in clinical setup with more development What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors created a multi-modal framework for COVID-19 diagnosis and segmentation that learns from both high-dimensional modality CT and X-ray images but infers from low-dimensional mono-modality X-ray images. The provided approach (multi-modal training) allowed authors to increase the AUC ROC metric from 0.89 to 0.93 and the Dice coefficient from 0.59 to 0.62. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors demonstrated not trivial training procedure and the proposed approach turned out to be pretty effective as it increased accuracy. The authors validated their idea not only for the classification task but also for the segmentation task. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors does not provide any description of how realistic synthetic X-ray images look like and what is the limitation of synthetic generation. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The trining procedure clearly described. Paper seems reproducibly despite using in-house datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The authors presented an interesting approach and good results were achieved using mult-modal training. 2) It would be useful to describe synthetic X-ray generation more detailed and specify features, limitations and differences from real X-ray images. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Relevance and novelty. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes X-ray-based triage and monitoring of covid-19, wherein CT images are used to simulate x-ray images for augmentation and training. Rich information from CT could benefit the network of X-Ray. The application and method are strong. The experimental results are sufficient to support the conclusion of the paper. Weakness needs to be addressed: 1) pls improve the writing and figures (make the lines straight); 2) make it clear about image-level annotation and ROI annotation and how they are used; 3) justify how well synthetic X-rays are. Additionally, suggest to address other comments raised by reviewers. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback The authors would like to thank the chair and all the reviewers for the precious comments and suggestions. The authors find the comments very insightful and have provided great feedback to improve both the readability and the interpretability of the presented work. We have taken the inputs very constructively to enhance the text and add any other meaningful content to ensure good comprehension of the content for possible reproduction or clinical experimentation. We have fixed the multiple-line issue of Fig 1, improved the writing and clarified regarding image-level annotations which are classification labels (COVID19, regular pneumonia and negative) and notation of ROI annotations to be pixel-level labels/annotations/markings of disease regions in this revision. We have also added details of the parameters used for generating realistic synthetic X-ray from the corresponding subject’s CT data. It should be noted that synthetic X-rays generated for our training have a lower spatial resolution compared to the corresponding X-rays (CR/DX) given the limitation that the original slice thickness of CT images ranges from 3mm to 6mm. Given the clinical nature of the data we have consciously adopted not to interpolate this data, yet maximally use the multi-modality content to enhance the model. Regarding paired data, X-rays and CTs were typically acquired within a small time-window (duration of patient hospital stay). We opted to use an empirical threshold of 48 hours to ensure that the clinical indication of pathology does not change significantly between the time of the X-ray and CT images. Since COVID-19 is a rapidly changing disease, including additional CTs or subjects for ground-truth (GT) transfer with a wider gap between the X-ray and CT images would misrepresent the training pool which aims to predict/triage the study and correlate to the RTPCR result. Although we have aimed to create an approximate spatial match between SXR and XR, we cannot directly use transferred GT from 3D CT onto 2D and consider that to be GT for XR. The disease can rapidly change even within 48 hours and so in our study the transferred GT can only be used as a directional guidance by a human expert to then precisely refine the annotation on the 2D X-rays. The general instruction to the annotators when adjusting the ROI annotation, to remove the CT-mapped regions where lesions are totally invisible on X-rays. On the other hand those regions which minimally overlap with clearly visible pathology on the X-ray are preserved. Similar complex situations were observed in the heart/diaphragm regions due to lesion masking by overlapping structure/organs in the projection image. We clarified these issues in the attached revision. Hope all changes improve the clarify of this paper. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Tan, Tao,Das, Bipul,Soni, Ravi,Fejes, Mate,Ranjan, Sohan,Szabo, Daniel Attila,Melapudi, Vikram,Shriram, K S,Agrawal, Utkarsh,Ruskó, László,Herczeg, Zita,Darazs, Barbara,Tegzes, Pal,Ferenczi, Lehel,Mullick, Rakesh,Avinash, Gopal" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Pristine annotations-based multi-modal trained artificial intelligence solution to triage chest X-Ray for COVID19</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Tan, Tao"
        class="post-tags">
        Tan, Tao
      </a> |  
      
      <a href="kittywong/tags#Das, Bipul"
        class="post-tags">
        Das, Bipul
      </a> |  
      
      <a href="kittywong/tags#Soni, Ravi"
        class="post-tags">
        Soni, Ravi
      </a> |  
      
      <a href="kittywong/tags#Fejes, Mate"
        class="post-tags">
        Fejes, Mate
      </a> |  
      
      <a href="kittywong/tags#Ranjan, Sohan"
        class="post-tags">
        Ranjan, Sohan
      </a> |  
      
      <a href="kittywong/tags#Szabo, Daniel Attila"
        class="post-tags">
        Szabo, Daniel Attila
      </a> |  
      
      <a href="kittywong/tags#Melapudi, Vikram"
        class="post-tags">
        Melapudi, Vikram
      </a> |  
      
      <a href="kittywong/tags#Shriram, K S"
        class="post-tags">
        Shriram, K S
      </a> |  
      
      <a href="kittywong/tags#Agrawal, Utkarsh"
        class="post-tags">
        Agrawal, Utkarsh
      </a> |  
      
      <a href="kittywong/tags#Ruskó, László"
        class="post-tags">
        Ruskó, László
      </a> |  
      
      <a href="kittywong/tags#Herczeg, Zita"
        class="post-tags">
        Herczeg, Zita
      </a> |  
      
      <a href="kittywong/tags#Darazs, Barbara"
        class="post-tags">
        Darazs, Barbara
      </a> |  
      
      <a href="kittywong/tags#Tegzes, Pal"
        class="post-tags">
        Tegzes, Pal
      </a> |  
      
      <a href="kittywong/tags#Ferenczi, Lehel"
        class="post-tags">
        Ferenczi, Lehel
      </a> |  
      
      <a href="kittywong/tags#Mullick, Rakesh"
        class="post-tags">
        Mullick, Rakesh
      </a> |  
      
      <a href="kittywong/tags#Avinash, Gopal"
        class="post-tags">
        Avinash, Gopal
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Tao Tan, Bipul Das, Ravi Soni, Mate Fejes, Sohan Ranjan, Daniel Attila Szabo, Vikram Melapudi, K S Shriram, Utkarsh Agrawal, László Ruskó, Zita Herczeg, Barbara Darazs, Pal Tegzes, Lehel Ferenczi, Rakesh Mullick, Gopal Avinash
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>The COVID-19 pandemic continues to spread and impact the well-being of the global population. The front-line modalities including computed tomography (CT) and X-ray play an important role for triaging COVID-19 patients. Considering the limited access of resources (both hardware and trained personnel) and decontamination, CT may not be ideal for triaging suspected subjects. Artificial intelligence (AI) assisted X-ray based applications for triaging and monitoring COVID-19 patients in a timely manner and to further delineate the disease region
boundary are seen as a promising solution. Our proposed solution differs from existing solutions by industry and academic communities, and demonstrates a functional AI model to triage by inferencing using a single X-ray image, while the deep-learning model is trained using both X-ray and CT data. We report on how such a multi-modal training improves the solution compared to X-ray only training. The multi-modal solution increases the AUC (area under the receiver operating characteristic curve) from 0.89 to 0.93 and also positively impacts the Dice coefficient(0.59 to 0.62) for localizing the pathology.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87234-2_31">https://doi.org/10.1007/978-3-030-87234-2_31</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>In this paper, a X-ray based triaging and monitoring COVID-19 approach is proposed. 
CT data is employed to generate the synthetic x-ray SXR to augment the training data. 
the AUC score has been improved from 0.89 to 0.93 for the triage classification task. 
Comparing to CT, portable X-ray units are cost and time effective.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>A x-ray based triaging approach COVID-19 is introduced. 
With the augmented straining samples from the CT scan, the x-ray based performance has been improve.<br />
It shows a potential for the practical value for COVID screening.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>Writing needs improvements 
abstract,  the multi-modal solution increases AUC and dice coefficient for what?   Please clarify the statements.</p>

      <p>sec2.1 HU terms should be clarified.<br />
sec2.3 what is “image level classification” . What do you mean the image level?  Isn’t x-ray an image?</p>

      <p>The fig.1 may be problematic,  why there are two lines from CT to SXR generation? Isn’t it redundant.</p>

      <p>For segmentation evaluation, which one is used as the ground truth?</p>

      <p>minor: 
page 3, “are still are added in the training pool.” ?<br />
sec2.2, To alleviate the problem of the during image registration, 
sec4.2,  “likeli-hood of COVID-10”.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>It is not clear if the in-house COVID-19 data will be released. 
Code no release.</p>

    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>See weakness .</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This works presents a x-ray based COVID-19 triaging approach. It potential to employ X-ray for time and cost efficiency.<br />
The writing is not in  high quality with multiple typos. 
Also, some concerns need to be addressed.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>Following has been demonstrated:</p>
      <ol>
        <li>Multi-model training to inform about pathology in X-ray images</li>
        <li>Synthetic X-ray generation to bridge the information translation from CT images to X-ray.</li>
        <li>Training with multiple modality data but inference with the easier modality.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The paper proposes a strong method that could be theoretically used in triaging cases based on pathology evidence.</li>
        <li>The training setup is designed to use information from both chest CT and X-ray images.</li>
        <li>High clinical feasibility</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>No major weakness
The method relies heavily on how well the synthetic X-ray generation. So, a stronger valdation for the generated images is necessary.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Reproducible with the information provided.
Pristine annotations usage requires adjustments which are not discussed further and this might hinder reproducibility.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>The validation of synthetic data generation could be stronger.</li>
        <li>Not sure how 48 hours was chosen as time-window.</li>
        <li>The transferred annotations on XR are
further adjusted manually reviewed by trained sta to build our pristine mask
ground-truth/annotations (see 2.2). - There is no information about these adjustments in 2.2 or elsewhere. How many required annotations and is this linked to the choice of 48 hours. Couple of sentences regarding why and what would be helpful in reproducing.</li>
        <li></li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ol>
        <li>Novelty clearly visible in approach and target application as well.</li>
        <li>Demonstration of how training using information from multi modality is demonstrated which can be translated to different problems.</li>
        <li>Reproducible and the idea is feasible to be realized in clinical setup with more development</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors created a multi-modal framework for COVID-19 diagnosis and segmentation that learns from both high-dimensional modality CT and X-ray images but infers from low-dimensional mono-modality X-ray images. The provided approach (multi-modal training) allowed authors to increase the AUC ROC metric from 0.89 to 0.93 and the Dice coefficient from 0.59 to 0.62.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The authors demonstrated not trivial training procedure and the proposed approach turned out to be pretty effective as it increased accuracy. The authors validated their idea not only for the classification task but also for the segmentation task.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The authors does not provide any description of how realistic synthetic X-ray images look like and what is the limitation of synthetic generation.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The trining procedure clearly described. Paper seems reproducibly despite using in-house datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>1) The authors presented an interesting approach and good results were achieved using mult-modal training.
2) It would be useful to describe synthetic X-ray generation more detailed and specify features, limitations and differences from real X-ray images.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Relevance and novelty.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper proposes X-ray-based triage and monitoring of covid-19, wherein CT images are used to simulate x-ray images for augmentation and training. Rich information from CT could benefit the network of X-Ray. The application and method are strong. The experimental results are sufficient to support the conclusion of the paper.</p>

      <p>Weakness needs to be addressed: 1) pls improve the writing and figures (make the lines straight);  2) make it clear about image-level annotation and ROI annotation and how they are used; 3) justify how well synthetic X-rays are.</p>

      <p>Additionally, suggest to address other comments raised by reviewers.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>The authors would like to thank the chair and all the reviewers for the precious comments and suggestions. The authors find the comments very insightful and have provided great feedback to improve both the readability and the interpretability of the presented work. We have taken the inputs very constructively to enhance the text and add any other meaningful content to ensure good comprehension of the content for possible reproduction or clinical experimentation.</p>

  <p>We have fixed the multiple-line issue of Fig 1, improved the writing and clarified regarding  image-level annotations which are classification labels (COVID19, regular pneumonia and negative) and notation of ROI annotations to be pixel-level labels/annotations/markings of disease regions in this revision.</p>

  <p>We have also added details of the parameters used for generating realistic synthetic X-ray from the corresponding subject’s CT data. It should be noted that synthetic X-rays generated for our training have a lower spatial resolution compared to the corresponding X-rays (CR/DX) given the limitation that the original slice thickness of CT images ranges from 3mm to 6mm. Given the clinical nature of the data we have consciously adopted not to interpolate this data, yet maximally use the multi-modality content to enhance the model.</p>

  <p>Regarding paired data, X-rays and CTs were typically acquired within a small time-window (duration of patient hospital stay). We opted to use an empirical threshold of 48 hours  to ensure that the clinical indication of pathology does not change significantly between the time of the X-ray and CT images. Since COVID-19 is a rapidly changing disease, including additional CTs or subjects for ground-truth (GT) transfer with a wider gap between the X-ray and CT images would misrepresent the training pool which aims to predict/triage the study and correlate to the RTPCR result.</p>

  <p>Although we have aimed to create an approximate spatial match between SXR and XR, we cannot directly use transferred GT from 3D CT onto 2D and consider that to be GT for XR. The disease can rapidly change even within 48 hours and so in our study the transferred GT can only be used as a directional guidance by a human expert to then precisely refine the annotation on the 2D X-rays. The general instruction to the annotators when adjusting the ROI annotation, to remove the CT-mapped regions where lesions are totally invisible on X-rays. On the other hand those regions which minimally overlap with clearly visible pathology on the X-ray are preserved. Similar complex situations were observed in the heart/diaphragm regions due to lesion masking by overlapping structure/organs in the projection image. We clarified these issues in the attached revision.</p>

  <p>Hope all changes improve the clarify of this paper.</p>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0730-12-31
      -->
      <!--
      
        ,
        updated at 
        0731-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Modalities - other"
        class="post-category">
        Modalities - other
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Lung"
        class="post-category">
        Clinical applications - Lung
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Domain adaptation"
        class="post-category">
        Machine Learning - Domain adaptation
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Tan, Tao"
        class="post-category">
        Tan, Tao
      </a> |  
      
      <a href="kittywong/tags#Das, Bipul"
        class="post-category">
        Das, Bipul
      </a> |  
      
      <a href="kittywong/tags#Soni, Ravi"
        class="post-category">
        Soni, Ravi
      </a> |  
      
      <a href="kittywong/tags#Fejes, Mate"
        class="post-category">
        Fejes, Mate
      </a> |  
      
      <a href="kittywong/tags#Ranjan, Sohan"
        class="post-category">
        Ranjan, Sohan
      </a> |  
      
      <a href="kittywong/tags#Szabo, Daniel Attila"
        class="post-category">
        Szabo, Daniel Attila
      </a> |  
      
      <a href="kittywong/tags#Melapudi, Vikram"
        class="post-category">
        Melapudi, Vikram
      </a> |  
      
      <a href="kittywong/tags#Shriram, K S"
        class="post-category">
        Shriram, K S
      </a> |  
      
      <a href="kittywong/tags#Agrawal, Utkarsh"
        class="post-category">
        Agrawal, Utkarsh
      </a> |  
      
      <a href="kittywong/tags#Ruskó, László"
        class="post-category">
        Ruskó, László
      </a> |  
      
      <a href="kittywong/tags#Herczeg, Zita"
        class="post-category">
        Herczeg, Zita
      </a> |  
      
      <a href="kittywong/tags#Darazs, Barbara"
        class="post-category">
        Darazs, Barbara
      </a> |  
      
      <a href="kittywong/tags#Tegzes, Pal"
        class="post-category">
        Tegzes, Pal
      </a> |  
      
      <a href="kittywong/tags#Ferenczi, Lehel"
        class="post-category">
        Ferenczi, Lehel
      </a> |  
      
      <a href="kittywong/tags#Mullick, Rakesh"
        class="post-category">
        Mullick, Rakesh
      </a> |  
      
      <a href="kittywong/tags#Avinash, Gopal"
        class="post-category">
        Avinash, Gopal
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0731/12/31/Paper1946">
          Determination of error in 3D CT to 2D fluoroscopy image registration for endobronchial guidance
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0729/12/31/Paper1644">
          Perceptual Quality Assessment of Chest Radiograph
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
