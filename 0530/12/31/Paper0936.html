<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Balanced-MixUp for highly imbalanced medical image classification | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Balanced-MixUp for highly imbalanced medical image classification" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Adrian Galdran, Gustavo Carneiro, Miguel A. González Ballester Abstract Highly imbalanced datasets are ubiquitous in medical image classification problems. In such problems, it is often the case that rare classes associated to less prevalent diseases are severely under-represented in labeled databases, typically resulting in poor performance of machine learning algorithms due to overfitting in the learning process. In this paper, we propose a novel mechanism for sampling training data based on the popular MixUp regularization technique, which we refer to as Balanced-MixUp. In short, Balanced-MixUp simultaneously performs regular (i.e., instance-based) and balanced (i.e., class-based) sampling of the training data. The resulting two sets of samples are then mixed-up to create a more balanced training distribution from which a neural network can effectively learn without incurring in heavily under-fitting the minority classes. We experiment with a highly imbalanced dataset of retinal images (55K samples, 5 classes) and a long-tail dataset of gastro-intestinal video frames (10K images, 23 classes), using two CNNs of varying representation capabilities. Experimental results demonstrate that applying Balanced-MixUp outperforms other conventional sampling schemes and loss functions specifically designed to deal with imbalanced data. Code to reproduce our results is released at \url{github.com/…}. Link to paper https://doi.org/10.1007/978-3-030-87240-3_31 Link to the code repository https://github.com/agaldran/balanced_mixup Link to the dataset(s) https://www.kaggle.com/c/diabetic-retinopathy-detection https://osf.io/mh9sj/ Reviews Review #1 Please describe the contribution of the paper The paper addresses a very important problem of medical domain, which is the issue of data skew. They have proposed a Balanced Mix-up sampling technique, which is focused on using regular instance-based and class-sampling based strategies. They have implemented this sampling strategies on 2 different classification tasks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The approach is good and it is kind of a smart technique, including the modification in existing methods. The implementation is also clear and well explained. While dealing with a very important technical issue in medical domain, the paper does not give a very novel solution, but seems to be an effective solution. The authors have provided various other methods to show the effectiveness of their approach. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. At some places, some sentences are not clear, for e.g., in Section 2.3. It should be elaborated well. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors provide a good explanation of used method, and also they are willing to give their codes also, on some repository. The paper seems to be reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html At some point, the author should give more explanation, for e.g., what is significance of selected values of alpha in Section 2.1, and How did you obtain the three values of alpha as 0.1, 0.2 and 0.3. We see that proposed method outerperforms the existing sampling methods but the performance is slightly better than instance-sampling. Does this much difference significant in presented classification scenarios, where we have sufficient test samples. The authors should provide performance measures without using any data augmentation method also. Please follow a common format for references. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good problem to attempt. Smart solution of the problem statement but lack of technical novelty. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This work proposes Balanced-MixUp to address imbalanced medical image classification. The main idea is to combine MixUp regularization and sampling strategies in a unified framework. Experimental results for imbalanced diabetic retinopathy grading and gastrointestinal classification demonstrate its effectiveness. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1) This paper is well-written and easy to understand. 2) The proposed method is easy to implement. 3) Quantitative experiments well validate the core idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1) The novelty is rather limited, since combing the MixUp and two-branch-resampling strategy has been proposed in BBN [1], and the proposed method is a special case of BBN (if conducting the mixup strategy in the image space). Though the proposed method works for medical image classification, BBN should be discussed in related works and comparison experiments. Reference: [1] BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition, CVPR 2020. 2) The performance improvement is limited compared with the baseline (instance-sampling). After all, there is no re-balancing strategy is used in baseline. Instead, the proposed method includes a hyper-parameter (\alpha) that somehow makes the result sensitive. 3) In Tabel 1 and 3, the results of MixUp should be listed, which will be helpful to quantify the performance improvement of the proposed method, brought by regularization or rebalancing. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance 1) The proposed method is validated on two public datasets, i.e., Eyepacs database and Hyper-Kvasir dataset. 2) The authors have promised releasing their source code, if the paper is accepted. 3) The implementation details are sufficient to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The differences between the proposed method and BBN should be carefully discussed. 2) Considering that most of the comparison methods fails to outperfom the baseline, finding out the reasons of this phenomenon may be meaningful. 3) The ablation analysis on removing the class-balanced resampling (i.e., only instance sampling and mixup strategy are used) should be necessary to quantify the contributions (regularization or rebalancing). Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The noverity of the proposed method is rather limited, and it appears like a special case of the previouly proposed BBN (Zhou et al.). What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper presents a novel data augmentation scheme, Balanced-MixUp to overcome imbalance-related poor performance in medical image classification problems. The authors build their technique upon an existing new data augmentation method, mixup which generates new training data sample by convex combinations of two data samples as well as their corresponding labels. This paper proposes to sample two data points using both instance- and class-based sampling procedure instead of random sampling proposed in the original mixup algorithm. Balanced-MixUp was shown to improve the performance in majority of the cases in both diabetic retinopathy grading and gastrointestinal image classification tasks across different datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A novel formulation for data augmentation Well-written paper High motivation: the addressed problem important and highly occurring in medical image applications Benchmarking with different methods on different tasks and on different datasets Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Lack of theoretical justification Marginal improvement in most of the cases Missing -important- baseline (comparison to mixup) Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors claim in the abstract that their code to reproduce the results will be made available. In additional, they also provided enough details about training parametrization in the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper presents a very interesting approach to overcome imbalanced data problem and overall, I am positive about its acceptance. However, there are a few concerns that I want to bring up as follows: The authors claim in Sec. 2.3 that combining instance-based and class-based sampling will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. How do the authors support this? This might be my lack of understanding, but this does not look so obvious to understand. Is there any theoretical justification of this claim? Why did the authors deviate from the original mixup formulation and used Beta(\alpha, 1)? Is this some empirical finding? There is an important missing experiment: the authors did not compare their method to the mixup technique, which should be the very first comparison to be shown in the paper. Since Balanced-MixUp basically derived from mixup, the benefits of the new method should be first shown over mixup before other techniques. I am personally curious to see how would the mixup method perform on the same tasks. It would be interesting to see how the new generated samples look like with the corresponding mixed training samples and \lambda parameter. The authors mention about higher performance of some published works ([11, 29]) on Eyepacs set. Could this approach be used with them and improve those mentioned works’ performances even more? Is there any limitation of the method or the cases where it led to worse performance? It would be nice if the authors can comment on this. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I believe the paper addresses an important problem, proposes an interesting solution and shows improved performances. However, I believe the claims made could be supported better and a few additional experiments are needed (see my comments above). What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses the issue of data imbalance by proposing the use of a data augmentation scheme. The paper addresses a very important topic for the MICCAI audience and shows experiments on two independent datasets. However, the reviewers have raised several questions regarding theoretical justification, questions about the comparison to baseline, clarity in explanation compared to BBN and novelty. Please respond to these in your rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal seems to address most of the concerns of the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Basically, the reviews are positive and consistent. And the authors’ response clarifies some details especially on the comparison with the baseline and BBN, which convinces me to recognize its novelty. In general, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The proposed solution is an improvement upon existing MixUp augmentation strategies. The presentation is solid and clear and the answers to the reviewers point clarify further the originality of the work. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Author Feedback We thank reviewers for finding our work interesting and with potential impact for the MICCAI community. Please find below our responses to their comments. 1) Reviewers 2 and 3 stress the need of including the performance of MixUp alone as a baseline in our experiments. We agree on the relevance of such comparison, and report now that analysis. Our findings indicate that MixUp regularization only brings a performance improvement when compared to standard instance-based sampling in the endoscopic image analysis experiment for the MobileNet architecture. In this case, performance is better than most of the other techniques, but MixUp still underperforms our proposed approach. For all other experiments (endoscopic with ResNext50 and retinal imaging with both architectures), MixUp alone leads to a decrease in performance. These results seem to reinforce the conclusion that Balanced MixUp is indeed an effective extension of MixUp for the imbalanced classification scenario. Our tables have been updated accordingly. 2) Reviewer 2 finds some similarities between our technique and a CVPR 2020 paper (BBN), and suggests a discussion of the differences between both methods. After careful analysis of the BBN technique, we agree that both approaches share some common patterns, but respectfully disagree with R2’s comment on our technique being a special case of BBN. The main difference between BBN and our method lies on the point in which data points are combined: unlike our approach that mixes data in the input image space, BBN mixes data in the feature space, which brings it closer to other techniques like SMOTE or Manifold MixUp. Another relevant difference is that BBN uses a Reversed Sampler that will draw much more frequently minority examples than our Class-balanced sampling, helping to prevent overfitting. Last, BBN has an extra layer of complexity due to the presence of a Cumulative Learning module, which requires to know beforehand the number of epochs for which the model will be trained, and introduces an extra hyperparameter in the “Adaptor layer”. In short, we believe that our Balanced MixUp is a more adequate technique for medical data imbalancing scenarios. We will add part of this discussion to our literature review. 3) Reviewers 1 and 3 mention lack of clarity in some of our explanations. In particular, both reviewers wonder why we selected Beta(\alpha, 1) with \alpha=0.1, 0.2, 0.3 as our mixing distribution. First, we apologize for a typo in eq. 3 which may have led to some confusion: \lambda and 1-\lambda should be swapped here. Second, the rationale behind our choice is that we intend to avoid the excessive sampling of minority class examples, which can easily lead to overfitting. By formulating our method like this, as \alpha tends to 0 we recover the standard instance-based sampling, whereas as \alpha increases we add more minority-class samples to the mix, which results in a hyperparameter that behaves more intuitively for the user. 4) Reviewer 3 asks why our approach will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. We admit a lack of theoretical analysis at this point, which is beyond the scope of this work and will be considered in the future. To compensate, we included Fig. 2 to give an intuition about why this is the case. In this image, the right hand side subplot shows schematically the impact of Balanced MixUp on the examples the model observes, where convex combinations of minority and majority class examples result in a less sparse data space. This is to be compared with regular instance-based sampling (leftmost subplot) and conventional oversampling (center subplot), where the sampling patterns contribute nothing to populate the data manifold. We would like to thank the AC for constructive criticism, and hope our response will clarify the most relevant doubts highlighted by reviewers. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Adrian Galdran, Gustavo Carneiro, Miguel A. González Ballester Abstract Highly imbalanced datasets are ubiquitous in medical image classification problems. In such problems, it is often the case that rare classes associated to less prevalent diseases are severely under-represented in labeled databases, typically resulting in poor performance of machine learning algorithms due to overfitting in the learning process. In this paper, we propose a novel mechanism for sampling training data based on the popular MixUp regularization technique, which we refer to as Balanced-MixUp. In short, Balanced-MixUp simultaneously performs regular (i.e., instance-based) and balanced (i.e., class-based) sampling of the training data. The resulting two sets of samples are then mixed-up to create a more balanced training distribution from which a neural network can effectively learn without incurring in heavily under-fitting the minority classes. We experiment with a highly imbalanced dataset of retinal images (55K samples, 5 classes) and a long-tail dataset of gastro-intestinal video frames (10K images, 23 classes), using two CNNs of varying representation capabilities. Experimental results demonstrate that applying Balanced-MixUp outperforms other conventional sampling schemes and loss functions specifically designed to deal with imbalanced data. Code to reproduce our results is released at \url{github.com/…}. Link to paper https://doi.org/10.1007/978-3-030-87240-3_31 Link to the code repository https://github.com/agaldran/balanced_mixup Link to the dataset(s) https://www.kaggle.com/c/diabetic-retinopathy-detection https://osf.io/mh9sj/ Reviews Review #1 Please describe the contribution of the paper The paper addresses a very important problem of medical domain, which is the issue of data skew. They have proposed a Balanced Mix-up sampling technique, which is focused on using regular instance-based and class-sampling based strategies. They have implemented this sampling strategies on 2 different classification tasks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The approach is good and it is kind of a smart technique, including the modification in existing methods. The implementation is also clear and well explained. While dealing with a very important technical issue in medical domain, the paper does not give a very novel solution, but seems to be an effective solution. The authors have provided various other methods to show the effectiveness of their approach. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. At some places, some sentences are not clear, for e.g., in Section 2.3. It should be elaborated well. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors provide a good explanation of used method, and also they are willing to give their codes also, on some repository. The paper seems to be reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html At some point, the author should give more explanation, for e.g., what is significance of selected values of alpha in Section 2.1, and How did you obtain the three values of alpha as 0.1, 0.2 and 0.3. We see that proposed method outerperforms the existing sampling methods but the performance is slightly better than instance-sampling. Does this much difference significant in presented classification scenarios, where we have sufficient test samples. The authors should provide performance measures without using any data augmentation method also. Please follow a common format for references. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good problem to attempt. Smart solution of the problem statement but lack of technical novelty. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This work proposes Balanced-MixUp to address imbalanced medical image classification. The main idea is to combine MixUp regularization and sampling strategies in a unified framework. Experimental results for imbalanced diabetic retinopathy grading and gastrointestinal classification demonstrate its effectiveness. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1) This paper is well-written and easy to understand. 2) The proposed method is easy to implement. 3) Quantitative experiments well validate the core idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1) The novelty is rather limited, since combing the MixUp and two-branch-resampling strategy has been proposed in BBN [1], and the proposed method is a special case of BBN (if conducting the mixup strategy in the image space). Though the proposed method works for medical image classification, BBN should be discussed in related works and comparison experiments. Reference: [1] BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition, CVPR 2020. 2) The performance improvement is limited compared with the baseline (instance-sampling). After all, there is no re-balancing strategy is used in baseline. Instead, the proposed method includes a hyper-parameter (\alpha) that somehow makes the result sensitive. 3) In Tabel 1 and 3, the results of MixUp should be listed, which will be helpful to quantify the performance improvement of the proposed method, brought by regularization or rebalancing. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance 1) The proposed method is validated on two public datasets, i.e., Eyepacs database and Hyper-Kvasir dataset. 2) The authors have promised releasing their source code, if the paper is accepted. 3) The implementation details are sufficient to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The differences between the proposed method and BBN should be carefully discussed. 2) Considering that most of the comparison methods fails to outperfom the baseline, finding out the reasons of this phenomenon may be meaningful. 3) The ablation analysis on removing the class-balanced resampling (i.e., only instance sampling and mixup strategy are used) should be necessary to quantify the contributions (regularization or rebalancing). Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The noverity of the proposed method is rather limited, and it appears like a special case of the previouly proposed BBN (Zhou et al.). What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper presents a novel data augmentation scheme, Balanced-MixUp to overcome imbalance-related poor performance in medical image classification problems. The authors build their technique upon an existing new data augmentation method, mixup which generates new training data sample by convex combinations of two data samples as well as their corresponding labels. This paper proposes to sample two data points using both instance- and class-based sampling procedure instead of random sampling proposed in the original mixup algorithm. Balanced-MixUp was shown to improve the performance in majority of the cases in both diabetic retinopathy grading and gastrointestinal image classification tasks across different datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A novel formulation for data augmentation Well-written paper High motivation: the addressed problem important and highly occurring in medical image applications Benchmarking with different methods on different tasks and on different datasets Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Lack of theoretical justification Marginal improvement in most of the cases Missing -important- baseline (comparison to mixup) Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors claim in the abstract that their code to reproduce the results will be made available. In additional, they also provided enough details about training parametrization in the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper presents a very interesting approach to overcome imbalanced data problem and overall, I am positive about its acceptance. However, there are a few concerns that I want to bring up as follows: The authors claim in Sec. 2.3 that combining instance-based and class-based sampling will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. How do the authors support this? This might be my lack of understanding, but this does not look so obvious to understand. Is there any theoretical justification of this claim? Why did the authors deviate from the original mixup formulation and used Beta(\alpha, 1)? Is this some empirical finding? There is an important missing experiment: the authors did not compare their method to the mixup technique, which should be the very first comparison to be shown in the paper. Since Balanced-MixUp basically derived from mixup, the benefits of the new method should be first shown over mixup before other techniques. I am personally curious to see how would the mixup method perform on the same tasks. It would be interesting to see how the new generated samples look like with the corresponding mixed training samples and \lambda parameter. The authors mention about higher performance of some published works ([11, 29]) on Eyepacs set. Could this approach be used with them and improve those mentioned works’ performances even more? Is there any limitation of the method or the cases where it led to worse performance? It would be nice if the authors can comment on this. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I believe the paper addresses an important problem, proposes an interesting solution and shows improved performances. However, I believe the claims made could be supported better and a few additional experiments are needed (see my comments above). What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses the issue of data imbalance by proposing the use of a data augmentation scheme. The paper addresses a very important topic for the MICCAI audience and shows experiments on two independent datasets. However, the reviewers have raised several questions regarding theoretical justification, questions about the comparison to baseline, clarity in explanation compared to BBN and novelty. Please respond to these in your rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal seems to address most of the concerns of the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Basically, the reviews are positive and consistent. And the authors’ response clarifies some details especially on the comparison with the baseline and BBN, which convinces me to recognize its novelty. In general, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The proposed solution is an improvement upon existing MixUp augmentation strategies. The presentation is solid and clear and the answers to the reviewers point clarify further the originality of the work. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Author Feedback We thank reviewers for finding our work interesting and with potential impact for the MICCAI community. Please find below our responses to their comments. 1) Reviewers 2 and 3 stress the need of including the performance of MixUp alone as a baseline in our experiments. We agree on the relevance of such comparison, and report now that analysis. Our findings indicate that MixUp regularization only brings a performance improvement when compared to standard instance-based sampling in the endoscopic image analysis experiment for the MobileNet architecture. In this case, performance is better than most of the other techniques, but MixUp still underperforms our proposed approach. For all other experiments (endoscopic with ResNext50 and retinal imaging with both architectures), MixUp alone leads to a decrease in performance. These results seem to reinforce the conclusion that Balanced MixUp is indeed an effective extension of MixUp for the imbalanced classification scenario. Our tables have been updated accordingly. 2) Reviewer 2 finds some similarities between our technique and a CVPR 2020 paper (BBN), and suggests a discussion of the differences between both methods. After careful analysis of the BBN technique, we agree that both approaches share some common patterns, but respectfully disagree with R2’s comment on our technique being a special case of BBN. The main difference between BBN and our method lies on the point in which data points are combined: unlike our approach that mixes data in the input image space, BBN mixes data in the feature space, which brings it closer to other techniques like SMOTE or Manifold MixUp. Another relevant difference is that BBN uses a Reversed Sampler that will draw much more frequently minority examples than our Class-balanced sampling, helping to prevent overfitting. Last, BBN has an extra layer of complexity due to the presence of a Cumulative Learning module, which requires to know beforehand the number of epochs for which the model will be trained, and introduces an extra hyperparameter in the “Adaptor layer”. In short, we believe that our Balanced MixUp is a more adequate technique for medical data imbalancing scenarios. We will add part of this discussion to our literature review. 3) Reviewers 1 and 3 mention lack of clarity in some of our explanations. In particular, both reviewers wonder why we selected Beta(\alpha, 1) with \alpha=0.1, 0.2, 0.3 as our mixing distribution. First, we apologize for a typo in eq. 3 which may have led to some confusion: \lambda and 1-\lambda should be swapped here. Second, the rationale behind our choice is that we intend to avoid the excessive sampling of minority class examples, which can easily lead to overfitting. By formulating our method like this, as \alpha tends to 0 we recover the standard instance-based sampling, whereas as \alpha increases we add more minority-class samples to the mix, which results in a hyperparameter that behaves more intuitively for the user. 4) Reviewer 3 asks why our approach will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. We admit a lack of theoretical analysis at this point, which is beyond the scope of this work and will be considered in the future. To compensate, we included Fig. 2 to give an intuition about why this is the case. In this image, the right hand side subplot shows schematically the impact of Balanced MixUp on the examples the model observes, where convex combinations of minority and majority class examples result in a less sparse data space. This is to be compared with regular instance-based sampling (leftmost subplot) and conventional oversampling (center subplot), where the sampling patterns contribute nothing to populate the data manifold. We would like to thank the AC for constructive criticism, and hope our response will clarify the most relevant doubts highlighted by reviewers. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0530/12/31/Paper0936" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0530/12/31/Paper0936" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0530-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Balanced-MixUp for highly imbalanced medical image classification" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0530/12/31/Paper0936"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0530/12/31/Paper0936","headline":"Balanced-MixUp for highly imbalanced medical image classification","dateModified":"0531-01-03T00:00:00-05:17","datePublished":"0530-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Adrian Galdran, Gustavo Carneiro, Miguel A. González Ballester Abstract Highly imbalanced datasets are ubiquitous in medical image classification problems. In such problems, it is often the case that rare classes associated to less prevalent diseases are severely under-represented in labeled databases, typically resulting in poor performance of machine learning algorithms due to overfitting in the learning process. In this paper, we propose a novel mechanism for sampling training data based on the popular MixUp regularization technique, which we refer to as Balanced-MixUp. In short, Balanced-MixUp simultaneously performs regular (i.e., instance-based) and balanced (i.e., class-based) sampling of the training data. The resulting two sets of samples are then mixed-up to create a more balanced training distribution from which a neural network can effectively learn without incurring in heavily under-fitting the minority classes. We experiment with a highly imbalanced dataset of retinal images (55K samples, 5 classes) and a long-tail dataset of gastro-intestinal video frames (10K images, 23 classes), using two CNNs of varying representation capabilities. Experimental results demonstrate that applying Balanced-MixUp outperforms other conventional sampling schemes and loss functions specifically designed to deal with imbalanced data. Code to reproduce our results is released at \\url{github.com/…}. Link to paper https://doi.org/10.1007/978-3-030-87240-3_31 Link to the code repository https://github.com/agaldran/balanced_mixup Link to the dataset(s) https://www.kaggle.com/c/diabetic-retinopathy-detection https://osf.io/mh9sj/ Reviews Review #1 Please describe the contribution of the paper The paper addresses a very important problem of medical domain, which is the issue of data skew. They have proposed a Balanced Mix-up sampling technique, which is focused on using regular instance-based and class-sampling based strategies. They have implemented this sampling strategies on 2 different classification tasks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The approach is good and it is kind of a smart technique, including the modification in existing methods. The implementation is also clear and well explained. While dealing with a very important technical issue in medical domain, the paper does not give a very novel solution, but seems to be an effective solution. The authors have provided various other methods to show the effectiveness of their approach. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. At some places, some sentences are not clear, for e.g., in Section 2.3. It should be elaborated well. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors provide a good explanation of used method, and also they are willing to give their codes also, on some repository. The paper seems to be reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html At some point, the author should give more explanation, for e.g., what is significance of selected values of alpha in Section 2.1, and How did you obtain the three values of alpha as 0.1, 0.2 and 0.3. We see that proposed method outerperforms the existing sampling methods but the performance is slightly better than instance-sampling. Does this much difference significant in presented classification scenarios, where we have sufficient test samples. The authors should provide performance measures without using any data augmentation method also. Please follow a common format for references. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good problem to attempt. Smart solution of the problem statement but lack of technical novelty. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Somewhat confident Review #2 Please describe the contribution of the paper This work proposes Balanced-MixUp to address imbalanced medical image classification. The main idea is to combine MixUp regularization and sampling strategies in a unified framework. Experimental results for imbalanced diabetic retinopathy grading and gastrointestinal classification demonstrate its effectiveness. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. 1) This paper is well-written and easy to understand. 2) The proposed method is easy to implement. 3) Quantitative experiments well validate the core idea. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. 1) The novelty is rather limited, since combing the MixUp and two-branch-resampling strategy has been proposed in BBN [1], and the proposed method is a special case of BBN (if conducting the mixup strategy in the image space). Though the proposed method works for medical image classification, BBN should be discussed in related works and comparison experiments. Reference: [1] BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition, CVPR 2020. 2) The performance improvement is limited compared with the baseline (instance-sampling). After all, there is no re-balancing strategy is used in baseline. Instead, the proposed method includes a hyper-parameter (\\alpha) that somehow makes the result sensitive. 3) In Tabel 1 and 3, the results of MixUp should be listed, which will be helpful to quantify the performance improvement of the proposed method, brought by regularization or rebalancing. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance 1) The proposed method is validated on two public datasets, i.e., Eyepacs database and Hyper-Kvasir dataset. 2) The authors have promised releasing their source code, if the paper is accepted. 3) The implementation details are sufficient to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html 1) The differences between the proposed method and BBN should be carefully discussed. 2) Considering that most of the comparison methods fails to outperfom the baseline, finding out the reasons of this phenomenon may be meaningful. 3) The ablation analysis on removing the class-balanced resampling (i.e., only instance sampling and mixup strategy are used) should be necessary to quantify the contributions (regularization or rebalancing). Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The noverity of the proposed method is rather limited, and it appears like a special case of the previouly proposed BBN (Zhou et al.). What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper This paper presents a novel data augmentation scheme, Balanced-MixUp to overcome imbalance-related poor performance in medical image classification problems. The authors build their technique upon an existing new data augmentation method, mixup which generates new training data sample by convex combinations of two data samples as well as their corresponding labels. This paper proposes to sample two data points using both instance- and class-based sampling procedure instead of random sampling proposed in the original mixup algorithm. Balanced-MixUp was shown to improve the performance in majority of the cases in both diabetic retinopathy grading and gastrointestinal image classification tasks across different datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. A novel formulation for data augmentation Well-written paper High motivation: the addressed problem important and highly occurring in medical image applications Benchmarking with different methods on different tasks and on different datasets Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Lack of theoretical justification Marginal improvement in most of the cases Missing -important- baseline (comparison to mixup) Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors claim in the abstract that their code to reproduce the results will be made available. In additional, they also provided enough details about training parametrization in the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html This paper presents a very interesting approach to overcome imbalanced data problem and overall, I am positive about its acceptance. However, there are a few concerns that I want to bring up as follows: The authors claim in Sec. 2.3 that combining instance-based and class-based sampling will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. How do the authors support this? This might be my lack of understanding, but this does not look so obvious to understand. Is there any theoretical justification of this claim? Why did the authors deviate from the original mixup formulation and used Beta(\\alpha, 1)? Is this some empirical finding? There is an important missing experiment: the authors did not compare their method to the mixup technique, which should be the very first comparison to be shown in the paper. Since Balanced-MixUp basically derived from mixup, the benefits of the new method should be first shown over mixup before other techniques. I am personally curious to see how would the mixup method perform on the same tasks. It would be interesting to see how the new generated samples look like with the corresponding mixed training samples and \\lambda parameter. The authors mention about higher performance of some published works ([11, 29]) on Eyepacs set. Could this approach be used with them and improve those mentioned works’ performances even more? Is there any limitation of the method or the cases where it led to worse performance? It would be nice if the authors can comment on this. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I believe the paper addresses an important problem, proposes an interesting solution and shows improved performances. However, I believe the claims made could be supported better and a few additional experiments are needed (see my comments above). What is the ranking of this paper in your review stack? 2 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper addresses the issue of data imbalance by proposing the use of a data augmentation scheme. The paper addresses a very important topic for the MICCAI audience and shows experiments on two independent datasets. However, the reviewers have raised several questions regarding theoretical justification, questions about the comparison to baseline, clarity in explanation compared to BBN and novelty. Please respond to these in your rebuttal. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal seems to address most of the concerns of the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Basically, the reviews are positive and consistent. And the authors’ response clarifies some details especially on the comparison with the baseline and BBN, which convinces me to recognize its novelty. In general, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The proposed solution is an improvement upon existing MixUp augmentation strategies. The presentation is solid and clear and the answers to the reviewers point clarify further the originality of the work. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 6 Author Feedback We thank reviewers for finding our work interesting and with potential impact for the MICCAI community. Please find below our responses to their comments. 1) Reviewers 2 and 3 stress the need of including the performance of MixUp alone as a baseline in our experiments. We agree on the relevance of such comparison, and report now that analysis. Our findings indicate that MixUp regularization only brings a performance improvement when compared to standard instance-based sampling in the endoscopic image analysis experiment for the MobileNet architecture. In this case, performance is better than most of the other techniques, but MixUp still underperforms our proposed approach. For all other experiments (endoscopic with ResNext50 and retinal imaging with both architectures), MixUp alone leads to a decrease in performance. These results seem to reinforce the conclusion that Balanced MixUp is indeed an effective extension of MixUp for the imbalanced classification scenario. Our tables have been updated accordingly. 2) Reviewer 2 finds some similarities between our technique and a CVPR 2020 paper (BBN), and suggests a discussion of the differences between both methods. After careful analysis of the BBN technique, we agree that both approaches share some common patterns, but respectfully disagree with R2’s comment on our technique being a special case of BBN. The main difference between BBN and our method lies on the point in which data points are combined: unlike our approach that mixes data in the input image space, BBN mixes data in the feature space, which brings it closer to other techniques like SMOTE or Manifold MixUp. Another relevant difference is that BBN uses a Reversed Sampler that will draw much more frequently minority examples than our Class-balanced sampling, helping to prevent overfitting. Last, BBN has an extra layer of complexity due to the presence of a Cumulative Learning module, which requires to know beforehand the number of epochs for which the model will be trained, and introduces an extra hyperparameter in the “Adaptor layer”. In short, we believe that our Balanced MixUp is a more adequate technique for medical data imbalancing scenarios. We will add part of this discussion to our literature review. 3) Reviewers 1 and 3 mention lack of clarity in some of our explanations. In particular, both reviewers wonder why we selected Beta(\\alpha, 1) with \\alpha=0.1, 0.2, 0.3 as our mixing distribution. First, we apologize for a typo in eq. 3 which may have led to some confusion: \\lambda and 1-\\lambda should be swapped here. Second, the rationale behind our choice is that we intend to avoid the excessive sampling of minority class examples, which can easily lead to overfitting. By formulating our method like this, as \\alpha tends to 0 we recover the standard instance-based sampling, whereas as \\alpha increases we add more minority-class samples to the mix, which results in a hyperparameter that behaves more intuitively for the user. 4) Reviewer 3 asks why our approach will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. We admit a lack of theoretical analysis at this point, which is beyond the scope of this work and will be considered in the future. To compensate, we included Fig. 2 to give an intuition about why this is the case. In this image, the right hand side subplot shows schematically the impact of Balanced MixUp on the examples the model observes, where convex combinations of minority and majority class examples result in a less sparse data space. This is to be compared with regular instance-based sampling (leftmost subplot) and conventional oversampling (center subplot), where the sampling patterns contribute nothing to populate the data manifold. We would like to thank the AC for constructive criticism, and hope our response will clarify the most relevant doubts highlighted by reviewers. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Galdran, Adrian,Carneiro, Gustavo,González Ballester, Miguel A." />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Balanced-MixUp for highly imbalanced medical image classification</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Abdomen"
        class="post-category">
        Clinical applications - Abdomen
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Galdran, Adrian"
        class="post-tags">
        Galdran, Adrian
      </a> |  
      
      <a href="kittywong/tags#Carneiro, Gustavo"
        class="post-tags">
        Carneiro, Gustavo
      </a> |  
      
      <a href="kittywong/tags#González Ballester, Miguel A."
        class="post-tags">
        González Ballester, Miguel A.
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Adrian Galdran, Gustavo Carneiro, Miguel A. González Ballester
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Highly imbalanced datasets are ubiquitous in medical image classification problems. In such problems, it is often the case that rare classes associated to less prevalent diseases are severely under-represented in labeled databases, typically resulting in poor performance of machine learning algorithms due to overfitting in the learning process. In this paper, we propose a novel mechanism for sampling training data based on the popular MixUp regularization technique, which we refer to as Balanced-MixUp. In short, Balanced-MixUp simultaneously performs regular (i.e., instance-based) and balanced (i.e., class-based) sampling of the training data. The resulting two sets of samples are then mixed-up to create a more balanced training distribution from which a neural network can effectively learn without incurring in heavily under-fitting the minority classes. We experiment with a highly imbalanced dataset of retinal images (55K samples, 5 classes) and a long-tail dataset of gastro-intestinal video frames (10K images, 23 classes), using two CNNs of varying representation capabilities. Experimental results demonstrate that applying Balanced-MixUp outperforms other conventional sampling schemes and loss functions specifically designed to deal with imbalanced data. Code to reproduce our results is released at \url{github.com/…}.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87240-3_31">https://doi.org/10.1007/978-3-030-87240-3_31</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/agaldran/balanced_mixup
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://www.kaggle.com/c/diabetic-retinopathy-detection
https://osf.io/mh9sj/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper addresses a very important problem of medical domain, which is the issue of data skew. They have proposed a Balanced Mix-up sampling technique, which is focused on using regular instance-based and class-sampling based strategies. They have implemented this sampling strategies on 2 different classification tasks.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>The approach is good and it is kind of a smart technique, including the modification in existing methods.</li>
        <li>The implementation is also clear and well explained.</li>
        <li>While dealing with a very important technical issue in medical domain, the paper does not give a very novel solution, but seems to be an effective solution.</li>
        <li>The authors have provided various other methods to show the effectiveness of their approach.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>At some places, some sentences are not clear, for e.g., in Section 2.3. It should be elaborated well.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors provide a good explanation of used method, and also they are willing to give their codes also, on some repository. The paper seems to be reproducible.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>At some point, the author should give more explanation, for e.g., what is significance of selected values of alpha in Section 2.1, and How did you obtain the three values of alpha as 0.1, 0.2 and 0.3.</li>
        <li>We see that proposed method outerperforms the existing sampling methods but the performance is slightly better than instance-sampling. Does this much difference significant in presented classification scenarios, where we have sufficient test samples.</li>
        <li>The authors should provide performance measures without using any data augmentation method also.</li>
        <li>Please follow a common format for references.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Good problem to attempt. Smart solution of the problem statement but lack of technical novelty.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Somewhat confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This work proposes Balanced-MixUp to address imbalanced medical image classification. The main idea is to combine MixUp regularization and sampling strategies in a unified framework. Experimental results for imbalanced diabetic retinopathy grading and gastrointestinal classification demonstrate its effectiveness.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>1) This paper is well-written and easy to understand.
2) The proposed method is easy to implement.
3) Quantitative experiments well validate the core idea.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>1) The novelty is rather limited, since combing the MixUp and two-branch-resampling strategy has been proposed in BBN [1], and the proposed method is a special case of BBN (if conducting the mixup strategy in the image space). Though the proposed method works for medical image classification, BBN should be discussed in related works and comparison experiments.</p>

      <p>Reference:
[1] BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition, CVPR 2020.</p>

      <p>2) The performance improvement is limited compared with the baseline (instance-sampling). After all, there is no re-balancing strategy is used in baseline. Instead, the proposed method includes a hyper-parameter (\alpha) that somehow makes the result sensitive. 
3) In Tabel 1 and 3, the results of MixUp should be listed, which will be helpful to quantify the performance improvement of the proposed method, brought by regularization or rebalancing.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>1) The proposed method is validated on two public datasets, i.e., Eyepacs database and Hyper-Kvasir dataset.
2) The authors have promised releasing their source code, if the paper is accepted.
3) The implementation details are sufficient to reproduce the results.</p>

    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>1) The differences between the proposed method and BBN should be carefully discussed.
2) Considering that most of the comparison methods fails to outperfom the baseline, finding out the reasons of this phenomenon may be meaningful.
3)  The ablation analysis on removing the class-balanced resampling (i.e., only instance sampling and mixup strategy are used) should be necessary to quantify the contributions (regularization or rebalancing).</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The noverity of the proposed method is rather limited, and it appears like a special case of the previouly proposed BBN (Zhou et al.).</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper presents a novel data augmentation scheme, Balanced-MixUp to overcome imbalance-related poor performance in medical image classification problems. The authors build their technique upon an existing new data augmentation method, mixup which generates new training data sample by convex combinations of two data samples as well as their corresponding labels. This paper proposes to sample two data points using both instance- and class-based sampling procedure instead of random sampling proposed in the original mixup algorithm. Balanced-MixUp was shown to improve the performance in majority of the cases in both diabetic retinopathy grading and gastrointestinal image classification tasks across different datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>A novel formulation for data augmentation</li>
        <li>Well-written paper</li>
        <li>High motivation: the addressed problem important and highly occurring in medical image applications</li>
        <li>Benchmarking with different methods on different tasks and on different datasets</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>Lack of theoretical justification</li>
        <li>Marginal improvement in most of the cases</li>
        <li>Missing -important- baseline (comparison to mixup)</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors claim in the abstract that their code to reproduce the results will be made available. In additional, they also provided enough details about training parametrization in the paper.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>This paper presents a very interesting approach to overcome imbalanced data problem and overall, I am positive about its acceptance. However, there are a few concerns that I want to bring up as follows:</p>

      <ul>
        <li>The authors claim in Sec. 2.3 that combining instance-based and class-based sampling will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. How do the authors support this? This might be my lack of understanding, but this does not look so obvious to understand. Is there any theoretical justification of this claim?</li>
        <li>Why did the authors deviate from the original mixup formulation and used Beta(\alpha, 1)? Is this some empirical finding?</li>
        <li>There is an important missing experiment: the authors did not compare their method to the mixup technique, which should be the very first comparison to be shown in the paper. Since Balanced-MixUp basically derived from mixup, the benefits of the new method should be first shown over mixup before other techniques. I am personally curious to see how would the mixup method perform on the same tasks.</li>
        <li>It would be interesting to see how the new generated samples look like with the corresponding mixed training samples and \lambda parameter.</li>
        <li>The authors mention about higher performance of some published works ([11, 29]) on Eyepacs set. Could this approach be used with them and improve those mentioned works’ performances even more?</li>
        <li>Is there any limitation of the method or the cases where it led to worse performance? It would be nice if the authors can comment on this.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>I believe the paper addresses an important problem, proposes an interesting solution and shows improved performances. However, I believe the claims made could be supported better and a few additional experiments are needed (see my comments above).</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper addresses the issue of data imbalance by proposing the use of a data augmentation scheme. The paper addresses a very important topic for the MICCAI audience and shows experiments on two independent datasets. However, the reviewers have raised several questions regarding theoretical justification, questions about the comparison to baseline, clarity in explanation compared to BBN and novelty. Please respond to these in your rebuttal.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The rebuttal seems to address most of the concerns of the reviewers.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>7</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>Basically, the reviews are positive and consistent. And the authors’ response clarifies some details especially on the comparison with the baseline and BBN, which convinces me to recognize its novelty. In general, I agree to accept this paper.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The proposed solution is an improvement upon existing MixUp augmentation strategies. The presentation is solid and clear and the answers to the reviewers point clarify further the originality of the work.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>

  <p>We thank reviewers for finding our work interesting and with potential impact for the MICCAI community. Please find below our responses to their comments.</p>

  <p>1) Reviewers 2 and 3 stress the need of including the performance of MixUp alone as a baseline in our experiments. We agree on the relevance of such comparison, and report now that analysis. Our findings indicate that MixUp regularization only brings a performance improvement when compared to standard instance-based sampling in the endoscopic image analysis experiment for the MobileNet architecture. In this case, performance is better than most of the other techniques, but MixUp still underperforms our proposed approach. For all other experiments (endoscopic with ResNext50 and retinal imaging with both architectures), MixUp alone leads to a decrease in performance. These results seem to reinforce the conclusion that Balanced MixUp is indeed an effective extension of MixUp for the imbalanced classification scenario. Our tables have been updated accordingly.</p>

  <p>2) Reviewer 2 finds some similarities between our technique and a CVPR 2020 paper (BBN), and suggests a discussion of the differences between both methods. After careful analysis of the BBN technique, we agree that both approaches share some common patterns, but respectfully disagree with R2’s comment on our technique being a special case of BBN. The main difference between BBN and our method lies on the point in which data points are combined: unlike our approach that mixes data in the input image space, BBN mixes data in the feature space, which brings it closer to other techniques like SMOTE or Manifold MixUp. Another relevant difference is that BBN uses a Reversed Sampler that will draw much more frequently minority examples than our Class-balanced sampling, helping to prevent overfitting. Last, BBN has an extra layer of complexity due to the presence of a Cumulative Learning module, which requires to know beforehand the number of epochs for which the model will be trained, and introduces an extra hyperparameter in the “Adaptor layer”. In short, we believe that our Balanced MixUp is a more adequate technique for medical data imbalancing scenarios. We will add part of this discussion to our literature review.</p>

  <p>3) Reviewers 1 and 3 mention lack of clarity in some of our explanations. In particular, both reviewers wonder why we selected Beta(\alpha, 1) with \alpha=0.1, 0.2, 0.3 as our mixing distribution. First, we apologize for a typo in eq. 3 which may have led to some confusion: \lambda and 1-\lambda should be swapped here. Second, the rationale behind our choice is that we intend to avoid the excessive sampling of minority class examples, which can easily lead to overfitting. By formulating our method like this, as \alpha tends to 0 we recover the standard instance-based sampling, whereas as \alpha increases we add more minority-class samples to the mix, which results in a hyperparameter that behaves more intuitively for the user.</p>

  <p>4) Reviewer 3 asks why our approach will “induce a more balanced distribution of training examples by creating synthetic data points around regions of space where minority classes provide less data density”. We admit a lack of theoretical analysis at this point, which is beyond the scope of this work and will be considered in the future. To compensate, we included Fig. 2 to give an intuition about why this is the case. In this image, the right hand side subplot shows schematically the impact of Balanced MixUp on the examples the model observes, where convex combinations of minority and majority class examples result in a less sparse data space. This is to be compared with regular instance-based sampling (leftmost subplot) and conventional oversampling (center subplot), where the sampling patterns contribute nothing to populate the data manifold.</p>

  <p>We would like to thank the AC for constructive criticism, and hope our response will clarify the most relevant doubts highlighted by reviewers.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0530-12-31
      -->
      <!--
      
        ,
        updated at 
        0531-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Abdomen"
        class="post-category">
        Clinical applications - Abdomen
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Galdran, Adrian"
        class="post-category">
        Galdran, Adrian
      </a> |  
      
      <a href="kittywong/tags#Carneiro, Gustavo"
        class="post-category">
        Carneiro, Gustavo
      </a> |  
      
      <a href="kittywong/tags#González Ballester, Miguel A."
        class="post-category">
        González Ballester, Miguel A.
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0531/12/31/Paper0995">
          Transfer Learning of Deep Spatiotemporal Networks to Model Arbitrarily Long Videos of Seizures
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0529/12/31/Paper0934">
          MBFF-Net: Multi-Branch Feature Fusion Network for Carotid Plaque Segmentation in Ultrasound
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
