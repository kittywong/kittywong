<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Depth Estimation for Colonoscopy Images with Self-supervised Learning from Videos | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Depth Estimation for Colonoscopy Images with Self-supervised Learning from Videos" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Kai Cheng, Yiting Ma, Bin Sun, Yang Li, Xuejin Chen Abstract Depth estimation in colonoscopy images provides geometric clues for downstream medical analysis tasks, such as polyp detection, 3D reconstruction, and diagnosis. Recently, deep learning technology has made significant progress in monocular depth estimation for natural scenes. However, without sufficient ground truth of dense depth maps for colonoscopy images, it is significantly challenging to train deep neural networks for colonoscopy depth estimation. In this paper, we propose a novel approach that makes full use of both synthetic data and real colonoscopy videos. We use synthetic data with ground truth depth maps to train a depth estimation network with a generative adversarial network model. Despite the lack of ground truth depth, real colonoscopy videos are used to train the network in a self-supervision manner by exploiting temporal consistency between neighboring frames. Furthermore, we design a masked gradient warping loss in order to ensure temporal consistency with more reliable correspondences. We conducted both quantitative and qualitative analysis on an existing synthetic dataset and a set of real colonoscopy videos, demonstrating the superiority of our method on more accurate and consistent depth estimation for colonoscopy images. Link to paper https://doi.org/10.1007/978-3-030-87231-1_12 Link to the code repository https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Link to the dataset(s) https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Reviews Review #1 Please describe the contribution of the paper In this paper, authors proposed a method to estimate the depth from real colonoscopy video frames using both synthetic and real colonoscopy videos; first, they trained a pix2pix network (DepthNet) in an adversarial manner to learn depth only from synthetic data, second, they used temporal consistency as a constrained to finetune their DepthNet on real colonoscopy videos. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -Using temporal consistency as a constraint on depth estimation from real colonoscopy videos Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -PWC-Net is designed and trained on outdoor video frames, and thus can introduce extra error in computing optical flow from real colonoscopy video frames. -The depth estimation method could be compared with geometrical self-supervised deep learning method as well -It is not clear whether the synthetic data has occlusion map and why it has not been used in the training as it could help as an extra constraint. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance considering the explanation of the method in the paper, it seems to be reasonably reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In Fig.1. , it would be better to replace FlowNet with PWC-Net, FlowNet itself is an optical flow method. Using a gradient of depth could smooth the effect of reflection but as can be seen on the last two columns of Fig.2., the method introduced some noise on the top left of the depth map. This is common when using generative networks to map from RGB to normalized depth. Instead of two frames, a sequence of 5 or even 10 frames (based on the hardware capacity) can be used, this can help to deal with the reflection noise as it appears and disappears based on camera movement inside the colon Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Estimating depth to determine the size and location of polyps can be a helpful assistive tool for clinicians. Even though the authors have tried to address this problem, I believe more experiments and comparison with the current SOTA in the computer vision method is necessary, which lack in this paper. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper presents a novel strategy to estimate depth on colonoscopy images using a deep learning framework. The depth estimation is useful to obtain colonoscopy polyp clues that thereafter determine the aggressiveness of the disease. The main contribution of the proposed strategy is the training of a deep architecture over synthetic and real colonoscopy data which also exploit temporal consistency as constrain to achieve better deep map representations. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed approach apport novel components regarding the depth estimation of colonoscopy. For instance, the use of temporal consistency to avoid artifacts in resultant deep maps. Despite the use of synthetic data is widely implemented in the literature, the configuration and transfer scheme may be new on this application. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main drawback of paper lies in the evaluation and results. I summarize the weaknesses in the following lines: There is not a clear statistical difference between the approaches: “our baseline” and “ours” in Table 1. The authors argue that real data not make further improvements over synthetic representation. I consider that a more deep discussion should be done, illustrating also the train results to discard possible overfitting. There is not an ablation study to demonstrate the contribution of temporal component I am surprised that the results of other baseline approaches are not ilustrated over real sequences. The differences of performance in such dataset should stand out main advantages of the proposed approach. I think that a state-of-the-art comparison is mandatory in this work since in the literature there exist a lot of approximation with the main objective With respect to other works, I found that the dataset is limtied and other ground strategies should be considered. In fact, there exist tools during colonoscopy to obtain a better approximation of polyp size. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has potential to be reproduced because the description of methodology is clear. The code and dataset seems that is not public available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper introduce a novel approach to depth estimation of colonoscopy. A main and intersting contribution is the integration of temporal consistency to achieve better estimations of depth. The use of synthetic data and the retrining with real data is also interesting and could be a potential alternative to achieve robust 3D estimations. Nonetheless, I consider that evaluation of the proposed approach should be enriched regarding the state-of-the-art and also with respect to the apport of each component in the strategy. For instance, an ablation study may determine the apport of temporal information. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Althought the paper is interesting, the idea is novel and the application is into the domain of the conference, I consider that a further evaluation is demanding to know the advantage and limitations of the proposed approach. What is the ranking of this paper in your review stack? 6 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Uses both synthetic and real colonoscopy data to train a network for depth estimation from colonoscopy videos. Uses temporal consistency and introduces a masked gradient warping loss to train the network in a self-supervised manner. Achieves smoother and more consistent depth estimation than other methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Exploiting both synthetic and real data, and training the network in a self-supervised manner: Given the lack of real ground truth data which is the main challenge in the medical field, it is very important to develop a method that works around this problem. This paper attempts it by using synthetic data and self-supervision. Masked gradient warping loss: This paper introduces a new loss to enforce temporal consistency between neighbouring frames, which leads to smoother and more consistent depth estimation (but with its own disadvantage - see comments below). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Depth estimation at the sharp boundaries: I can see that the proposed method generates smoother depth at the locations with specularity, but the method makes the depth at sharp boundaries also quite smoother which is not very ideal. On the supplementary video, this depth bleeding at boundaries is more noticeable than in the figures. I think this might be from the gradient warping loss which could make the gradients at the boundaries small. No discussions on failure cases/limitations: I believe this will improve the quality of paper in general as well as help other researchers think about how to build upon the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It looks fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a question about Eq 3. Is this loss for pretraining on synthetic data as well as for finetuning on real data? If so, how is the GAN loss computed for finetuning? Unless I misunderstood it, this loss is for training pix2pixHD which requires paired images. So I am wondering what is the paired image for a real image here. As mentioned above, it would be great if the authors can add failure cases and discussions on the limitations of the method. Now, some minor comments: pp2: In the 3rd paragraph, ‘train a image translation’ -&gt; ‘train an image translation’. Sec 3.2: CGAN is not defined before. pp7: In line 2, ‘This is reasonable because that the self-supervision’ -&gt; remove ‘that’. pp7: in line 4, ‘it does not increase more information for the synthetic data.’ -&gt; ‘it does not increase the amount of information…’. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper addresses one of the main challenges in medical imaging, i.e. how to work around the lack of ground truth data in the real domain. This paper does it by exploiting both synthetic and real data in a self-supervised fashion with a novel masked gradient warping loss. This new loss enforces the temporal consistency between neighbouring frames which results in smoother depth estimation. However, there is an adverse effect in this approach: the estimated depth loses fidelity around sharp boundaries. I think this might hinder, e.g. reconstructing the correct 3D geometry of colon. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper describes a method to train a 3D depth estimation network from both simulated and real data. The contribution is a novel loss based on temporal consistency. Training such a network is a currently open problem given the lack of labeled data. This is hence a worthy contribution to publish. The paper should be revised according to the reviews for the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank the reviewers for their constructive comments. Here we would like to address some specific concerns and comments. [R1, R2] Comparison with SOTA methods. [Reply] We actually had tried several SOTA geometrical self-supervised learning methods such as Zhou et al. [23]. But suffering from the occlusions and non-Lambertian surfaces, the results are poor. The same conclusion can be found in Liu et al.’s work [6]. W.r.t. real colonoscopy videos, since there is no ground truth, it is difficult to make a quantitative comparison. The main contribution of our paper is proposing a novel strategy and loss to achieve more consistent and reasonable depth prediction for real colonoscopy videos without ground truths. The advantage is demonstrated by reconstructed depth maps for real data. We will release our data and code for comparison. [R1] Error from optical flow. [Reply] Due to the inevitable errors in optical flow estimation, we filter most pixels that have high optical flow errors by forward-backward consistency check (as described in the second paragraph of Sec. 2.2). Besides, the optical flow does not explicitly constrain the depth values but only provides extra temporal information for training, which is tolerant to small errors. Moreover, the optical flow is used only on the training stage, thus it does not introduce extra errors on the inference stage. [R1] Occlusion map of the synthetic data. [Reply] In the synthetic dataset released by Rau et al. [11], only the paired RGB images and depth maps are provided. The occlusion maps are not available. [R2] Ablation study and analysis of the contribution of temporal component. [Reply] According to our understanding, the temporal component refers to the elements in the depth gradient warping module, such as using the gradient of depth instead of depth, forward-backward warping distance check. We did an ablation study before, but due to the limitation of the number of pages in MICCAI, there may not be enough space for discussion on ablation study. [R2, R3] The limitations of the proposed approach. [Reply] Due to the limitation of the page, we did not discuss much about the limitations of our method. We did test our method on a large number of real colonoscopy videos. In general, our method produces reasonable depth estimation in a general colonoscopy environment. But it occasionally fails to recover the shape of small polyps that are difficult to distinguish from the background. Further discussions will be added to the paper. [R3] The adverse effect of the gradient loss. [Reply] The temporal consistency of the predicted depth is much more important than sharp boundaries for multi-view 3D reconstruction in our paper. Our framework is flexible to integrate existing solutions to strengthen boundaries, such as emphasizing the depth estimation error at boundaries on synthetic data. [R3] GAN loss for finetuning. [Reply] The GAN loss is computed with paired images from the synthetic dataset. It is not computed on the real data. During the finetuning stage, both synthetic data and real data are used to compute the loss in Eq. 3, while L_MGW is computed with real data and L_FM, L_GAN are computed with synthetic data. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Kai Cheng, Yiting Ma, Bin Sun, Yang Li, Xuejin Chen Abstract Depth estimation in colonoscopy images provides geometric clues for downstream medical analysis tasks, such as polyp detection, 3D reconstruction, and diagnosis. Recently, deep learning technology has made significant progress in monocular depth estimation for natural scenes. However, without sufficient ground truth of dense depth maps for colonoscopy images, it is significantly challenging to train deep neural networks for colonoscopy depth estimation. In this paper, we propose a novel approach that makes full use of both synthetic data and real colonoscopy videos. We use synthetic data with ground truth depth maps to train a depth estimation network with a generative adversarial network model. Despite the lack of ground truth depth, real colonoscopy videos are used to train the network in a self-supervision manner by exploiting temporal consistency between neighboring frames. Furthermore, we design a masked gradient warping loss in order to ensure temporal consistency with more reliable correspondences. We conducted both quantitative and qualitative analysis on an existing synthetic dataset and a set of real colonoscopy videos, demonstrating the superiority of our method on more accurate and consistent depth estimation for colonoscopy images. Link to paper https://doi.org/10.1007/978-3-030-87231-1_12 Link to the code repository https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Link to the dataset(s) https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Reviews Review #1 Please describe the contribution of the paper In this paper, authors proposed a method to estimate the depth from real colonoscopy video frames using both synthetic and real colonoscopy videos; first, they trained a pix2pix network (DepthNet) in an adversarial manner to learn depth only from synthetic data, second, they used temporal consistency as a constrained to finetune their DepthNet on real colonoscopy videos. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -Using temporal consistency as a constraint on depth estimation from real colonoscopy videos Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -PWC-Net is designed and trained on outdoor video frames, and thus can introduce extra error in computing optical flow from real colonoscopy video frames. -The depth estimation method could be compared with geometrical self-supervised deep learning method as well -It is not clear whether the synthetic data has occlusion map and why it has not been used in the training as it could help as an extra constraint. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance considering the explanation of the method in the paper, it seems to be reasonably reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In Fig.1. , it would be better to replace FlowNet with PWC-Net, FlowNet itself is an optical flow method. Using a gradient of depth could smooth the effect of reflection but as can be seen on the last two columns of Fig.2., the method introduced some noise on the top left of the depth map. This is common when using generative networks to map from RGB to normalized depth. Instead of two frames, a sequence of 5 or even 10 frames (based on the hardware capacity) can be used, this can help to deal with the reflection noise as it appears and disappears based on camera movement inside the colon Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Estimating depth to determine the size and location of polyps can be a helpful assistive tool for clinicians. Even though the authors have tried to address this problem, I believe more experiments and comparison with the current SOTA in the computer vision method is necessary, which lack in this paper. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper presents a novel strategy to estimate depth on colonoscopy images using a deep learning framework. The depth estimation is useful to obtain colonoscopy polyp clues that thereafter determine the aggressiveness of the disease. The main contribution of the proposed strategy is the training of a deep architecture over synthetic and real colonoscopy data which also exploit temporal consistency as constrain to achieve better deep map representations. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed approach apport novel components regarding the depth estimation of colonoscopy. For instance, the use of temporal consistency to avoid artifacts in resultant deep maps. Despite the use of synthetic data is widely implemented in the literature, the configuration and transfer scheme may be new on this application. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main drawback of paper lies in the evaluation and results. I summarize the weaknesses in the following lines: There is not a clear statistical difference between the approaches: “our baseline” and “ours” in Table 1. The authors argue that real data not make further improvements over synthetic representation. I consider that a more deep discussion should be done, illustrating also the train results to discard possible overfitting. There is not an ablation study to demonstrate the contribution of temporal component I am surprised that the results of other baseline approaches are not ilustrated over real sequences. The differences of performance in such dataset should stand out main advantages of the proposed approach. I think that a state-of-the-art comparison is mandatory in this work since in the literature there exist a lot of approximation with the main objective With respect to other works, I found that the dataset is limtied and other ground strategies should be considered. In fact, there exist tools during colonoscopy to obtain a better approximation of polyp size. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has potential to be reproduced because the description of methodology is clear. The code and dataset seems that is not public available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper introduce a novel approach to depth estimation of colonoscopy. A main and intersting contribution is the integration of temporal consistency to achieve better estimations of depth. The use of synthetic data and the retrining with real data is also interesting and could be a potential alternative to achieve robust 3D estimations. Nonetheless, I consider that evaluation of the proposed approach should be enriched regarding the state-of-the-art and also with respect to the apport of each component in the strategy. For instance, an ablation study may determine the apport of temporal information. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Althought the paper is interesting, the idea is novel and the application is into the domain of the conference, I consider that a further evaluation is demanding to know the advantage and limitations of the proposed approach. What is the ranking of this paper in your review stack? 6 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Uses both synthetic and real colonoscopy data to train a network for depth estimation from colonoscopy videos. Uses temporal consistency and introduces a masked gradient warping loss to train the network in a self-supervised manner. Achieves smoother and more consistent depth estimation than other methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Exploiting both synthetic and real data, and training the network in a self-supervised manner: Given the lack of real ground truth data which is the main challenge in the medical field, it is very important to develop a method that works around this problem. This paper attempts it by using synthetic data and self-supervision. Masked gradient warping loss: This paper introduces a new loss to enforce temporal consistency between neighbouring frames, which leads to smoother and more consistent depth estimation (but with its own disadvantage - see comments below). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Depth estimation at the sharp boundaries: I can see that the proposed method generates smoother depth at the locations with specularity, but the method makes the depth at sharp boundaries also quite smoother which is not very ideal. On the supplementary video, this depth bleeding at boundaries is more noticeable than in the figures. I think this might be from the gradient warping loss which could make the gradients at the boundaries small. No discussions on failure cases/limitations: I believe this will improve the quality of paper in general as well as help other researchers think about how to build upon the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It looks fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a question about Eq 3. Is this loss for pretraining on synthetic data as well as for finetuning on real data? If so, how is the GAN loss computed for finetuning? Unless I misunderstood it, this loss is for training pix2pixHD which requires paired images. So I am wondering what is the paired image for a real image here. As mentioned above, it would be great if the authors can add failure cases and discussions on the limitations of the method. Now, some minor comments: pp2: In the 3rd paragraph, ‘train a image translation’ -&gt; ‘train an image translation’. Sec 3.2: CGAN is not defined before. pp7: In line 2, ‘This is reasonable because that the self-supervision’ -&gt; remove ‘that’. pp7: in line 4, ‘it does not increase more information for the synthetic data.’ -&gt; ‘it does not increase the amount of information…’. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper addresses one of the main challenges in medical imaging, i.e. how to work around the lack of ground truth data in the real domain. This paper does it by exploiting both synthetic and real data in a self-supervised fashion with a novel masked gradient warping loss. This new loss enforces the temporal consistency between neighbouring frames which results in smoother depth estimation. However, there is an adverse effect in this approach: the estimated depth loses fidelity around sharp boundaries. I think this might hinder, e.g. reconstructing the correct 3D geometry of colon. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper describes a method to train a 3D depth estimation network from both simulated and real data. The contribution is a novel loss based on temporal consistency. Training such a network is a currently open problem given the lack of labeled data. This is hence a worthy contribution to publish. The paper should be revised according to the reviews for the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank the reviewers for their constructive comments. Here we would like to address some specific concerns and comments. [R1, R2] Comparison with SOTA methods. [Reply] We actually had tried several SOTA geometrical self-supervised learning methods such as Zhou et al. [23]. But suffering from the occlusions and non-Lambertian surfaces, the results are poor. The same conclusion can be found in Liu et al.’s work [6]. W.r.t. real colonoscopy videos, since there is no ground truth, it is difficult to make a quantitative comparison. The main contribution of our paper is proposing a novel strategy and loss to achieve more consistent and reasonable depth prediction for real colonoscopy videos without ground truths. The advantage is demonstrated by reconstructed depth maps for real data. We will release our data and code for comparison. [R1] Error from optical flow. [Reply] Due to the inevitable errors in optical flow estimation, we filter most pixels that have high optical flow errors by forward-backward consistency check (as described in the second paragraph of Sec. 2.2). Besides, the optical flow does not explicitly constrain the depth values but only provides extra temporal information for training, which is tolerant to small errors. Moreover, the optical flow is used only on the training stage, thus it does not introduce extra errors on the inference stage. [R1] Occlusion map of the synthetic data. [Reply] In the synthetic dataset released by Rau et al. [11], only the paired RGB images and depth maps are provided. The occlusion maps are not available. [R2] Ablation study and analysis of the contribution of temporal component. [Reply] According to our understanding, the temporal component refers to the elements in the depth gradient warping module, such as using the gradient of depth instead of depth, forward-backward warping distance check. We did an ablation study before, but due to the limitation of the number of pages in MICCAI, there may not be enough space for discussion on ablation study. [R2, R3] The limitations of the proposed approach. [Reply] Due to the limitation of the page, we did not discuss much about the limitations of our method. We did test our method on a large number of real colonoscopy videos. In general, our method produces reasonable depth estimation in a general colonoscopy environment. But it occasionally fails to recover the shape of small polyps that are difficult to distinguish from the background. Further discussions will be added to the paper. [R3] The adverse effect of the gradient loss. [Reply] The temporal consistency of the predicted depth is much more important than sharp boundaries for multi-view 3D reconstruction in our paper. Our framework is flexible to integrate existing solutions to strengthen boundaries, such as emphasizing the depth estimation error at boundaries on synthetic data. [R3] GAN loss for finetuning. [Reply] The GAN loss is computed with paired images from the synthetic dataset. It is not computed on the real data. During the finetuning stage, both synthetic data and real data are used to compute the loss in Eq. 3, while L_MGW is computed with real data and L_FM, L_GAN are computed with synthetic data. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0611/12/31/Paper0443" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0611/12/31/Paper0443" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0611-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Depth Estimation for Colonoscopy Images with Self-supervised Learning from Videos" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0611/12/31/Paper0443"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0611/12/31/Paper0443","headline":"Depth Estimation for Colonoscopy Images with Self-supervised Learning from Videos","dateModified":"0612-01-04T00:00:00-05:17","datePublished":"0611-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Kai Cheng, Yiting Ma, Bin Sun, Yang Li, Xuejin Chen Abstract Depth estimation in colonoscopy images provides geometric clues for downstream medical analysis tasks, such as polyp detection, 3D reconstruction, and diagnosis. Recently, deep learning technology has made significant progress in monocular depth estimation for natural scenes. However, without sufficient ground truth of dense depth maps for colonoscopy images, it is significantly challenging to train deep neural networks for colonoscopy depth estimation. In this paper, we propose a novel approach that makes full use of both synthetic data and real colonoscopy videos. We use synthetic data with ground truth depth maps to train a depth estimation network with a generative adversarial network model. Despite the lack of ground truth depth, real colonoscopy videos are used to train the network in a self-supervision manner by exploiting temporal consistency between neighboring frames. Furthermore, we design a masked gradient warping loss in order to ensure temporal consistency with more reliable correspondences. We conducted both quantitative and qualitative analysis on an existing synthetic dataset and a set of real colonoscopy videos, demonstrating the superiority of our method on more accurate and consistent depth estimation for colonoscopy images. Link to paper https://doi.org/10.1007/978-3-030-87231-1_12 Link to the code repository https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Link to the dataset(s) https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy Reviews Review #1 Please describe the contribution of the paper In this paper, authors proposed a method to estimate the depth from real colonoscopy video frames using both synthetic and real colonoscopy videos; first, they trained a pix2pix network (DepthNet) in an adversarial manner to learn depth only from synthetic data, second, they used temporal consistency as a constrained to finetune their DepthNet on real colonoscopy videos. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. -Using temporal consistency as a constraint on depth estimation from real colonoscopy videos Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. -PWC-Net is designed and trained on outdoor video frames, and thus can introduce extra error in computing optical flow from real colonoscopy video frames. -The depth estimation method could be compared with geometrical self-supervised deep learning method as well -It is not clear whether the synthetic data has occlusion map and why it has not been used in the training as it could help as an extra constraint. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance considering the explanation of the method in the paper, it seems to be reasonably reproducible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html In Fig.1. , it would be better to replace FlowNet with PWC-Net, FlowNet itself is an optical flow method. Using a gradient of depth could smooth the effect of reflection but as can be seen on the last two columns of Fig.2., the method introduced some noise on the top left of the depth map. This is common when using generative networks to map from RGB to normalized depth. Instead of two frames, a sequence of 5 or even 10 frames (based on the hardware capacity) can be used, this can help to deal with the reflection noise as it appears and disappears based on camera movement inside the colon Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Estimating depth to determine the size and location of polyps can be a helpful assistive tool for clinicians. Even though the authors have tried to address this problem, I believe more experiments and comparison with the current SOTA in the computer vision method is necessary, which lack in this paper. What is the ranking of this paper in your review stack? 5 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper presents a novel strategy to estimate depth on colonoscopy images using a deep learning framework. The depth estimation is useful to obtain colonoscopy polyp clues that thereafter determine the aggressiveness of the disease. The main contribution of the proposed strategy is the training of a deep architecture over synthetic and real colonoscopy data which also exploit temporal consistency as constrain to achieve better deep map representations. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The proposed approach apport novel components regarding the depth estimation of colonoscopy. For instance, the use of temporal consistency to avoid artifacts in resultant deep maps. Despite the use of synthetic data is widely implemented in the literature, the configuration and transfer scheme may be new on this application. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The main drawback of paper lies in the evaluation and results. I summarize the weaknesses in the following lines: There is not a clear statistical difference between the approaches: “our baseline” and “ours” in Table 1. The authors argue that real data not make further improvements over synthetic representation. I consider that a more deep discussion should be done, illustrating also the train results to discard possible overfitting. There is not an ablation study to demonstrate the contribution of temporal component I am surprised that the results of other baseline approaches are not ilustrated over real sequences. The differences of performance in such dataset should stand out main advantages of the proposed approach. I think that a state-of-the-art comparison is mandatory in this work since in the literature there exist a lot of approximation with the main objective With respect to other works, I found that the dataset is limtied and other ground strategies should be considered. In fact, there exist tools during colonoscopy to obtain a better approximation of polyp size. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper has potential to be reproduced because the description of methodology is clear. The code and dataset seems that is not public available. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper introduce a novel approach to depth estimation of colonoscopy. A main and intersting contribution is the integration of temporal consistency to achieve better estimations of depth. The use of synthetic data and the retrining with real data is also interesting and could be a potential alternative to achieve robust 3D estimations. Nonetheless, I consider that evaluation of the proposed approach should be enriched regarding the state-of-the-art and also with respect to the apport of each component in the strategy. For instance, an ablation study may determine the apport of temporal information. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Althought the paper is interesting, the idea is novel and the application is into the domain of the conference, I consider that a further evaluation is demanding to know the advantage and limitations of the proposed approach. What is the ranking of this paper in your review stack? 6 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper Uses both synthetic and real colonoscopy data to train a network for depth estimation from colonoscopy videos. Uses temporal consistency and introduces a masked gradient warping loss to train the network in a self-supervised manner. Achieves smoother and more consistent depth estimation than other methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Exploiting both synthetic and real data, and training the network in a self-supervised manner: Given the lack of real ground truth data which is the main challenge in the medical field, it is very important to develop a method that works around this problem. This paper attempts it by using synthetic data and self-supervision. Masked gradient warping loss: This paper introduces a new loss to enforce temporal consistency between neighbouring frames, which leads to smoother and more consistent depth estimation (but with its own disadvantage - see comments below). Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Depth estimation at the sharp boundaries: I can see that the proposed method generates smoother depth at the locations with specularity, but the method makes the depth at sharp boundaries also quite smoother which is not very ideal. On the supplementary video, this depth bleeding at boundaries is more noticeable than in the figures. I think this might be from the gradient warping loss which could make the gradients at the boundaries small. No discussions on failure cases/limitations: I believe this will improve the quality of paper in general as well as help other researchers think about how to build upon the proposed method. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance It looks fine. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a question about Eq 3. Is this loss for pretraining on synthetic data as well as for finetuning on real data? If so, how is the GAN loss computed for finetuning? Unless I misunderstood it, this loss is for training pix2pixHD which requires paired images. So I am wondering what is the paired image for a real image here. As mentioned above, it would be great if the authors can add failure cases and discussions on the limitations of the method. Now, some minor comments: pp2: In the 3rd paragraph, ‘train a image translation’ -&gt; ‘train an image translation’. Sec 3.2: CGAN is not defined before. pp7: In line 2, ‘This is reasonable because that the self-supervision’ -&gt; remove ‘that’. pp7: in line 4, ‘it does not increase more information for the synthetic data.’ -&gt; ‘it does not increase the amount of information…’. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper addresses one of the main challenges in medical imaging, i.e. how to work around the lack of ground truth data in the real domain. This paper does it by exploiting both synthetic and real data in a self-supervised fashion with a novel masked gradient warping loss. This new loss enforces the temporal consistency between neighbouring frames which results in smoother depth estimation. However, there is an adverse effect in this approach: the estimated depth loses fidelity around sharp boundaries. I think this might hinder, e.g. reconstructing the correct 3D geometry of colon. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper describes a method to train a 3D depth estimation network from both simulated and real data. The contribution is a novel loss based on temporal consistency. Training such a network is a currently open problem given the lack of labeled data. This is hence a worthy contribution to publish. The paper should be revised according to the reviews for the final version. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Author Feedback We thank the reviewers for their constructive comments. Here we would like to address some specific concerns and comments. [R1, R2] Comparison with SOTA methods. [Reply] We actually had tried several SOTA geometrical self-supervised learning methods such as Zhou et al. [23]. But suffering from the occlusions and non-Lambertian surfaces, the results are poor. The same conclusion can be found in Liu et al.’s work [6]. W.r.t. real colonoscopy videos, since there is no ground truth, it is difficult to make a quantitative comparison. The main contribution of our paper is proposing a novel strategy and loss to achieve more consistent and reasonable depth prediction for real colonoscopy videos without ground truths. The advantage is demonstrated by reconstructed depth maps for real data. We will release our data and code for comparison. [R1] Error from optical flow. [Reply] Due to the inevitable errors in optical flow estimation, we filter most pixels that have high optical flow errors by forward-backward consistency check (as described in the second paragraph of Sec. 2.2). Besides, the optical flow does not explicitly constrain the depth values but only provides extra temporal information for training, which is tolerant to small errors. Moreover, the optical flow is used only on the training stage, thus it does not introduce extra errors on the inference stage. [R1] Occlusion map of the synthetic data. [Reply] In the synthetic dataset released by Rau et al. [11], only the paired RGB images and depth maps are provided. The occlusion maps are not available. [R2] Ablation study and analysis of the contribution of temporal component. [Reply] According to our understanding, the temporal component refers to the elements in the depth gradient warping module, such as using the gradient of depth instead of depth, forward-backward warping distance check. We did an ablation study before, but due to the limitation of the number of pages in MICCAI, there may not be enough space for discussion on ablation study. [R2, R3] The limitations of the proposed approach. [Reply] Due to the limitation of the page, we did not discuss much about the limitations of our method. We did test our method on a large number of real colonoscopy videos. In general, our method produces reasonable depth estimation in a general colonoscopy environment. But it occasionally fails to recover the shape of small polyps that are difficult to distinguish from the background. Further discussions will be added to the paper. [R3] The adverse effect of the gradient loss. [Reply] The temporal consistency of the predicted depth is much more important than sharp boundaries for multi-view 3D reconstruction in our paper. Our framework is flexible to integrate existing solutions to strengthen boundaries, such as emphasizing the depth estimation error at boundaries on synthetic data. [R3] GAN loss for finetuning. [Reply] The GAN loss is computed with paired images from the synthetic dataset. It is not computed on the real data. During the finetuning stage, both synthetic data and real data are used to compute the loss in Eq. 3, while L_MGW is computed with real data and L_FM, L_GAN are computed with synthetic data. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Cheng, Kai,Ma, Yiting,Sun, Bin,Li, Yang,Chen, Xuejin" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Depth Estimation for Colonoscopy Images with Self-supervised Learning from Videos</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a>
      
      <a 
        href="kittywong/categories#Modalities - Video"
        class="post-category">
        Modalities - Video
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Cheng, Kai"
        class="post-tags">
        Cheng, Kai
      </a> |  
      
      <a href="kittywong/tags#Ma, Yiting"
        class="post-tags">
        Ma, Yiting
      </a> |  
      
      <a href="kittywong/tags#Sun, Bin"
        class="post-tags">
        Sun, Bin
      </a> |  
      
      <a href="kittywong/tags#Li, Yang"
        class="post-tags">
        Li, Yang
      </a> |  
      
      <a href="kittywong/tags#Chen, Xuejin"
        class="post-tags">
        Chen, Xuejin
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Kai Cheng, Yiting Ma, Bin Sun, Yang Li, Xuejin Chen
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Depth estimation in colonoscopy images provides geometric clues for downstream medical analysis tasks, such as polyp detection, 3D reconstruction, and diagnosis. Recently, deep learning technology has made significant progress in monocular depth estimation for natural scenes. However, without sufficient ground truth of dense depth maps for colonoscopy images, it is significantly challenging to train deep neural networks for colonoscopy depth estimation. In this paper, we propose a novel approach that makes full use of both synthetic data and real colonoscopy videos. We use synthetic data with ground truth depth maps to train a depth estimation network with a generative adversarial network model. Despite the lack of ground truth depth, real colonoscopy videos are used to train the network in a self-supervision manner by exploiting temporal consistency between neighboring frames. Furthermore, we design a masked gradient warping loss in order to ensure temporal consistency with more reliable correspondences. We conducted both quantitative and qualitative analysis on an existing synthetic dataset and a set of real colonoscopy videos, demonstrating the superiority of our method on more accurate and consistent depth estimation for colonoscopy images.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87231-1_12">https://doi.org/10.1007/978-3-030-87231-1_12</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://github.com/ckLibra/Self-Supervised-Depth-Estimation-for-Colonoscopy
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>In this paper, authors proposed a method to estimate the depth from real colonoscopy video frames using both synthetic and real colonoscopy videos; first, they trained a pix2pix network (DepthNet) in an adversarial manner to learn depth only from synthetic data, second, they used temporal consistency as a constrained to finetune their DepthNet on real colonoscopy videos.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>-Using temporal consistency as a constraint on depth estimation from real colonoscopy videos</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>-PWC-Net is designed and trained on outdoor video frames, and thus can introduce extra error in computing optical flow from real colonoscopy video frames. 
-The depth estimation method could be compared with geometrical self-supervised deep learning method as well 
-It is not clear whether the synthetic data has occlusion map and why it has not been used in the training as it could help as an extra constraint.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>considering the explanation of the method in the paper, it seems to be reasonably reproducible.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>In Fig.1. , it would be better to replace FlowNet with PWC-Net, FlowNet itself is an optical flow method.</li>
        <li>Using a gradient of depth could smooth the effect of reflection but as can be seen on the last two columns of Fig.2., the method introduced some noise on the top left of the depth map. This is common when using generative networks to map from RGB to normalized depth.</li>
        <li>Instead of two frames, a sequence of 5 or even 10 frames (based on the hardware capacity) can be used, this can help to deal with the reflection noise as it appears and disappears based on camera movement inside the colon</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Estimating depth to determine the size and location of polyps can be a helpful assistive tool for clinicians.  Even though the authors have tried to address this problem, I believe more experiments and comparison with the current SOTA in the computer vision method is necessary, which lack in this paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper presents a novel strategy to estimate depth on colonoscopy images using a deep learning framework. The depth estimation is useful to obtain colonoscopy polyp clues that thereafter determine the aggressiveness of the disease.  The main contribution of the proposed strategy is the training of a deep architecture over synthetic and real colonoscopy data which also exploit temporal consistency as constrain to achieve better deep map representations.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The proposed approach apport novel components regarding the depth estimation of colonoscopy. For instance, the use of temporal consistency to avoid artifacts in resultant deep maps. Despite the use of synthetic data is widely implemented in the literature, the configuration and transfer scheme may be new on this application.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The main drawback of paper lies in the evaluation and results. I summarize the weaknesses in the following lines:</p>

      <ul>
        <li>
          <p>There is not a clear statistical difference between the approaches: “our baseline” and “ours” in Table 1. The authors argue that real data not make further improvements over synthetic representation. I consider that a more deep discussion should be done, illustrating also the train results to discard possible overfitting.</p>
        </li>
        <li>There is not an ablation study to demonstrate the contribution of temporal component</li>
        <li>I am surprised that the results of other baseline approaches are not ilustrated over real sequences. The differences of performance in such dataset should stand out main advantages of the proposed approach.  I think that a state-of-the-art comparison is mandatory in this work since in the literature there exist a lot of approximation with the main objective</li>
        <li>With respect to other works, I found that the dataset is limtied and other ground strategies should be considered. In fact, there exist tools during colonoscopy to obtain a better approximation of polyp size.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The paper has potential to be reproduced because the description of methodology is clear. The code and dataset seems that is not public available.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The paper introduce a novel approach to depth estimation of colonoscopy. A main and intersting contribution is the integration of temporal consistency to achieve better estimations of depth.  The use of synthetic data and the retrining with real data is also interesting and could be a potential alternative to achieve robust 3D estimations.</p>

      <p>Nonetheless, I consider that evaluation of the proposed approach should be enriched regarding the state-of-the-art and also with respect to the apport of each component in the strategy. For instance, an ablation study may determine the apport of temporal information.</p>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Althought the paper is interesting, the idea is novel and the application is into the domain of the conference, I consider that a further evaluation is demanding to know the advantage and limitations of the proposed approach.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>6</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <ul>
        <li>
          <p>Uses both synthetic and real colonoscopy data to train a network for depth estimation from colonoscopy videos.</p>
        </li>
        <li>
          <p>Uses temporal consistency and introduces a masked gradient warping loss to train the network in a self-supervised manner.</p>
        </li>
        <li>
          <p>Achieves smoother and more consistent depth estimation than other methods.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>
          <p>Exploiting both synthetic and real data, and training the network in a self-supervised manner: Given the lack of real ground truth data which is the main challenge in the medical field, it is very important to develop a method that works around this problem. This paper attempts it by using synthetic data and self-supervision.</p>
        </li>
        <li>
          <p>Masked gradient warping loss: This paper introduces a new loss to enforce temporal consistency between neighbouring frames, which leads to smoother and more consistent depth estimation (but with its own disadvantage - see comments below).</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>
          <p>Depth estimation at the sharp boundaries: I can see that the proposed method generates smoother depth at the locations with specularity, but the method makes the depth at sharp boundaries also quite smoother which is not very ideal. On the supplementary video, this depth bleeding at boundaries is more noticeable than in the figures. I think this might be from the gradient warping loss which could make the gradients at the boundaries small.</p>
        </li>
        <li>
          <p>No discussions on failure cases/limitations: I believe this will improve the quality of paper in general as well as help other researchers think about how to build upon the proposed method.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>It looks fine.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>
          <p>I have a question about Eq 3. Is this loss for pretraining on synthetic data as well as for finetuning on real data? If so, how is the GAN loss computed for finetuning? Unless I misunderstood it, this loss is for training pix2pixHD which requires paired images. So I am wondering what is the paired image for a real image here.</p>
        </li>
        <li>
          <p>As mentioned above, it would be great if the authors can add failure cases and discussions on the limitations of the method.</p>
        </li>
        <li>Now, some minor comments:</li>
        <li>pp2: In the 3rd paragraph, ‘train a image translation’ -&gt; ‘train an image translation’.</li>
        <li>Sec 3.2: CGAN is not defined before.</li>
        <li>pp7: In line 2, ‘This is reasonable because that the self-supervision’ -&gt; remove ‘that’.</li>
        <li>pp7: in line 4, ‘it does not increase more information for the synthetic data.’ -&gt; ‘it does not increase the amount of information…’.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This paper addresses one of the main challenges in medical imaging, i.e. how to work around the lack of ground truth data in the real domain. This paper does it by exploiting both synthetic and real data in a self-supervised fashion with a novel masked gradient warping loss. This new loss enforces the temporal consistency between neighbouring frames which results in smoother depth estimation. However, there is an adverse effect in this approach: the estimated depth loses fidelity around sharp boundaries. I think this might hinder, e.g. reconstructing the correct 3D geometry of colon.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The paper describes a method to train a 3D depth estimation network from both simulated and real data. The contribution is a novel loss based on temporal consistency. Training such a network is a currently open problem given the lack of labeled data. This is hence a worthy contribution to publish. The paper should be revised according to the reviews for the final version.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the reviewers for their constructive comments. Here we would like to  address some specific concerns and comments.</p>

  <p>[R1, R2] Comparison with SOTA methods.
[Reply] We actually had tried several SOTA geometrical self-supervised learning methods such as Zhou et al. [23]. But suffering from the occlusions and non-Lambertian surfaces, the results are poor. The same conclusion can be found in Liu et al.’s work [6]. W.r.t. real colonoscopy videos, since there is no ground truth, it is difficult to make a quantitative comparison. The main contribution of our paper is proposing a novel strategy and loss to achieve more consistent and reasonable depth prediction for real colonoscopy videos without ground truths. The advantage is demonstrated by reconstructed depth maps for real data. We will release our data and code for comparison.</p>

  <p>[R1] Error from optical flow.
[Reply] Due to the inevitable errors in optical flow estimation, we filter most pixels that have high optical flow errors by forward-backward consistency check (as described in the second paragraph of Sec. 2.2). Besides, the optical flow does not explicitly constrain the depth values but only provides extra temporal information for training, which is tolerant to small errors. Moreover, the optical flow is used only on the training stage, thus it does not introduce extra errors on the inference stage.</p>

  <p>[R1] Occlusion map of the synthetic data.
[Reply] In the synthetic dataset released by Rau et al. [11], only the paired RGB images and depth maps are provided. The occlusion maps are not available.</p>

  <p>[R2] Ablation study and analysis of the contribution of temporal component.
[Reply] According to our understanding, the temporal component refers to the elements in the depth gradient warping module, such as using the gradient of depth instead of depth, forward-backward warping distance check. We did an ablation study before, but due to the limitation of the number of pages in MICCAI, there may not be enough space for discussion on ablation study.</p>

  <p>[R2, R3] The limitations of the proposed approach. 
[Reply] Due to the limitation of the page, we did not discuss much about the limitations of our method. We did test our method on a large number of real colonoscopy videos. In general, our method produces reasonable depth estimation in a general colonoscopy environment. But it occasionally fails to recover the shape of small polyps that are difficult to distinguish from the background.  Further discussions will be added to the paper.</p>

  <p>[R3] The adverse effect of the gradient loss. 
[Reply] The temporal consistency of the predicted depth is much more important than sharp boundaries for multi-view 3D reconstruction in our paper. Our framework is flexible to integrate existing solutions to strengthen boundaries, such as emphasizing the depth estimation error at boundaries on synthetic data.</p>

  <p>[R3] GAN loss for finetuning.
[Reply] The GAN loss is computed with paired images from the synthetic dataset. It is not computed on the real data. During the finetuning stage, both synthetic data and real data are used to compute the loss in Eq. 3, while L_MGW is computed with real data and L_FM, L_GAN are computed with synthetic data.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0611-12-31
      -->
      <!--
      
        ,
        updated at 
        0612-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Reconstruction"
        class="post-category">
        Image Reconstruction
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - Video"
        class="post-category">
        Modalities - Video
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Cheng, Kai"
        class="post-category">
        Cheng, Kai
      </a> |  
      
      <a href="kittywong/tags#Ma, Yiting"
        class="post-category">
        Ma, Yiting
      </a> |  
      
      <a href="kittywong/tags#Sun, Bin"
        class="post-category">
        Sun, Bin
      </a> |  
      
      <a href="kittywong/tags#Li, Yang"
        class="post-category">
        Li, Yang
      </a> |  
      
      <a href="kittywong/tags#Chen, Xuejin"
        class="post-category">
        Chen, Xuejin
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0612/12/31/Paper0475">
          Joint Optimization of Hadamard Sensing and Reconstruction in Compressed Sensing Fluorescence Microscopy
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0610/12/31/Paper0432">
          InDuDoNet: An Interpretable Dual Domain Network for CT Metal Artifact Reduction
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
