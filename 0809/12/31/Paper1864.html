<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Few-shot Transfer Learning for Hereditary Retinal Diseases Recognition | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Few-shot Transfer Learning for Hereditary Retinal Diseases Recognition" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Siwei Mai, Qian Li, Qi Zhao, Mingchen Gao Abstract This project aims to recognize a group of rare retinal diseases, the hereditary macular dystrophies, based on Optical Coherence Tomography (OCT) images, whose primary manifestation is the interruption, disruption, and loss of the layers of the retina. The challenge of using machine learning models to recognize those diseases arises from the limited number of collected images due to their rareness. We formulate the problems caused by lacking labeled data as a Student-Teacher learning task with a discriminative feature space and knowledge distillation (KD). OCT images have large variations due to different types of macular structural changes, capturing devices, and angles. To alleviate such issues, a pipeline of preprocessing is first utilized for image alignment. Tissue images at different angles can be roughly calibrated to a horizontal state for better feature representation. Extensive experiments on our dataset demonstrate the effectiveness of the proposed approach. Link to paper https://doi.org/10.1007/978-3-030-87237-3_10 Link to the code repository N/A Link to the dataset(s) Cell dataset: https://data.mendeley.com/datasets/rscbjbr9sj/2 BOE dataset: http://people.duke.edu/~sf59/Srinivasan_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors implemented a Student-Teacher learning method with a discriminative feature space and knowledge distillation (KD) applied in OCT scans to classify rare retinal diseases related to hereditary macular dystrophies. Finally, the authors presented the effectiveness of the proposed approach reported in accuracy performance metric. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The application of Student-teacher strategy and KD in OCT scans. The use of two good free public datasets of OCT Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors should include more information about the datasets. The BOE dataset contains scans and disease classification. But, the Cell dataset contains scans and clinical findings classification. Therefore, the control labels (normal set) for the two datasets are not the same! Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The two dataset are free public available. The performance metrics and experimental setup is clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html An extensive evaluation of the proposed method with other datasets and ocular conditions is needed. Why not use the Farsiu dataset? [https://www.sciencedirect.com/science/article/abs/pii/S016164201300612X] The inclusion of other baseline methods will be a plus for this paper. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The experimental setup is good but the datasets should be explained in details. Normal test for the two dataset cluster different ocular conditions. i.e. in the Boe dataset, the OCT normal label are patients without DME and without AMD… But patients with other ocular condition could be included…. and in the Cell dataset, the OCT normal label only have non-DME, non-drusen and non-CNV. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper proposes a student-teacher model for the classification of hereditary retinal diseases using small dataset. The papers also use knowledge distillation to train the student model. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The are many strengths in the paper novel application of the student-teacher model for the classification of hereditary retinal diseases strong evaluation of the method and comparing it to classical siamese network the paper is very well written and organized Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. For the test parameters, authors should use grid search to find the best parameters instead of finding each parameter independently (Fig. 6) For all figures, especially Fig. 2, consider putting all the sub-captions into the main caption to be more readable Page 6: Feature Space Representation (grammatical error) to projection =&gt; to project Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors should talk more about the specs of their machine used to train the models Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Authors may use deep learning for the image alignment instead of using classical methods authors should justify the use of ResNet50 and maybe they should do experiments on other networks in their future extended study Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper proposes a novel application of its methods on hereditary retinal diseases classification The paper provides a good approach to train a network using small datasets, which is can be of great usefulness practically What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The paper presents a method for training a multi-class classifier for rare hereditary diseases from OCT b-scans. The difficulty of the setting stems from the limited amount of training data due to the rarity of the conditions. The method consists of a teacher (ResNet-50) and a student model (ResNet-18). The teacher model is pre-trained on an auxiliary dataset and then transferred to the target dataset. Afterwards its outputs are used to train the student network in addition to the labels in the target dataset. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. interesting combination of deep learning methods sensible solution for a difficult problem Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. weak analysis at times hard to follow train-test split [only found that in the reproducibility checklist]) information is missing. Please rate the clarity and organization of this paper Poor Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides enough information to implement the training pipeline but since data is not provided, fully reproducing the results is not possible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I believe that this submission tackles an important problem. Currently, most of the research in medical deep learning is focused on easily obtainable datasets so many difficult problems, such as classifying rare condition as in this case, are somewhat neglected. The method presented on the paper is well crafted and the results indicate that it works better than the baselines, which are chosen sensibly. I am leaning towards accepting the paper, but it still has two significant weaknesses: Firstly, although the results indicate that the proposed method outperforms the baselines, I am not sure about the robustness of those results. There can be a great deal of randomness in the outcomes when working with so little data. I believe that a cross-validation analysis would have been appropriate in this case. Given the small amount of data, the training time should not have been the limiting factor here. Secondly, the clarity of the paper needs to be improved. The mathematical notation is not decently explained and often confusing. For example what indices i, j and k represent in equations 1 and 2 or what is minimized in equation 2. Also f in equation 2 and H and sigma in equation 3 are not introduced and it is up to the reader to deduce / guess what they stand for. Readers who are not familiar with SNNL or Knowledge Distillation will have a hard time understanding these equations. At times the text can also be hard to follow, since some sentences are strangely constructed. As a non-native English speaker myself, I understand that this can be difficult but that is what grammar- and spell-checking tools are for. Other remarks: I found that the data was split 0.7/0.15/0.15 between training/validation/test in the reproducibility checklist but that information should be in the paper itself. Also it is important to know how the split was done. I do not understand why the images had to be resized to 224². This erodes many important details in the images and is not required since the authors are not working with an ImageNet pre-trained model here. The ResNet architecture itself does not require the images to be 224². Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? While the paper still has flaws, I believe that it could be of use to researches and practitioners in the field who are working on similar problems where data is hard to come by. I find that in this case the creativity of the approach and the importance of the problem outweigh the issues I have detailed in 7. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All the reviewers found the introduced student-teacher method and the paper very interesting and important. The methodological contribution is strong and appropriate for this clinically relevant task. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their valuable comments. We will revise our final version accordingly to improve the clarity of our manuscript. Here we want to respond to a few critical points raised by reviewers. Q: Reviewer 1, “the control labels of BOE and Cell datasets are not the same” A: The BOE dataset does differ from the Cell dataset in terms of labels, quantity, type of diseases, and quality of images. However, there is no requirement for matched “normal” labels in our algorithm. The “normal” cases in two datasets can be considered as two separate labels. Our algorithm is generalizable to datasets with unmatched labels. The diversity of the two auxiliary datasets is beneficial for better representation learning. We will clarity that in our final version. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Siwei Mai, Qian Li, Qi Zhao, Mingchen Gao Abstract This project aims to recognize a group of rare retinal diseases, the hereditary macular dystrophies, based on Optical Coherence Tomography (OCT) images, whose primary manifestation is the interruption, disruption, and loss of the layers of the retina. The challenge of using machine learning models to recognize those diseases arises from the limited number of collected images due to their rareness. We formulate the problems caused by lacking labeled data as a Student-Teacher learning task with a discriminative feature space and knowledge distillation (KD). OCT images have large variations due to different types of macular structural changes, capturing devices, and angles. To alleviate such issues, a pipeline of preprocessing is first utilized for image alignment. Tissue images at different angles can be roughly calibrated to a horizontal state for better feature representation. Extensive experiments on our dataset demonstrate the effectiveness of the proposed approach. Link to paper https://doi.org/10.1007/978-3-030-87237-3_10 Link to the code repository N/A Link to the dataset(s) Cell dataset: https://data.mendeley.com/datasets/rscbjbr9sj/2 BOE dataset: http://people.duke.edu/~sf59/Srinivasan_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors implemented a Student-Teacher learning method with a discriminative feature space and knowledge distillation (KD) applied in OCT scans to classify rare retinal diseases related to hereditary macular dystrophies. Finally, the authors presented the effectiveness of the proposed approach reported in accuracy performance metric. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The application of Student-teacher strategy and KD in OCT scans. The use of two good free public datasets of OCT Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors should include more information about the datasets. The BOE dataset contains scans and disease classification. But, the Cell dataset contains scans and clinical findings classification. Therefore, the control labels (normal set) for the two datasets are not the same! Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The two dataset are free public available. The performance metrics and experimental setup is clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html An extensive evaluation of the proposed method with other datasets and ocular conditions is needed. Why not use the Farsiu dataset? [https://www.sciencedirect.com/science/article/abs/pii/S016164201300612X] The inclusion of other baseline methods will be a plus for this paper. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The experimental setup is good but the datasets should be explained in details. Normal test for the two dataset cluster different ocular conditions. i.e. in the Boe dataset, the OCT normal label are patients without DME and without AMD… But patients with other ocular condition could be included…. and in the Cell dataset, the OCT normal label only have non-DME, non-drusen and non-CNV. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper proposes a student-teacher model for the classification of hereditary retinal diseases using small dataset. The papers also use knowledge distillation to train the student model. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The are many strengths in the paper novel application of the student-teacher model for the classification of hereditary retinal diseases strong evaluation of the method and comparing it to classical siamese network the paper is very well written and organized Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. For the test parameters, authors should use grid search to find the best parameters instead of finding each parameter independently (Fig. 6) For all figures, especially Fig. 2, consider putting all the sub-captions into the main caption to be more readable Page 6: Feature Space Representation (grammatical error) to projection =&gt; to project Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors should talk more about the specs of their machine used to train the models Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Authors may use deep learning for the image alignment instead of using classical methods authors should justify the use of ResNet50 and maybe they should do experiments on other networks in their future extended study Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper proposes a novel application of its methods on hereditary retinal diseases classification The paper provides a good approach to train a network using small datasets, which is can be of great usefulness practically What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The paper presents a method for training a multi-class classifier for rare hereditary diseases from OCT b-scans. The difficulty of the setting stems from the limited amount of training data due to the rarity of the conditions. The method consists of a teacher (ResNet-50) and a student model (ResNet-18). The teacher model is pre-trained on an auxiliary dataset and then transferred to the target dataset. Afterwards its outputs are used to train the student network in addition to the labels in the target dataset. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. interesting combination of deep learning methods sensible solution for a difficult problem Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. weak analysis at times hard to follow train-test split [only found that in the reproducibility checklist]) information is missing. Please rate the clarity and organization of this paper Poor Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides enough information to implement the training pipeline but since data is not provided, fully reproducing the results is not possible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I believe that this submission tackles an important problem. Currently, most of the research in medical deep learning is focused on easily obtainable datasets so many difficult problems, such as classifying rare condition as in this case, are somewhat neglected. The method presented on the paper is well crafted and the results indicate that it works better than the baselines, which are chosen sensibly. I am leaning towards accepting the paper, but it still has two significant weaknesses: Firstly, although the results indicate that the proposed method outperforms the baselines, I am not sure about the robustness of those results. There can be a great deal of randomness in the outcomes when working with so little data. I believe that a cross-validation analysis would have been appropriate in this case. Given the small amount of data, the training time should not have been the limiting factor here. Secondly, the clarity of the paper needs to be improved. The mathematical notation is not decently explained and often confusing. For example what indices i, j and k represent in equations 1 and 2 or what is minimized in equation 2. Also f in equation 2 and H and sigma in equation 3 are not introduced and it is up to the reader to deduce / guess what they stand for. Readers who are not familiar with SNNL or Knowledge Distillation will have a hard time understanding these equations. At times the text can also be hard to follow, since some sentences are strangely constructed. As a non-native English speaker myself, I understand that this can be difficult but that is what grammar- and spell-checking tools are for. Other remarks: I found that the data was split 0.7/0.15/0.15 between training/validation/test in the reproducibility checklist but that information should be in the paper itself. Also it is important to know how the split was done. I do not understand why the images had to be resized to 224². This erodes many important details in the images and is not required since the authors are not working with an ImageNet pre-trained model here. The ResNet architecture itself does not require the images to be 224². Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? While the paper still has flaws, I believe that it could be of use to researches and practitioners in the field who are working on similar problems where data is hard to come by. I find that in this case the creativity of the approach and the importance of the problem outweigh the issues I have detailed in 7. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All the reviewers found the introduced student-teacher method and the paper very interesting and important. The methodological contribution is strong and appropriate for this clinically relevant task. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their valuable comments. We will revise our final version accordingly to improve the clarity of our manuscript. Here we want to respond to a few critical points raised by reviewers. Q: Reviewer 1, “the control labels of BOE and Cell datasets are not the same” A: The BOE dataset does differ from the Cell dataset in terms of labels, quantity, type of diseases, and quality of images. However, there is no requirement for matched “normal” labels in our algorithm. The “normal” cases in two datasets can be considered as two separate labels. Our algorithm is generalizable to datasets with unmatched labels. The diversity of the two auxiliary datasets is beneficial for better representation learning. We will clarity that in our final version. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0809/12/31/Paper1864" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0809/12/31/Paper1864" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0809-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Few-shot Transfer Learning for Hereditary Retinal Diseases Recognition" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0809/12/31/Paper1864"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0809/12/31/Paper1864","headline":"Few-shot Transfer Learning for Hereditary Retinal Diseases Recognition","dateModified":"0810-01-05T00:00:00-05:17","datePublished":"0809-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Siwei Mai, Qian Li, Qi Zhao, Mingchen Gao Abstract This project aims to recognize a group of rare retinal diseases, the hereditary macular dystrophies, based on Optical Coherence Tomography (OCT) images, whose primary manifestation is the interruption, disruption, and loss of the layers of the retina. The challenge of using machine learning models to recognize those diseases arises from the limited number of collected images due to their rareness. We formulate the problems caused by lacking labeled data as a Student-Teacher learning task with a discriminative feature space and knowledge distillation (KD). OCT images have large variations due to different types of macular structural changes, capturing devices, and angles. To alleviate such issues, a pipeline of preprocessing is first utilized for image alignment. Tissue images at different angles can be roughly calibrated to a horizontal state for better feature representation. Extensive experiments on our dataset demonstrate the effectiveness of the proposed approach. Link to paper https://doi.org/10.1007/978-3-030-87237-3_10 Link to the code repository N/A Link to the dataset(s) Cell dataset: https://data.mendeley.com/datasets/rscbjbr9sj/2 BOE dataset: http://people.duke.edu/~sf59/Srinivasan_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors implemented a Student-Teacher learning method with a discriminative feature space and knowledge distillation (KD) applied in OCT scans to classify rare retinal diseases related to hereditary macular dystrophies. Finally, the authors presented the effectiveness of the proposed approach reported in accuracy performance metric. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The application of Student-teacher strategy and KD in OCT scans. The use of two good free public datasets of OCT Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors should include more information about the datasets. The BOE dataset contains scans and disease classification. But, the Cell dataset contains scans and clinical findings classification. Therefore, the control labels (normal set) for the two datasets are not the same! Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The two dataset are free public available. The performance metrics and experimental setup is clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html An extensive evaluation of the proposed method with other datasets and ocular conditions is needed. Why not use the Farsiu dataset? [https://www.sciencedirect.com/science/article/abs/pii/S016164201300612X] The inclusion of other baseline methods will be a plus for this paper. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The experimental setup is good but the datasets should be explained in details. Normal test for the two dataset cluster different ocular conditions. i.e. in the Boe dataset, the OCT normal label are patients without DME and without AMD… But patients with other ocular condition could be included…. and in the Cell dataset, the OCT normal label only have non-DME, non-drusen and non-CNV. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper The paper proposes a student-teacher model for the classification of hereditary retinal diseases using small dataset. The papers also use knowledge distillation to train the student model. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The are many strengths in the paper novel application of the student-teacher model for the classification of hereditary retinal diseases strong evaluation of the method and comparing it to classical siamese network the paper is very well written and organized Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. For the test parameters, authors should use grid search to find the best parameters instead of finding each parameter independently (Fig. 6) For all figures, especially Fig. 2, consider putting all the sub-captions into the main caption to be more readable Page 6: Feature Space Representation (grammatical error) to projection =&gt; to project Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Authors should talk more about the specs of their machine used to train the models Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Authors may use deep learning for the image alignment instead of using classical methods authors should justify the use of ResNet50 and maybe they should do experiments on other networks in their future extended study Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper proposes a novel application of its methods on hereditary retinal diseases classification The paper provides a good approach to train a network using small datasets, which is can be of great usefulness practically What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper The paper presents a method for training a multi-class classifier for rare hereditary diseases from OCT b-scans. The difficulty of the setting stems from the limited amount of training data due to the rarity of the conditions. The method consists of a teacher (ResNet-50) and a student model (ResNet-18). The teacher model is pre-trained on an auxiliary dataset and then transferred to the target dataset. Afterwards its outputs are used to train the student network in addition to the labels in the target dataset. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. interesting combination of deep learning methods sensible solution for a difficult problem Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. weak analysis at times hard to follow train-test split [only found that in the reproducibility checklist]) information is missing. Please rate the clarity and organization of this paper Poor Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides enough information to implement the training pipeline but since data is not provided, fully reproducing the results is not possible. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I believe that this submission tackles an important problem. Currently, most of the research in medical deep learning is focused on easily obtainable datasets so many difficult problems, such as classifying rare condition as in this case, are somewhat neglected. The method presented on the paper is well crafted and the results indicate that it works better than the baselines, which are chosen sensibly. I am leaning towards accepting the paper, but it still has two significant weaknesses: Firstly, although the results indicate that the proposed method outperforms the baselines, I am not sure about the robustness of those results. There can be a great deal of randomness in the outcomes when working with so little data. I believe that a cross-validation analysis would have been appropriate in this case. Given the small amount of data, the training time should not have been the limiting factor here. Secondly, the clarity of the paper needs to be improved. The mathematical notation is not decently explained and often confusing. For example what indices i, j and k represent in equations 1 and 2 or what is minimized in equation 2. Also f in equation 2 and H and sigma in equation 3 are not introduced and it is up to the reader to deduce / guess what they stand for. Readers who are not familiar with SNNL or Knowledge Distillation will have a hard time understanding these equations. At times the text can also be hard to follow, since some sentences are strangely constructed. As a non-native English speaker myself, I understand that this can be difficult but that is what grammar- and spell-checking tools are for. Other remarks: I found that the data was split 0.7/0.15/0.15 between training/validation/test in the reproducibility checklist but that information should be in the paper itself. Also it is important to know how the split was done. I do not understand why the images had to be resized to 224². This erodes many important details in the images and is not required since the authors are not working with an ImageNet pre-trained model here. The ResNet architecture itself does not require the images to be 224². Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? While the paper still has flaws, I believe that it could be of use to researches and practitioners in the field who are working on similar problems where data is hard to come by. I find that in this case the creativity of the approach and the importance of the problem outweigh the issues I have detailed in 7. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. All the reviewers found the introduced student-teacher method and the paper very interesting and important. The methodological contribution is strong and appropriate for this clinically relevant task. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback We sincerely thank all the reviewers and ACs for their valuable comments. We will revise our final version accordingly to improve the clarity of our manuscript. Here we want to respond to a few critical points raised by reviewers. Q: Reviewer 1, “the control labels of BOE and Cell datasets are not the same” A: The BOE dataset does differ from the Cell dataset in terms of labels, quantity, type of diseases, and quality of images. However, there is no requirement for matched “normal” labels in our algorithm. The “normal” cases in two datasets can be considered as two separate labels. Our algorithm is generalizable to datasets with unmatched labels. The diversity of the two auxiliary datasets is beneficial for better representation learning. We will clarity that in our final version. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Mai, Siwei,Li, Qian,Zhao, Qi,Gao, Mingchen" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Few-shot Transfer Learning for Hereditary Retinal Diseases Recognition</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Mai, Siwei"
        class="post-tags">
        Mai, Siwei
      </a> |  
      
      <a href="kittywong/tags#Li, Qian"
        class="post-tags">
        Li, Qian
      </a> |  
      
      <a href="kittywong/tags#Zhao, Qi"
        class="post-tags">
        Zhao, Qi
      </a> |  
      
      <a href="kittywong/tags#Gao, Mingchen"
        class="post-tags">
        Gao, Mingchen
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Siwei Mai, Qian Li, Qi Zhao, Mingchen Gao
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>This project aims to recognize a group of rare retinal diseases, the hereditary macular dystrophies, based on Optical Coherence Tomography (OCT) images, whose primary manifestation is the interruption, disruption, and loss of the layers of the retina. The challenge of using machine learning models to recognize those diseases arises from the limited number of collected images due to their rareness. We formulate the problems caused by lacking labeled data as a Student-Teacher learning task with a discriminative feature space and knowledge distillation (KD). OCT images have large variations due to different types of macular structural changes, capturing devices, and angles. To alleviate such issues, a pipeline of preprocessing is first utilized for image alignment. Tissue images at different angles can be roughly calibrated to a horizontal state for better feature representation. Extensive experiments on our dataset demonstrate the effectiveness of the proposed approach.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87237-3_10">https://doi.org/10.1007/978-3-030-87237-3_10</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>Cell dataset: https://data.mendeley.com/datasets/rscbjbr9sj/2
BOE dataset: http://people.duke.edu/~sf59/Srinivasan_BOE_2014_dataset.htm</p>

<p><br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors implemented a Student-Teacher learning method with a discriminative feature space and knowledge distillation (KD) applied in OCT scans to classify rare retinal diseases related  to hereditary macular dystrophies. Finally, the authors presented the effectiveness of the proposed approach reported in accuracy performance metric.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>The application of Student-teacher strategy and KD in OCT scans.</li>
        <li>The use of two good free public datasets of OCT</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>The authors should include more information about the datasets. The BOE dataset contains scans and disease classification. But, the Cell dataset contains scans and clinical findings classification. Therefore, the control labels (normal set) for the two datasets are not the same!</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <ul>
        <li>The two dataset are free public available.</li>
        <li>The performance metrics and experimental setup is clear.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>An extensive evaluation of the proposed method with other datasets and ocular conditions is needed. Why not use the Farsiu dataset? [https://www.sciencedirect.com/science/article/abs/pii/S016164201300612X]
The inclusion of other baseline methods will be a plus for this paper.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The experimental setup is good but the datasets should be explained in details.
Normal test for the two dataset cluster different ocular conditions. i.e. in the Boe dataset, the OCT normal label are patients without DME and without AMD… But patients with other ocular condition could be included…. and in the Cell dataset, the OCT normal label only have non-DME, non-drusen and non-CNV.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper proposes a student-teacher model for the classification of hereditary
retinal diseases using small dataset. The papers also use knowledge distillation to train the student model.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The are many strengths in the paper</p>
      <ul>
        <li>novel application of the student-teacher model for the classification of hereditary
retinal diseases</li>
        <li>strong evaluation of the method and comparing it to classical siamese network</li>
        <li>the paper is very well written and organized</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>For the test parameters, authors should use grid search to find the best parameters instead of finding each parameter independently (Fig. 6)</p>

      <p>For all figures, especially Fig. 2, consider putting all the sub-captions into the main caption to be more readable</p>

      <p>Page 6: Feature Space Representation 
(grammatical error) to projection =&gt; to project</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Authors should talk more about the specs of their machine used to train the models</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>
          <p>Authors may use deep learning for the image alignment instead of using classical methods</p>
        </li>
        <li>
          <p>authors should justify the use of ResNet50 and maybe they should do experiments on other networks in their future extended study</p>
        </li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ul>
        <li>The paper proposes a novel application of its methods on hereditary
retinal diseases classification</li>
        <li>The paper provides a good approach to train a network using small datasets, which is can be of great usefulness practically</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The paper presents a method for training a multi-class classifier for rare hereditary diseases from OCT b-scans. The difficulty of the setting stems from the limited amount of training data due to the rarity of the conditions. The method consists of a teacher (ResNet-50) and a student model (ResNet-18). The teacher model is pre-trained on an auxiliary dataset and then transferred to the target dataset. Afterwards its outputs are used to train the student network in addition to the labels in the target dataset.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>interesting combination of deep learning methods</li>
        <li>sensible solution for a difficult problem</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>weak analysis</li>
        <li>at times hard to follow</li>
        <li>train-test split [only found that in the reproducibility checklist]) information is missing.</li>
      </ul>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Poor</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The paper provides enough information to implement the training pipeline but since data is not provided, fully reproducing the results is not possible.</p>

    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>I believe that this submission tackles an important problem. Currently, most of the research in medical deep learning is focused on easily obtainable datasets so many difficult problems, such as classifying rare condition as in this case, are somewhat neglected. The method presented on the paper is well crafted and the results indicate that it works better than the baselines, which are chosen sensibly.</p>

      <p>I am leaning towards accepting the paper, but it still has two significant weaknesses:</p>

      <p>Firstly, although the results indicate that the proposed method outperforms the baselines, I am not sure about the robustness of those results. There can be a great deal of randomness  in the outcomes when working with so little data. I believe that a cross-validation analysis would have been appropriate in this case. Given the small amount of data, the training time should not have been the limiting factor here.</p>

      <p>Secondly, the clarity of the paper needs to be improved. The mathematical notation is not decently explained and often confusing. For example what indices i, j and k represent in equations 1 and 2 or what is minimized in equation 2. Also f in equation 2 and H and sigma in equation 3 are not introduced and it is up to the reader to deduce / guess what they stand for. Readers who are not familiar with SNNL or Knowledge Distillation will have a hard time understanding these equations. At times the text can also be hard to follow, since some sentences are strangely constructed. As a non-native English speaker myself, I understand that this can be difficult but that is what grammar- and spell-checking tools are for.</p>

      <p>Other remarks:
I found that the data was split 0.7/0.15/0.15 between training/validation/test in the reproducibility checklist but that information should be in the paper itself. Also it is important to know how the split was done.</p>

      <p>I do not understand why the images had to be resized to 224². This erodes many important details in the images and is not required since the authors are not working with an ImageNet pre-trained model here. The ResNet architecture itself does not require the images to be 224².</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>While the paper still has flaws, I believe that it could be of use to researches and practitioners in the field who are working on similar problems where data is hard to come by. I find that in this case the creativity of the approach and the importance of the problem outweigh the issues I have detailed in 7.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>All the reviewers found the introduced student-teacher method and the paper very interesting and important. The methodological contribution is strong and appropriate for this clinically relevant task.</p>

    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>

  <p>We sincerely thank all the reviewers and ACs for their valuable comments. We will revise our final version accordingly to improve the clarity of our manuscript. Here we want to respond to a few critical points raised by reviewers.</p>

  <p>Q: Reviewer 1, “the control labels of BOE and Cell datasets are not the same”
A: The BOE dataset does differ from the Cell dataset in terms of labels, quantity, type of diseases, and quality of images. However, there is no requirement for matched “normal” labels in our algorithm. The “normal” cases in two datasets can be considered as two separate labels. Our algorithm is generalizable to datasets with unmatched labels. The diversity of the two auxiliary datasets is beneficial for better representation learning. We will clarity that in our final version.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0809-12-31
      -->
      <!--
      
        ,
        updated at 
        0810-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Mai, Siwei"
        class="post-category">
        Mai, Siwei
      </a> |  
      
      <a href="kittywong/tags#Li, Qian"
        class="post-category">
        Li, Qian
      </a> |  
      
      <a href="kittywong/tags#Zhao, Qi"
        class="post-category">
        Zhao, Qi
      </a> |  
      
      <a href="kittywong/tags#Gao, Mingchen"
        class="post-category">
        Gao, Mingchen
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0810/12/31/Paper1968">
          Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D Networks for 3D Coherent Layer Segmentation of Retina OCT Images
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0808/12/31/Paper0988">
          I-SECRET: Importance-guided fundus image enhancement via semi-supervised contrastive constraining
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
