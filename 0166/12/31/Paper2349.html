<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Heiko Maier, Shahrooz Faghihroohi, Nassir Navab Abstract In order to scan for or monitor retinal diseases, OCT is a useful diagnostic tool that allows to take high-resolution images of the retinal layers. For the aim of fully automated, semantic segmentation of OCT images, both graph based models and deep neural networks have been used so far. Here, we propose to interpret the semantic segmentation of 2D OCT images as a sequence alignment task. Splitting the image into its constituent OCT scanning lines (A-Modes), we align an anatomically justified sequence of labels to these pixel sequences, using dynamic time warping. Combining this dynamic programming approach with learned convolutional filters allows us to leverage the feature extraction capabilities of deep neural networks, while at the same time enforcing explicit guarantees in terms of the anatomical order of layers through the dynamic programming. We investigate both the solitary training of the feature extraction stage, as well as an end-to-end learning of the alignment. The latter makes use of a recently proposed, relaxed formulation of dynamic time warping, that allows us to backpropagate through the dynamic program to enable end-to-end training of the network. Complementing these approaches, a local consistency criterion for the alignment task is investigated, that allows to improve consistency in the alignment of neighbouring A-Modes. We compare this approach to two state of the art methods, showing favourable results. Link to paper https://doi.org/10.1007/978-3-030-87193-2_67 Link to the code repository N/A Link to the dataset(s) http://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors present an approach for segmenting retinal layers in OCT by integrating dynamic time warping (DTW) with deep learning. Two approaches for integrating the CNN was investigated: 1) using pretrained CNN features and 2) End-to end CNN features. The evaluation was performed on a patient cohort of 10 subjects with diabetic macular edema, and showed improvements in the fluid class. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is very well written with clear descriptions of existing literature, the two proposed methods, and the details for the training and evaluation. The proposed work represent a nice integration of existing ideas for OCT segmentation approaches with deep learning. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The primary weakness of the work is that the evaluation is a bit lacking. The experiment result is missing several key details, such as 1.) a baseline comparison against using DWT without deep learning. 2.) standard deviations for the dice results 3.) a evaluation of the topology in the final segmentations. The dataset used was also exceptionally small, with only 10 images in total and 2 subjects used for validation. Lastly, the proposed method does not, in general, seem to perform significantly better than the two baseline methods compared. The only improvement in performance seems to be the fluid class, but without knowing the variance of the performance, it is difficult to determine if such differences are significant. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The reproducibility is passable. An openly available dataset was used, but the authors do not appear willing to release their code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a few recommendations that might help improve the quality of this paper: -Including additional details for the evaluation as listed above (i.e. baseline DWT comparison, standard deviation of the results, analysis of the layer topology). -Improving the quantity of subjects used for evaluation. Perhaps also demonstrating its performance on a dataset acquired from a different scanner. To show the model is not just overfitting the currently limited data. -In Figure 3 it is a bit unclear what the 2nd image is. And it is difficult to determine what structure each of the colors in each of the segmentations represent. Showing more than one example would also be helpful. Or showing the difference in segmentation result between the various methods being compared. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors present a novel integration of deep learning into an existing approach for retinal layer segmentation. The paper was very well written, and the results suggests improvement in the detection of the fluid class. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper this paper use the dynamic time warping in the task of retinal OCT segmentation The proposed method is fully end-to-end trainable. in addition, the method can guarantee too adhere to topological constraints. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. the idea of dynamic time warping in the task of OCT segmentation seems novel. The investigation of related work is sufficient. the authors also compare the result between DTW as post-processing and end-to-end training with DTW Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. the experiment is insufficient. there are only two papers for comparison. And only Language is published in 2020. So comparison with the latest method is not sufficient. About Table I, the best result should be shown in bold for comparison. This paper should be introduced DTW in detail rather than giving a reference. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance the description of the proposed method (DTW) is not clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html provide the detail of DTW more comparative experiment are necessary. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? the idea of dynamic time warping in the task of OCT segmentation seems novel. the sufficient study of releated work the insufficient comparative experiment. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is consensus about the novelty of the proposed DTW-based segmentation method, but several questions about the experimental results were raised such as key missing details about the standard deviation of Dice coefficients, and a lack of evaluation of the topology of the final segmentation. The small sample size of the dataset also raises some concern about overfitting. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal adequately addressed questions from the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded to the reviewers concerns. The authors propose that they will add the results of the Dice coefficients in the paper. Their response on the evaluation methodology is satisfactory and the paper presents novel and interesting ideas. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviews are positive and consistent, which recognize the novelty of this work. The authors’ response amends some essential details of the validation, which well addresses the concerns summarised from 1st round review. In summary, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback Dear Chairs, We would like to thank the reviewers for their constructive comments and the discussion. We are especially glad that both reviewers appreciate the novelty of our approach. Still, we would like to discuss a few points mentioned by the them: 1) We will gladly provide standard deviations of our dice scores (asked by R2). To summarize, over the 22 B-Modes in the test set, our 4 methods have standard deviations in their dice scores that are on average, over all classes, between 0.065 and 0.076, with the largest contributions coming from the fluid class (between 0.322 and 0.332). The latter makes sense as fluid comprises one of the smallest classes and is often concentrated in only one region in the B-Mode. If the network does not recognize this region as containing fluid, the dice score for fluid in one single B-Mode can easily become 0, leading to a higher std deviation than for the retinal layer classes. A full listing of all the standard deviations could be added to the paper if desirable. 2) R2 wishes to see a study of the topology of the final segmentations. On the specified test set, we counted the number of topological violations, defined as the number of times the method assigned a pixel to a layer (N-1) after it had already assigned at least one pixel as being of layer (N). Means and std deviations of these violations over 4 training runs were: using only a CNN (no DTW at all) : (27570 +- 2504); soft-DTW: (28 +- 17); pretr. Only and soft-hard DTW (with and without cumulative dist. matrix): (0 +- 0). This clearly shows that using soft DTW strongly diminishes the violations a simple CNN alone produces and using a “hard” DTW completely prevents violations by design. These numbers can be added to the paper for completeness. 3) R2&amp;3 mention that we evaluate our results on only one dataset. We would like to point out that the given DUKE Dataset for retinal layer and fluid segmentation, with its 110 OCT images (10 subjects x 11 images), is a comprehensive, public dataset that is popular in the field. Due to this, we think firstly evaluating a new approach on this dataset is a reasonable choice. 4) R2 asked us to evaluate DTW without deep learning for the distance function. We did not add such a comparison because the only paper doing so [Source 6 in our paper] only does semi-automatic segmentation, and thus is not directly comparable to the fully automated approaches presented here. Furthermore, we do not see a straightforward way of using DTW for retinal OCT segmentation in a fully automated manner without a learned distance function. (Note that as DTW needs a distance function giving the “cost” of aligning to entries of two sequences, one would need to design such a distance function manually if he or she does not want to learn it. This manual design can rather easily be done to align two sequences of identical type, like two A-Modes, e.g. using a squared Euclidean distance as in [6]. It would be much more challenging to define it between two sequences of different kinds – e.g. an A-Mode and a symbolic series like our topological reference series, which is why we think a data driven approach is expected to outperform any non-deep learning approach here.) 5) R3 mentioned that we only compare to two baseline methods, of which only one is from 2020. We agree that we did not perform an exhaustive comparison of state of the art methods. Our aim was mostly to present our novel idea to the community and to validate the applicability of DTW, in combination with Deep Learning, to OCT. For this, these two baselines were useful because the paper that provided them had evaluated their experiments using the same train/validation/test split that we had worked on, and because they also do joint segmentation of layers and fluid unlike many other approaches that only segment layers. If the chairs would like, we could add more methods or recent approaches to the results section to better pin down the performance of our methods. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Heiko Maier, Shahrooz Faghihroohi, Nassir Navab Abstract In order to scan for or monitor retinal diseases, OCT is a useful diagnostic tool that allows to take high-resolution images of the retinal layers. For the aim of fully automated, semantic segmentation of OCT images, both graph based models and deep neural networks have been used so far. Here, we propose to interpret the semantic segmentation of 2D OCT images as a sequence alignment task. Splitting the image into its constituent OCT scanning lines (A-Modes), we align an anatomically justified sequence of labels to these pixel sequences, using dynamic time warping. Combining this dynamic programming approach with learned convolutional filters allows us to leverage the feature extraction capabilities of deep neural networks, while at the same time enforcing explicit guarantees in terms of the anatomical order of layers through the dynamic programming. We investigate both the solitary training of the feature extraction stage, as well as an end-to-end learning of the alignment. The latter makes use of a recently proposed, relaxed formulation of dynamic time warping, that allows us to backpropagate through the dynamic program to enable end-to-end training of the network. Complementing these approaches, a local consistency criterion for the alignment task is investigated, that allows to improve consistency in the alignment of neighbouring A-Modes. We compare this approach to two state of the art methods, showing favourable results. Link to paper https://doi.org/10.1007/978-3-030-87193-2_67 Link to the code repository N/A Link to the dataset(s) http://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors present an approach for segmenting retinal layers in OCT by integrating dynamic time warping (DTW) with deep learning. Two approaches for integrating the CNN was investigated: 1) using pretrained CNN features and 2) End-to end CNN features. The evaluation was performed on a patient cohort of 10 subjects with diabetic macular edema, and showed improvements in the fluid class. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is very well written with clear descriptions of existing literature, the two proposed methods, and the details for the training and evaluation. The proposed work represent a nice integration of existing ideas for OCT segmentation approaches with deep learning. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The primary weakness of the work is that the evaluation is a bit lacking. The experiment result is missing several key details, such as 1.) a baseline comparison against using DWT without deep learning. 2.) standard deviations for the dice results 3.) a evaluation of the topology in the final segmentations. The dataset used was also exceptionally small, with only 10 images in total and 2 subjects used for validation. Lastly, the proposed method does not, in general, seem to perform significantly better than the two baseline methods compared. The only improvement in performance seems to be the fluid class, but without knowing the variance of the performance, it is difficult to determine if such differences are significant. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The reproducibility is passable. An openly available dataset was used, but the authors do not appear willing to release their code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a few recommendations that might help improve the quality of this paper: -Including additional details for the evaluation as listed above (i.e. baseline DWT comparison, standard deviation of the results, analysis of the layer topology). -Improving the quantity of subjects used for evaluation. Perhaps also demonstrating its performance on a dataset acquired from a different scanner. To show the model is not just overfitting the currently limited data. -In Figure 3 it is a bit unclear what the 2nd image is. And it is difficult to determine what structure each of the colors in each of the segmentations represent. Showing more than one example would also be helpful. Or showing the difference in segmentation result between the various methods being compared. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors present a novel integration of deep learning into an existing approach for retinal layer segmentation. The paper was very well written, and the results suggests improvement in the detection of the fluid class. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper this paper use the dynamic time warping in the task of retinal OCT segmentation The proposed method is fully end-to-end trainable. in addition, the method can guarantee too adhere to topological constraints. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. the idea of dynamic time warping in the task of OCT segmentation seems novel. The investigation of related work is sufficient. the authors also compare the result between DTW as post-processing and end-to-end training with DTW Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. the experiment is insufficient. there are only two papers for comparison. And only Language is published in 2020. So comparison with the latest method is not sufficient. About Table I, the best result should be shown in bold for comparison. This paper should be introduced DTW in detail rather than giving a reference. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance the description of the proposed method (DTW) is not clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html provide the detail of DTW more comparative experiment are necessary. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? the idea of dynamic time warping in the task of OCT segmentation seems novel. the sufficient study of releated work the insufficient comparative experiment. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is consensus about the novelty of the proposed DTW-based segmentation method, but several questions about the experimental results were raised such as key missing details about the standard deviation of Dice coefficients, and a lack of evaluation of the topology of the final segmentation. The small sample size of the dataset also raises some concern about overfitting. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal adequately addressed questions from the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded to the reviewers concerns. The authors propose that they will add the results of the Dice coefficients in the paper. Their response on the evaluation methodology is satisfactory and the paper presents novel and interesting ideas. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviews are positive and consistent, which recognize the novelty of this work. The authors’ response amends some essential details of the validation, which well addresses the concerns summarised from 1st round review. In summary, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback Dear Chairs, We would like to thank the reviewers for their constructive comments and the discussion. We are especially glad that both reviewers appreciate the novelty of our approach. Still, we would like to discuss a few points mentioned by the them: 1) We will gladly provide standard deviations of our dice scores (asked by R2). To summarize, over the 22 B-Modes in the test set, our 4 methods have standard deviations in their dice scores that are on average, over all classes, between 0.065 and 0.076, with the largest contributions coming from the fluid class (between 0.322 and 0.332). The latter makes sense as fluid comprises one of the smallest classes and is often concentrated in only one region in the B-Mode. If the network does not recognize this region as containing fluid, the dice score for fluid in one single B-Mode can easily become 0, leading to a higher std deviation than for the retinal layer classes. A full listing of all the standard deviations could be added to the paper if desirable. 2) R2 wishes to see a study of the topology of the final segmentations. On the specified test set, we counted the number of topological violations, defined as the number of times the method assigned a pixel to a layer (N-1) after it had already assigned at least one pixel as being of layer (N). Means and std deviations of these violations over 4 training runs were: using only a CNN (no DTW at all) : (27570 +- 2504); soft-DTW: (28 +- 17); pretr. Only and soft-hard DTW (with and without cumulative dist. matrix): (0 +- 0). This clearly shows that using soft DTW strongly diminishes the violations a simple CNN alone produces and using a “hard” DTW completely prevents violations by design. These numbers can be added to the paper for completeness. 3) R2&amp;3 mention that we evaluate our results on only one dataset. We would like to point out that the given DUKE Dataset for retinal layer and fluid segmentation, with its 110 OCT images (10 subjects x 11 images), is a comprehensive, public dataset that is popular in the field. Due to this, we think firstly evaluating a new approach on this dataset is a reasonable choice. 4) R2 asked us to evaluate DTW without deep learning for the distance function. We did not add such a comparison because the only paper doing so [Source 6 in our paper] only does semi-automatic segmentation, and thus is not directly comparable to the fully automated approaches presented here. Furthermore, we do not see a straightforward way of using DTW for retinal OCT segmentation in a fully automated manner without a learned distance function. (Note that as DTW needs a distance function giving the “cost” of aligning to entries of two sequences, one would need to design such a distance function manually if he or she does not want to learn it. This manual design can rather easily be done to align two sequences of identical type, like two A-Modes, e.g. using a squared Euclidean distance as in [6]. It would be much more challenging to define it between two sequences of different kinds – e.g. an A-Mode and a symbolic series like our topological reference series, which is why we think a data driven approach is expected to outperform any non-deep learning approach here.) 5) R3 mentioned that we only compare to two baseline methods, of which only one is from 2020. We agree that we did not perform an exhaustive comparison of state of the art methods. Our aim was mostly to present our novel idea to the community and to validate the applicability of DTW, in combination with Deep Learning, to OCT. For this, these two baselines were useful because the paper that provided them had evaluated their experiments using the same train/validation/test split that we had worked on, and because they also do joint segmentation of layers and fluid unlike many other approaches that only segment layers. If the chairs would like, we could add more methods or recent approaches to the results section to better pin down the performance of our methods. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0166/12/31/Paper2349" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0166/12/31/Paper2349" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0166-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0166/12/31/Paper2349"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0166/12/31/Paper2349","headline":"A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation","dateModified":"0166-12-31T00:00:00-05:17","datePublished":"0166-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Heiko Maier, Shahrooz Faghihroohi, Nassir Navab Abstract In order to scan for or monitor retinal diseases, OCT is a useful diagnostic tool that allows to take high-resolution images of the retinal layers. For the aim of fully automated, semantic segmentation of OCT images, both graph based models and deep neural networks have been used so far. Here, we propose to interpret the semantic segmentation of 2D OCT images as a sequence alignment task. Splitting the image into its constituent OCT scanning lines (A-Modes), we align an anatomically justified sequence of labels to these pixel sequences, using dynamic time warping. Combining this dynamic programming approach with learned convolutional filters allows us to leverage the feature extraction capabilities of deep neural networks, while at the same time enforcing explicit guarantees in terms of the anatomical order of layers through the dynamic programming. We investigate both the solitary training of the feature extraction stage, as well as an end-to-end learning of the alignment. The latter makes use of a recently proposed, relaxed formulation of dynamic time warping, that allows us to backpropagate through the dynamic program to enable end-to-end training of the network. Complementing these approaches, a local consistency criterion for the alignment task is investigated, that allows to improve consistency in the alignment of neighbouring A-Modes. We compare this approach to two state of the art methods, showing favourable results. Link to paper https://doi.org/10.1007/978-3-030-87193-2_67 Link to the code repository N/A Link to the dataset(s) http://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm Reviews Review #1 Please describe the contribution of the paper The authors present an approach for segmenting retinal layers in OCT by integrating dynamic time warping (DTW) with deep learning. Two approaches for integrating the CNN was investigated: 1) using pretrained CNN features and 2) End-to end CNN features. The evaluation was performed on a patient cohort of 10 subjects with diabetic macular edema, and showed improvements in the fluid class. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Overall, the paper is very well written with clear descriptions of existing literature, the two proposed methods, and the details for the training and evaluation. The proposed work represent a nice integration of existing ideas for OCT segmentation approaches with deep learning. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The primary weakness of the work is that the evaluation is a bit lacking. The experiment result is missing several key details, such as 1.) a baseline comparison against using DWT without deep learning. 2.) standard deviations for the dice results 3.) a evaluation of the topology in the final segmentations. The dataset used was also exceptionally small, with only 10 images in total and 2 subjects used for validation. Lastly, the proposed method does not, in general, seem to perform significantly better than the two baseline methods compared. The only improvement in performance seems to be the fluid class, but without knowing the variance of the performance, it is difficult to determine if such differences are significant. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The reproducibility is passable. An openly available dataset was used, but the authors do not appear willing to release their code. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I have a few recommendations that might help improve the quality of this paper: -Including additional details for the evaluation as listed above (i.e. baseline DWT comparison, standard deviation of the results, analysis of the layer topology). -Improving the quantity of subjects used for evaluation. Perhaps also demonstrating its performance on a dataset acquired from a different scanner. To show the model is not just overfitting the currently limited data. -In Figure 3 it is a bit unclear what the 2nd image is. And it is difficult to determine what structure each of the colors in each of the segmentations represent. Showing more than one example would also be helpful. Or showing the difference in segmentation result between the various methods being compared. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The authors present a novel integration of deep learning into an existing approach for retinal layer segmentation. The paper was very well written, and the results suggests improvement in the detection of the fluid class. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper this paper use the dynamic time warping in the task of retinal OCT segmentation The proposed method is fully end-to-end trainable. in addition, the method can guarantee too adhere to topological constraints. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. the idea of dynamic time warping in the task of OCT segmentation seems novel. The investigation of related work is sufficient. the authors also compare the result between DTW as post-processing and end-to-end training with DTW Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. the experiment is insufficient. there are only two papers for comparison. And only Language is published in 2020. So comparison with the latest method is not sufficient. About Table I, the best result should be shown in bold for comparison. This paper should be introduced DTW in detail rather than giving a reference. Please rate the clarity and organization of this paper Satisfactory Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance the description of the proposed method (DTW) is not clear. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html provide the detail of DTW more comparative experiment are necessary. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? the idea of dynamic time warping in the task of OCT segmentation seems novel. the sufficient study of releated work the insufficient comparative experiment. What is the ranking of this paper in your review stack? 3 Number of papers in your stack 5 Reviewer confidence Somewhat confident Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. There is consensus about the novelty of the proposed DTW-based segmentation method, but several questions about the experimental results were raised such as key missing details about the standard deviation of Dice coefficients, and a lack of evaluation of the topology of the final segmentation. The small sample size of the dataset also raises some concern about overfitting. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The rebuttal adequately addressed questions from the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 1 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The authors have responded to the reviewers concerns. The authors propose that they will add the results of the Dice coefficients in the paper. Their response on the evaluation methodology is satisfactory and the paper presents novel and interesting ideas. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 3 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. The reviews are positive and consistent, which recognize the novelty of this work. The authors’ response amends some essential details of the validation, which well addresses the concerns summarised from 1st round review. In summary, I agree to accept this paper. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback Dear Chairs, We would like to thank the reviewers for their constructive comments and the discussion. We are especially glad that both reviewers appreciate the novelty of our approach. Still, we would like to discuss a few points mentioned by the them: 1) We will gladly provide standard deviations of our dice scores (asked by R2). To summarize, over the 22 B-Modes in the test set, our 4 methods have standard deviations in their dice scores that are on average, over all classes, between 0.065 and 0.076, with the largest contributions coming from the fluid class (between 0.322 and 0.332). The latter makes sense as fluid comprises one of the smallest classes and is often concentrated in only one region in the B-Mode. If the network does not recognize this region as containing fluid, the dice score for fluid in one single B-Mode can easily become 0, leading to a higher std deviation than for the retinal layer classes. A full listing of all the standard deviations could be added to the paper if desirable. 2) R2 wishes to see a study of the topology of the final segmentations. On the specified test set, we counted the number of topological violations, defined as the number of times the method assigned a pixel to a layer (N-1) after it had already assigned at least one pixel as being of layer (N). Means and std deviations of these violations over 4 training runs were: using only a CNN (no DTW at all) : (27570 +- 2504); soft-DTW: (28 +- 17); pretr. Only and soft-hard DTW (with and without cumulative dist. matrix): (0 +- 0). This clearly shows that using soft DTW strongly diminishes the violations a simple CNN alone produces and using a “hard” DTW completely prevents violations by design. These numbers can be added to the paper for completeness. 3) R2&amp;3 mention that we evaluate our results on only one dataset. We would like to point out that the given DUKE Dataset for retinal layer and fluid segmentation, with its 110 OCT images (10 subjects x 11 images), is a comprehensive, public dataset that is popular in the field. Due to this, we think firstly evaluating a new approach on this dataset is a reasonable choice. 4) R2 asked us to evaluate DTW without deep learning for the distance function. We did not add such a comparison because the only paper doing so [Source 6 in our paper] only does semi-automatic segmentation, and thus is not directly comparable to the fully automated approaches presented here. Furthermore, we do not see a straightforward way of using DTW for retinal OCT segmentation in a fully automated manner without a learned distance function. (Note that as DTW needs a distance function giving the “cost” of aligning to entries of two sequences, one would need to design such a distance function manually if he or she does not want to learn it. This manual design can rather easily be done to align two sequences of identical type, like two A-Modes, e.g. using a squared Euclidean distance as in [6]. It would be much more challenging to define it between two sequences of different kinds – e.g. an A-Mode and a symbolic series like our topological reference series, which is why we think a data driven approach is expected to outperform any non-deep learning approach here.) 5) R3 mentioned that we only compare to two baseline methods, of which only one is from 2020. We agree that we did not perform an exhaustive comparison of state of the art methods. Our aim was mostly to present our novel idea to the community and to validate the applicability of DTW, in combination with Deep Learning, to OCT. For this, these two baselines were useful because the paper that provided them had evaluated their experiments using the same train/validation/test split that we had worked on, and because they also do joint segmentation of layers and fluid unlike many other approaches that only segment layers. If the chairs would like, we could add more methods or recent approaches to the results section to better pin down the performance of our methods. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Maier, Heiko,Faghihroohi, Shahrooz,Navab, Nassir" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>A Line to Align: Deep Dynamic Time Warping for Retinal OCT Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a>
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a>
      
      <a 
        href="kittywong/categories#Modalities - Biophotonics"
        class="post-category">
        Modalities - Biophotonics
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Maier, Heiko"
        class="post-tags">
        Maier, Heiko
      </a> |  
      
      <a href="kittywong/tags#Faghihroohi, Shahrooz"
        class="post-tags">
        Faghihroohi, Shahrooz
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-tags">
        Navab, Nassir
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Heiko Maier, Shahrooz Faghihroohi, Nassir Navab
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>In order to scan for or monitor retinal diseases, OCT is a useful diagnostic tool that allows to take high-resolution images of the retinal layers. For the aim of fully automated, semantic segmentation of OCT images, both graph based models and deep neural networks have been used so far. Here, we propose to interpret the semantic segmentation of 2D OCT images as a sequence alignment task. Splitting the image into its constituent OCT scanning lines (A-Modes), we align an anatomically justified sequence of labels to these pixel sequences, using dynamic time warping. Combining this dynamic programming approach with learned convolutional filters allows us to leverage the feature extraction capabilities of deep neural networks, while at the same time enforcing explicit guarantees in terms of the anatomical order of layers through the dynamic programming. We investigate both the solitary training of the feature extraction stage, as well as an end-to-end learning of the alignment. The latter makes use of a recently proposed, relaxed formulation of dynamic time warping, that allows us to backpropagate through the dynamic program to enable end-to-end training of the network. Complementing these approaches, a local consistency criterion for the alignment task is investigated, that allows to improve consistency in the alignment of neighbouring A-Modes. We compare this approach to two state of the art methods, showing favourable results.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87193-2_67">https://doi.org/10.1007/978-3-030-87193-2_67</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>N/A
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>http://people.duke.edu/~sf59/Chiu_BOE_2014_dataset.htm
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors present an approach for segmenting retinal layers in OCT by integrating dynamic time warping (DTW) with deep learning. Two approaches for integrating the CNN was investigated: 1) using pretrained CNN features and 2) End-to end CNN features. The evaluation was performed on a patient cohort of 10 subjects with diabetic macular edema, and showed improvements in the fluid class.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>Overall, the paper is very well written with clear descriptions of existing literature, the two proposed methods, and the details for the training and evaluation. The proposed work represent a nice integration of existing ideas for OCT segmentation approaches with deep learning.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The primary weakness of the work is that the evaluation is a bit lacking. The experiment result is missing several key details, such as 1.) a baseline comparison against using DWT without deep learning. 2.) standard deviations for the dice results 3.) a evaluation of the topology in the final segmentations. The dataset used was also exceptionally small, with only 10 images in total and 2 subjects used for validation. Lastly, the proposed method does not, in general, seem to perform significantly better than the two baseline methods compared. The only improvement in performance seems to be the fluid class, but without knowing the variance of the performance, it is difficult to determine if such differences are significant.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The reproducibility is passable. An openly available dataset was used, but the authors do not appear willing to release their code.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>I have a few recommendations that might help improve the quality of this paper:</p>

      <p>-Including additional details for the evaluation as listed above (i.e. baseline DWT comparison, standard deviation of the results, analysis of the layer topology).</p>

      <p>-Improving the quantity of subjects used for evaluation. Perhaps also demonstrating its performance on a dataset acquired from a different scanner. To show the model is not just overfitting the currently limited data.</p>

      <p>-In Figure 3 it is a bit unclear what the 2nd image is. And it is difficult to determine what structure each of the colors in each of the segmentations represent. Showing more than one example would also be helpful. Or showing the difference in segmentation result between the various methods being compared.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The authors present a novel integration of deep learning into an existing approach for retinal layer segmentation. The paper was very well written, and the results suggests improvement in the detection of the fluid class.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <ul>
        <li>this paper use the dynamic time warping in the task of retinal OCT segmentation</li>
        <li>The proposed method is fully end-to-end trainable. in addition, the method can guarantee too adhere to topological constraints.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>the idea of dynamic time warping in the task of OCT segmentation seems novel.</li>
        <li>The investigation of related work is sufficient.</li>
        <li>the authors also compare the result between DTW as post-processing and end-to-end training with DTW</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>the experiment is insufficient. there are only two papers for comparison. And only Language is  published in 2020. So comparison with the latest method is not sufficient.</li>
        <li>About Table I, the best result should be shown in bold for comparison.</li>
        <li>This paper should be introduced DTW in detail rather than giving a reference.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Satisfactory</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <ul>
        <li>the description of the proposed method (DTW) is not clear.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ul>
        <li>provide the detail of DTW</li>
        <li>more comparative experiment are necessary.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <ul>
        <li>the idea of dynamic time warping in the task of OCT segmentation seems novel.</li>
        <li>the sufficient study of releated work</li>
        <li>the insufficient comparative experiment.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Somewhat confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>There is consensus about the novelty of the proposed DTW-based segmentation method, but several questions about the experimental results were raised such as key missing details about the standard deviation of Dice coefficients, and a lack of evaluation of the topology of the final segmentation. The small sample size of the dataset also raises some concern about overfitting.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The rebuttal adequately addressed questions from the reviewers.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The authors have responded to the reviewers concerns. The authors propose that they will add the results of the Dice coefficients in the paper. Their response on the evaluation methodology is satisfactory and the paper presents novel and interesting ideas.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>The reviews are positive and consistent, which recognize the novelty of this work. The authors’ response amends some essential details of the validation, which well addresses the concerns summarised from 1st round review. In summary, I agree to accept this paper.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>Dear Chairs,
We would like to thank the reviewers for their constructive comments and the discussion. We are especially glad that both reviewers appreciate the novelty of our approach. Still, we would like to discuss a few points mentioned by the them:
1) We will gladly provide standard deviations of our dice scores (asked by R2). To summarize, over the 22 B-Modes in the test set, our 4 methods have standard deviations in their dice scores that are on average, over all classes, between 0.065 and 0.076, with the largest contributions coming from the fluid class (between 0.322 and 0.332). The latter makes sense as fluid comprises one of the smallest classes and is often concentrated in only one region in the B-Mode. If the network does not recognize this region as containing fluid, the dice score for fluid in one single B-Mode can easily become 0, leading to a higher std deviation than for the retinal layer classes. A full listing of all the standard deviations could be added to the paper if desirable.
2) R2 wishes to see a study of the topology of the final segmentations. On the specified test set, we counted the number of topological violations, defined as the number of times the method assigned a pixel to a layer (N-1) after it had already assigned at least one pixel as being of layer (N). Means and std deviations of these violations over 4 training runs were: using only a CNN (no DTW at all) : (27570 +- 2504);  soft-DTW: (28 +- 17); pretr. Only and soft-hard DTW (with and without cumulative dist. matrix): (0 +- 0). This clearly shows that using soft DTW strongly diminishes the violations a simple CNN alone produces and using a “hard” DTW completely prevents violations by design. These numbers can be added to the paper for completeness.
3) R2&amp;3  mention that we evaluate our results on only one dataset. We would like to point out that the given DUKE Dataset for retinal layer and fluid segmentation, with its 110 OCT images (10 subjects x 11 images), is a comprehensive, public dataset that is popular in the field. Due to this, we think firstly evaluating a new approach on this dataset is a reasonable choice. 
4) R2 asked us to evaluate DTW without deep learning for the distance function. We did not add such a comparison because the only paper doing so [Source 6 in our paper] only does semi-automatic segmentation, and thus is not directly comparable to the fully automated approaches presented here. Furthermore, we do not see a straightforward way of using DTW for retinal OCT segmentation in a fully automated manner without a learned distance function. (Note that as DTW needs a distance function giving the “cost” of aligning to entries of two sequences, one would need to design such a distance function manually if he or she does not want to learn it. This manual design can rather easily be done to align two sequences of identical type, like two A-Modes, e.g. using a squared Euclidean distance as in [6]. It would be much more challenging to define it between two sequences of different kinds – e.g.  an A-Mode and a symbolic series like our topological reference series, which is why we think a data driven approach is expected to outperform any non-deep learning approach here.)
5) R3 mentioned that we only compare to two baseline methods, of which only one is from 2020. We agree that we did not perform an exhaustive comparison of state of the art methods. Our aim was mostly to present our novel idea to the community and to validate the applicability of DTW, in combination with Deep Learning, to OCT. For this, these two baselines were useful because the paper that provided them had evaluated their experiments using the same train/validation/test split that we had worked on, and because they also do joint segmentation of layers and fluid unlike many other approaches that only segment layers. If the chairs would like, we could add more methods or recent approaches to the results section to better pin down the performance of our methods.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0166-12-31
      -->
      <!--
      
        ,
        updated at 
        0167-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Clinical applications - Ophthalmology"
        class="post-category">
        Clinical applications - Ophthalmology
      </a> |
      
      <a 
        href="kittywong/categories#Computer Aided Diagnosis"
        class="post-category">
        Computer Aided Diagnosis
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - Biophotonics"
        class="post-category">
        Modalities - Biophotonics
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Maier, Heiko"
        class="post-category">
        Maier, Heiko
      </a> |  
      
      <a href="kittywong/tags#Faghihroohi, Shahrooz"
        class="post-category">
        Faghihroohi, Shahrooz
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-category">
        Navab, Nassir
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0167/12/31/Paper2375">
          Learnable Oriented-Derivative Network for Polyp Segmentation
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0165/12/31/Paper2335">
          Shallow Attention Network for Polyp Segmentation
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
