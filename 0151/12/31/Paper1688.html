<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tan Nguyen, Binh-Son Hua, Ngan Le Abstract Medical image segmentation has been so far achieving promising results with Convolutional Neural Networks (CNNs). However, it is arguable that in traditional CNNs, its pooling layer tends to discard important information such as positions. Moreover, CNNs are sensitive to rotation and affine transformation. Capsule network is a data-efficient network design proposed to overcome such limitations by replacing pooling layers with dynamic routing and convolutional strides, which aims to preserve the part-whole relationships. Capsule network has shown a great performance in image recognition and natural language processing, but applications for medical image segmentation, particularly volumetric image segmentation, has been limited. In this work, we propose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image segmentation.We build the concept of capsules into a CNN by designing a network with two pathways: the first pathway is encoded by 3D Capsule blocks,whereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps,therefore inherits the merits from both Capsule network to preserve the spatial relationship and CNNs to learn visual representation. We conducted experiments on various datasets to demonstrate the robustness of 3D-UCaps including iSeg-2017, LUNA16, Hippocampus, and Cardiac,where our method outperforms previous Capsule networks and 3D-UNets. Our code is available at https://github.com/VinAIResearch/3D-UCaps. Link to paper https://doi.org/10.1007/978-3-030-87193-2_52 Link to the code repository https://github.com/VinAIResearch/3D-UCaps Link to the dataset(s) https://iseg2017.web.unc.edu/download/ https://luna16.grand-challenge.org/Download/ http://medicaldecathlon.com/ Reviews Review #1 Please describe the contribution of the paper The authors present an investigation of how to exploit the capsules network in medical image segmentation tasks. Compared to previous SegCaps, the proposed 3D-UCaps make 3D volumetric segmentation possible and enjoy the merits of both capsule blocks (rotation and translation invariant) and CNN (feature extraction). With only 17 layers, the results outperform previous leading approaches. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The exploration of how to effectively use the capsules network in the medical image segmentation task itself stands for its novelty. The work presents a thorough and extensive experimental section using iSeg, LUNA16, Hippocampus, and Cardiac datasets for evaluation. The current method presents a design of more capsule types in the lower-level layers, which contrasts with the SegCaps design. The resulting network obtains better results when compared to the previous work. Paper is clear and well written. I enjoy reading this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I couldn’t find major weaknesses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors listed “yes” for both code and pre-trained models. In this case, it can be an easy task for both training and testing. If the reproduction was only based on the descriptions in the paper, it could be somewhat difficult. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Minor concerns: It would be nice if the authors could show some examples for demonstration. I have some concerns about the empirical finding, i.e., the expanding path has negligible effects. It would be great if the authors can further discuss this finding. I know the optimization could be an obstacle, but I am still interested to see if the proposed network can handle multi-class segmentation, e.g., the 2019 head and neck MICCAI challenge. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The investigation of how to exploit the capsule networks in medical image segmentation stands out as its novelty. The paper also has some unique designs and fruitful findings, which are neat and in principle. Thus, I would recommend this paper to be accepted. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper investigates a 3D voxel-based capsule network where 3D capsule blocks in the encoder branch and 3D deconv blocks in the decoder branch for medical image segmentation. It uses publicly available datasets and shows the robustness of the proposed network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper uses capsule networks to tackle some of issues with CNN due to rotation and affine transformation and pooling. The paper includes the contextual information along the temporal axis. The proposed methodology is an extension to the volumetric data with additional improvements and it can be considered as novel. Some design selections are explained well with their reasons in the paper, which is helpful. Extensive experiments are done in the paper and comparisons as well as discussions are provided. Rotation variance and motion artifacts are studied. Considerable performance improvements are shown. For a meaningful comparison, the paper also implements a 3D-SegCaps which is the 3D extenstion of the existing SegCaps. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. One major weakness is that the paper does not provide any results for 3D SegCaps for the LUNA16, Hippocampus, cardiac datasets even though the authors have already implemented the network. What is the reasoning behind this? Also, why does the paper compare 3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts? The motion artifacts created in the paper may be not realistic and it does not cover whole range of motion artifacts that could occur in clinical scenario. If the authors could address this point, that would help. Lastly, when the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides the code according to the reproducibility checklist and the datasets are publicly available so it should not be difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I think overall the paper is presented well however, as a reviewer and a reader, it would help if the authors answers the questions above related to the reasoning of the missing results of 3D SegCaps for other datasets, selection of 3D SkipDense instead of 3D U-Net, rotation invariance and motion artifacts. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novel metholodogy, extensive experiments and well explained design choices. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. Based on the reviewers’ comments, we think this is a high-quality paper with significant technical contributions. Authors should address reviewers’ comments in the camera-ready submission. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their feedback. We are glad to receive positive comments that value the contribution of our work. We clarify the key points and then address specific concerns individually. MAJOR CONCERNS KP1. Reproducibility and expandability We will release both source code and pre-trained models. Our code is implemented with Pytorch Lightning with MONAI framework for processing data, running sliding window inference and computing dice score with fixed seed. We hope that by having up-to-date frameworks, the community can reproduce our results and extend our method to other problems. KP2. Motion artifacts Motion artifact is a complex problem with many partial solutions as given in Zaitsev et al., Motion artifacts in MRI: A complex problem with many partial solutions, Journal of Magnetic Resonance Imaging, 2015. In this work, we simplify the motion artifacts caused by patient movement during scanning by rotating 20\% number of slides with angle randomly chosen from (-5, 5) degrees around x/y/z-axis. More realistic experiments with various k-space motion artifacts argumentation will be examined with TorchIO in our future study. KP3. “Performance of 3D SegCaps on the LUNA16, Hippocampus, cardiac datasets” Our best trial for 3D SegCaps produced result no better than [24], and so we have shifted the focus to our proposed method. The possible answer for this problem can be seen in the third concern of Reviewer 1. As per request, we will provide additional segmentation performance of 3D SegCaps to get a full comparison. INDIVIDUAL CONCERNS Reviewer 1 Reproducibility: Please refer KP1. Demonstration: Qualitative results will be made as a supplementary and will be added to the code release. The empirical finding, i.e., the expanding path has negligible effects” Further investigation is needed to understand the effects of capsules in the expanding path. In our hypothesis, routing algorithm works based on routing-by-agreement between part to whole relationship, however the relationship between whole to part is one-to-many, and it is ambiguous to find the agreement between whole to active corresponding parts. Multi-class segmentation: We have conducted the experimental results on multi-class segmentation with 3D UCaps as given in Tables 1, 2, 3 on iSeg dataset with 3 classes i.e. WT, GM, CSF. Reviewer 3 “3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts?” We are motivated by the iSeg2017 challenge [26] in which all participating methods performed poorly on the testing subjects acquired with motion artifacts and unusual scan poses. We choose to report 3D SkipDense as this method is proposed in 2019 and has the state-of-the-art performance. Their code and pretrained model are also publicly available. “When the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen?” We trained our network with provided data in the dataset without any rotation data augmentation. During testing, we choose an axis to rotate the volume, and apply the rotation with angle values fixed to 5, 10, 15, .., 90 degrees. In our experiment, the performance tends to drop slightly when the rotation angles increases. We also found that rotating about a single axis or all axes does not have significant performance difference, which explains the capability to handle rotation invariance in a capsule network. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Tan Nguyen, Binh-Son Hua, Ngan Le Abstract Medical image segmentation has been so far achieving promising results with Convolutional Neural Networks (CNNs). However, it is arguable that in traditional CNNs, its pooling layer tends to discard important information such as positions. Moreover, CNNs are sensitive to rotation and affine transformation. Capsule network is a data-efficient network design proposed to overcome such limitations by replacing pooling layers with dynamic routing and convolutional strides, which aims to preserve the part-whole relationships. Capsule network has shown a great performance in image recognition and natural language processing, but applications for medical image segmentation, particularly volumetric image segmentation, has been limited. In this work, we propose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image segmentation.We build the concept of capsules into a CNN by designing a network with two pathways: the first pathway is encoded by 3D Capsule blocks,whereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps,therefore inherits the merits from both Capsule network to preserve the spatial relationship and CNNs to learn visual representation. We conducted experiments on various datasets to demonstrate the robustness of 3D-UCaps including iSeg-2017, LUNA16, Hippocampus, and Cardiac,where our method outperforms previous Capsule networks and 3D-UNets. Our code is available at https://github.com/VinAIResearch/3D-UCaps. Link to paper https://doi.org/10.1007/978-3-030-87193-2_52 Link to the code repository https://github.com/VinAIResearch/3D-UCaps Link to the dataset(s) https://iseg2017.web.unc.edu/download/ https://luna16.grand-challenge.org/Download/ http://medicaldecathlon.com/ Reviews Review #1 Please describe the contribution of the paper The authors present an investigation of how to exploit the capsules network in medical image segmentation tasks. Compared to previous SegCaps, the proposed 3D-UCaps make 3D volumetric segmentation possible and enjoy the merits of both capsule blocks (rotation and translation invariant) and CNN (feature extraction). With only 17 layers, the results outperform previous leading approaches. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The exploration of how to effectively use the capsules network in the medical image segmentation task itself stands for its novelty. The work presents a thorough and extensive experimental section using iSeg, LUNA16, Hippocampus, and Cardiac datasets for evaluation. The current method presents a design of more capsule types in the lower-level layers, which contrasts with the SegCaps design. The resulting network obtains better results when compared to the previous work. Paper is clear and well written. I enjoy reading this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I couldn’t find major weaknesses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors listed “yes” for both code and pre-trained models. In this case, it can be an easy task for both training and testing. If the reproduction was only based on the descriptions in the paper, it could be somewhat difficult. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Minor concerns: It would be nice if the authors could show some examples for demonstration. I have some concerns about the empirical finding, i.e., the expanding path has negligible effects. It would be great if the authors can further discuss this finding. I know the optimization could be an obstacle, but I am still interested to see if the proposed network can handle multi-class segmentation, e.g., the 2019 head and neck MICCAI challenge. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The investigation of how to exploit the capsule networks in medical image segmentation stands out as its novelty. The paper also has some unique designs and fruitful findings, which are neat and in principle. Thus, I would recommend this paper to be accepted. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper investigates a 3D voxel-based capsule network where 3D capsule blocks in the encoder branch and 3D deconv blocks in the decoder branch for medical image segmentation. It uses publicly available datasets and shows the robustness of the proposed network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper uses capsule networks to tackle some of issues with CNN due to rotation and affine transformation and pooling. The paper includes the contextual information along the temporal axis. The proposed methodology is an extension to the volumetric data with additional improvements and it can be considered as novel. Some design selections are explained well with their reasons in the paper, which is helpful. Extensive experiments are done in the paper and comparisons as well as discussions are provided. Rotation variance and motion artifacts are studied. Considerable performance improvements are shown. For a meaningful comparison, the paper also implements a 3D-SegCaps which is the 3D extenstion of the existing SegCaps. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. One major weakness is that the paper does not provide any results for 3D SegCaps for the LUNA16, Hippocampus, cardiac datasets even though the authors have already implemented the network. What is the reasoning behind this? Also, why does the paper compare 3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts? The motion artifacts created in the paper may be not realistic and it does not cover whole range of motion artifacts that could occur in clinical scenario. If the authors could address this point, that would help. Lastly, when the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides the code according to the reproducibility checklist and the datasets are publicly available so it should not be difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I think overall the paper is presented well however, as a reviewer and a reader, it would help if the authors answers the questions above related to the reasoning of the missing results of 3D SegCaps for other datasets, selection of 3D SkipDense instead of 3D U-Net, rotation invariance and motion artifacts. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novel metholodogy, extensive experiments and well explained design choices. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. Based on the reviewers’ comments, we think this is a high-quality paper with significant technical contributions. Authors should address reviewers’ comments in the camera-ready submission. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their feedback. We are glad to receive positive comments that value the contribution of our work. We clarify the key points and then address specific concerns individually. MAJOR CONCERNS KP1. Reproducibility and expandability We will release both source code and pre-trained models. Our code is implemented with Pytorch Lightning with MONAI framework for processing data, running sliding window inference and computing dice score with fixed seed. We hope that by having up-to-date frameworks, the community can reproduce our results and extend our method to other problems. KP2. Motion artifacts Motion artifact is a complex problem with many partial solutions as given in Zaitsev et al., Motion artifacts in MRI: A complex problem with many partial solutions, Journal of Magnetic Resonance Imaging, 2015. In this work, we simplify the motion artifacts caused by patient movement during scanning by rotating 20\% number of slides with angle randomly chosen from (-5, 5) degrees around x/y/z-axis. More realistic experiments with various k-space motion artifacts argumentation will be examined with TorchIO in our future study. KP3. “Performance of 3D SegCaps on the LUNA16, Hippocampus, cardiac datasets” Our best trial for 3D SegCaps produced result no better than [24], and so we have shifted the focus to our proposed method. The possible answer for this problem can be seen in the third concern of Reviewer 1. As per request, we will provide additional segmentation performance of 3D SegCaps to get a full comparison. INDIVIDUAL CONCERNS Reviewer 1 Reproducibility: Please refer KP1. Demonstration: Qualitative results will be made as a supplementary and will be added to the code release. The empirical finding, i.e., the expanding path has negligible effects” Further investigation is needed to understand the effects of capsules in the expanding path. In our hypothesis, routing algorithm works based on routing-by-agreement between part to whole relationship, however the relationship between whole to part is one-to-many, and it is ambiguous to find the agreement between whole to active corresponding parts. Multi-class segmentation: We have conducted the experimental results on multi-class segmentation with 3D UCaps as given in Tables 1, 2, 3 on iSeg dataset with 3 classes i.e. WT, GM, CSF. Reviewer 3 “3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts?” We are motivated by the iSeg2017 challenge [26] in which all participating methods performed poorly on the testing subjects acquired with motion artifacts and unusual scan poses. We choose to report 3D SkipDense as this method is proposed in 2019 and has the state-of-the-art performance. Their code and pretrained model are also publicly available. “When the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen?” We trained our network with provided data in the dataset without any rotation data augmentation. During testing, we choose an axis to rotate the volume, and apply the rotation with angle values fixed to 5, 10, 15, .., 90 degrees. In our experiment, the performance tends to drop slightly when the rotation angles increases. We also found that rotating about a single axis or all axes does not have significant performance difference, which explains the capability to handle rotation invariance in a capsule network. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0151/12/31/Paper1688" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0151/12/31/Paper1688" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0151-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0151/12/31/Paper1688"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0151/12/31/Paper1688","headline":"3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation","dateModified":"0151-12-31T00:00:00-05:17","datePublished":"0151-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Tan Nguyen, Binh-Son Hua, Ngan Le Abstract Medical image segmentation has been so far achieving promising results with Convolutional Neural Networks (CNNs). However, it is arguable that in traditional CNNs, its pooling layer tends to discard important information such as positions. Moreover, CNNs are sensitive to rotation and affine transformation. Capsule network is a data-efficient network design proposed to overcome such limitations by replacing pooling layers with dynamic routing and convolutional strides, which aims to preserve the part-whole relationships. Capsule network has shown a great performance in image recognition and natural language processing, but applications for medical image segmentation, particularly volumetric image segmentation, has been limited. In this work, we propose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image segmentation.We build the concept of capsules into a CNN by designing a network with two pathways: the first pathway is encoded by 3D Capsule blocks,whereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps,therefore inherits the merits from both Capsule network to preserve the spatial relationship and CNNs to learn visual representation. We conducted experiments on various datasets to demonstrate the robustness of 3D-UCaps including iSeg-2017, LUNA16, Hippocampus, and Cardiac,where our method outperforms previous Capsule networks and 3D-UNets. Our code is available at https://github.com/VinAIResearch/3D-UCaps. Link to paper https://doi.org/10.1007/978-3-030-87193-2_52 Link to the code repository https://github.com/VinAIResearch/3D-UCaps Link to the dataset(s) https://iseg2017.web.unc.edu/download/ https://luna16.grand-challenge.org/Download/ http://medicaldecathlon.com/ Reviews Review #1 Please describe the contribution of the paper The authors present an investigation of how to exploit the capsules network in medical image segmentation tasks. Compared to previous SegCaps, the proposed 3D-UCaps make 3D volumetric segmentation possible and enjoy the merits of both capsule blocks (rotation and translation invariant) and CNN (feature extraction). With only 17 layers, the results outperform previous leading approaches. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The exploration of how to effectively use the capsules network in the medical image segmentation task itself stands for its novelty. The work presents a thorough and extensive experimental section using iSeg, LUNA16, Hippocampus, and Cardiac datasets for evaluation. The current method presents a design of more capsule types in the lower-level layers, which contrasts with the SegCaps design. The resulting network obtains better results when compared to the previous work. Paper is clear and well written. I enjoy reading this paper. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. I couldn’t find major weaknesses. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The authors listed “yes” for both code and pre-trained models. In this case, it can be an easy task for both training and testing. If the reproduction was only based on the descriptions in the paper, it could be somewhat difficult. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Minor concerns: It would be nice if the authors could show some examples for demonstration. I have some concerns about the empirical finding, i.e., the expanding path has negligible effects. It would be great if the authors can further discuss this finding. I know the optimization could be an obstacle, but I am still interested to see if the proposed network can handle multi-class segmentation, e.g., the 2019 head and neck MICCAI challenge. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The investigation of how to exploit the capsule networks in medical image segmentation stands out as its novelty. The paper also has some unique designs and fruitful findings, which are neat and in principle. Thus, I would recommend this paper to be accepted. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 3 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper investigates a 3D voxel-based capsule network where 3D capsule blocks in the encoder branch and 3D deconv blocks in the decoder branch for medical image segmentation. It uses publicly available datasets and shows the robustness of the proposed network. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The paper uses capsule networks to tackle some of issues with CNN due to rotation and affine transformation and pooling. The paper includes the contextual information along the temporal axis. The proposed methodology is an extension to the volumetric data with additional improvements and it can be considered as novel. Some design selections are explained well with their reasons in the paper, which is helpful. Extensive experiments are done in the paper and comparisons as well as discussions are provided. Rotation variance and motion artifacts are studied. Considerable performance improvements are shown. For a meaningful comparison, the paper also implements a 3D-SegCaps which is the 3D extenstion of the existing SegCaps. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. One major weakness is that the paper does not provide any results for 3D SegCaps for the LUNA16, Hippocampus, cardiac datasets even though the authors have already implemented the network. What is the reasoning behind this? Also, why does the paper compare 3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts? The motion artifacts created in the paper may be not realistic and it does not cover whole range of motion artifacts that could occur in clinical scenario. If the authors could address this point, that would help. Lastly, when the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen? Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper provides the code according to the reproducibility checklist and the datasets are publicly available so it should not be difficult to reproduce the results. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html I think overall the paper is presented well however, as a reviewer and a reader, it would help if the authors answers the questions above related to the reasoning of the missing results of 3D SegCaps for other datasets, selection of 3D SkipDense instead of 3D U-Net, rotation invariance and motion artifacts. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Novel metholodogy, extensive experiments and well explained design choices. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. Based on the reviewers’ comments, we think this is a high-quality paper with significant technical contributions. Authors should address reviewers’ comments in the camera-ready submission. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 4 Author Feedback We thank the reviewers for their feedback. We are glad to receive positive comments that value the contribution of our work. We clarify the key points and then address specific concerns individually. MAJOR CONCERNS KP1. Reproducibility and expandability We will release both source code and pre-trained models. Our code is implemented with Pytorch Lightning with MONAI framework for processing data, running sliding window inference and computing dice score with fixed seed. We hope that by having up-to-date frameworks, the community can reproduce our results and extend our method to other problems. KP2. Motion artifacts Motion artifact is a complex problem with many partial solutions as given in Zaitsev et al., Motion artifacts in MRI: A complex problem with many partial solutions, Journal of Magnetic Resonance Imaging, 2015. In this work, we simplify the motion artifacts caused by patient movement during scanning by rotating 20\\% number of slides with angle randomly chosen from (-5, 5) degrees around x/y/z-axis. More realistic experiments with various k-space motion artifacts argumentation will be examined with TorchIO in our future study. KP3. “Performance of 3D SegCaps on the LUNA16, Hippocampus, cardiac datasets” Our best trial for 3D SegCaps produced result no better than [24], and so we have shifted the focus to our proposed method. The possible answer for this problem can be seen in the third concern of Reviewer 1. As per request, we will provide additional segmentation performance of 3D SegCaps to get a full comparison. INDIVIDUAL CONCERNS Reviewer 1 Reproducibility: Please refer KP1. Demonstration: Qualitative results will be made as a supplementary and will be added to the code release. The empirical finding, i.e., the expanding path has negligible effects” Further investigation is needed to understand the effects of capsules in the expanding path. In our hypothesis, routing algorithm works based on routing-by-agreement between part to whole relationship, however the relationship between whole to part is one-to-many, and it is ambiguous to find the agreement between whole to active corresponding parts. Multi-class segmentation: We have conducted the experimental results on multi-class segmentation with 3D UCaps as given in Tables 1, 2, 3 on iSeg dataset with 3 classes i.e. WT, GM, CSF. Reviewer 3 “3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts?” We are motivated by the iSeg2017 challenge [26] in which all participating methods performed poorly on the testing subjects acquired with motion artifacts and unusual scan poses. We choose to report 3D SkipDense as this method is proposed in 2019 and has the state-of-the-art performance. Their code and pretrained model are also publicly available. “When the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen?” We trained our network with provided data in the dataset without any rotation data augmentation. During testing, we choose an axis to rotate the volume, and apply the rotation with angle values fixed to 5, 10, 15, .., 90 degrees. In our experiment, the performance tends to drop slightly when the rotation angles increases. We also found that rotating about a single axis or all axes does not have significant performance difference, which explains the capability to handle rotation invariance in a capsule network. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Nguyen, Tan,Hua, Binh-Son,Le, Ngan" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Interpretability / Explainability"
        class="post-category">
        Machine Learning - Interpretability / Explainability
      </a>
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a>
      
      <a 
        href="kittywong/categories#Modalities - MRI"
        class="post-category">
        Modalities - MRI
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Nguyen, Tan"
        class="post-tags">
        Nguyen, Tan
      </a> |  
      
      <a href="kittywong/tags#Hua, Binh-Son"
        class="post-tags">
        Hua, Binh-Son
      </a> |  
      
      <a href="kittywong/tags#Le, Ngan"
        class="post-tags">
        Le, Ngan
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Tan Nguyen, Binh-Son Hua, Ngan Le
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Medical image segmentation has been so far achieving promising results with Convolutional Neural Networks (CNNs). However, it is arguable that in traditional CNNs, its pooling layer tends to discard important information such as positions. Moreover, CNNs are sensitive to rotation and affine transformation. Capsule network is a data-efficient network design proposed to overcome such limitations by replacing pooling layers with dynamic routing and convolutional strides, which aims to preserve the part-whole relationships. Capsule network has shown a great performance in image recognition and natural language processing, but applications for medical image segmentation, particularly volumetric image segmentation, has been limited. In this work, we propose 3D-UCaps, a 3D voxel-based Capsule network for medical volumetric image segmentation.We build the concept of capsules into a CNN by designing a network with two pathways: the first pathway is encoded by 3D Capsule blocks,whereas the second pathway is decoded by 3D CNNs blocks. 3D-UCaps,therefore inherits the merits from both Capsule network to preserve the spatial relationship and CNNs to learn visual representation. We conducted experiments on various datasets to demonstrate the robustness of 3D-UCaps including iSeg-2017, LUNA16, Hippocampus, and Cardiac,where our method outperforms previous Capsule networks and 3D-UNets. Our code is available at https://github.com/VinAIResearch/3D-UCaps.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87193-2_52">https://doi.org/10.1007/978-3-030-87193-2_52</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/VinAIResearch/3D-UCaps
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://iseg2017.web.unc.edu/download/
https://luna16.grand-challenge.org/Download/
http://medicaldecathlon.com/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors present an investigation of how to exploit the capsules network in medical image segmentation tasks. Compared to previous SegCaps, the proposed 3D-UCaps make 3D volumetric segmentation possible and enjoy the merits of both capsule blocks (rotation and translation invariant) and CNN (feature extraction). With only 17 layers, the results outperform previous leading approaches.</p>

    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>
          <p>The exploration of how to effectively use the capsules network in the medical image segmentation task itself stands for its novelty.</p>
        </li>
        <li>
          <p>The work presents a thorough and extensive experimental section using iSeg, LUNA16, Hippocampus, and Cardiac datasets for evaluation.</p>
        </li>
        <li>
          <p>The current method presents a design of more capsule types in the lower-level layers, which contrasts with the SegCaps design. The resulting network obtains better results when compared to the previous work.</p>
        </li>
        <li>
          <p>Paper is clear and well written. I enjoy reading this paper.</p>
        </li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>I couldn’t find major weaknesses.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The authors listed “yes” for both code and pre-trained models. In this case, it can be an easy task for both training and testing. 
If the reproduction was only based on the descriptions in the paper, it could be somewhat difficult.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Minor concerns:</p>
      <ul>
        <li>It would be nice if the authors could show some examples for demonstration.</li>
        <li>I have some concerns about the empirical finding, i.e., the expanding path has negligible effects. It would be great if the authors can further discuss this finding.</li>
        <li>I know the optimization could be an obstacle, but I am still interested to see if the proposed network can handle multi-class segmentation, e.g., the 2019 head and neck MICCAI challenge.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The investigation of how to exploit the capsule networks in medical image segmentation stands out as its novelty. The paper also has some unique designs and fruitful findings, which are neat and in principle. Thus, I would recommend this paper to be accepted.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>3</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper investigates a 3D voxel-based capsule network where 3D capsule blocks in the encoder branch and 3D deconv blocks in the decoder branch for medical image segmentation. It uses publicly available datasets and shows the robustness of the proposed network.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The paper uses capsule networks to tackle some of issues with CNN due to rotation and affine transformation and pooling. The paper includes the contextual information along the temporal axis. The proposed methodology is an extension to the volumetric data with additional improvements and it can be considered as novel.</p>

      <p>Some design selections are explained well with their reasons in the paper, which is helpful.</p>

      <p>Extensive experiments are done in the paper and comparisons as well as discussions are provided. Rotation variance and motion artifacts are studied. Considerable performance improvements are shown.</p>

      <p>For a meaningful comparison, the paper also implements a 3D-SegCaps which is the 3D extenstion of the existing SegCaps.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>One major weakness is that the paper does not provide any results for 3D SegCaps for the LUNA16, Hippocampus, cardiac datasets even though the authors have already implemented the network. What is the reasoning behind this?</p>

      <p>Also, why does the paper compare 3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts?</p>

      <p>The motion artifacts created in the paper may be not realistic and it does not cover whole range of motion artifacts that could occur in clinical scenario. If the authors could address this point, that would help.</p>

      <p>Lastly, when the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen?</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The paper provides the code according to the reproducibility checklist and the datasets are publicly available so it should not be difficult to reproduce the results.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>I think overall the paper is presented well however, as a reviewer and a reader, it would help if the authors answers the questions above related to the reasoning of the missing results of 3D SegCaps for other datasets, selection of 3D SkipDense instead of 3D U-Net, rotation invariance and motion artifacts.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Novel metholodogy, extensive experiments and well explained design choices.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>Based on the reviewers’ comments, we think this is a high-quality paper with significant technical contributions. Authors should address reviewers’ comments in the camera-ready submission.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>We thank the reviewers for their feedback. We are glad to receive positive comments that value the contribution of our work. We clarify the key points and then address specific concerns individually.</p>

  <h2 id="major-concerns">MAJOR CONCERNS</h2>

  <p><strong>KP1. Reproducibility and expandability</strong></p>

  <p>We will release both source code and pre-trained models. Our code is implemented with Pytorch Lightning with MONAI framework for processing data, running sliding window inference and computing dice score with fixed seed. We hope that by having up-to-date frameworks, the community can reproduce our results and extend our method to other problems.</p>

  <p><strong>KP2. Motion artifacts</strong></p>

  <p>Motion artifact is a complex problem with many partial solutions as given in Zaitsev et al., Motion artifacts in MRI: A complex problem with many partial solutions, Journal of Magnetic Resonance Imaging, 2015. In this work, we simplify the motion artifacts caused by patient movement during scanning by rotating 20\% number of slides with angle randomly chosen from  (-5, 5) degrees around x/y/z-axis. More realistic experiments with various k-space motion artifacts argumentation will be examined with TorchIO in our future study.</p>

  <p><strong>KP3. “Performance of 3D SegCaps on the LUNA16, Hippocampus, cardiac datasets”</strong></p>

  <p>Our best trial for 3D SegCaps produced result no better than [24], and so we have shifted the focus to our proposed method. The possible answer for this problem can be seen in the third concern of Reviewer 1. As per request, we will provide additional segmentation performance of 3D SegCaps to get a full comparison.</p>

  <h2 id="individual-concerns">INDIVIDUAL CONCERNS</h2>

  <p><strong>Reviewer 1</strong></p>

  <ol>
    <li>
      <p>Reproducibility: Please refer KP1.</p>
    </li>
    <li>
      <p>Demonstration: Qualitative results will be made as a supplementary and will be added to the code release.</p>
    </li>
    <li>
      <p>The empirical finding, i.e., the expanding path has negligible effects”
Further investigation is needed to understand the effects of capsules in the expanding path. In our hypothesis, routing algorithm works based on routing-by-agreement between part to whole relationship, however the relationship between whole to part is one-to-many, and it is ambiguous to find the agreement between whole to active corresponding parts.</p>
    </li>
    <li>
      <p>Multi-class segmentation: We have conducted the experimental results on multi-class segmentation with 3D UCaps as given in Tables 1, 2, 3  on iSeg dataset with 3 classes i.e. WT, GM, CSF.</p>
    </li>
  </ol>

  <p><strong>Reviewer 3</strong></p>

  <ol>
    <li>“3D SkipDense instead of 3D U-Net which is more popular in the literature when considering rotation invariance and motion artifacts?”</li>
  </ol>

  <p>We are motivated by the iSeg2017 challenge [26] in which all participating methods performed poorly on the testing subjects acquired with motion artifacts and unusual scan poses. We choose to report 3D SkipDense as this method is proposed in 2019 and has the state-of-the-art performance. Their code and pretrained model are also publicly available.</p>

  <ol>
    <li>“When the the rotation variance is created for the testing dataset, was this random? Also, what would happen if the rotation was in x-axis or y-axis or both x- and y- axes or all axes? How is the performance affected if those rotations happen?”</li>
  </ol>

  <p>We trained our network with provided data in the dataset without any rotation data augmentation. During testing, we choose an axis to rotate the volume, and apply the rotation with angle values fixed to 5, 10, 15, .., 90 degrees. In our experiment, the performance tends to drop slightly when the rotation angles increases. We also found that rotating about a single axis or all axes does not have significant performance difference, which explains the capability to handle rotation invariance in a capsule network.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0151-12-31
      -->
      <!--
      
        ,
        updated at 
        0152-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Interpretability / Explainability"
        class="post-category">
        Machine Learning - Interpretability / Explainability
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - CT"
        class="post-category">
        Modalities - CT
      </a> |
      
      <a 
        href="kittywong/categories#Modalities - MRI"
        class="post-category">
        Modalities - MRI
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Nguyen, Tan"
        class="post-category">
        Nguyen, Tan
      </a> |  
      
      <a href="kittywong/tags#Hua, Binh-Son"
        class="post-category">
        Hua, Binh-Son
      </a> |  
      
      <a href="kittywong/tags#Le, Ngan"
        class="post-category">
        Le, Ngan
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0152/12/31/Paper1769">
          HRENet: A Hard Region Enhancement Network for Polyp Segmentation
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0150/12/31/Paper1667">
          A hybrid attention ensemble framework for zonal prostate segmentation
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
