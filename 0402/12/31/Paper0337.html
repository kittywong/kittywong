<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Learning Unsupervised Parameter-specific Affine Transformation for Medical Images Registration | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Learning Unsupervised Parameter-specific Affine Transformation for Medical Images Registration" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Xu Chen, Yanda Meng, Yitian Zhao, Rachel Williams, Srinivasa R. Vallabhaneni, Yalin Zheng Abstract Affine registration has recently been formulated using deep learning frameworks to establish spatial correspondences between different images. In this work, we propose a new unsupervised model that investigates two new strategies to tackle fundamental problems related to affine registration. More specifically, the new model 1) has the advantage to explicitly learn specific geometric transformation parameters (e.g. translations, rotation, scaling and shearing); and 2) can effectively understand the context between the images via cross-stitch units allowing feature exchange. The proposed model is evaluated on two two-dimensional X-ray datasets and a three-dimensional CT dataset. Our experimental results show that our model not only outperforms state-of-art approaches and also can predict specific transformation parameters. Our core source code is made available online. Link to paper https://doi.org/10.1007/978-3-030-87202-1_3 Link to the code repository https://github.com/xuuuuuuchen/PASTA Link to the dataset(s) https://medmnist.github.io/#dataset https://learn2reg.grand-challenge.org/Datasets/ Reviews Review #1 Please describe the contribution of the paper This paper a parameter-specific affine transformation model by explicitly learning all these spatial transformation parameters rather than learning their combinations. Furthermore, cross-stitch units have been developing for multi-task learning, and cross-stitch units to effectively learn an optimal combination of shared representations between image pairs. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Good organization and easy to follow. Has the advantage to learn specific geometric transformation parameters explicitly (e.g., translations, rotation, scaling and shearing). The authors have done comprehensive evaluation of the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Good. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The intuition/motivation/contribution of such work is a bit unclear. It would be better to list the contributions as bullets. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good organization and easy to follow. But predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposes a novel parameter specific affine learning network. Instead of directly predicting the affine transformation matrix, the network learns each parameter separately - translation, rotation, shearing and scaling. The final affine transformation is the composite of each individual transform. In addition, the network also integrates a cross-stitch unit from multi-task learning. Experiments show that by separately predicting affine network parameters the proposed structure outperformed existing networks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novelty of the paper would be the proposed parameter specific learning network and the benefit of such a network is that it allows us to retrieve each individual transformation. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While the result of the experiment is impressive in the way that authors set up, it was conducted on image pairs between the “same” image, i.e., the target image is just a synthetically affinely transformed moving image. For medical images, this setup typically is not the case. Affine transformation is usually applied as an initial step for registration problems whereas the moving and target image have local deformable changes. It would be interesting to know when local changes exist whether the network is able to learn better than other baseline methods. Also it would be interesting to see if the network is sensitive to noise in the image. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Datasets that have been used in this work are all publicly available. Links are provided. Parameters in the network are explicitly mentioned in the manuscript. Authors have mentioned that the code will be released after the work is published. The reproducibility of the work is greatly appreciated. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Thanks for the nice work proposed by authors. Please see my questions and comments : During the initialization, authors setup some maximum ranges for each parameter that later are used to normalize the output. What is the unit for the \lamda of the translation? Is it just for example 0.2 pixels/voxels? If so it seems too small. The authors mentioned the order of the composition matters for affine results. Is there any exploration of the order of the composition? It may be nice to have some discussion on how sensitive for each parameter network is. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I would recommend borderline acceptance of the paper given the novel network design and the performance of the network compared against baseline methods, although it would be nice to investigate whether the network is robust to noise or local changes. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper proposed a novel framework for affine registration to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. A novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Experiments are sufficient and convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. no obvious weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Excellent reproducibility with code. Experiments are carried out on public datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Writing: Page 1 paragraph 2, “is commonly for” should be “is commonly used for”. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper proposed a novel framework for affine registration, instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. The paper is well organized, the experiments are sufficient and convincing. Reproducibility is excellent with code and necessary details. Overall I recommend strong accept for this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes regressing affine transformation parameters for image registration via a deep network. In particular, the authors propose to use an overcomplete parameterization of the affine transform (explicitly predicting translations, shear, and rotations) and combine it with cross-stitch units in the network design. There are several concerns which should be addressed during a rebuttal: 1) The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). How does the approach compare to a simple optimization based baseline with respect to NCC then? 2) Are results statistically significantly different? 3) What size do the images have? The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? 4) What are your evaluations based on? Are they only trying to recover synthetically created transformations (as suggested by reviewer 2)? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? Fig. 2 appears to indicate that evaluation is also for synthetic transformations only. 5) What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? 6) Lastly, 2D/3D in the title suggests that this is a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This work proposes a simple approach for affine registration parameterization which can be integrated with CNNs to obtain easier control over the parameter ranges. All three reviewers appreciated this work. However, there were some concerns raised in the review in particular related to the evaluation (which appeared to be based on synthetic deformations only) and statistical significance of the obtained results. The statistical significance of the results were provided in the rebuttal (and would presumably be integrated into a final version). However, evaluations are indeed only based on synthetic deformations, hence this concern remains. It would be useful to include this concern as potential shortcomings of the experimental results in the manuscript. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. While achieving high accuracy on synthetic transformations the paper fails to provide any clinically relevant evaluation. I found two of the reviews rather low-quality and concur with the statement that the novelty is very limited (conventional methods also over-parameterise the estimation of linear transforms). The meta-reviewer asked authors to provide meaningful results (TRE) which would be available for Learn2Reg lung and could at least be computed for the synthetic 2D transforms. The authors did not respond adequately to this request. Evaluating registration simply with NCC is not appropriate (see Rohlfing TMI 2013). I think this submission falls short of MICCAI standards for clinical impact. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 20 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Overall, the paper was appreciated by reviewers and MR, but overall the idea felt simple and underexplored, which I agree with. Affine registration is important, of course, but there are a plethora of datasets to work with, annotations to use for measuring, baselines to run. It does seem like the authors could’ve done a better job on these experimental aspects. The authors address some of this in the rebuttal – adding more number, statistical tests, etc. This is good, and needs to be in the paper, but it keeps the paper borderline in my view, as all of this should have been done better and more thoroughly during submission, in a problem that is so widely studied. Given the nature of MICCAI2021, I believe the paper can be accepted and will lead to a good discussion, but I strongly encourage the authors to improve their paper during the camera ready by adding thorough experimental results and discussion mentioned in the rebuttal and otherwise requested by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Author Feedback Thank the meta-reviewer and all the reviewers for the constructive comments. We respond to the comments point by point below. Meta-review (MR) Q1: The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). MR Q4: What are your evaluations based on? Are they only trying to recover synthetically created transformations? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? A: In the current manuscript, we only reported experiment results by aligning synthetical image pairs as we can directly evaluate the errors between the predicted transformation parameters and the synthetical ‘true’ parameters (e.g. Table 2). For the MedMNIST and HandMNIST datasets, no landmarks or segmentation are available. We have used normalized cross-correlation (NCC) as the performance metric. The segmentations are provided with the Learn2Reg dataset. We have evaluated the registration performance by the segmentation overlap as measured by Dice scores. Inspired by Q1 and Q4, we have performed real experiments on the HandMNIST dataset and share the results here. In brief, 44,850 unique pairs were generated by randomly chosen from 300 different images of left hands (a ratio of 60:20:20 for training, validation and testing). The results on the testing set proved the CANet and PASTA would introduce improvement in NCC compared to the methods not using them or without registration (NCC=0.655). Furthermore, we randomly chose 50 pairs of images and annotated the middle finger fingertips. We then evaluated the distance between them in each paired image before and after registration. The average distance is 8.33 pixels before registration, 6.88 for DLIR, 4.46 for GlobalNet, 4.69 for GlobalNet+PASTA and 3.88 for CANet (n=3)+PASTA. We will include these results in the final version for completeness. MR Q2: Are results statistically significantly different? A: We have performed t-tests, and results are as follows: except DLIR and CANet (n=1) for the HandMNIST and CANet (n=1) for ChestMNIST and 3D lung dataset, all the other networks using PASTA have shown statistically significant improvements than those without PASTA (p&lt;0.001). On the other hand, when PASTA is used, CANet (n=3) performs significantly better than all the other networks (p&lt;0.001) but GlobalNet for the 3D lung dataset. These results confirmed the value of PASTA and the effectiveness of CANet. We will update Table 1 with these results in the revision. MR Q3: The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? A: We used the original size 64x64 available when we downloaded both the HandMNIST and ChestMNIST. MR Q5: What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? A: Compared to existing deep registration methods, our PASTA decoupled the transformation parameters and regressed each of them in a normalized range; thus, it is more effective to optimize. It allows the recovery of all the ‘physical’ transformation parameters, thus more intuitive and explainable. Cross-stitch units help to extract more useful features so that the regression performance is improved accordingly. Note, PASTA is generic and could be compatible with other networks. We will clarify the contributions and list them in bullets in the revision. MR Q6: 2D/3D in the title suggests a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. A: Thank meta-reviewer #1! We will change the title to avoid confusion about using “2D/3D” term. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Xu Chen, Yanda Meng, Yitian Zhao, Rachel Williams, Srinivasa R. Vallabhaneni, Yalin Zheng Abstract Affine registration has recently been formulated using deep learning frameworks to establish spatial correspondences between different images. In this work, we propose a new unsupervised model that investigates two new strategies to tackle fundamental problems related to affine registration. More specifically, the new model 1) has the advantage to explicitly learn specific geometric transformation parameters (e.g. translations, rotation, scaling and shearing); and 2) can effectively understand the context between the images via cross-stitch units allowing feature exchange. The proposed model is evaluated on two two-dimensional X-ray datasets and a three-dimensional CT dataset. Our experimental results show that our model not only outperforms state-of-art approaches and also can predict specific transformation parameters. Our core source code is made available online. Link to paper https://doi.org/10.1007/978-3-030-87202-1_3 Link to the code repository https://github.com/xuuuuuuchen/PASTA Link to the dataset(s) https://medmnist.github.io/#dataset https://learn2reg.grand-challenge.org/Datasets/ Reviews Review #1 Please describe the contribution of the paper This paper a parameter-specific affine transformation model by explicitly learning all these spatial transformation parameters rather than learning their combinations. Furthermore, cross-stitch units have been developing for multi-task learning, and cross-stitch units to effectively learn an optimal combination of shared representations between image pairs. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Good organization and easy to follow. Has the advantage to learn specific geometric transformation parameters explicitly (e.g., translations, rotation, scaling and shearing). The authors have done comprehensive evaluation of the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Good. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The intuition/motivation/contribution of such work is a bit unclear. It would be better to list the contributions as bullets. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good organization and easy to follow. But predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposes a novel parameter specific affine learning network. Instead of directly predicting the affine transformation matrix, the network learns each parameter separately - translation, rotation, shearing and scaling. The final affine transformation is the composite of each individual transform. In addition, the network also integrates a cross-stitch unit from multi-task learning. Experiments show that by separately predicting affine network parameters the proposed structure outperformed existing networks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novelty of the paper would be the proposed parameter specific learning network and the benefit of such a network is that it allows us to retrieve each individual transformation. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While the result of the experiment is impressive in the way that authors set up, it was conducted on image pairs between the “same” image, i.e., the target image is just a synthetically affinely transformed moving image. For medical images, this setup typically is not the case. Affine transformation is usually applied as an initial step for registration problems whereas the moving and target image have local deformable changes. It would be interesting to know when local changes exist whether the network is able to learn better than other baseline methods. Also it would be interesting to see if the network is sensitive to noise in the image. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Datasets that have been used in this work are all publicly available. Links are provided. Parameters in the network are explicitly mentioned in the manuscript. Authors have mentioned that the code will be released after the work is published. The reproducibility of the work is greatly appreciated. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Thanks for the nice work proposed by authors. Please see my questions and comments : During the initialization, authors setup some maximum ranges for each parameter that later are used to normalize the output. What is the unit for the \lamda of the translation? Is it just for example 0.2 pixels/voxels? If so it seems too small. The authors mentioned the order of the composition matters for affine results. Is there any exploration of the order of the composition? It may be nice to have some discussion on how sensitive for each parameter network is. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I would recommend borderline acceptance of the paper given the novel network design and the performance of the network compared against baseline methods, although it would be nice to investigate whether the network is robust to noise or local changes. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper proposed a novel framework for affine registration to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. A novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Experiments are sufficient and convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. no obvious weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Excellent reproducibility with code. Experiments are carried out on public datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Writing: Page 1 paragraph 2, “is commonly for” should be “is commonly used for”. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper proposed a novel framework for affine registration, instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. The paper is well organized, the experiments are sufficient and convincing. Reproducibility is excellent with code and necessary details. Overall I recommend strong accept for this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes regressing affine transformation parameters for image registration via a deep network. In particular, the authors propose to use an overcomplete parameterization of the affine transform (explicitly predicting translations, shear, and rotations) and combine it with cross-stitch units in the network design. There are several concerns which should be addressed during a rebuttal: 1) The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). How does the approach compare to a simple optimization based baseline with respect to NCC then? 2) Are results statistically significantly different? 3) What size do the images have? The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? 4) What are your evaluations based on? Are they only trying to recover synthetically created transformations (as suggested by reviewer 2)? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? Fig. 2 appears to indicate that evaluation is also for synthetic transformations only. 5) What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? 6) Lastly, 2D/3D in the title suggests that this is a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This work proposes a simple approach for affine registration parameterization which can be integrated with CNNs to obtain easier control over the parameter ranges. All three reviewers appreciated this work. However, there were some concerns raised in the review in particular related to the evaluation (which appeared to be based on synthetic deformations only) and statistical significance of the obtained results. The statistical significance of the results were provided in the rebuttal (and would presumably be integrated into a final version). However, evaluations are indeed only based on synthetic deformations, hence this concern remains. It would be useful to include this concern as potential shortcomings of the experimental results in the manuscript. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. While achieving high accuracy on synthetic transformations the paper fails to provide any clinically relevant evaluation. I found two of the reviews rather low-quality and concur with the statement that the novelty is very limited (conventional methods also over-parameterise the estimation of linear transforms). The meta-reviewer asked authors to provide meaningful results (TRE) which would be available for Learn2Reg lung and could at least be computed for the synthetic 2D transforms. The authors did not respond adequately to this request. Evaluating registration simply with NCC is not appropriate (see Rohlfing TMI 2013). I think this submission falls short of MICCAI standards for clinical impact. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 20 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Overall, the paper was appreciated by reviewers and MR, but overall the idea felt simple and underexplored, which I agree with. Affine registration is important, of course, but there are a plethora of datasets to work with, annotations to use for measuring, baselines to run. It does seem like the authors could’ve done a better job on these experimental aspects. The authors address some of this in the rebuttal – adding more number, statistical tests, etc. This is good, and needs to be in the paper, but it keeps the paper borderline in my view, as all of this should have been done better and more thoroughly during submission, in a problem that is so widely studied. Given the nature of MICCAI2021, I believe the paper can be accepted and will lead to a good discussion, but I strongly encourage the authors to improve their paper during the camera ready by adding thorough experimental results and discussion mentioned in the rebuttal and otherwise requested by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Author Feedback Thank the meta-reviewer and all the reviewers for the constructive comments. We respond to the comments point by point below. Meta-review (MR) Q1: The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). MR Q4: What are your evaluations based on? Are they only trying to recover synthetically created transformations? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? A: In the current manuscript, we only reported experiment results by aligning synthetical image pairs as we can directly evaluate the errors between the predicted transformation parameters and the synthetical ‘true’ parameters (e.g. Table 2). For the MedMNIST and HandMNIST datasets, no landmarks or segmentation are available. We have used normalized cross-correlation (NCC) as the performance metric. The segmentations are provided with the Learn2Reg dataset. We have evaluated the registration performance by the segmentation overlap as measured by Dice scores. Inspired by Q1 and Q4, we have performed real experiments on the HandMNIST dataset and share the results here. In brief, 44,850 unique pairs were generated by randomly chosen from 300 different images of left hands (a ratio of 60:20:20 for training, validation and testing). The results on the testing set proved the CANet and PASTA would introduce improvement in NCC compared to the methods not using them or without registration (NCC=0.655). Furthermore, we randomly chose 50 pairs of images and annotated the middle finger fingertips. We then evaluated the distance between them in each paired image before and after registration. The average distance is 8.33 pixels before registration, 6.88 for DLIR, 4.46 for GlobalNet, 4.69 for GlobalNet+PASTA and 3.88 for CANet (n=3)+PASTA. We will include these results in the final version for completeness. MR Q2: Are results statistically significantly different? A: We have performed t-tests, and results are as follows: except DLIR and CANet (n=1) for the HandMNIST and CANet (n=1) for ChestMNIST and 3D lung dataset, all the other networks using PASTA have shown statistically significant improvements than those without PASTA (p&lt;0.001). On the other hand, when PASTA is used, CANet (n=3) performs significantly better than all the other networks (p&lt;0.001) but GlobalNet for the 3D lung dataset. These results confirmed the value of PASTA and the effectiveness of CANet. We will update Table 1 with these results in the revision. MR Q3: The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? A: We used the original size 64x64 available when we downloaded both the HandMNIST and ChestMNIST. MR Q5: What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? A: Compared to existing deep registration methods, our PASTA decoupled the transformation parameters and regressed each of them in a normalized range; thus, it is more effective to optimize. It allows the recovery of all the ‘physical’ transformation parameters, thus more intuitive and explainable. Cross-stitch units help to extract more useful features so that the regression performance is improved accordingly. Note, PASTA is generic and could be compatible with other networks. We will clarify the contributions and list them in bullets in the revision. MR Q6: 2D/3D in the title suggests a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. A: Thank meta-reviewer #1! We will change the title to avoid confusion about using “2D/3D” term. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0402/12/31/Paper0337" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0402/12/31/Paper0337" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0402-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Learning Unsupervised Parameter-specific Affine Transformation for Medical Images Registration" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0402/12/31/Paper0337"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0402/12/31/Paper0337","headline":"Learning Unsupervised Parameter-specific Affine Transformation for Medical Images Registration","dateModified":"0403-01-02T00:00:00-05:17","datePublished":"0402-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Xu Chen, Yanda Meng, Yitian Zhao, Rachel Williams, Srinivasa R. Vallabhaneni, Yalin Zheng Abstract Affine registration has recently been formulated using deep learning frameworks to establish spatial correspondences between different images. In this work, we propose a new unsupervised model that investigates two new strategies to tackle fundamental problems related to affine registration. More specifically, the new model 1) has the advantage to explicitly learn specific geometric transformation parameters (e.g. translations, rotation, scaling and shearing); and 2) can effectively understand the context between the images via cross-stitch units allowing feature exchange. The proposed model is evaluated on two two-dimensional X-ray datasets and a three-dimensional CT dataset. Our experimental results show that our model not only outperforms state-of-art approaches and also can predict specific transformation parameters. Our core source code is made available online. Link to paper https://doi.org/10.1007/978-3-030-87202-1_3 Link to the code repository https://github.com/xuuuuuuchen/PASTA Link to the dataset(s) https://medmnist.github.io/#dataset https://learn2reg.grand-challenge.org/Datasets/ Reviews Review #1 Please describe the contribution of the paper This paper a parameter-specific affine transformation model by explicitly learning all these spatial transformation parameters rather than learning their combinations. Furthermore, cross-stitch units have been developing for multi-task learning, and cross-stitch units to effectively learn an optimal combination of shared representations between image pairs. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Good organization and easy to follow. Has the advantage to learn specific geometric transformation parameters explicitly (e.g., translations, rotation, scaling and shearing). The authors have done comprehensive evaluation of the proposed method. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Good. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The intuition/motivation/contribution of such work is a bit unclear. It would be better to list the contributions as bullets. Please state your overall opinion of the paper Probably accept (7) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? Good organization and easy to follow. But predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 5 Reviewer confidence Very confident Review #2 Please describe the contribution of the paper This paper proposes a novel parameter specific affine learning network. Instead of directly predicting the affine transformation matrix, the network learns each parameter separately - translation, rotation, shearing and scaling. The final affine transformation is the composite of each individual transform. In addition, the network also integrates a cross-stitch unit from multi-task learning. Experiments show that by separately predicting affine network parameters the proposed structure outperformed existing networks. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The novelty of the paper would be the proposed parameter specific learning network and the benefit of such a network is that it allows us to retrieve each individual transformation. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. While the result of the experiment is impressive in the way that authors set up, it was conducted on image pairs between the “same” image, i.e., the target image is just a synthetically affinely transformed moving image. For medical images, this setup typically is not the case. Affine transformation is usually applied as an initial step for registration problems whereas the moving and target image have local deformable changes. It would be interesting to know when local changes exist whether the network is able to learn better than other baseline methods. Also it would be interesting to see if the network is sensitive to noise in the image. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Datasets that have been used in this work are all publicly available. Links are provided. Parameters in the network are explicitly mentioned in the manuscript. Authors have mentioned that the code will be released after the work is published. The reproducibility of the work is greatly appreciated. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Thanks for the nice work proposed by authors. Please see my questions and comments : During the initialization, authors setup some maximum ranges for each parameter that later are used to normalize the output. What is the unit for the \\lamda of the translation? Is it just for example 0.2 pixels/voxels? If so it seems too small. The authors mentioned the order of the composition matters for affine results. Is there any exploration of the order of the composition? It may be nice to have some discussion on how sensitive for each parameter network is. Please state your overall opinion of the paper borderline accept (6) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? I would recommend borderline acceptance of the paper given the novel network design and the performance of the network compared against baseline methods, although it would be nice to investigate whether the network is robust to noise or local changes. What is the ranking of this paper in your review stack? 4 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Review #3 Please describe the contribution of the paper This paper proposed a novel framework for affine registration to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. A novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. Experiments are sufficient and convincing. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. no obvious weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Excellent reproducibility with code. Experiments are carried out on public datasets. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Writing: Page 1 paragraph 2, “is commonly for” should be “is commonly used for”. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This paper proposed a novel framework for affine registration, instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. The paper is well organized, the experiments are sufficient and convincing. Reproducibility is excellent with code and necessary details. Overall I recommend strong accept for this paper. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 4 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. This paper proposes regressing affine transformation parameters for image registration via a deep network. In particular, the authors propose to use an overcomplete parameterization of the affine transform (explicitly predicting translations, shear, and rotations) and combine it with cross-stitch units in the network design. There are several concerns which should be addressed during a rebuttal: 1) The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). How does the approach compare to a simple optimization based baseline with respect to NCC then? 2) Are results statistically significantly different? 3) What size do the images have? The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? 4) What are your evaluations based on? Are they only trying to recover synthetically created transformations (as suggested by reviewer 2)? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? Fig. 2 appears to indicate that evaluation is also for synthetic transformations only. 5) What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? 6) Lastly, 2D/3D in the title suggests that this is a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 5 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. This work proposes a simple approach for affine registration parameterization which can be integrated with CNNs to obtain easier control over the parameter ranges. All three reviewers appreciated this work. However, there were some concerns raised in the review in particular related to the evaluation (which appeared to be based on synthetic deformations only) and statistical significance of the obtained results. The statistical significance of the results were provided in the rebuttal (and would presumably be integrated into a final version). However, evaluations are indeed only based on synthetic deformations, hence this concern remains. It would be useful to include this concern as potential shortcomings of the experimental results in the manuscript. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Meta-Review #2 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. While achieving high accuracy on synthetic transformations the paper fails to provide any clinically relevant evaluation. I found two of the reviews rather low-quality and concur with the statement that the novelty is very limited (conventional methods also over-parameterise the estimation of linear transforms). The meta-reviewer asked authors to provide meaningful results (TRE) which would be available for Learn2Reg lung and could at least be computed for the synthetic 2D transforms. The authors did not respond adequately to this request. Evaluating registration simply with NCC is not appropriate (see Rohlfing TMI 2013). I think this submission falls short of MICCAI standards for clinical impact. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Reject What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 20 Meta-Review #3 Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores, indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision. Overall, the paper was appreciated by reviewers and MR, but overall the idea felt simple and underexplored, which I agree with. Affine registration is important, of course, but there are a plethora of datasets to work with, annotations to use for measuring, baselines to run. It does seem like the authors could’ve done a better job on these experimental aspects. The authors address some of this in the rebuttal – adding more number, statistical tests, etc. This is good, and needs to be in the paper, but it keeps the paper borderline in my view, as all of this should have been done better and more thoroughly during submission, in a problem that is so widely studied. Given the nature of MICCAI2021, I believe the paper can be accepted and will lead to a good discussion, but I strongly encourage the authors to improve their paper during the camera ready by adding thorough experimental results and discussion mentioned in the rebuttal and otherwise requested by the reviewers. After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal. Accept What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 7 Author Feedback Thank the meta-reviewer and all the reviewers for the constructive comments. We respond to the comments point by point below. Meta-review (MR) Q1: The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). MR Q4: What are your evaluations based on? Are they only trying to recover synthetically created transformations? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? A: In the current manuscript, we only reported experiment results by aligning synthetical image pairs as we can directly evaluate the errors between the predicted transformation parameters and the synthetical ‘true’ parameters (e.g. Table 2). For the MedMNIST and HandMNIST datasets, no landmarks or segmentation are available. We have used normalized cross-correlation (NCC) as the performance metric. The segmentations are provided with the Learn2Reg dataset. We have evaluated the registration performance by the segmentation overlap as measured by Dice scores. Inspired by Q1 and Q4, we have performed real experiments on the HandMNIST dataset and share the results here. In brief, 44,850 unique pairs were generated by randomly chosen from 300 different images of left hands (a ratio of 60:20:20 for training, validation and testing). The results on the testing set proved the CANet and PASTA would introduce improvement in NCC compared to the methods not using them or without registration (NCC=0.655). Furthermore, we randomly chose 50 pairs of images and annotated the middle finger fingertips. We then evaluated the distance between them in each paired image before and after registration. The average distance is 8.33 pixels before registration, 6.88 for DLIR, 4.46 for GlobalNet, 4.69 for GlobalNet+PASTA and 3.88 for CANet (n=3)+PASTA. We will include these results in the final version for completeness. MR Q2: Are results statistically significantly different? A: We have performed t-tests, and results are as follows: except DLIR and CANet (n=1) for the HandMNIST and CANet (n=1) for ChestMNIST and 3D lung dataset, all the other networks using PASTA have shown statistically significant improvements than those without PASTA (p&lt;0.001). On the other hand, when PASTA is used, CANet (n=3) performs significantly better than all the other networks (p&lt;0.001) but GlobalNet for the 3D lung dataset. These results confirmed the value of PASTA and the effectiveness of CANet. We will update Table 1 with these results in the revision. MR Q3: The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? A: We used the original size 64x64 available when we downloaded both the HandMNIST and ChestMNIST. MR Q5: What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? A: Compared to existing deep registration methods, our PASTA decoupled the transformation parameters and regressed each of them in a normalized range; thus, it is more effective to optimize. It allows the recovery of all the ‘physical’ transformation parameters, thus more intuitive and explainable. Cross-stitch units help to extract more useful features so that the regression performance is improved accordingly. Note, PASTA is generic and could be compatible with other networks. We will clarify the contributions and list them in bullets in the revision. MR Q6: 2D/3D in the title suggests a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively. A: Thank meta-reviewer #1! We will change the title to avoid confusion about using “2D/3D” term. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Chen, Xu,Meng, Yanda,Zhao, Yitian,Williams, Rachel,Vallabhaneni, Srinivasa R.,Zheng, Yalin" />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Learning Unsupervised Parameter-specific Affine Transformation for Medical Images Registration</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Registration"
        class="post-category">
        Image Registration
      </a>
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Chen, Xu"
        class="post-tags">
        Chen, Xu
      </a> |  
      
      <a href="kittywong/tags#Meng, Yanda"
        class="post-tags">
        Meng, Yanda
      </a> |  
      
      <a href="kittywong/tags#Zhao, Yitian"
        class="post-tags">
        Zhao, Yitian
      </a> |  
      
      <a href="kittywong/tags#Williams, Rachel"
        class="post-tags">
        Williams, Rachel
      </a> |  
      
      <a href="kittywong/tags#Vallabhaneni, Srinivasa R."
        class="post-tags">
        Vallabhaneni, Srinivasa R.
      </a> |  
      
      <a href="kittywong/tags#Zheng, Yalin"
        class="post-tags">
        Zheng, Yalin
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Xu Chen, Yanda Meng, Yitian Zhao, Rachel Williams, Srinivasa R. Vallabhaneni, Yalin Zheng
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Affine registration has recently been formulated using deep learning frameworks to establish spatial correspondences between different images. In this work, we propose a new unsupervised model that investigates two new strategies to tackle fundamental problems related to affine registration. More specifically, the new model 1) has the advantage to explicitly learn specific geometric transformation parameters (e.g. translations, rotation, scaling and shearing); and 2) can effectively understand the context between the images via cross-stitch units allowing feature exchange. The proposed model is evaluated on two two-dimensional X-ray datasets and a three-dimensional CT dataset. Our experimental results show that our model not only outperforms state-of-art approaches and also can predict specific transformation parameters. Our core source code is made available online.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87202-1_3">https://doi.org/10.1007/978-3-030-87202-1_3</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/xuuuuuuchen/PASTA
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>https://medmnist.github.io/#dataset
https://learn2reg.grand-challenge.org/Datasets/
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper a parameter-specific affine transformation model by explicitly learning all these spatial transformation parameters rather than learning their combinations. Furthermore, cross-stitch units have been developing for multi-task learning, and cross-stitch units to effectively learn an optimal combination of shared representations between image pairs.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ol>
        <li>Good organization and easy to follow.</li>
        <li>Has the advantage to learn specific geometric transformation parameters explicitly (e.g., translations, rotation, scaling and shearing).</li>
        <li>The authors have done comprehensive evaluation of the proposed method.</li>
      </ol>

    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ol>
        <li>Predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Good.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <ol>
        <li>The intuition/motivation/contribution of such work is a bit unclear. It would be better to list the contributions as bullets.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>Probably accept (7)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>Good organization and easy to follow. But predicting translation, rotation and scaling to form the transformation is a standard way in conventional method. In spite of implement this framework in deep learning based registration method, few novelty is drawn.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposes a novel parameter specific affine learning network. Instead of directly predicting the affine transformation matrix, the network learns each parameter separately - translation, rotation, shearing and scaling. The final affine transformation is the composite of each individual transform. In addition, the network also integrates a cross-stitch unit from multi-task learning. Experiments show that by separately predicting affine network parameters the proposed structure outperformed existing networks.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The novelty of the paper would be the proposed parameter specific learning network and the benefit of such a network is that it allows us to retrieve each individual transformation.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>While the result of the experiment is impressive in the way that authors set up, it was conducted on image pairs between the “same” image, i.e., the target image is just a synthetically affinely transformed moving image. For medical images, this setup typically is not the case. Affine transformation is usually applied as an initial step for registration problems whereas the moving and target image have local deformable changes. It would be interesting to know when local changes exist whether the network is able to learn better than other baseline methods. Also it would be interesting to see if the network is sensitive to noise in the image.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Datasets that have been used in this work are all publicly available. Links are provided. Parameters in the network are explicitly mentioned in the manuscript. Authors have mentioned that the code will be released after the work is published. The reproducibility of the work is greatly appreciated.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Thanks for the nice work proposed by authors. Please see my questions and comments :</p>
      <ol>
        <li>During the initialization, authors setup some maximum ranges for each parameter that later are used to normalize the output. What is the unit for the \lamda of the translation? Is it just for example 0.2 pixels/voxels? If so it seems too small.</li>
        <li>The authors mentioned the order of the composition matters for affine results. Is there any exploration of the order of the composition?</li>
        <li>It may be nice to have some discussion on how sensitive for each parameter network is.</li>
      </ol>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline accept (6)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>I would recommend borderline acceptance of the paper given the novel network design and the performance of the network compared against baseline methods, although it would be nice to investigate whether the network is robust to noise or local changes.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper proposed a novel framework for affine registration to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>Instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods.</li>
        <li>A novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario.</li>
        <li>Experiments are sufficient and convincing.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>no obvious weakness.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Excellent reproducibility with code. Experiments are carried out on public datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Writing:</p>
      <ul>
        <li>Page 1 paragraph 2, “is commonly for” should be “is commonly used for”.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This paper proposed a novel framework for affine registration, instead of regress transformation matrix A with 6 parameters, the proposed method directly regress rotation, translation, scaling and shear (7 parameters in total) to interpret the effect of each type of transformations. The proposed PASTA framework also improved performance on baseline methods. In addition, a novel architecture with cross-stitch units is proposed and proven to be effective in 2D scenario. The paper is well organized, the experiments are sufficient and convincing. Reproducibility is excellent with code and necessary details. Overall I recommend strong accept for this paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>4</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>This paper proposes regressing affine transformation parameters for image registration via a deep network. In particular, the authors propose to use an overcomplete parameterization of the affine transform (explicitly predicting translations, shear, and rotations) and combine it with cross-stitch units in the network design. There are several concerns which should be addressed during a rebuttal: 1) The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.). How does the approach compare to a simple optimization based baseline with respect to NCC then? 2) Are results statistically significantly different? 3) What size do the images have? The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? 4) What are your evaluations based on? Are they only trying to recover synthetically created transformations (as suggested by reviewer 2)? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? Fig. 2 appears to indicate that evaluation is also for synthetic transformations only. 5) What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? 6) Lastly, 2D/3D in the title suggests that this is a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>This work proposes a simple approach for affine registration parameterization which can be integrated with CNNs to obtain easier control over the parameter ranges. All three reviewers appreciated this work. However, there were some concerns raised in the review in particular related to the evaluation (which appeared to be based on synthetic deformations only) and statistical significance of the obtained results. The statistical significance of the results were provided in the rebuttal (and would presumably be integrated into a final version). However, evaluations are indeed only based on synthetic deformations, hence this concern remains. It would be useful to include this concern as potential shortcomings of the experimental results in the manuscript.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>7</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h2 id="meta-review-2">Meta-Review #2</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>While achieving high accuracy on synthetic transformations the paper fails to provide any clinically relevant evaluation. I found two of the reviews rather low-quality and concur with the statement that the novelty is very limited (conventional methods also over-parameterise the estimation of linear transforms). The meta-reviewer asked authors to provide meaningful results (TRE) which would be available for Learn2Reg lung and could at least be computed for the synthetic 2D transforms. The authors did not respond adequately to this request. Evaluating registration simply with NCC is not appropriate (see Rohlfing TMI 2013). I think this submission falls short of MICCAI standards for clinical impact.</p>
    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Reject</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>20</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>
<h2 id="meta-review-3">Meta-Review #3</h2>
<ul>
  <li><strong>Please provide your assessment of the paper taking all information into account, including rebuttal. Highlight the key strengths and weaknesses of the paper, clarify how you reconciled contrasting review comments and scores,  indicate if concerns were successfully addressed in the rebuttal, and provide a clear justification of your decision. If you disagree with some of the (meta)reviewer statements, you can indicate so in your meta-review. Please make sure that the authors, program chairs, and the public can understand the reason for your decision.</strong>
    <blockquote>
      <p>Overall, the paper was appreciated by reviewers and MR, but overall the idea felt simple and underexplored, which I agree with. Affine registration is important, of course, but there are a plethora of datasets to work with, annotations to use for measuring, baselines to run. It does seem like the authors could’ve done a better job on these experimental aspects.</p>

      <p>The authors address some of this in the rebuttal – adding more number, statistical tests, etc. This is good, and needs to be in the paper, but it keeps the paper borderline in my view, as all of this should have been done better and more thoroughly during submission, in a problem that is so widely studied.</p>

      <p>Given the nature of MICCAI2021, I believe the paper can be accepted and will lead to a good discussion, but I strongly encourage the authors to improve their paper during the camera ready by adding  <em>thorough</em> experimental results and discussion mentioned in the rebuttal and otherwise requested by the reviewers.</p>

    </blockquote>
  </li>
  <li><strong>After you have reviewed the rebuttal, please provide your final rating based on all reviews and the authors’ rebuttal.</strong>
    <blockquote>
      <p>Accept</p>
    </blockquote>
  </li>
  <li><strong>What is the rank of this paper among all your rebuttal papers? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>7</p>
    </blockquote>
  </li>
</ul>

<h2><br /><br /></h2>
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>

  <p>Thank the meta-reviewer and all the reviewers for the constructive comments. We respond to the comments point by point below.</p>

  <p>Meta-review (MR) Q1: The only real registration validation measure appears to be the Dice scores for the Learn2Reg task 2. How does the approach compare to other approaches on Learn2Reg? The other experiments only provide normalized cross correlation measures, but no real registration validation measures (e.g., landmark error, segmentation overlap, etc.).  MR Q4: What are your evaluations based on? Are they only trying to recover synthetically created transformations? If this is the case, what validation strategy was used for Learn2Reg? Also synthetic transformation recovery or truly across different images? 
A: In the current manuscript, we only reported experiment results by aligning synthetical image pairs as we can directly evaluate the errors between the predicted transformation parameters and the synthetical ‘true’ parameters (e.g. Table 2). For the MedMNIST and HandMNIST datasets, no landmarks or segmentation are available. We have used normalized cross-correlation (NCC) as the performance metric. The segmentations are provided with the Learn2Reg dataset. We have evaluated the registration performance by the segmentation overlap as measured by Dice scores. Inspired by Q1 and Q4, we have performed real experiments on the HandMNIST dataset and share the results here. In brief, 44,850 unique pairs were generated by randomly chosen from 300 different images of left hands (a ratio of 60:20:20 for training, validation and testing). The results on the testing set proved the CANet and PASTA would introduce improvement in NCC compared to the methods not using them or without registration (NCC=0.655). Furthermore, we randomly chose 50 pairs of images and annotated the middle finger fingertips. We then evaluated the distance between them in each paired image before and after registration. The average distance is 8.33 pixels before registration, 6.88 for DLIR, 4.46 for GlobalNet, 4.69 for GlobalNet+PASTA and 3.88 for CANet (n=3)+PASTA. We will include these results in the final version for completeness.</p>

  <p>MR Q2: Are results statistically significantly different?
A: We have performed t-tests, and results are as follows: except DLIR and CANet (n=1) for the HandMNIST and CANet (n=1) for ChestMNIST and 3D lung dataset, all the other networks using PASTA have shown statistically significant improvements than those without PASTA (p&lt;0.001). On the other hand, when PASTA is used, CANet (n=3) performs significantly better than all the other networks (p&lt;0.001) but GlobalNet for the 3D lung dataset. These results confirmed the value of PASTA and the effectiveness of CANet. We will update Table 1 with these results in the revision.</p>

  <p>MR Q3: The HandMNIST dataset and the ChestMNIST dataset appear to all be resized to 28x28 according to the MedMNIST paper; are you using higher resolution images? 
A: We used the original size 64x64 available when we downloaded both the HandMNIST and ChestMNIST.</p>

  <p>MR Q5: What are the intuitions behind improvements using the different affine transformation parameterization and the cross-stitch units? 
A: Compared to existing deep registration methods, our PASTA decoupled the transformation parameters and regressed each of them in a normalized range; thus, it is more effective to optimize. It allows the recovery of all the ‘physical’ transformation parameters, thus more intuitive and explainable. Cross-stitch units help to extract more useful features so that the regression performance is improved accordingly. Note, PASTA is generic and could be compatible with other networks. We will clarify the contributions and list them in bullets in the revision.</p>

  <p>MR Q6: 2D/3D in the title suggests a 2D/3D registration approach. Instead it is a registration approach for 2D or 3D registration respectively.
A: Thank meta-reviewer #1! We will change the title to avoid confusion about using “2D/3D” term.</p>
</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0402-12-31
      -->
      <!--
      
        ,
        updated at 
        0403-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Registration"
        class="post-category">
        Image Registration
      </a> |
      
      <a 
        href="kittywong/categories#Machine Learning - Self-supervised learning"
        class="post-category">
        Machine Learning - Self-supervised learning
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Chen, Xu"
        class="post-category">
        Chen, Xu
      </a> |  
      
      <a href="kittywong/tags#Meng, Yanda"
        class="post-category">
        Meng, Yanda
      </a> |  
      
      <a href="kittywong/tags#Zhao, Yitian"
        class="post-category">
        Zhao, Yitian
      </a> |  
      
      <a href="kittywong/tags#Williams, Rachel"
        class="post-category">
        Williams, Rachel
      </a> |  
      
      <a href="kittywong/tags#Vallabhaneni, Srinivasa R."
        class="post-category">
        Vallabhaneni, Srinivasa R.
      </a> |  
      
      <a href="kittywong/tags#Zheng, Yalin"
        class="post-category">
        Zheng, Yalin
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0403/12/31/Paper0422">
          Conditional Deformable Image Registration with Convolutional Neural Network
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0401/12/31/Paper0219">
          Atlas-Based Segmentation of Intracochlear Anatomy in Metal Artifact Affected CT Images of the Ear with Co-trained Deep Neural Networks
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
