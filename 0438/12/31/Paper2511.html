<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Co-Generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data | MICCAI 2021 - Accepted Papers and Reviews</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Co-Generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Megha Kalia, Tajwar Abrar Aleef, Nassir Navab, Peter Black, Septimiu E. Salcudean Abstract Surgical instrument segmentation for robot-assisted surgery is needed for accurate instrument tracking and augmented reality overlays. Therefore, the topic has been the subject of a number of recent papers in the CAI community. Deep learning-based methods have shown state-of-the-art performance for surgical instrument segmentation, but their results depend on labelled data. However, labelled surgical data is of limited availability and is a bottleneck in surgical translation of these methods. In this paper, we demonstrate the limited generalizability of these methods on different datasets, including robot-assisted surgeries on human subjects. We then propose a novel joint generation and segmentation strategy to learn a segmentation model with better generalization capability to domains that have no labelled data. The method leverages the availability of labelled data in a different domain. The generator does the domain translation from the labelled domain to the unlabelled domain and simultaneously, the segmentation model learns using the generated data while regularizing the generative model. We compared our method with state-of-the-art methods and showed its generalizability on publicly available datasets and on our own recorded video frames from robot-assisted prostatectomies. Our method shows consistently high mean Dice scores on both labelled and unlabelled domains when data is available only for one of the domains. Link to paper https://doi.org/10.1007/978-3-030-87202-1_39 Link to the code repository https://github.com/tajwarabraraleef/coSegGAN Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper the authors propose a surgical instrument segmentation framework that includes an Image-to-Image translation method to address the lack of clinical labeled data. In this way, it is thus possible to train a segmentation model with labeled data from different domains. The generative network is based on cycleGan and the segmentation model is based on U-Net. A shape constraint is included to avoid changes of the surgical instruments. The results achieved outperform state-of-the-art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. When clinical data are not available, it is common to use translated labels, which are generated from other domains, to train a segmentation model. The novelty in the paper is the way the framework is trained. The generative and the segmentation models are trained together; so that, the quality of both models increases simultaneously. Focal loss function and structural loss are incorporated to improve accuracy. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Only Dice Index is reported. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Implementation details are given. It seems code and data will be available after the acceptance of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper in general is well written and the proposal is clearly presented. I missed that only Dice Index is reported. Usually Intersection-Over-Union (IoU) and area-under-the curve (AUC) are also included. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses segmentation of surgical instruments with no labeled data. They propose to translate labels from a different domain, while avoiding changes in the surgical instruments. The results achieved state-of-the-art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper combines cycleGAN, structural loss, and segmentation module to solve the problem of generalizing surgical instrument segmentation to unlabelled data. Experimental results demonstrate that the proposed method achieves good results on several datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Well motivated problem and real datasets Good results Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Limited novelty. As far as I understand, this paper is a merely combination of existing techniques: cycleGAN, structural loss, and segmentation module. It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper is rather clear. The authors also intend to release their code. Therefore, I believe one can reproduce the results with some minor efforts. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please address the novelty problem and why the failure case does not work. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? limited novelty of the paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors present a method for segmentation of Surgical Instruments on Unlabelled Data. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors present a novel method that outperforms state-of-the-art algorithms for the segmentation of unlabeled data. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. It will be interesting to understand why UCL data was associated with less generability. No major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Clear and easy to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It will be interesting to see an in-depth investigation regarding the results. Please report the SD in addition to the mean. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This is a very impressive result considering no labelled data. The authors incorporate a generative model to translate the train-set image domain to another one and then used the train-image domain to segment the images. This is a nice and creative idea that facilitates the segmentation of unlabeled endoscopic surgeries. It is the best work in my set of papers. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposed a surgical instrument segmentation method that utilises cycleGAN, focal loss and structural loss to solve the unlabelled clinical data problem. The paper is well-written, the experimentation is thorough and convincing. Reviewers comments must be addressed in the camera ready including highlighting the novelty, failure case discussion and addition of IoU metric. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback *The paper has limited novelty. As far as I understand, this paper is merely a combination of existing techniques: cycleGAN, structural loss, and segmentation module. We disagree with the reviewer. The novelty and main contribution of the paper is presenting a framework where each of these individual components work jointly to segment surgical instruments on videos from real surgeries without labels. Indeed, our framework consists of a combination of generative and segmentation modules, but the particular combination is not obvious. Moreover, we have shown in the paper that neither of these modules produce good results, when used individually. In fact, we have shown that when cycleGAN is used alone for data augmentation to go from non-surgical (with labeled images) to surgical domain (no labels), the model does not generalize well to the surgical domain (Table 1). This is the case with all state-of-the-art (SOTA) methods that are trained on the data, using cycleGAN augmentation alone (Table 1). Here, we would like to highlight another major challenge in unsupervised image-to-image (I2I) mapping techniques (such as cycleGAN), i.e., the change of shape of objects during the domain translation. This problem has been shown in Fig 1. This shortcoming limits the use of any such I2I mapping method, specially in medical and surgical applications. Our framework mitigates these two major challenges in the field, by jointly training generative and segmentation modules in an alternative fashion (details can be seen in Figure 2). The segmentation module provides feedback to the generator thus preventing the change of shapes of the surgical instruments during the translation. Simultaneously, the segmentation module learns using generated data from the generator, thus seeing much more varied data. To provide an additional shape constraint on the latent space we introduce a structural loss. We show that our model consistently achieves significantly better results on both the non-surgical (with labels) and surgical domain (with no labels) (with a delta Dice (less the better) of 0.9%, as opposed to 33%, 10% and 5% in U-Net, RASnet and Ternausnet, respectively). This validates our method’s generalizability when compared to the SOTA. *It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Yes, although the images in columns 2 and 4 look similar, they have a crucial difference. In column 4, in the region of failure, the presence of blood on the surgical instrument blends in with the background. In addition to this, this portion of the tool is very close to the edge of the endoscopic camera image, which is not well lit and creates a vignetting effect. This could be one the reasons for the poor segmentation in this region. Please note though, our model generalizes better than others, producing consistently good segmentation and fewer false positives across all four surgeries. It could be the case that the model tries to strike a trade-off where it generalizes better at the expense of slightly higher segmentation error in some cases. *The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Delta Dice decreases (less the better) with structural loss from 1.8% to 0.9% and from 19.0% to 16.8 % in cases where the target domain is human surgeries. We argue that although quantitatively this absolute difference in improvement seems small, it is essential. The numbers alone might not give a true picture here. Preserving small structural details add marginally to the quantitative results. However, it is important to retain the correct structure of the surgical instrument. An example of such a detail can be seen in Fig 3, column 1, row1. back to top" />
<meta property="og:description" content="Paper Info Reviews Meta-review(s) Author Feedback Authors Megha Kalia, Tajwar Abrar Aleef, Nassir Navab, Peter Black, Septimiu E. Salcudean Abstract Surgical instrument segmentation for robot-assisted surgery is needed for accurate instrument tracking and augmented reality overlays. Therefore, the topic has been the subject of a number of recent papers in the CAI community. Deep learning-based methods have shown state-of-the-art performance for surgical instrument segmentation, but their results depend on labelled data. However, labelled surgical data is of limited availability and is a bottleneck in surgical translation of these methods. In this paper, we demonstrate the limited generalizability of these methods on different datasets, including robot-assisted surgeries on human subjects. We then propose a novel joint generation and segmentation strategy to learn a segmentation model with better generalization capability to domains that have no labelled data. The method leverages the availability of labelled data in a different domain. The generator does the domain translation from the labelled domain to the unlabelled domain and simultaneously, the segmentation model learns using the generated data while regularizing the generative model. We compared our method with state-of-the-art methods and showed its generalizability on publicly available datasets and on our own recorded video frames from robot-assisted prostatectomies. Our method shows consistently high mean Dice scores on both labelled and unlabelled domains when data is available only for one of the domains. Link to paper https://doi.org/10.1007/978-3-030-87202-1_39 Link to the code repository https://github.com/tajwarabraraleef/coSegGAN Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper the authors propose a surgical instrument segmentation framework that includes an Image-to-Image translation method to address the lack of clinical labeled data. In this way, it is thus possible to train a segmentation model with labeled data from different domains. The generative network is based on cycleGan and the segmentation model is based on U-Net. A shape constraint is included to avoid changes of the surgical instruments. The results achieved outperform state-of-the-art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. When clinical data are not available, it is common to use translated labels, which are generated from other domains, to train a segmentation model. The novelty in the paper is the way the framework is trained. The generative and the segmentation models are trained together; so that, the quality of both models increases simultaneously. Focal loss function and structural loss are incorporated to improve accuracy. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Only Dice Index is reported. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Implementation details are given. It seems code and data will be available after the acceptance of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper in general is well written and the proposal is clearly presented. I missed that only Dice Index is reported. Usually Intersection-Over-Union (IoU) and area-under-the curve (AUC) are also included. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses segmentation of surgical instruments with no labeled data. They propose to translate labels from a different domain, while avoiding changes in the surgical instruments. The results achieved state-of-the-art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper combines cycleGAN, structural loss, and segmentation module to solve the problem of generalizing surgical instrument segmentation to unlabelled data. Experimental results demonstrate that the proposed method achieves good results on several datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Well motivated problem and real datasets Good results Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Limited novelty. As far as I understand, this paper is a merely combination of existing techniques: cycleGAN, structural loss, and segmentation module. It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper is rather clear. The authors also intend to release their code. Therefore, I believe one can reproduce the results with some minor efforts. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please address the novelty problem and why the failure case does not work. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? limited novelty of the paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors present a method for segmentation of Surgical Instruments on Unlabelled Data. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors present a novel method that outperforms state-of-the-art algorithms for the segmentation of unlabeled data. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. It will be interesting to understand why UCL data was associated with less generability. No major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Clear and easy to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It will be interesting to see an in-depth investigation regarding the results. Please report the SD in addition to the mean. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This is a very impressive result considering no labelled data. The authors incorporate a generative model to translate the train-set image domain to another one and then used the train-image domain to segment the images. This is a nice and creative idea that facilitates the segmentation of unlabeled endoscopic surgeries. It is the best work in my set of papers. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposed a surgical instrument segmentation method that utilises cycleGAN, focal loss and structural loss to solve the unlabelled clinical data problem. The paper is well-written, the experimentation is thorough and convincing. Reviewers comments must be addressed in the camera ready including highlighting the novelty, failure case discussion and addition of IoU metric. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback *The paper has limited novelty. As far as I understand, this paper is merely a combination of existing techniques: cycleGAN, structural loss, and segmentation module. We disagree with the reviewer. The novelty and main contribution of the paper is presenting a framework where each of these individual components work jointly to segment surgical instruments on videos from real surgeries without labels. Indeed, our framework consists of a combination of generative and segmentation modules, but the particular combination is not obvious. Moreover, we have shown in the paper that neither of these modules produce good results, when used individually. In fact, we have shown that when cycleGAN is used alone for data augmentation to go from non-surgical (with labeled images) to surgical domain (no labels), the model does not generalize well to the surgical domain (Table 1). This is the case with all state-of-the-art (SOTA) methods that are trained on the data, using cycleGAN augmentation alone (Table 1). Here, we would like to highlight another major challenge in unsupervised image-to-image (I2I) mapping techniques (such as cycleGAN), i.e., the change of shape of objects during the domain translation. This problem has been shown in Fig 1. This shortcoming limits the use of any such I2I mapping method, specially in medical and surgical applications. Our framework mitigates these two major challenges in the field, by jointly training generative and segmentation modules in an alternative fashion (details can be seen in Figure 2). The segmentation module provides feedback to the generator thus preventing the change of shapes of the surgical instruments during the translation. Simultaneously, the segmentation module learns using generated data from the generator, thus seeing much more varied data. To provide an additional shape constraint on the latent space we introduce a structural loss. We show that our model consistently achieves significantly better results on both the non-surgical (with labels) and surgical domain (with no labels) (with a delta Dice (less the better) of 0.9%, as opposed to 33%, 10% and 5% in U-Net, RASnet and Ternausnet, respectively). This validates our method’s generalizability when compared to the SOTA. *It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Yes, although the images in columns 2 and 4 look similar, they have a crucial difference. In column 4, in the region of failure, the presence of blood on the surgical instrument blends in with the background. In addition to this, this portion of the tool is very close to the edge of the endoscopic camera image, which is not well lit and creates a vignetting effect. This could be one the reasons for the poor segmentation in this region. Please note though, our model generalizes better than others, producing consistently good segmentation and fewer false positives across all four surgeries. It could be the case that the model tries to strike a trade-off where it generalizes better at the expense of slightly higher segmentation error in some cases. *The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Delta Dice decreases (less the better) with structural loss from 1.8% to 0.9% and from 19.0% to 16.8 % in cases where the target domain is human surgeries. We argue that although quantitatively this absolute difference in improvement seems small, it is essential. The numbers alone might not give a true picture here. Preserving small structural details add marginally to the quantitative results. However, it is important to retain the correct structure of the surgical instrument. An example of such a detail can be seen in Fig 3, column 1, row1. back to top" />
<link rel="canonical" href="https://kittywong.github.io/kittywong/0438/12/31/Paper2511" />
<meta property="og:url" content="https://kittywong.github.io/kittywong/0438/12/31/Paper2511" />
<meta property="og:site_name" content="MICCAI 2021 - Accepted Papers and Reviews" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="0438-12-31T23:58:56-05:17" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Co-Generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://kittywong.github.io/kittywong/0438/12/31/Paper2511"},"@type":"BlogPosting","url":"https://kittywong.github.io/kittywong/0438/12/31/Paper2511","headline":"Co-Generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data","dateModified":"0439-01-02T00:00:00-05:17","datePublished":"0438-12-31T23:58:56-05:17","description":"Paper Info Reviews Meta-review(s) Author Feedback Authors Megha Kalia, Tajwar Abrar Aleef, Nassir Navab, Peter Black, Septimiu E. Salcudean Abstract Surgical instrument segmentation for robot-assisted surgery is needed for accurate instrument tracking and augmented reality overlays. Therefore, the topic has been the subject of a number of recent papers in the CAI community. Deep learning-based methods have shown state-of-the-art performance for surgical instrument segmentation, but their results depend on labelled data. However, labelled surgical data is of limited availability and is a bottleneck in surgical translation of these methods. In this paper, we demonstrate the limited generalizability of these methods on different datasets, including robot-assisted surgeries on human subjects. We then propose a novel joint generation and segmentation strategy to learn a segmentation model with better generalization capability to domains that have no labelled data. The method leverages the availability of labelled data in a different domain. The generator does the domain translation from the labelled domain to the unlabelled domain and simultaneously, the segmentation model learns using the generated data while regularizing the generative model. We compared our method with state-of-the-art methods and showed its generalizability on publicly available datasets and on our own recorded video frames from robot-assisted prostatectomies. Our method shows consistently high mean Dice scores on both labelled and unlabelled domains when data is available only for one of the domains. Link to paper https://doi.org/10.1007/978-3-030-87202-1_39 Link to the code repository https://github.com/tajwarabraraleef/coSegGAN Link to the dataset(s) N/A Reviews Review #1 Please describe the contribution of the paper In this paper the authors propose a surgical instrument segmentation framework that includes an Image-to-Image translation method to address the lack of clinical labeled data. In this way, it is thus possible to train a segmentation model with labeled data from different domains. The generative network is based on cycleGan and the segmentation model is based on U-Net. A shape constraint is included to avoid changes of the surgical instruments. The results achieved outperform state-of-the-art methods. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. When clinical data are not available, it is common to use translated labels, which are generated from other domains, to train a segmentation model. The novelty in the paper is the way the framework is trained. The generative and the segmentation models are trained together; so that, the quality of both models increases simultaneously. Focal loss function and structural loss are incorporated to improve accuracy. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Only Dice Index is reported. Please rate the clarity and organization of this paper Very Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Implementation details are given. It seems code and data will be available after the acceptance of the paper. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html The paper in general is well written and the proposal is clearly presented. I missed that only Dice Index is reported. Usually Intersection-Over-Union (IoU) and area-under-the curve (AUC) are also included. Please state your overall opinion of the paper strong accept (9) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? The paper addresses segmentation of surgical instruments with no labeled data. They propose to translate labels from a different domain, while avoiding changes in the surgical instruments. The results achieved state-of-the-art methods. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 2 Reviewer confidence Confident but not absolutely certain Review #2 Please describe the contribution of the paper This paper combines cycleGAN, structural loss, and segmentation module to solve the problem of generalizing surgical instrument segmentation to unlabelled data. Experimental results demonstrate that the proposed method achieves good results on several datasets. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. Well motivated problem and real datasets Good results Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. Limited novelty. As far as I understand, this paper is a merely combination of existing techniques: cycleGAN, structural loss, and segmentation module. It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Please rate the clarity and organization of this paper Good Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance The paper is rather clear. The authors also intend to release their code. Therefore, I believe one can reproduce the results with some minor efforts. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html Please address the novelty problem and why the failure case does not work. Please state your overall opinion of the paper borderline reject (5) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? limited novelty of the paper. What is the ranking of this paper in your review stack? 2 Number of papers in your stack 2 Reviewer confidence Very confident Review #3 Please describe the contribution of the paper The authors present a method for segmentation of Surgical Instruments on Unlabelled Data. Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting. The authors present a novel method that outperforms state-of-the-art algorithms for the segmentation of unlabeled data. Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work. It will be interesting to understand why UCL data was associated with less generability. No major weakness. Please rate the clarity and organization of this paper Excellent Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance Clear and easy to reproduce. Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: https://miccai2021.org/en/REVIEWER-GUIDELINES.html It will be interesting to see an in-depth investigation regarding the results. Please report the SD in addition to the mean. Please state your overall opinion of the paper accept (8) Please justify your recommendation. What were the major factors that led you to your overall score for this paper? This is a very impressive result considering no labelled data. The authors incorporate a generative model to translate the train-set image domain to another one and then used the train-image domain to segment the images. This is a nice and creative idea that facilitates the segmentation of unlabeled endoscopic surgeries. It is the best work in my set of papers. What is the ranking of this paper in your review stack? 1 Number of papers in your stack 5 Reviewer confidence Confident but not absolutely certain Meta-Review(s) Primary Meta-Review Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal. The paper proposed a surgical instrument segmentation method that utilises cycleGAN, focal loss and structural loss to solve the unlabelled clinical data problem. The paper is well-written, the experimentation is thorough and convincing. Reviewers comments must be addressed in the camera ready including highlighting the novelty, failure case discussion and addition of IoU metric. What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers). 2 Author Feedback *The paper has limited novelty. As far as I understand, this paper is merely a combination of existing techniques: cycleGAN, structural loss, and segmentation module. We disagree with the reviewer. The novelty and main contribution of the paper is presenting a framework where each of these individual components work jointly to segment surgical instruments on videos from real surgeries without labels. Indeed, our framework consists of a combination of generative and segmentation modules, but the particular combination is not obvious. Moreover, we have shown in the paper that neither of these modules produce good results, when used individually. In fact, we have shown that when cycleGAN is used alone for data augmentation to go from non-surgical (with labeled images) to surgical domain (no labels), the model does not generalize well to the surgical domain (Table 1). This is the case with all state-of-the-art (SOTA) methods that are trained on the data, using cycleGAN augmentation alone (Table 1). Here, we would like to highlight another major challenge in unsupervised image-to-image (I2I) mapping techniques (such as cycleGAN), i.e., the change of shape of objects during the domain translation. This problem has been shown in Fig 1. This shortcoming limits the use of any such I2I mapping method, specially in medical and surgical applications. Our framework mitigates these two major challenges in the field, by jointly training generative and segmentation modules in an alternative fashion (details can be seen in Figure 2). The segmentation module provides feedback to the generator thus preventing the change of shapes of the surgical instruments during the translation. Simultaneously, the segmentation module learns using generated data from the generator, thus seeing much more varied data. To provide an additional shape constraint on the latent space we introduce a structural loss. We show that our model consistently achieves significantly better results on both the non-surgical (with labels) and surgical domain (with no labels) (with a delta Dice (less the better) of 0.9%, as opposed to 33%, 10% and 5% in U-Net, RASnet and Ternausnet, respectively). This validates our method’s generalizability when compared to the SOTA. *It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear. Yes, although the images in columns 2 and 4 look similar, they have a crucial difference. In column 4, in the region of failure, the presence of blood on the surgical instrument blends in with the background. In addition to this, this portion of the tool is very close to the edge of the endoscopic camera image, which is not well lit and creates a vignetting effect. This could be one the reasons for the poor segmentation in this region. Please note though, our model generalizes better than others, producing consistently good segmentation and fewer false positives across all four surgeries. It could be the case that the model tries to strike a trade-off where it generalizes better at the expense of slightly higher segmentation error in some cases. *The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. Delta Dice decreases (less the better) with structural loss from 1.8% to 0.9% and from 19.0% to 16.8 % in cases where the target domain is human surgeries. We argue that although quantitatively this absolute difference in improvement seems small, it is essential. The numbers alone might not give a true picture here. Preserving small structural details add marginally to the quantitative results. However, it is important to retain the correct structure of the surgical instrument. An example of such a detail can be seen in Fig 3, column 1, row1. back to top","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<meta
  name="keywords"
  content="Kalia, Megha,Aleef, Tajwar Abrar,Navab, Nassir,Black, Peter,Salcudean, Septimiu E." />

<link rel="shortcut icon" href="/favicon.ico" />
<link rel="apple-touch-icon" href="/favicon.ico" />
<link
  rel="alternate"
  type="application/rss+xml"
  title="MICCAI 2021 - Accepted Papers and Reviews - "
  href="kittywong/feed.xml" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/base.css" />
<link
  rel="stylesheet"
  type="text/css"
  href="kittywong/assets/css/highlight.css" />

<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->


<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  async>
</script>


<script src="/assets/scripts/jekyllpaper.js" async></script>
<script
  src="https://unpkg.com/mermaid@8.5.1/dist/mermaid.min.js"
  onload="javascript:loadMermaid();"
  async>
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
      displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
    //,
    //displayAlign: "left",
    //displayIndent: "2em"
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head>
  <body>
    <div class="container-wrapper">
      <header class="container-header">
        <div class="header-info">
  <!-- Added by Elvis Chen -->
  <img src="https://kittywong.github.io/assets/images/miccai2021header.jpg" alt="MICCAI banner">
  <!-- END Added by Elvis Chen -->
  <span class="header-info-name">MICCAI 2021 - Accepted Papers and Reviews</span>
  <span class="header-info-desc"></span>
</div>
<nav class="header-nav">
  <ul class="header-main-nav">
    <h2>
    
    <li class="header-main-nav-item">
      <a href="kittywong/">
        
          <b>List of Papers</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/categories">
        
          <b>By topics</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/tags">
        
          <b>Author List</b>
        
      </a>
    </li>
      
    <li class="header-main-nav-item">
      <a href="kittywong/about">
        
          <b>About</b>
        
      </a>
    </li>
      
    </h2>
  </ul>
</nav>
      </header>
      <main class="container-main">
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<article class="container-post">
  <div class="post-title">
    <h1><span style="color:#1040a7"><b>Co-Generation and Segmentation for Generalized Surgical Instrument Segmentation on Unlabelled Data</b></span></h1>
  </div>
  
  <div class="post-author print-post-author">
    <span>Kitty K. Wong</span>
  </div>
  <hr>
    
   
  <div class="post-content">
    <!--
    <div class="post-categories">
      <h2><span style="color:#1040a7">Paper Topic(s):</span></h2> 
      
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a>
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a>
      
    
    </div>
    <div class="post-tags">
      
      <h2><span style="color:#1040a7">Author(s):</span></h2> 
      
      <a href="kittywong/tags#Kalia, Megha"
        class="post-tags">
        Kalia, Megha
      </a> |  
      
      <a href="kittywong/tags#Aleef, Tajwar Abrar"
        class="post-tags">
        Aleef, Tajwar Abrar
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-tags">
        Navab, Nassir
      </a> |  
      
      <a href="kittywong/tags#Black, Peter"
        class="post-tags">
        Black, Peter
      </a> |  
      
      <a href="kittywong/tags#Salcudean, Septimiu E."
        class="post-tags">
        Salcudean, Septimiu E.
      </a> |  
      
    </div>
  -->
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>

    .sidenav {
      width: 200px;
      position: fixed;
      z-index: 1;
      top: 150px;
      left: 50px;
      background: #eee;
      overflow-x: hidden;
      padding: 0px 0;
    }
  
    .sidenav a {
      padding: 6px 8px 6px 16px;
      text-decoration: none;
      font-size: 16px;
      color: #2196F3;
      color: #FF4500;
      display: block;
    }
  
    .sidenav a:hover {
      color: #064579;
    }
    </style>
  </head>

  <div class="sidenav">
    <a href="#author-id">Paper Info</a>
    <a href="#review-id">Reviews</a>
    <a href="#metareview-id">Meta-Review(s)</a>
    <a href="#authorFeedback-id">Author Feedback</a>
    <a href="">Back to top</a>
    <a href="https://kittywong.github.io">Back to List of papers</a>
  </div>

    <table>
  <tbody>
    <tr>
      <td><a href="#author-id"><span style="color:#ff9900"><b>Paper Info</b></span></a></td>
      <td><a href="#review-id"><span style="color:#ff9900"><b>Reviews</b></span></a></td>
      <td><a href="#metareview-id"><span style="color:#ff9900"><b>Meta-review(s)</b></span></a></td>
      <td><a href="#authorFeedback-id"><span style="color:#ff9900"><b>Author Feedback</b></span></a></td>
    </tr>
  </tbody>
</table>

<h1 id="author-id">Authors</h1>
<p>Megha Kalia, Tajwar Abrar Aleef, Nassir Navab, Peter Black, Septimiu E. Salcudean
<br /><br /></p>

<h1 id="abstract-id">Abstract</h1>
<p>Surgical instrument segmentation for robot-assisted surgery is needed for accurate instrument tracking and augmented reality overlays. Therefore, the topic has been the subject of a number of recent papers in the CAI community. Deep learning-based methods have shown state-of-the-art performance for surgical instrument segmentation, but their results depend on labelled data. However, labelled surgical data is of limited availability and is a bottleneck in surgical translation of these methods. In this paper, we demonstrate the limited generalizability of these methods on different datasets, including robot-assisted surgeries on human subjects. We then propose a novel joint generation and segmentation strategy to learn a segmentation model with better generalization capability to domains that have no labelled data. The method leverages the availability of labelled data in a different domain. The generator does the domain translation from the labelled domain to the unlabelled domain and simultaneously, the segmentation model learns using the generated data while regularizing the generative model. 
We compared our method with state-of-the-art methods and showed its generalizability on publicly available datasets and on our own recorded video frames from robot-assisted prostatectomies. Our method shows consistently high mean Dice scores on both labelled and unlabelled domains when data is available only for one of the domains.
<br /><br /></p>

<h1 id="link-id">Link to paper</h1>
<p><a href="https://doi.org/10.1007/978-3-030-87202-1_39">https://doi.org/10.1007/978-3-030-87202-1_39</a>
<br /><br /></p>

<h1 id="code-id">Link to the code repository</h1>
<p>https://github.com/tajwarabraraleef/coSegGAN
<br /><br /></p>

<h1 id="dataset-id">Link to the dataset(s)</h1>
<p>N/A
<br /><br /></p>

<hr />
<h1 id="review-id">Reviews</h1>

<h3 id="review-1">Review #1</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>In this paper the authors propose a surgical instrument segmentation framework that includes an Image-to-Image translation method to address the lack of clinical labeled data. In this way, it is thus possible to train a segmentation model with labeled data from different domains. The generative network is based on cycleGan and the segmentation model is based on U-Net. A shape constraint is included to avoid changes of the surgical instruments. The results achieved outperform state-of-the-art methods.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>When clinical data are not available, it is common to use translated labels, which are generated from other domains, to train a segmentation model. The novelty in the paper is the way the framework is trained. The generative and the segmentation models are trained together; so that, the quality of both models increases simultaneously. Focal loss function and structural loss are incorporated to improve accuracy.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal. 
Only Dice Index is reported.</p>

    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Very Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Implementation details are given. It seems code and data will be available after the acceptance of the paper.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>The paper in general is well written and the proposal is clearly presented.
I missed that only Dice Index is reported. Usually Intersection-Over-Union (IoU) and area-under-the curve (AUC) are also included.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>strong accept (9)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>The paper addresses segmentation of surgical instruments with no labeled data. They propose to translate labels from a different domain, while avoiding changes in the surgical instruments. The results achieved state-of-the-art methods.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-2">Review #2</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>This paper combines cycleGAN, structural loss, and segmentation module to solve the problem of generalizing surgical instrument segmentation to unlabelled data. Experimental results demonstrate that the proposed method achieves good results on several datasets.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <ul>
        <li>Well motivated problem and real datasets</li>
        <li>Good results</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <ul>
        <li>Limited novelty. As far as I understand, this paper is a merely combination of existing techniques:  cycleGAN, structural loss, and segmentation module.</li>
        <li>It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear.</li>
      </ul>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Good</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>The paper is rather clear. The authors also intend to release their code. Therefore, I believe one can reproduce the results with some minor efforts.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>Please address the novelty problem and why the failure case does not work.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>borderline reject (5)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>limited novelty of the paper.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Very confident</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<h3 id="review-3">Review #3</h3>

<ul>
  <li><strong>Please describe the contribution of the paper</strong>
    <blockquote>
      <p>The authors present a method for segmentation of Surgical Instruments on Unlabelled Data.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main strengths of the paper; you should write about a novel formulation, an original way to use data, demonstration of clinical feasibility, a novel application, a particularly strong evaluation, or anything else that is a strong aspect of this work. Please provide details, for instance, if a method is novel, explain what aspect is novel and why this is interesting.</strong>
    <blockquote>
      <p>The authors present a novel method that outperforms state-of-the-art algorithms for the segmentation of unlabeled data.</p>
    </blockquote>
  </li>
  <li><strong>Please list the main weaknesses of the paper. Please provide details, for instance, if you think a method is not novel, explain why and provide a reference to prior work.</strong>
    <blockquote>
      <p>It will be interesting to understand why UCL data was associated with less generability. No major weakness.</p>
    </blockquote>
  </li>
  <li><strong>Please rate the clarity and organization of this paper</strong>
    <blockquote>
      <p>Excellent</p>
    </blockquote>
  </li>
  <li><strong>Please comment on the reproducibility of the paper. Note, that authors have filled out a reproducibility checklist upon submission. Please be aware that authors are not required to meet all criteria on the checklist - for instance, providing code and data is a plus, but not a requirement for acceptance</strong>
    <blockquote>
      <p>Clear and easy to reproduce.</p>
    </blockquote>
  </li>
  <li><strong>Please provide detailed and constructive comments for the authors. Please also refer to our Reviewer’s guide on what makes a good review: <a href="https://miccai2021.org/en/REVIEWER-GUIDELINES.html">https://miccai2021.org/en/REVIEWER-GUIDELINES.html</a></strong>
    <blockquote>
      <p>It will be interesting to see an in-depth investigation regarding the results.
Please report the SD in addition to the mean.</p>
    </blockquote>
  </li>
  <li><strong>Please state your overall opinion of the paper</strong>
    <blockquote>
      <p>accept (8)</p>
    </blockquote>
  </li>
  <li><strong>Please justify your recommendation. What were the major factors that led you to your overall score for this paper?</strong>
    <blockquote>
      <p>This is a very impressive result considering no labelled data. The authors incorporate a generative model to translate the train-set image domain to another one and then used the train-image domain to segment the images. This is a nice and creative idea that facilitates the segmentation of unlabeled endoscopic surgeries. It is the best work in my set of papers.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your review stack?</strong>
    <blockquote>
      <p>1</p>
    </blockquote>
  </li>
  <li><strong>Number of papers in your stack</strong>
    <blockquote>
      <p>5</p>
    </blockquote>
  </li>
  <li><strong>Reviewer confidence</strong>
    <blockquote>
      <p>Confident but not absolutely certain</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="metareview-id">Meta-Review(s)</h1>

<h2 id="primary-meta-review">Primary Meta-Review</h2>
<ul>
  <li><strong>Please provide your assessment of this work, taking into account all reviews. Summarize the key strengths and weaknesses of the paper and justify your recommendation. In case you deviate from the reviewers’ recommendations, explain in detail the reasons why. In case of an invitation for rebuttal, clarify which points are important to address in the rebuttal.</strong>
    <blockquote>
      <p>The paper proposed a surgical instrument segmentation method that utilises cycleGAN, focal loss and structural loss to solve the unlabelled clinical data problem. The paper is well-written, the experimentation is thorough and convincing. Reviewers comments must be addressed in the camera ready including highlighting the novelty, failure case discussion and addition of IoU metric.</p>
    </blockquote>
  </li>
  <li><strong>What is the ranking of this paper in your stack? Use a number between 1 (best paper in your stack) and n (worst paper in your stack of n papers).</strong>
    <blockquote>
      <p>2</p>
    </blockquote>
  </li>
</ul>

<p><br /><br /></p>

<hr />
<h1 id="authorFeedback-id">Author Feedback</h1>
<blockquote>
  <p>*The paper has limited novelty. As far as I understand, this paper is merely a combination of existing techniques: cycleGAN, structural loss, and segmentation module.</p>

  <p>We disagree with the reviewer. The novelty and main contribution of the paper is presenting a framework where each of these individual components work jointly to segment surgical instruments on videos from real surgeries without labels. Indeed, our framework consists of a combination of generative and segmentation modules, but the particular combination is not obvious. Moreover, we have shown in the paper that neither of these modules produce good results, when used individually. In fact, we have shown that when cycleGAN is used alone for data augmentation to go from non-surgical (with labeled images) to surgical domain (no labels), the model does not generalize well to the surgical domain (Table 1). This is the case with all state-of-the-art (SOTA) methods that are trained on the data, using cycleGAN augmentation alone (Table 1). Here, we would like to highlight another major challenge in unsupervised image-to-image (I2I) mapping techniques (such as cycleGAN), i.e., the change of shape of objects during the domain translation. This problem has been shown in Fig 1. This shortcoming limits the use of any such I2I mapping method, specially in medical and surgical applications. 
Our framework mitigates these two major challenges in the field, by jointly training generative and segmentation modules in an alternative fashion (details can be seen in Figure 2). The segmentation module provides feedback to the generator thus preventing the change of shapes of the surgical instruments during the translation. Simultaneously, the segmentation module learns using generated data from the generator, thus seeing much more varied data. To provide an additional shape constraint on the latent space we introduce a structural loss. We show that our model consistently achieves significantly better results on both the non-surgical (with labels) and surgical domain (with no labels) (with a delta Dice (less the better) of 0.9%, as opposed to 33%, 10% and 5% in U-Net, RASnet and Ternausnet, respectively). This validates our method’s generalizability when compared to the SOTA.</p>

  <p>*It is very nice to show a failure case. Yet, why it fails, the failure case on the right column of Fig. 3 is very similar with the case of the second column in Fig. 3. Why it fails is not clear.</p>

  <p>Yes, although the images in columns 2 and 4 look similar, they have a crucial difference. In column 4, in the region of failure, the presence of blood on the surgical instrument blends in with the background. In addition to this, this portion of the tool is very close to the edge of the endoscopic camera image, which is not well lit and creates a vignetting effect. This could be one the reasons for the poor segmentation in this region. 
Please note though, our model generalizes better than others, producing consistently good segmentation and fewer false positives across all four surgeries. It could be the case that the model tries to strike a trade-off where it generalizes better at the expense of slightly higher segmentation error in some cases.</p>

  <p>*The authors added an explicit latent space loss to preserve structural properties of the final scene. Namely, the structural loss function avoids changes on the surgical instruments. However, its impact is marginal.</p>

  <p>Delta Dice decreases (less the better) with structural loss from 1.8% to 0.9% and from 19.0% to 16.8 % in cases where the target domain is human surgeries. We argue that although quantitatively this absolute difference in improvement seems small, it is essential. The numbers alone might not give a true picture here. Preserving small structural details add marginally to the quantitative results. However, it is important to retain the correct structure of the surgical instrument. An example of such a detail can be seen in Fig 3, column 1, row1.</p>

</blockquote>

<p><br /><br />
<a href=""><span style="color:#ff9900"><b>back to top</b></span></a></p>

<hr />


  </div>

  <div class="post-info">
    <!--
    <div class="post-date">
      Poster presentation date:  
      0438-12-31
      -->
      <!--
      
        ,
        updated at 
        0439-01-01
      
      .
      
    </div>
    -->
    <!--
    
    <div class="post-author">
      Author: Kitty K. Wong
    </div>
    
    -->
    <div class="post-categories">
      <span><b>Topic(s): </b></span>
      
      <a 
        href="kittywong/categories#Image Segmentation"
        class="post-category">
        Image Segmentation
      </a> |
      
      <a 
        href="kittywong/categories#Image-Guided Interventions and Surgery"
        class="post-category">
        Image-Guided Interventions and Surgery
      </a> |
      
    </div>
    <div class="post-tags">
      <!--<span>Author List</span>-->
      <span><b> Author(s): </b></span>
      
      <a href="kittywong/tags#Kalia, Megha"
        class="post-category">
        Kalia, Megha
      </a> |  
      
      <a href="kittywong/tags#Aleef, Tajwar Abrar"
        class="post-category">
        Aleef, Tajwar Abrar
      </a> |  
      
      <a href="kittywong/tags#Navab, Nassir"
        class="post-category">
        Navab, Nassir
      </a> |  
      
      <a href="kittywong/tags#Black, Peter"
        class="post-category">
        Black, Peter
      </a> |  
      
      <a href="kittywong/tags#Salcudean, Septimiu E."
        class="post-category">
        Salcudean, Septimiu E.
      </a> |  
      
    </div>
    <div class="post-other">
      
      <div>
        <span><b>
          Next paper: 
        </b>
        </span>
        <a href="/0439/12/31/Paper0151">
          E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with Transformer-based Stereoscopic Depth Perception
        </a>
      </div>
      
      
      <div>
        <span><b>
          Previous paper: 
        </b>
        </span>
        <a href="/0437/12/31/Paper2510">
          hSDB-instrument: Instrument Localization Database for Laparoscopic and Robotic Surgeries
        </a>
      </div>
      
    </div>
    
  </div>
</article>

      </main>
      <footer class="container-footer">
        <div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. Kitty K. Wong, The MICCAI Society
  </span>
</div>
<!--
<div class="footer-copyright">
  <span class="footer-copyright-text float-left">
    Copyright &copy; 2021. example.com.
  </span>
  <span class="footer-copyright-text float-right">
    Powered by <a href="https://jekyllrb.com/">Jekyll</a>, themed by <a href="https://github.com/ghosind/Jekyll-Paper-Github">Jekyll-Paper-Github</a>.
  </span>
</div>
-->

      </footer>
    </div>
  </body>
</html>
